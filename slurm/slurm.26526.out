python keras_dn_simple_multigpu.py
python keras_dn_simple.py
python custom_gridsearch_dn_siamese.py
python custom_gs_dn_siamese_layers_multi.py -g 1
python custom_gridsearch_dn_siamese_layers_avg.py
python custom_gridsearch_dn_siamese_layers.py
Column names are nb_layers_per_block, growth_rate, nb_dense_block, nb_filter, dropout, lr, epochs, opt, reduction, bn, batch_size, pooling
['2-2', '12', '2', '16', '0.2', '0.07', '27', 'adadelta', '0.5', 'FALSE', '64', 'flatten']
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  27  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 12, 24, 24)   1728        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 12, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 28, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 28, 24, 24)   112         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 28, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 12, 24, 24)   3024        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 12, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 40, 24, 24)   160         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 20, 24, 24)   800         activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 20, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 20, 12, 12)   80          average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 20, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 12, 12, 12)   2160        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 12, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 32, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 32, 12, 12)   128         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 32, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 12, 12, 12)   3456        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 12, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 44, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 44, 12, 12)   176         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 44, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 6336)         0           activation_7[0][0]               
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            6337        flatten_1[0][0]                  
==================================================================================================
Total params: 19,857
Trainable params: 19,465
Non-trainable params: 392
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/27
 - 21s - loss: 0.5099 - acc: 0.7487 - val_loss: 0.4383 - val_acc: 0.8013
Epoch 2/27
 - 19s - loss: 0.4106 - acc: 0.8159 - val_loss: 0.4214 - val_acc: 0.8117
Epoch 3/27
 - 19s - loss: 0.3688 - acc: 0.8400 - val_loss: 0.3359 - val_acc: 0.8591
Epoch 4/27
 - 19s - loss: 0.3415 - acc: 0.8557 - val_loss: 0.3164 - val_acc: 0.8656
Epoch 5/27
 - 19s - loss: 0.3204 - acc: 0.8657 - val_loss: 0.2954 - val_acc: 0.8764
Epoch 6/27
 - 19s - loss: 0.3043 - acc: 0.8737 - val_loss: 0.2980 - val_acc: 0.8749
Epoch 7/27
 - 19s - loss: 0.2913 - acc: 0.8815 - val_loss: 0.2645 - val_acc: 0.8933
Epoch 8/27
 - 19s - loss: 0.2779 - acc: 0.8870 - val_loss: 0.2883 - val_acc: 0.8740
Epoch 9/27
 - 19s - loss: 0.2661 - acc: 0.8926 - val_loss: 0.2461 - val_acc: 0.9017
Epoch 10/27
 - 19s - loss: 0.2570 - acc: 0.8965 - val_loss: 0.2307 - val_acc: 0.9081
Epoch 11/27
 - 19s - loss: 0.2468 - acc: 0.9014 - val_loss: 0.2875 - val_acc: 0.8791
Epoch 12/27
 - 19s - loss: 0.2400 - acc: 0.9057 - val_loss: 0.2244 - val_acc: 0.9103
Epoch 13/27
 - 19s - loss: 0.2320 - acc: 0.9086 - val_loss: 0.2091 - val_acc: 0.9167
Epoch 14/27
 - 19s - loss: 0.2245 - acc: 0.9124 - val_loss: 0.2010 - val_acc: 0.9212
Epoch 15/27
 - 19s - loss: 0.2191 - acc: 0.9146 - val_loss: 0.1931 - val_acc: 0.9272
Epoch 16/27
 - 19s - loss: 0.2129 - acc: 0.9185 - val_loss: 0.1863 - val_acc: 0.9297
Epoch 17/27
 - 19s - loss: 0.2092 - acc: 0.9198 - val_loss: 0.1783 - val_acc: 0.9332
Epoch 18/27
 - 19s - loss: 0.2017 - acc: 0.9235 - val_loss: 0.1751 - val_acc: 0.9307
Epoch 19/27
 - 19s - loss: 0.1969 - acc: 0.9262 - val_loss: 0.1760 - val_acc: 0.9352
Epoch 20/27
 - 19s - loss: 0.1912 - acc: 0.9281 - val_loss: 0.1645 - val_acc: 0.9401
Epoch 21/27
 - 19s - loss: 0.1885 - acc: 0.9290 - val_loss: 0.1635 - val_acc: 0.9395
Epoch 22/27
 - 19s - loss: 0.1837 - acc: 0.9308 - val_loss: 0.1557 - val_acc: 0.9421
Epoch 23/27
 - 19s - loss: 0.1788 - acc: 0.9338 - val_loss: 0.1518 - val_acc: 0.9439
Epoch 24/27
 - 19s - loss: 0.1798 - acc: 0.9331 - val_loss: 0.1472 - val_acc: 0.9488
Epoch 25/27
 - 19s - loss: 0.1744 - acc: 0.9353 - val_loss: 0.1476 - val_acc: 0.9501
Epoch 26/27
 - 19s - loss: 0.1702 - acc: 0.9367 - val_loss: 0.1594 - val_acc: 0.9378
Epoch 27/27
 - 19s - loss: 0.1655 - acc: 0.9391 - val_loss: 0.1371 - val_acc: 0.9502
Test accuracy:0.802
current auc_score ------------------> 0.916
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  27  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 12, 24, 24)   1728        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 12, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 28, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 28, 24, 24)   112         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 28, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 12, 24, 24)   3024        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 12, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 40, 24, 24)   160         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 20, 24, 24)   800         activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 20, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 20, 12, 12)   80          average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 20, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 12, 12, 12)   2160        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 12, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 32, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 32, 12, 12)   128         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 32, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 12, 12, 12)   3456        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 12, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 44, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 44, 12, 12)   176         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 44, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 6336)         0           activation_7[0][0]               
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            6337        flatten_1[0][0]                  
==================================================================================================
Total params: 19,857
Trainable params: 19,465
Non-trainable params: 392
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/27
 - 20s - loss: 0.5165 - acc: 0.7435 - val_loss: 0.4612 - val_acc: 0.7755
Epoch 2/27
 - 19s - loss: 0.4159 - acc: 0.8110 - val_loss: 0.3881 - val_acc: 0.8233
Epoch 3/27
 - 19s - loss: 0.3720 - acc: 0.8367 - val_loss: 0.3937 - val_acc: 0.8125
Epoch 4/27
 - 19s - loss: 0.3416 - acc: 0.8541 - val_loss: 0.3567 - val_acc: 0.8350
Epoch 5/27
 - 19s - loss: 0.3209 - acc: 0.8651 - val_loss: 0.3018 - val_acc: 0.8686
Epoch 6/27
 - 18s - loss: 0.3036 - acc: 0.8742 - val_loss: 0.3073 - val_acc: 0.8642
Epoch 7/27
 - 19s - loss: 0.2892 - acc: 0.8800 - val_loss: 0.2989 - val_acc: 0.8690
Epoch 8/27
 - 20s - loss: 0.2750 - acc: 0.8875 - val_loss: 0.2975 - val_acc: 0.8696
Epoch 9/27
 - 20s - loss: 0.2635 - acc: 0.8948 - val_loss: 0.2803 - val_acc: 0.8788
Epoch 10/27
 - 20s - loss: 0.2570 - acc: 0.8963 - val_loss: 0.2509 - val_acc: 0.8963
Epoch 11/27
 - 19s - loss: 0.2474 - acc: 0.9006 - val_loss: 0.2643 - val_acc: 0.8864
Epoch 12/27
 - 19s - loss: 0.2377 - acc: 0.9072 - val_loss: 0.2172 - val_acc: 0.9149
Epoch 13/27
 - 19s - loss: 0.2314 - acc: 0.9090 - val_loss: 0.2140 - val_acc: 0.9170
Epoch 14/27
 - 19s - loss: 0.2246 - acc: 0.9122 - val_loss: 0.2010 - val_acc: 0.9241
Epoch 15/27
 - 19s - loss: 0.2174 - acc: 0.9156 - val_loss: 0.1978 - val_acc: 0.9256
Epoch 16/27
 - 19s - loss: 0.2121 - acc: 0.9193 - val_loss: 0.1916 - val_acc: 0.9262
Epoch 17/27
 - 19s - loss: 0.2062 - acc: 0.9210 - val_loss: 0.1911 - val_acc: 0.9287
Epoch 18/27
 - 19s - loss: 0.1992 - acc: 0.9252 - val_loss: 0.1966 - val_acc: 0.9252
Epoch 19/27
 - 19s - loss: 0.1962 - acc: 0.9266 - val_loss: 0.1781 - val_acc: 0.9340
Epoch 20/27
 - 19s - loss: 0.1908 - acc: 0.9291 - val_loss: 0.1683 - val_acc: 0.9365
Epoch 21/27
 - 19s - loss: 0.1874 - acc: 0.9291 - val_loss: 0.1611 - val_acc: 0.9416
Epoch 22/27
 - 19s - loss: 0.1834 - acc: 0.9313 - val_loss: 0.1684 - val_acc: 0.9374
Epoch 23/27
 - 19s - loss: 0.1793 - acc: 0.9342 - val_loss: 0.1549 - val_acc: 0.9434
Epoch 24/27
 - 19s - loss: 0.1731 - acc: 0.9369 - val_loss: 0.1550 - val_acc: 0.9431
Epoch 25/27
 - 19s - loss: 0.1710 - acc: 0.9374 - val_loss: 0.1460 - val_acc: 0.9470
Epoch 26/27
 - 19s - loss: 0.1684 - acc: 0.9379 - val_loss: 0.1483 - val_acc: 0.9453
Epoch 27/27
 - 19s - loss: 0.1654 - acc: 0.9398 - val_loss: 0.1444 - val_acc: 0.9467
Test accuracy:0.828
current auc_score ------------------> 0.897
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  27  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 12, 24, 24)   1728        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 12, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 28, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 28, 24, 24)   112         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 28, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 12, 24, 24)   3024        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 12, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 40, 24, 24)   160         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 20, 24, 24)   800         activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 20, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 20, 12, 12)   80          average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 20, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 12, 12, 12)   2160        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 12, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 32, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 32, 12, 12)   128         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 32, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 12, 12, 12)   3456        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 12, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 44, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 44, 12, 12)   176         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 44, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 6336)         0           activation_7[0][0]               
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            6337        flatten_1[0][0]                  
==================================================================================================
Total params: 19,857
Trainable params: 19,465
Non-trainable params: 392
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/27
 - 21s - loss: 0.5038 - acc: 0.7505 - val_loss: 0.4187 - val_acc: 0.8031
Epoch 2/27
 - 19s - loss: 0.4048 - acc: 0.8148 - val_loss: 0.3642 - val_acc: 0.8358
Epoch 3/27
 - 19s - loss: 0.3630 - acc: 0.8385 - val_loss: 0.3308 - val_acc: 0.8529
Epoch 4/27
 - 19s - loss: 0.3364 - acc: 0.8550 - val_loss: 0.3047 - val_acc: 0.8706
Epoch 5/27
 - 19s - loss: 0.3147 - acc: 0.8652 - val_loss: 0.2986 - val_acc: 0.8690
Epoch 6/27
 - 19s - loss: 0.2980 - acc: 0.8722 - val_loss: 0.2755 - val_acc: 0.8844
Epoch 7/27
 - 19s - loss: 0.2859 - acc: 0.8806 - val_loss: 0.2594 - val_acc: 0.8953
Epoch 8/27
 - 19s - loss: 0.2721 - acc: 0.8887 - val_loss: 0.2468 - val_acc: 0.9031
Epoch 9/27
 - 19s - loss: 0.2609 - acc: 0.8940 - val_loss: 0.2366 - val_acc: 0.9090
Epoch 10/27
 - 19s - loss: 0.2535 - acc: 0.8996 - val_loss: 0.2309 - val_acc: 0.9115
Epoch 11/27
 - 19s - loss: 0.2426 - acc: 0.9033 - val_loss: 0.2134 - val_acc: 0.9179
Epoch 12/27
 - 19s - loss: 0.2349 - acc: 0.9077 - val_loss: 0.2112 - val_acc: 0.9194
Epoch 13/27
 - 19s - loss: 0.2289 - acc: 0.9086 - val_loss: 0.2121 - val_acc: 0.9185
Epoch 14/27
 - 19s - loss: 0.2207 - acc: 0.9130 - val_loss: 0.1988 - val_acc: 0.9222
Epoch 15/27
 - 19s - loss: 0.2149 - acc: 0.9168 - val_loss: 0.2079 - val_acc: 0.9212
Epoch 16/27
 - 19s - loss: 0.2096 - acc: 0.9188 - val_loss: 0.1790 - val_acc: 0.9344
Epoch 17/27
 - 19s - loss: 0.2047 - acc: 0.9218 - val_loss: 0.1905 - val_acc: 0.9260
Epoch 18/27
 - 19s - loss: 0.1987 - acc: 0.9241 - val_loss: 0.1701 - val_acc: 0.9384
Epoch 19/27
 - 19s - loss: 0.1939 - acc: 0.9259 - val_loss: 0.1702 - val_acc: 0.9400
Epoch 20/27
 - 19s - loss: 0.1902 - acc: 0.9283 - val_loss: 0.1590 - val_acc: 0.9434
Epoch 21/27
 - 19s - loss: 0.1870 - acc: 0.9298 - val_loss: 0.1738 - val_acc: 0.9355
Epoch 22/27
 - 19s - loss: 0.1802 - acc: 0.9336 - val_loss: 0.1621 - val_acc: 0.9429
Epoch 23/27
 - 19s - loss: 0.1783 - acc: 0.9339 - val_loss: 0.1924 - val_acc: 0.9229

Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 24/27
 - 19s - loss: 0.1714 - acc: 0.9372 - val_loss: 0.1490 - val_acc: 0.9485
Epoch 25/27
 - 19s - loss: 0.1693 - acc: 0.9382 - val_loss: 0.1459 - val_acc: 0.9487
Epoch 26/27
 - 19s - loss: 0.1684 - acc: 0.9389 - val_loss: 0.1540 - val_acc: 0.9455
Epoch 27/27
 - 19s - loss: 0.1667 - acc: 0.9388 - val_loss: 0.1481 - val_acc: 0.9502
Test accuracy:0.828
current auc_score ------------------> 0.903
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  27  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 12, 24, 24)   1728        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 12, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 28, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 28, 24, 24)   112         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 28, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 12, 24, 24)   3024        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 12, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 40, 24, 24)   160         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 20, 24, 24)   800         activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 20, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 20, 12, 12)   80          average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 20, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 12, 12, 12)   2160        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 12, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 32, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 32, 12, 12)   128         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 32, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 12, 12, 12)   3456        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 12, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 44, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 44, 12, 12)   176         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 44, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 6336)         0           activation_7[0][0]               
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            6337        flatten_1[0][0]                  
==================================================================================================
Total params: 19,857
Trainable params: 19,465
Non-trainable params: 392
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/27
 - 21s - loss: 0.5294 - acc: 0.7291 - val_loss: 0.4226 - val_acc: 0.8037
Epoch 2/27
 - 19s - loss: 0.4014 - acc: 0.8166 - val_loss: 0.3899 - val_acc: 0.8245
Epoch 3/27
 - 19s - loss: 0.3592 - acc: 0.8434 - val_loss: 0.3290 - val_acc: 0.8586
Epoch 4/27
 - 19s - loss: 0.3311 - acc: 0.8582 - val_loss: 0.3138 - val_acc: 0.8636
Epoch 5/27
 - 19s - loss: 0.3126 - acc: 0.8672 - val_loss: 0.3050 - val_acc: 0.8667
Epoch 6/27
 - 19s - loss: 0.2969 - acc: 0.8767 - val_loss: 0.2823 - val_acc: 0.8788
Epoch 7/27
 - 19s - loss: 0.2819 - acc: 0.8842 - val_loss: 0.2578 - val_acc: 0.8970
Epoch 8/27
 - 19s - loss: 0.2708 - acc: 0.8880 - val_loss: 0.2462 - val_acc: 0.9002
Epoch 9/27
 - 19s - loss: 0.2602 - acc: 0.8944 - val_loss: 0.2577 - val_acc: 0.8913
Epoch 10/27
 - 19s - loss: 0.2501 - acc: 0.8988 - val_loss: 0.2286 - val_acc: 0.9076
Epoch 11/27
 - 19s - loss: 0.2430 - acc: 0.9044 - val_loss: 0.2152 - val_acc: 0.9177
Epoch 12/27
 - 19s - loss: 0.2317 - acc: 0.9087 - val_loss: 0.2196 - val_acc: 0.9125
Epoch 13/27
 - 19s - loss: 0.2245 - acc: 0.9124 - val_loss: 0.2002 - val_acc: 0.9238
Epoch 14/27
 - 19s - loss: 0.2182 - acc: 0.9137 - val_loss: 0.1965 - val_acc: 0.9244
Epoch 15/27
 - 19s - loss: 0.2119 - acc: 0.9185 - val_loss: 0.1858 - val_acc: 0.9327
Epoch 16/27
 - 19s - loss: 0.2080 - acc: 0.9210 - val_loss: 0.1815 - val_acc: 0.9329
Epoch 17/27
 - 19s - loss: 0.2025 - acc: 0.9212 - val_loss: 0.1877 - val_acc: 0.9272
Epoch 18/27
 - 19s - loss: 0.1964 - acc: 0.9247 - val_loss: 0.1723 - val_acc: 0.9371
Epoch 19/27
 - 19s - loss: 0.1913 - acc: 0.9282 - val_loss: 0.1704 - val_acc: 0.9362
Epoch 20/27
 - 19s - loss: 0.1873 - acc: 0.9311 - val_loss: 0.1619 - val_acc: 0.9444
Epoch 21/27
 - 19s - loss: 0.1832 - acc: 0.9309 - val_loss: 0.1597 - val_acc: 0.9409
Epoch 22/27
 - 19s - loss: 0.1771 - acc: 0.9340 - val_loss: 0.1502 - val_acc: 0.9477
Epoch 23/27
 - 19s - loss: 0.1746 - acc: 0.9359 - val_loss: 0.1548 - val_acc: 0.9445
Epoch 24/27
 - 19s - loss: 0.1709 - acc: 0.9370 - val_loss: 0.1452 - val_acc: 0.9467
Epoch 25/27
 - 19s - loss: 0.1676 - acc: 0.9388 - val_loss: 0.1397 - val_acc: 0.9498
Epoch 26/27
 - 19s - loss: 0.1629 - acc: 0.9395 - val_loss: 0.1407 - val_acc: 0.9480
Epoch 27/27
 - 19s - loss: 0.1619 - acc: 0.9403 - val_loss: 0.1465 - val_acc: 0.9455
Test accuracy:0.830
current auc_score ------------------> 0.908
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  27  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 12, 24, 24)   1728        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 12, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 28, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 28, 24, 24)   112         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 28, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 12, 24, 24)   3024        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 12, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 40, 24, 24)   160         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 20, 24, 24)   800         activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 20, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 20, 12, 12)   80          average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 20, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 12, 12, 12)   2160        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 12, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 32, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 32, 12, 12)   128         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 32, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 12, 12, 12)   3456        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 12, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 44, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 44, 12, 12)   176         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 44, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 6336)         0           activation_7[0][0]               
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            6337        flatten_1[0][0]                  
==================================================================================================
Total params: 19,857
Trainable params: 19,465
Non-trainable params: 392
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/27
 - 20s - loss: 0.5136 - acc: 0.7446 - val_loss: 0.4169 - val_acc: 0.8090
Epoch 2/27
 - 18s - loss: 0.4025 - acc: 0.8193 - val_loss: 0.3602 - val_acc: 0.8401
Epoch 3/27
 - 18s - loss: 0.3615 - acc: 0.8452 - val_loss: 0.3454 - val_acc: 0.8431
Epoch 4/27
 - 18s - loss: 0.3323 - acc: 0.8590 - val_loss: 0.3021 - val_acc: 0.8724
Epoch 5/27
 - 18s - loss: 0.3114 - acc: 0.8703 - val_loss: 0.3221 - val_acc: 0.8537
Epoch 6/27
 - 18s - loss: 0.2954 - acc: 0.8785 - val_loss: 0.2682 - val_acc: 0.8897
Epoch 7/27
 - 18s - loss: 0.2831 - acc: 0.8846 - val_loss: 0.2651 - val_acc: 0.8926
Epoch 8/27
 - 18s - loss: 0.2691 - acc: 0.8920 - val_loss: 0.2510 - val_acc: 0.8986
Epoch 9/27
 - 18s - loss: 0.2594 - acc: 0.8966 - val_loss: 0.2300 - val_acc: 0.9121
Epoch 10/27
 - 18s - loss: 0.2471 - acc: 0.9038 - val_loss: 0.2311 - val_acc: 0.9045
Epoch 11/27
 - 18s - loss: 0.2384 - acc: 0.9074 - val_loss: 0.2136 - val_acc: 0.9192
Epoch 12/27
 - 18s - loss: 0.2298 - acc: 0.9118 - val_loss: 0.2087 - val_acc: 0.9197
Epoch 13/27
 - 19s - loss: 0.2225 - acc: 0.9150 - val_loss: 0.2133 - val_acc: 0.9114
Epoch 14/27
 - 18s - loss: 0.2160 - acc: 0.9148 - val_loss: 0.1986 - val_acc: 0.9239
Epoch 15/27
 - 18s - loss: 0.2098 - acc: 0.9207 - val_loss: 0.2320 - val_acc: 0.9036
Epoch 16/27
 - 18s - loss: 0.2043 - acc: 0.9225 - val_loss: 0.1786 - val_acc: 0.9355
Epoch 17/27
 - 18s - loss: 0.1994 - acc: 0.9255 - val_loss: 0.2047 - val_acc: 0.9198
Epoch 18/27
 - 18s - loss: 0.1956 - acc: 0.9270 - val_loss: 0.1700 - val_acc: 0.9391
Epoch 19/27
 - 18s - loss: 0.1891 - acc: 0.9295 - val_loss: 0.1627 - val_acc: 0.9426
Epoch 20/27
 - 18s - loss: 0.1829 - acc: 0.9323 - val_loss: 0.1683 - val_acc: 0.9362
Epoch 21/27
 - 18s - loss: 0.1794 - acc: 0.9332 - val_loss: 0.1769 - val_acc: 0.9327
Epoch 22/27
 - 18s - loss: 0.1752 - acc: 0.9363 - val_loss: 0.2028 - val_acc: 0.9191

Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 23/27
 - 18s - loss: 0.1703 - acc: 0.9371 - val_loss: 0.1704 - val_acc: 0.9349
Epoch 00023: early stopping
Test accuracy:0.792
current auc_score ------------------> 0.873
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  27  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 12, 24, 24)   1728        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 12, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 28, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 28, 24, 24)   112         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 28, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 12, 24, 24)   3024        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 12, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 40, 24, 24)   160         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 20, 24, 24)   800         activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 20, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 20, 12, 12)   80          average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 20, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 12, 12, 12)   2160        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 12, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 32, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 32, 12, 12)   128         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 32, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 12, 12, 12)   3456        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 12, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 44, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 44, 12, 12)   176         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 44, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 6336)         0           activation_7[0][0]               
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            6337        flatten_1[0][0]                  
==================================================================================================
Total params: 19,857
Trainable params: 19,465
Non-trainable params: 392
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/27
 - 20s - loss: 0.5342 - acc: 0.7298 - val_loss: 0.4699 - val_acc: 0.7757
Epoch 2/27
 - 19s - loss: 0.4150 - acc: 0.8114 - val_loss: 0.3812 - val_acc: 0.8313
Epoch 3/27
 - 19s - loss: 0.3696 - acc: 0.8397 - val_loss: 0.3873 - val_acc: 0.8202
Epoch 4/27
 - 19s - loss: 0.3398 - acc: 0.8557 - val_loss: 0.3379 - val_acc: 0.8508
Epoch 5/27
 - 19s - loss: 0.3195 - acc: 0.8656 - val_loss: 0.3210 - val_acc: 0.8589
Epoch 6/27
 - 19s - loss: 0.3001 - acc: 0.8767 - val_loss: 0.2993 - val_acc: 0.8724
Epoch 7/27
 - 19s - loss: 0.2869 - acc: 0.8834 - val_loss: 0.2820 - val_acc: 0.8818
Epoch 8/27
 - 19s - loss: 0.2750 - acc: 0.8879 - val_loss: 0.3258 - val_acc: 0.8515
Epoch 9/27
 - 19s - loss: 0.2630 - acc: 0.8943 - val_loss: 0.3110 - val_acc: 0.8609
Epoch 10/27
 - 19s - loss: 0.2541 - acc: 0.8990 - val_loss: 0.2401 - val_acc: 0.9054
Epoch 11/27
 - 19s - loss: 0.2453 - acc: 0.9040 - val_loss: 0.2253 - val_acc: 0.9118
Epoch 12/27
 - 19s - loss: 0.2352 - acc: 0.9076 - val_loss: 0.2360 - val_acc: 0.9039
Epoch 13/27
 - 18s - loss: 0.2306 - acc: 0.9111 - val_loss: 0.2035 - val_acc: 0.9224
Epoch 14/27
 - 18s - loss: 0.2241 - acc: 0.9128 - val_loss: 0.2172 - val_acc: 0.9143
Epoch 15/27
 - 19s - loss: 0.2163 - acc: 0.9172 - val_loss: 0.2020 - val_acc: 0.9229
Epoch 16/27
 - 19s - loss: 0.2112 - acc: 0.9185 - val_loss: 0.2202 - val_acc: 0.9130
Epoch 17/27
 - 19s - loss: 0.2039 - acc: 0.9226 - val_loss: 0.2099 - val_acc: 0.9168
Epoch 18/27
 - 19s - loss: 0.1985 - acc: 0.9257 - val_loss: 0.1819 - val_acc: 0.9344
Epoch 19/27
 - 19s - loss: 0.1952 - acc: 0.9264 - val_loss: 0.1763 - val_acc: 0.9364
Epoch 20/27
 - 19s - loss: 0.1926 - acc: 0.9266 - val_loss: 0.1725 - val_acc: 0.9372
Epoch 21/27
 - 19s - loss: 0.1873 - acc: 0.9298 - val_loss: 0.1834 - val_acc: 0.9300
Epoch 22/27
 - 19s - loss: 0.1830 - acc: 0.9319 - val_loss: 0.1627 - val_acc: 0.9419
Epoch 23/27
 - 19s - loss: 0.1793 - acc: 0.9332 - val_loss: 0.1605 - val_acc: 0.9438
Epoch 24/27
 - 19s - loss: 0.1747 - acc: 0.9357 - val_loss: 0.1622 - val_acc: 0.9423
Epoch 25/27
 - 19s - loss: 0.1698 - acc: 0.9381 - val_loss: 0.1464 - val_acc: 0.9499
Epoch 26/27
 - 18s - loss: 0.1691 - acc: 0.9384 - val_loss: 0.1441 - val_acc: 0.9514
Epoch 27/27
 - 19s - loss: 0.1655 - acc: 0.9395 - val_loss: 0.1391 - val_acc: 0.9524
Test accuracy:0.817
current auc_score ------------------> 0.885
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  27  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 12, 24, 24)   1728        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 12, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 28, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 28, 24, 24)   112         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 28, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 12, 24, 24)   3024        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 12, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 40, 24, 24)   160         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 20, 24, 24)   800         activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 20, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 20, 12, 12)   80          average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 20, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 12, 12, 12)   2160        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 12, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 32, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 32, 12, 12)   128         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 32, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 12, 12, 12)   3456        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 12, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 44, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 44, 12, 12)   176         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 44, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 6336)         0           activation_7[0][0]               
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            6337        flatten_1[0][0]                  
==================================================================================================
Total params: 19,857
Trainable params: 19,465
Non-trainable params: 392
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/27
 - 21s - loss: 0.5019 - acc: 0.7558 - val_loss: 0.4176 - val_acc: 0.8091
Epoch 2/27
 - 20s - loss: 0.3951 - acc: 0.8254 - val_loss: 0.3548 - val_acc: 0.8479
Epoch 3/27
 - 19s - loss: 0.3514 - acc: 0.8469 - val_loss: 0.3272 - val_acc: 0.8606
Epoch 4/27
 - 19s - loss: 0.3205 - acc: 0.8646 - val_loss: 0.2946 - val_acc: 0.8775
Epoch 5/27
 - 19s - loss: 0.2998 - acc: 0.8770 - val_loss: 0.2717 - val_acc: 0.8909
Epoch 6/27
 - 19s - loss: 0.2816 - acc: 0.8867 - val_loss: 0.2562 - val_acc: 0.9005
Epoch 7/27
 - 19s - loss: 0.2659 - acc: 0.8945 - val_loss: 0.3000 - val_acc: 0.8645
Epoch 8/27
 - 19s - loss: 0.2548 - acc: 0.8974 - val_loss: 0.2447 - val_acc: 0.8981
Epoch 9/27
 - 19s - loss: 0.2433 - acc: 0.9041 - val_loss: 0.2242 - val_acc: 0.9121
Epoch 10/27
 - 19s - loss: 0.2336 - acc: 0.9068 - val_loss: 0.2090 - val_acc: 0.9201
Epoch 11/27
 - 19s - loss: 0.2266 - acc: 0.9121 - val_loss: 0.2030 - val_acc: 0.9208
Epoch 12/27
 - 19s - loss: 0.2176 - acc: 0.9160 - val_loss: 0.1979 - val_acc: 0.9222
Epoch 13/27
 - 19s - loss: 0.2091 - acc: 0.9195 - val_loss: 0.1901 - val_acc: 0.9251
Epoch 14/27
 - 19s - loss: 0.2038 - acc: 0.9223 - val_loss: 0.1839 - val_acc: 0.9288
Epoch 15/27
 - 19s - loss: 0.1990 - acc: 0.9259 - val_loss: 0.1722 - val_acc: 0.9336
Epoch 16/27
 - 19s - loss: 0.1923 - acc: 0.9292 - val_loss: 0.1657 - val_acc: 0.9364
Epoch 17/27
 - 19s - loss: 0.1858 - acc: 0.9316 - val_loss: 0.1587 - val_acc: 0.9399
Epoch 18/27
 - 19s - loss: 0.1803 - acc: 0.9322 - val_loss: 0.1538 - val_acc: 0.9401
Epoch 19/27
 - 19s - loss: 0.1764 - acc: 0.9340 - val_loss: 0.1488 - val_acc: 0.9438
Epoch 20/27
 - 19s - loss: 0.1714 - acc: 0.9373 - val_loss: 0.1623 - val_acc: 0.9378
Epoch 21/27
 - 19s - loss: 0.1656 - acc: 0.9387 - val_loss: 0.1470 - val_acc: 0.9450
Epoch 22/27
 - 19s - loss: 0.1657 - acc: 0.9383 - val_loss: 0.1430 - val_acc: 0.9478
Epoch 23/27
 - 19s - loss: 0.1613 - acc: 0.9413 - val_loss: 0.1306 - val_acc: 0.9522
Epoch 24/27
 - 19s - loss: 0.1565 - acc: 0.9429 - val_loss: 0.1283 - val_acc: 0.9528
Epoch 25/27
 - 19s - loss: 0.1539 - acc: 0.9440 - val_loss: 0.1417 - val_acc: 0.9477
Epoch 26/27
 - 19s - loss: 0.1508 - acc: 0.9459 - val_loss: 0.1389 - val_acc: 0.9502
Epoch 27/27
 - 19s - loss: 0.1475 - acc: 0.9470 - val_loss: 0.1184 - val_acc: 0.9580
Test accuracy:0.812
current auc_score ------------------> 0.889
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  27  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 12, 24, 24)   1728        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 12, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 28, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 28, 24, 24)   112         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 28, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 12, 24, 24)   3024        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 12, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 40, 24, 24)   160         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 20, 24, 24)   800         activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 20, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 20, 12, 12)   80          average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 20, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 12, 12, 12)   2160        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 12, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 32, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 32, 12, 12)   128         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 32, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 12, 12, 12)   3456        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 12, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 44, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 44, 12, 12)   176         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 44, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 6336)         0           activation_7[0][0]               
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            6337        flatten_1[0][0]                  
==================================================================================================
Total params: 19,857
Trainable params: 19,465
Non-trainable params: 392
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/27
 - 21s - loss: 0.5042 - acc: 0.7553 - val_loss: 0.4376 - val_acc: 0.7961
Epoch 2/27
 - 20s - loss: 0.3957 - acc: 0.8236 - val_loss: 0.3585 - val_acc: 0.8424
Epoch 3/27
 - 20s - loss: 0.3561 - acc: 0.8463 - val_loss: 0.3233 - val_acc: 0.8630
Epoch 4/27
 - 20s - loss: 0.3279 - acc: 0.8606 - val_loss: 0.3540 - val_acc: 0.8384
Epoch 5/27
 - 20s - loss: 0.3080 - acc: 0.8699 - val_loss: 0.2816 - val_acc: 0.8876
Epoch 6/27
 - 19s - loss: 0.2898 - acc: 0.8814 - val_loss: 0.2802 - val_acc: 0.8852
Epoch 7/27
 - 20s - loss: 0.2781 - acc: 0.8876 - val_loss: 0.2633 - val_acc: 0.8929
Epoch 8/27
 - 20s - loss: 0.2662 - acc: 0.8923 - val_loss: 0.2452 - val_acc: 0.9052
Epoch 9/27
 - 20s - loss: 0.2565 - acc: 0.8975 - val_loss: 0.2302 - val_acc: 0.9121
Epoch 10/27
 - 20s - loss: 0.2455 - acc: 0.9016 - val_loss: 0.2302 - val_acc: 0.9113
Epoch 11/27
 - 20s - loss: 0.2371 - acc: 0.9066 - val_loss: 0.2189 - val_acc: 0.9158
Epoch 12/27
 - 19s - loss: 0.2295 - acc: 0.9096 - val_loss: 0.2035 - val_acc: 0.9234
Epoch 13/27
 - 20s - loss: 0.2220 - acc: 0.9137 - val_loss: 0.2062 - val_acc: 0.9213
Epoch 14/27
 - 19s - loss: 0.2159 - acc: 0.9169 - val_loss: 0.1944 - val_acc: 0.9257
Epoch 15/27
 - 19s - loss: 0.2111 - acc: 0.9192 - val_loss: 0.1865 - val_acc: 0.9292
Epoch 16/27
 - 19s - loss: 0.2067 - acc: 0.9214 - val_loss: 0.1825 - val_acc: 0.9324
Epoch 17/27
 - 19s - loss: 0.2004 - acc: 0.9238 - val_loss: 0.1721 - val_acc: 0.9374
Epoch 18/27
 - 19s - loss: 0.1942 - acc: 0.9269 - val_loss: 0.1750 - val_acc: 0.9332
Epoch 19/27
 - 19s - loss: 0.1891 - acc: 0.9289 - val_loss: 0.1623 - val_acc: 0.9413
Epoch 20/27
 - 19s - loss: 0.1870 - acc: 0.9301 - val_loss: 0.1627 - val_acc: 0.9406
Epoch 21/27
 - 19s - loss: 0.1816 - acc: 0.9319 - val_loss: 0.1549 - val_acc: 0.9459
Epoch 22/27
 - 18s - loss: 0.1774 - acc: 0.9353 - val_loss: 0.1623 - val_acc: 0.9413
Epoch 23/27
 - 19s - loss: 0.1737 - acc: 0.9371 - val_loss: 0.1452 - val_acc: 0.9489
Epoch 24/27
 - 19s - loss: 0.1701 - acc: 0.9373 - val_loss: 0.1752 - val_acc: 0.9342
Epoch 25/27
 - 19s - loss: 0.1680 - acc: 0.9386 - val_loss: 0.1386 - val_acc: 0.9507
Epoch 26/27
 - 19s - loss: 0.1639 - acc: 0.9404 - val_loss: 0.1361 - val_acc: 0.9526
Epoch 27/27
 - 19s - loss: 0.1612 - acc: 0.9412 - val_loss: 0.1307 - val_acc: 0.9542
Test accuracy:0.846
current auc_score ------------------> 0.907
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  27  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 12, 24, 24)   1728        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 12, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 28, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 28, 24, 24)   112         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 28, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 12, 24, 24)   3024        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 12, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 40, 24, 24)   160         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 20, 24, 24)   800         activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 20, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 20, 12, 12)   80          average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 20, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 12, 12, 12)   2160        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 12, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 32, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 32, 12, 12)   128         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 32, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 12, 12, 12)   3456        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 12, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 44, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 44, 12, 12)   176         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 44, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 6336)         0           activation_7[0][0]               
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            6337        flatten_1[0][0]                  
==================================================================================================
Total params: 19,857
Trainable params: 19,465
Non-trainable params: 392
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/27
 - 21s - loss: 0.5112 - acc: 0.7485 - val_loss: 0.4121 - val_acc: 0.8148
Epoch 2/27
 - 19s - loss: 0.3914 - acc: 0.8264 - val_loss: 0.3512 - val_acc: 0.8445
Epoch 3/27
 - 19s - loss: 0.3517 - acc: 0.8475 - val_loss: 0.3261 - val_acc: 0.8604
Epoch 4/27
 - 19s - loss: 0.3236 - acc: 0.8634 - val_loss: 0.3103 - val_acc: 0.8653
Epoch 5/27
 - 19s - loss: 0.3048 - acc: 0.8723 - val_loss: 0.2828 - val_acc: 0.8864
Epoch 6/27
 - 19s - loss: 0.2863 - acc: 0.8811 - val_loss: 0.2651 - val_acc: 0.8963
Epoch 7/27
 - 19s - loss: 0.2733 - acc: 0.8880 - val_loss: 0.2668 - val_acc: 0.8868
Epoch 8/27
 - 19s - loss: 0.2607 - acc: 0.8943 - val_loss: 0.2361 - val_acc: 0.9075
Epoch 9/27
 - 19s - loss: 0.2485 - acc: 0.9007 - val_loss: 0.2302 - val_acc: 0.9086
Epoch 10/27
 - 19s - loss: 0.2397 - acc: 0.9034 - val_loss: 0.2273 - val_acc: 0.9060
Epoch 11/27
 - 19s - loss: 0.2314 - acc: 0.9073 - val_loss: 0.2115 - val_acc: 0.9144
Epoch 12/27
 - 19s - loss: 0.2237 - acc: 0.9113 - val_loss: 0.2057 - val_acc: 0.9184
Epoch 13/27
 - 19s - loss: 0.2171 - acc: 0.9137 - val_loss: 0.1938 - val_acc: 0.9270
Epoch 14/27
 - 19s - loss: 0.2105 - acc: 0.9186 - val_loss: 0.1894 - val_acc: 0.9270
Epoch 15/27
 - 19s - loss: 0.2023 - acc: 0.9225 - val_loss: 0.1851 - val_acc: 0.9300
Epoch 16/27
 - 19s - loss: 0.1982 - acc: 0.9251 - val_loss: 0.1735 - val_acc: 0.9344
Epoch 17/27
 - 18s - loss: 0.1911 - acc: 0.9271 - val_loss: 0.1762 - val_acc: 0.9351
Epoch 18/27
 - 19s - loss: 0.1867 - acc: 0.9290 - val_loss: 0.1662 - val_acc: 0.9405
Epoch 19/27
 - 19s - loss: 0.1815 - acc: 0.9324 - val_loss: 0.1626 - val_acc: 0.9421
Epoch 20/27
 - 19s - loss: 0.1782 - acc: 0.9327 - val_loss: 0.1585 - val_acc: 0.9415
Epoch 21/27
 - 19s - loss: 0.1744 - acc: 0.9350 - val_loss: 0.1543 - val_acc: 0.9457
Epoch 22/27
 - 19s - loss: 0.1713 - acc: 0.9368 - val_loss: 0.1504 - val_acc: 0.9473
Epoch 23/27
 - 19s - loss: 0.1676 - acc: 0.9380 - val_loss: 0.1517 - val_acc: 0.9472
Epoch 24/27
 - 19s - loss: 0.1650 - acc: 0.9390 - val_loss: 0.1606 - val_acc: 0.9404
Epoch 25/27
 - 19s - loss: 0.1617 - acc: 0.9406 - val_loss: 0.1412 - val_acc: 0.9502
Epoch 26/27
 - 19s - loss: 0.1570 - acc: 0.9435 - val_loss: 0.1374 - val_acc: 0.9507
Epoch 27/27
 - 19s - loss: 0.1548 - acc: 0.9442 - val_loss: 0.1341 - val_acc: 0.9551
Test accuracy:0.808
current auc_score ------------------> 0.908
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  27  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 12, 24, 24)   1728        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 12, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 28, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 28, 24, 24)   112         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 28, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 12, 24, 24)   3024        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 12, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 40, 24, 24)   160         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 20, 24, 24)   800         activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 20, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 20, 12, 12)   80          average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 20, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 12, 12, 12)   2160        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 12, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 32, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 32, 12, 12)   128         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 32, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 12, 12, 12)   3456        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 12, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 44, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 44, 12, 12)   176         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 44, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 6336)         0           activation_7[0][0]               
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            6337        flatten_1[0][0]                  
==================================================================================================
Total params: 19,857
Trainable params: 19,465
Non-trainable params: 392
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/27
 - 20s - loss: 0.5093 - acc: 0.7495 - val_loss: 0.4551 - val_acc: 0.7895
Epoch 2/27
 - 19s - loss: 0.4016 - acc: 0.8206 - val_loss: 0.3692 - val_acc: 0.8382
Epoch 3/27
 - 18s - loss: 0.3602 - acc: 0.8445 - val_loss: 0.3475 - val_acc: 0.8476
Epoch 4/27
 - 19s - loss: 0.3325 - acc: 0.8587 - val_loss: 0.3421 - val_acc: 0.8481
Epoch 5/27
 - 19s - loss: 0.3137 - acc: 0.8695 - val_loss: 0.2947 - val_acc: 0.8768
Epoch 6/27
 - 19s - loss: 0.2991 - acc: 0.8757 - val_loss: 0.2743 - val_acc: 0.8904
Epoch 7/27
 - 19s - loss: 0.2842 - acc: 0.8848 - val_loss: 0.2631 - val_acc: 0.8938
Epoch 8/27
 - 19s - loss: 0.2739 - acc: 0.8894 - val_loss: 0.2512 - val_acc: 0.9014
Epoch 9/27
 - 19s - loss: 0.2636 - acc: 0.8940 - val_loss: 0.2407 - val_acc: 0.9061
Epoch 10/27
 - 19s - loss: 0.2537 - acc: 0.8990 - val_loss: 0.2656 - val_acc: 0.8863
Epoch 11/27
 - 19s - loss: 0.2443 - acc: 0.9043 - val_loss: 0.2253 - val_acc: 0.9140
Epoch 12/27
 - 19s - loss: 0.2349 - acc: 0.9065 - val_loss: 0.2241 - val_acc: 0.9111
Epoch 13/27
 - 19s - loss: 0.2305 - acc: 0.9103 - val_loss: 0.2224 - val_acc: 0.9118
Epoch 14/27
 - 19s - loss: 0.2240 - acc: 0.9126 - val_loss: 0.2037 - val_acc: 0.9219
Epoch 15/27
 - 19s - loss: 0.2148 - acc: 0.9175 - val_loss: 0.1902 - val_acc: 0.9292
Epoch 16/27
 - 19s - loss: 0.2093 - acc: 0.9195 - val_loss: 0.2026 - val_acc: 0.9203
Epoch 17/27
 - 19s - loss: 0.2034 - acc: 0.9227 - val_loss: 0.1887 - val_acc: 0.9288
Epoch 18/27
 - 19s - loss: 0.1974 - acc: 0.9248 - val_loss: 0.1711 - val_acc: 0.9369
Epoch 19/27
 - 19s - loss: 0.1931 - acc: 0.9265 - val_loss: 0.1790 - val_acc: 0.9307
Epoch 20/27
 - 19s - loss: 0.1892 - acc: 0.9293 - val_loss: 0.1592 - val_acc: 0.9409
Epoch 21/27
 - 19s - loss: 0.1837 - acc: 0.9305 - val_loss: 0.2163 - val_acc: 0.9129
Epoch 22/27
 - 19s - loss: 0.1789 - acc: 0.9323 - val_loss: 0.1495 - val_acc: 0.9475
Epoch 23/27
 - 19s - loss: 0.1733 - acc: 0.9368 - val_loss: 0.1466 - val_acc: 0.9489
Epoch 24/27
 - 19s - loss: 0.1702 - acc: 0.9370 - val_loss: 0.1422 - val_acc: 0.9503
Epoch 25/27
 - 19s - loss: 0.1677 - acc: 0.9380 - val_loss: 0.1416 - val_acc: 0.9507
Epoch 26/27
 - 19s - loss: 0.1631 - acc: 0.9401 - val_loss: 0.1400 - val_acc: 0.9527
Epoch 27/27
 - 19s - loss: 0.1577 - acc: 0.9432 - val_loss: 0.1417 - val_acc: 0.9522
Test accuracy:0.830
current auc_score ------------------> 0.912
accuracies:  [0.801747311827957, 0.8276881720430107, 0.8276881720430107, 0.8295698924731183, 0.7922043010752688, 0.8172043010752689, 0.8115591397849462, 0.8456989247311828, 0.8084677419354839, 0.8298387096774194]
aucs:  [0.9158, 0.8969, 0.9026, 0.9085, 0.8728, 0.8851, 0.8887, 0.907, 0.9081, 0.9119]
mean and std AUC:  0.9+/-0.013  max:   0.9158
['2-2', '18', '2', '16', '0.2', '0.07', '25', 'adadelta', '0.5', 'FALSE', '64', 'flatten']
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  25  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   2592        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 34, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 34, 24, 24)   136         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 34, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   5508        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 52, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 52, 24, 24)   208         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 52, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 26, 24, 24)   1352        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 26, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 26, 12, 12)   104         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 26, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   4212        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 44, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 44, 12, 12)   176         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 44, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   7128        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 62, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 62, 12, 12)   248         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 62, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 8928)         0           activation_7[0][0]               
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            8929        flatten_1[0][0]                  
==================================================================================================
Total params: 32,289
Trainable params: 31,789
Non-trainable params: 500
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/25
 - 23s - loss: 0.4938 - acc: 0.7640 - val_loss: 0.4000 - val_acc: 0.8218
Epoch 2/25
 - 21s - loss: 0.3815 - acc: 0.8305 - val_loss: 0.3947 - val_acc: 0.8143
Epoch 3/25
 - 21s - loss: 0.3319 - acc: 0.8597 - val_loss: 0.3042 - val_acc: 0.8704
Epoch 4/25
 - 21s - loss: 0.3039 - acc: 0.8744 - val_loss: 0.2660 - val_acc: 0.8980
Epoch 5/25
 - 21s - loss: 0.2790 - acc: 0.8863 - val_loss: 0.2619 - val_acc: 0.8960
Epoch 6/25
 - 21s - loss: 0.2632 - acc: 0.8950 - val_loss: 0.2673 - val_acc: 0.8872
Epoch 7/25
 - 21s - loss: 0.2457 - acc: 0.9037 - val_loss: 0.2257 - val_acc: 0.9125
Epoch 8/25
 - 21s - loss: 0.2345 - acc: 0.9079 - val_loss: 0.2101 - val_acc: 0.9231
Epoch 9/25
 - 21s - loss: 0.2237 - acc: 0.9140 - val_loss: 0.2040 - val_acc: 0.9262
Epoch 10/25
 - 21s - loss: 0.2116 - acc: 0.9205 - val_loss: 0.2373 - val_acc: 0.9016
Epoch 11/25
 - 21s - loss: 0.2011 - acc: 0.9250 - val_loss: 0.1751 - val_acc: 0.9408
Epoch 12/25
 - 21s - loss: 0.1944 - acc: 0.9284 - val_loss: 0.1665 - val_acc: 0.9440
Epoch 13/25
 - 21s - loss: 0.1880 - acc: 0.9309 - val_loss: 0.2088 - val_acc: 0.9154
Epoch 14/25
 - 21s - loss: 0.1814 - acc: 0.9337 - val_loss: 0.1690 - val_acc: 0.9411
Epoch 15/25
 - 21s - loss: 0.1744 - acc: 0.9367 - val_loss: 0.1538 - val_acc: 0.9482
Epoch 16/25
 - 21s - loss: 0.1680 - acc: 0.9391 - val_loss: 0.1551 - val_acc: 0.9467
Epoch 17/25
 - 21s - loss: 0.1626 - acc: 0.9408 - val_loss: 0.1374 - val_acc: 0.9533
Epoch 18/25
 - 21s - loss: 0.1567 - acc: 0.9442 - val_loss: 0.1297 - val_acc: 0.9568
Epoch 19/25
 - 21s - loss: 0.1548 - acc: 0.9459 - val_loss: 0.1271 - val_acc: 0.9595
Epoch 20/25
 - 21s - loss: 0.1498 - acc: 0.9472 - val_loss: 0.1259 - val_acc: 0.9600
Epoch 21/25
 - 21s - loss: 0.1447 - acc: 0.9497 - val_loss: 0.1480 - val_acc: 0.9462
Epoch 22/25
 - 21s - loss: 0.1422 - acc: 0.9500 - val_loss: 0.1168 - val_acc: 0.9623
Epoch 23/25
 - 21s - loss: 0.1367 - acc: 0.9520 - val_loss: 0.1090 - val_acc: 0.9655
Epoch 24/25
 - 21s - loss: 0.1346 - acc: 0.9532 - val_loss: 0.1225 - val_acc: 0.9581
Epoch 25/25
 - 21s - loss: 0.1308 - acc: 0.9546 - val_loss: 0.1013 - val_acc: 0.9695
Test accuracy:0.835
current auc_score ------------------> 0.905
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  25  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   2592        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 34, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 34, 24, 24)   136         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 34, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   5508        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 52, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 52, 24, 24)   208         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 52, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 26, 24, 24)   1352        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 26, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 26, 12, 12)   104         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 26, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   4212        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 44, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 44, 12, 12)   176         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 44, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   7128        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 62, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 62, 12, 12)   248         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 62, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 8928)         0           activation_7[0][0]               
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            8929        flatten_1[0][0]                  
==================================================================================================
Total params: 32,289
Trainable params: 31,789
Non-trainable params: 500
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/25
 - 23s - loss: 0.4995 - acc: 0.7550 - val_loss: 0.4373 - val_acc: 0.7971
Epoch 2/25
 - 21s - loss: 0.3911 - acc: 0.8258 - val_loss: 0.3775 - val_acc: 0.8249
Epoch 3/25
 - 21s - loss: 0.3437 - acc: 0.8514 - val_loss: 0.3222 - val_acc: 0.8636
Epoch 4/25
 - 21s - loss: 0.3171 - acc: 0.8667 - val_loss: 0.3027 - val_acc: 0.8667
Epoch 5/25
 - 21s - loss: 0.2927 - acc: 0.8791 - val_loss: 0.3207 - val_acc: 0.8533
Epoch 6/25
 - 21s - loss: 0.2739 - acc: 0.8897 - val_loss: 0.3047 - val_acc: 0.8624
Epoch 7/25
 - 21s - loss: 0.2587 - acc: 0.8964 - val_loss: 0.2689 - val_acc: 0.8833
Epoch 8/25
 - 21s - loss: 0.2450 - acc: 0.9035 - val_loss: 0.2284 - val_acc: 0.9085
Epoch 9/25
 - 21s - loss: 0.2334 - acc: 0.9081 - val_loss: 0.2523 - val_acc: 0.8912
Epoch 10/25
 - 21s - loss: 0.2239 - acc: 0.9136 - val_loss: 0.1927 - val_acc: 0.9282
Epoch 11/25
 - 21s - loss: 0.2131 - acc: 0.9179 - val_loss: 0.1930 - val_acc: 0.9275
Epoch 12/25
 - 21s - loss: 0.2051 - acc: 0.9225 - val_loss: 0.2069 - val_acc: 0.9144
Epoch 13/25
 - 21s - loss: 0.1982 - acc: 0.9255 - val_loss: 0.1798 - val_acc: 0.9347
Epoch 14/25
 - 21s - loss: 0.1908 - acc: 0.9287 - val_loss: 0.1621 - val_acc: 0.9430
Epoch 15/25
 - 21s - loss: 0.1833 - acc: 0.9326 - val_loss: 0.1576 - val_acc: 0.9459
Epoch 16/25
 - 21s - loss: 0.1783 - acc: 0.9339 - val_loss: 0.1545 - val_acc: 0.9469
Epoch 17/25
 - 21s - loss: 0.1723 - acc: 0.9368 - val_loss: 0.1567 - val_acc: 0.9439
Epoch 18/25
 - 21s - loss: 0.1656 - acc: 0.9410 - val_loss: 0.1903 - val_acc: 0.9212
Epoch 19/25
 - 21s - loss: 0.1618 - acc: 0.9421 - val_loss: 0.1412 - val_acc: 0.9518
Epoch 20/25
 - 21s - loss: 0.1578 - acc: 0.9432 - val_loss: 0.1486 - val_acc: 0.9440
Epoch 21/25
 - 21s - loss: 0.1518 - acc: 0.9470 - val_loss: 0.1500 - val_acc: 0.9442
Epoch 22/25
 - 21s - loss: 0.1490 - acc: 0.9470 - val_loss: 0.1180 - val_acc: 0.9617
Epoch 23/25
 - 21s - loss: 0.1450 - acc: 0.9490 - val_loss: 0.1350 - val_acc: 0.9521
Epoch 24/25
 - 21s - loss: 0.1396 - acc: 0.9517 - val_loss: 0.1800 - val_acc: 0.9281
Epoch 25/25
 - 21s - loss: 0.1373 - acc: 0.9514 - val_loss: 0.1150 - val_acc: 0.9629
Test accuracy:0.794
current auc_score ------------------> 0.897
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  25  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   2592        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 34, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 34, 24, 24)   136         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 34, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   5508        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 52, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 52, 24, 24)   208         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 52, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 26, 24, 24)   1352        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 26, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 26, 12, 12)   104         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 26, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   4212        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 44, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 44, 12, 12)   176         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 44, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   7128        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 62, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 62, 12, 12)   248         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 62, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 8928)         0           activation_7[0][0]               
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            8929        flatten_1[0][0]                  
==================================================================================================
Total params: 32,289
Trainable params: 31,789
Non-trainable params: 500
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/25
 - 22s - loss: 0.4801 - acc: 0.7704 - val_loss: 0.3987 - val_acc: 0.8237
Epoch 2/25
 - 21s - loss: 0.3711 - acc: 0.8393 - val_loss: 0.3335 - val_acc: 0.8535
Epoch 3/25
 - 21s - loss: 0.3285 - acc: 0.8603 - val_loss: 0.3053 - val_acc: 0.8732
Epoch 4/25
 - 21s - loss: 0.2985 - acc: 0.8763 - val_loss: 0.2696 - val_acc: 0.8892
Epoch 5/25
 - 21s - loss: 0.2772 - acc: 0.8868 - val_loss: 0.2520 - val_acc: 0.8968
Epoch 6/25
 - 21s - loss: 0.2591 - acc: 0.8977 - val_loss: 0.2354 - val_acc: 0.9123
Epoch 7/25
 - 21s - loss: 0.2454 - acc: 0.9043 - val_loss: 0.2235 - val_acc: 0.9123
Epoch 8/25
 - 21s - loss: 0.2326 - acc: 0.9104 - val_loss: 0.2054 - val_acc: 0.9231
Epoch 9/25
 - 22s - loss: 0.2226 - acc: 0.9146 - val_loss: 0.2257 - val_acc: 0.9080
Epoch 10/25
 - 24s - loss: 0.2120 - acc: 0.9187 - val_loss: 0.1911 - val_acc: 0.9273
Epoch 11/25
 - 22s - loss: 0.2042 - acc: 0.9233 - val_loss: 0.2118 - val_acc: 0.9174
Epoch 12/25
 - 22s - loss: 0.1964 - acc: 0.9269 - val_loss: 0.1676 - val_acc: 0.9394
Epoch 13/25
 - 22s - loss: 0.1915 - acc: 0.9296 - val_loss: 0.1859 - val_acc: 0.9256
Epoch 14/25
 - 22s - loss: 0.1833 - acc: 0.9327 - val_loss: 0.1684 - val_acc: 0.9364
Epoch 15/25
 - 22s - loss: 0.1772 - acc: 0.9344 - val_loss: 0.1469 - val_acc: 0.9485
Epoch 16/25
 - 22s - loss: 0.1701 - acc: 0.9380 - val_loss: 0.1619 - val_acc: 0.9378
Epoch 17/25
 - 22s - loss: 0.1640 - acc: 0.9410 - val_loss: 0.1571 - val_acc: 0.9396
Epoch 18/25
 - 22s - loss: 0.1614 - acc: 0.9420 - val_loss: 0.1316 - val_acc: 0.9549
Epoch 19/25
 - 22s - loss: 0.1561 - acc: 0.9440 - val_loss: 0.1657 - val_acc: 0.9354
Epoch 20/25
 - 22s - loss: 0.1509 - acc: 0.9473 - val_loss: 0.1338 - val_acc: 0.9514
Epoch 21/25
 - 22s - loss: 0.1487 - acc: 0.9480 - val_loss: 0.1211 - val_acc: 0.9587
Epoch 22/25
 - 21s - loss: 0.1421 - acc: 0.9505 - val_loss: 0.1147 - val_acc: 0.9621
Epoch 23/25
 - 22s - loss: 0.1399 - acc: 0.9522 - val_loss: 0.1172 - val_acc: 0.9581
Epoch 24/25
 - 21s - loss: 0.1375 - acc: 0.9526 - val_loss: 0.1083 - val_acc: 0.9636
Epoch 25/25
 - 22s - loss: 0.1353 - acc: 0.9529 - val_loss: 0.1091 - val_acc: 0.9627
Test accuracy:0.852
current auc_score ------------------> 0.930
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  25  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   2592        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 34, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 34, 24, 24)   136         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 34, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   5508        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 52, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 52, 24, 24)   208         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 52, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 26, 24, 24)   1352        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 26, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 26, 12, 12)   104         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 26, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   4212        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 44, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 44, 12, 12)   176         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 44, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   7128        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 62, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 62, 12, 12)   248         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 62, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 8928)         0           activation_7[0][0]               
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            8929        flatten_1[0][0]                  
==================================================================================================
Total params: 32,289
Trainable params: 31,789
Non-trainable params: 500
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/25
 - 23s - loss: 0.4971 - acc: 0.7591 - val_loss: 0.4126 - val_acc: 0.8128
Epoch 2/25
 - 21s - loss: 0.3826 - acc: 0.8339 - val_loss: 0.3392 - val_acc: 0.8528
Epoch 3/25
 - 22s - loss: 0.3394 - acc: 0.8556 - val_loss: 0.3448 - val_acc: 0.8415
Epoch 4/25
 - 22s - loss: 0.3096 - acc: 0.8713 - val_loss: 0.2811 - val_acc: 0.8805
Epoch 5/25
 - 21s - loss: 0.2877 - acc: 0.8818 - val_loss: 0.2631 - val_acc: 0.8963
Epoch 6/25
 - 22s - loss: 0.2705 - acc: 0.8889 - val_loss: 0.2431 - val_acc: 0.9021
Epoch 7/25
 - 21s - loss: 0.2525 - acc: 0.8982 - val_loss: 0.2377 - val_acc: 0.9016
Epoch 8/25
 - 22s - loss: 0.2371 - acc: 0.9048 - val_loss: 0.2119 - val_acc: 0.9162
Epoch 9/25
 - 21s - loss: 0.2257 - acc: 0.9117 - val_loss: 0.2089 - val_acc: 0.9194
Epoch 10/25
 - 22s - loss: 0.2146 - acc: 0.9174 - val_loss: 0.1946 - val_acc: 0.9260
Epoch 11/25
 - 22s - loss: 0.2051 - acc: 0.9224 - val_loss: 0.2244 - val_acc: 0.9083
Epoch 12/25
 - 22s - loss: 0.1975 - acc: 0.9232 - val_loss: 0.1819 - val_acc: 0.9347
Epoch 13/25
 - 20s - loss: 0.1889 - acc: 0.9278 - val_loss: 0.1769 - val_acc: 0.9345
Epoch 14/25
 - 21s - loss: 0.1836 - acc: 0.9314 - val_loss: 0.1578 - val_acc: 0.9429
Epoch 15/25
 - 21s - loss: 0.1774 - acc: 0.9348 - val_loss: 0.1572 - val_acc: 0.9444
Epoch 16/25
 - 21s - loss: 0.1703 - acc: 0.9365 - val_loss: 0.1450 - val_acc: 0.9478
Epoch 17/25
 - 21s - loss: 0.1646 - acc: 0.9409 - val_loss: 0.1610 - val_acc: 0.9406
Epoch 18/25
 - 21s - loss: 0.1614 - acc: 0.9424 - val_loss: 0.1371 - val_acc: 0.9517
Epoch 19/25
 - 21s - loss: 0.1544 - acc: 0.9440 - val_loss: 0.1333 - val_acc: 0.9534
Epoch 20/25
 - 21s - loss: 0.1503 - acc: 0.9472 - val_loss: 0.1284 - val_acc: 0.9534
Epoch 21/25
 - 21s - loss: 0.1459 - acc: 0.9475 - val_loss: 0.1230 - val_acc: 0.9570
Epoch 22/25
 - 21s - loss: 0.1444 - acc: 0.9486 - val_loss: 0.1142 - val_acc: 0.9623
Epoch 23/25
 - 21s - loss: 0.1389 - acc: 0.9524 - val_loss: 0.1129 - val_acc: 0.9623
Epoch 24/25
 - 21s - loss: 0.1352 - acc: 0.9533 - val_loss: 0.1146 - val_acc: 0.9610
Epoch 25/25
 - 21s - loss: 0.1326 - acc: 0.9553 - val_loss: 0.1085 - val_acc: 0.9670
Test accuracy:0.812
current auc_score ------------------> 0.916
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  25  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   2592        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 34, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 34, 24, 24)   136         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 34, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   5508        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 52, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 52, 24, 24)   208         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 52, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 26, 24, 24)   1352        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 26, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 26, 12, 12)   104         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 26, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   4212        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 44, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 44, 12, 12)   176         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 44, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   7128        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 62, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 62, 12, 12)   248         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 62, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 8928)         0           activation_7[0][0]               
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            8929        flatten_1[0][0]                  
==================================================================================================
Total params: 32,289
Trainable params: 31,789
Non-trainable params: 500
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/25
 - 23s - loss: 0.4932 - acc: 0.7596 - val_loss: 0.4046 - val_acc: 0.8165
Epoch 2/25
 - 21s - loss: 0.3855 - acc: 0.8285 - val_loss: 0.3392 - val_acc: 0.8558
Epoch 3/25
 - 21s - loss: 0.3409 - acc: 0.8541 - val_loss: 0.3082 - val_acc: 0.8694
Epoch 4/25
 - 21s - loss: 0.3103 - acc: 0.8713 - val_loss: 0.3074 - val_acc: 0.8681
Epoch 5/25
 - 21s - loss: 0.2855 - acc: 0.8840 - val_loss: 0.2524 - val_acc: 0.9022
Epoch 6/25
 - 21s - loss: 0.2676 - acc: 0.8927 - val_loss: 0.2368 - val_acc: 0.9088
Epoch 7/25
 - 21s - loss: 0.2516 - acc: 0.8997 - val_loss: 0.2152 - val_acc: 0.9182
Epoch 8/25
 - 21s - loss: 0.2359 - acc: 0.9074 - val_loss: 0.2145 - val_acc: 0.9183
Epoch 9/25
 - 21s - loss: 0.2247 - acc: 0.9121 - val_loss: 0.1988 - val_acc: 0.9281
Epoch 10/25
 - 21s - loss: 0.2161 - acc: 0.9175 - val_loss: 0.1963 - val_acc: 0.9273
Epoch 11/25
 - 21s - loss: 0.2051 - acc: 0.9235 - val_loss: 0.1712 - val_acc: 0.9410
Epoch 12/25
 - 21s - loss: 0.1948 - acc: 0.9268 - val_loss: 0.1660 - val_acc: 0.9398
Epoch 13/25
 - 21s - loss: 0.1867 - acc: 0.9297 - val_loss: 0.1583 - val_acc: 0.9434
Epoch 14/25
 - 20s - loss: 0.1817 - acc: 0.9328 - val_loss: 0.1472 - val_acc: 0.9473
Epoch 15/25
 - 20s - loss: 0.1736 - acc: 0.9372 - val_loss: 0.1434 - val_acc: 0.9516
Epoch 16/25
 - 21s - loss: 0.1679 - acc: 0.9388 - val_loss: 0.1451 - val_acc: 0.9514
Epoch 17/25
 - 21s - loss: 0.1636 - acc: 0.9409 - val_loss: 0.1356 - val_acc: 0.9563
Epoch 18/25
 - 23s - loss: 0.1573 - acc: 0.9440 - val_loss: 0.1290 - val_acc: 0.9551
Epoch 19/25
 - 21s - loss: 0.1520 - acc: 0.9464 - val_loss: 0.1214 - val_acc: 0.9600
Epoch 20/25
 - 21s - loss: 0.1484 - acc: 0.9492 - val_loss: 0.1192 - val_acc: 0.9592
Epoch 21/25
 - 21s - loss: 0.1460 - acc: 0.9497 - val_loss: 0.1109 - val_acc: 0.9646
Epoch 22/25
 - 21s - loss: 0.1401 - acc: 0.9525 - val_loss: 0.1077 - val_acc: 0.9661
Epoch 23/25
 - 21s - loss: 0.1360 - acc: 0.9534 - val_loss: 0.1141 - val_acc: 0.9591
Epoch 24/25
 - 21s - loss: 0.1330 - acc: 0.9548 - val_loss: 0.1050 - val_acc: 0.9667
Epoch 25/25
 - 21s - loss: 0.1314 - acc: 0.9554 - val_loss: 0.0995 - val_acc: 0.9670
Test accuracy:0.866
current auc_score ------------------> 0.935
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  25  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   2592        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 34, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 34, 24, 24)   136         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 34, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   5508        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 52, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 52, 24, 24)   208         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 52, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 26, 24, 24)   1352        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 26, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 26, 12, 12)   104         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 26, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   4212        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 44, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 44, 12, 12)   176         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 44, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   7128        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 62, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 62, 12, 12)   248         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 62, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 8928)         0           activation_7[0][0]               
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            8929        flatten_1[0][0]                  
==================================================================================================
Total params: 32,289
Trainable params: 31,789
Non-trainable params: 500
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/25
 - 22s - loss: 0.4891 - acc: 0.7613 - val_loss: 0.4791 - val_acc: 0.7573
Epoch 2/25
 - 21s - loss: 0.3786 - acc: 0.8324 - val_loss: 0.3774 - val_acc: 0.8197
Epoch 3/25
 - 21s - loss: 0.3346 - acc: 0.8589 - val_loss: 0.3194 - val_acc: 0.8622
Epoch 4/25
 - 21s - loss: 0.3076 - acc: 0.8720 - val_loss: 0.2795 - val_acc: 0.8878
Epoch 5/25
 - 21s - loss: 0.2873 - acc: 0.8813 - val_loss: 0.2607 - val_acc: 0.8977
Epoch 6/25
 - 21s - loss: 0.2682 - acc: 0.8928 - val_loss: 0.2445 - val_acc: 0.9059
Epoch 7/25
 - 21s - loss: 0.2530 - acc: 0.8985 - val_loss: 0.2404 - val_acc: 0.9084
Epoch 8/25
 - 21s - loss: 0.2384 - acc: 0.9063 - val_loss: 0.2101 - val_acc: 0.9198
Epoch 9/25
 - 21s - loss: 0.2274 - acc: 0.9109 - val_loss: 0.1994 - val_acc: 0.9271
Epoch 10/25
 - 21s - loss: 0.2166 - acc: 0.9167 - val_loss: 0.1933 - val_acc: 0.9300
Epoch 11/25
 - 21s - loss: 0.2075 - acc: 0.9205 - val_loss: 0.1805 - val_acc: 0.9339
Epoch 12/25
 - 21s - loss: 0.2007 - acc: 0.9252 - val_loss: 0.1709 - val_acc: 0.9400
Epoch 13/25
 - 21s - loss: 0.1924 - acc: 0.9295 - val_loss: 0.1685 - val_acc: 0.9423
Epoch 14/25
 - 21s - loss: 0.1856 - acc: 0.9305 - val_loss: 0.1629 - val_acc: 0.9433
Epoch 15/25
 - 21s - loss: 0.1795 - acc: 0.9324 - val_loss: 0.1508 - val_acc: 0.9488
Epoch 16/25
 - 21s - loss: 0.1731 - acc: 0.9363 - val_loss: 0.1483 - val_acc: 0.9482
Epoch 17/25
 - 21s - loss: 0.1675 - acc: 0.9390 - val_loss: 0.1414 - val_acc: 0.9542
Epoch 18/25
 - 21s - loss: 0.1619 - acc: 0.9416 - val_loss: 0.1365 - val_acc: 0.9551
Epoch 19/25
 - 23s - loss: 0.1574 - acc: 0.9437 - val_loss: 0.1317 - val_acc: 0.9568
Epoch 20/25
 - 23s - loss: 0.1541 - acc: 0.9453 - val_loss: 0.1249 - val_acc: 0.9587
Epoch 21/25
 - 22s - loss: 0.1496 - acc: 0.9463 - val_loss: 0.1262 - val_acc: 0.9573
Epoch 22/25
 - 22s - loss: 0.1456 - acc: 0.9479 - val_loss: 0.1234 - val_acc: 0.9612
Epoch 23/25
 - 22s - loss: 0.1412 - acc: 0.9512 - val_loss: 0.1142 - val_acc: 0.9627
Epoch 24/25
 - 22s - loss: 0.1381 - acc: 0.9520 - val_loss: 0.1086 - val_acc: 0.9655
Epoch 25/25
 - 21s - loss: 0.1341 - acc: 0.9540 - val_loss: 0.1059 - val_acc: 0.9669
Test accuracy:0.838
current auc_score ------------------> 0.914
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  25  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   2592        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 34, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 34, 24, 24)   136         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 34, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   5508        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 52, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 52, 24, 24)   208         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 52, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 26, 24, 24)   1352        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 26, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 26, 12, 12)   104         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 26, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   4212        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 44, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 44, 12, 12)   176         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 44, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   7128        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 62, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 62, 12, 12)   248         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 62, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 8928)         0           activation_7[0][0]               
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            8929        flatten_1[0][0]                  
==================================================================================================
Total params: 32,289
Trainable params: 31,789
Non-trainable params: 500
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/25
 - 23s - loss: 0.5111 - acc: 0.7479 - val_loss: 0.4049 - val_acc: 0.8170
Epoch 2/25
 - 22s - loss: 0.3951 - acc: 0.8233 - val_loss: 0.3803 - val_acc: 0.8289
Epoch 3/25
 - 22s - loss: 0.3522 - acc: 0.8503 - val_loss: 0.3433 - val_acc: 0.8459
Epoch 4/25
 - 22s - loss: 0.3201 - acc: 0.8643 - val_loss: 0.2947 - val_acc: 0.8756
Epoch 5/25
 - 22s - loss: 0.2981 - acc: 0.8769 - val_loss: 0.3031 - val_acc: 0.8706
Epoch 6/25
 - 22s - loss: 0.2778 - acc: 0.8862 - val_loss: 0.2755 - val_acc: 0.8868
Epoch 7/25
 - 22s - loss: 0.2619 - acc: 0.8946 - val_loss: 0.2336 - val_acc: 0.9083
Epoch 8/25
 - 22s - loss: 0.2467 - acc: 0.9028 - val_loss: 0.2170 - val_acc: 0.9179
Epoch 9/25
 - 22s - loss: 0.2349 - acc: 0.9092 - val_loss: 0.2315 - val_acc: 0.9106
Epoch 10/25
 - 21s - loss: 0.2234 - acc: 0.9150 - val_loss: 0.1987 - val_acc: 0.9281
Epoch 11/25
 - 21s - loss: 0.2151 - acc: 0.9170 - val_loss: 0.1876 - val_acc: 0.9306
Epoch 12/25
 - 21s - loss: 0.2040 - acc: 0.9227 - val_loss: 0.1785 - val_acc: 0.9336
Epoch 13/25
 - 21s - loss: 0.1985 - acc: 0.9258 - val_loss: 0.1707 - val_acc: 0.9399
Epoch 14/25
 - 21s - loss: 0.1881 - acc: 0.9295 - val_loss: 0.1655 - val_acc: 0.9389
Epoch 15/25
 - 21s - loss: 0.1816 - acc: 0.9328 - val_loss: 0.1694 - val_acc: 0.9370
Epoch 16/25
 - 21s - loss: 0.1753 - acc: 0.9350 - val_loss: 0.1526 - val_acc: 0.9460
Epoch 17/25
 - 21s - loss: 0.1707 - acc: 0.9373 - val_loss: 0.1520 - val_acc: 0.9478
Epoch 18/25
 - 21s - loss: 0.1630 - acc: 0.9404 - val_loss: 0.1427 - val_acc: 0.9517
Epoch 19/25
 - 21s - loss: 0.1600 - acc: 0.9418 - val_loss: 0.1341 - val_acc: 0.9544
Epoch 20/25
 - 21s - loss: 0.1554 - acc: 0.9426 - val_loss: 0.1324 - val_acc: 0.9549
Epoch 21/25
 - 21s - loss: 0.1509 - acc: 0.9476 - val_loss: 0.1253 - val_acc: 0.9597
Epoch 22/25
 - 21s - loss: 0.1472 - acc: 0.9479 - val_loss: 0.1281 - val_acc: 0.9548
Epoch 23/25
 - 21s - loss: 0.1419 - acc: 0.9510 - val_loss: 0.1153 - val_acc: 0.9623
Epoch 24/25
 - 21s - loss: 0.1381 - acc: 0.9523 - val_loss: 0.1148 - val_acc: 0.9625
Epoch 25/25
 - 21s - loss: 0.1355 - acc: 0.9527 - val_loss: 0.1114 - val_acc: 0.9635
Test accuracy:0.839
current auc_score ------------------> 0.917
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  25  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   2592        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 34, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 34, 24, 24)   136         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 34, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   5508        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 52, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 52, 24, 24)   208         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 52, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 26, 24, 24)   1352        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 26, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 26, 12, 12)   104         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 26, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   4212        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 44, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 44, 12, 12)   176         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 44, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   7128        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 62, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 62, 12, 12)   248         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 62, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 8928)         0           activation_7[0][0]               
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            8929        flatten_1[0][0]                  
==================================================================================================
Total params: 32,289
Trainable params: 31,789
Non-trainable params: 500
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/25
 - 23s - loss: 0.5051 - acc: 0.7581 - val_loss: 0.4123 - val_acc: 0.8133
Epoch 2/25
 - 21s - loss: 0.3788 - acc: 0.8365 - val_loss: 0.4128 - val_acc: 0.8003
Epoch 3/25
 - 21s - loss: 0.3347 - acc: 0.8601 - val_loss: 0.3078 - val_acc: 0.8707
Epoch 4/25
 - 21s - loss: 0.3038 - acc: 0.8756 - val_loss: 0.2693 - val_acc: 0.8945
Epoch 5/25
 - 21s - loss: 0.2811 - acc: 0.8871 - val_loss: 0.2525 - val_acc: 0.8997
Epoch 6/25
 - 21s - loss: 0.2626 - acc: 0.8958 - val_loss: 0.2298 - val_acc: 0.9133
Epoch 7/25
 - 21s - loss: 0.2481 - acc: 0.9021 - val_loss: 0.2113 - val_acc: 0.9216
Epoch 8/25
 - 21s - loss: 0.2339 - acc: 0.9082 - val_loss: 0.2125 - val_acc: 0.9222
Epoch 9/25
 - 21s - loss: 0.2214 - acc: 0.9149 - val_loss: 0.1986 - val_acc: 0.9260
Epoch 10/25
 - 21s - loss: 0.2109 - acc: 0.9202 - val_loss: 0.1821 - val_acc: 0.9317
Epoch 11/25
 - 21s - loss: 0.1997 - acc: 0.9237 - val_loss: 0.1695 - val_acc: 0.9416
Epoch 12/25
 - 21s - loss: 0.1950 - acc: 0.9274 - val_loss: 0.1628 - val_acc: 0.9429
Epoch 13/25
 - 21s - loss: 0.1871 - acc: 0.9302 - val_loss: 0.1568 - val_acc: 0.9448
Epoch 14/25
 - 21s - loss: 0.1821 - acc: 0.9336 - val_loss: 0.1541 - val_acc: 0.9436
Epoch 15/25
 - 21s - loss: 0.1745 - acc: 0.9367 - val_loss: 0.1774 - val_acc: 0.9322
Epoch 16/25
 - 21s - loss: 0.1696 - acc: 0.9375 - val_loss: 0.1359 - val_acc: 0.9547
Epoch 17/25
 - 21s - loss: 0.1648 - acc: 0.9409 - val_loss: 0.1368 - val_acc: 0.9509
Epoch 18/25
 - 21s - loss: 0.1580 - acc: 0.9443 - val_loss: 0.1337 - val_acc: 0.9507
Epoch 19/25
 - 21s - loss: 0.1542 - acc: 0.9460 - val_loss: 0.1230 - val_acc: 0.9572
Epoch 20/25
 - 21s - loss: 0.1489 - acc: 0.9476 - val_loss: 0.1170 - val_acc: 0.9625
Epoch 21/25
 - 21s - loss: 0.1455 - acc: 0.9493 - val_loss: 0.1152 - val_acc: 0.9607
Epoch 22/25
 - 21s - loss: 0.1418 - acc: 0.9497 - val_loss: 0.1136 - val_acc: 0.9608
Epoch 23/25
 - 21s - loss: 0.1382 - acc: 0.9522 - val_loss: 0.1059 - val_acc: 0.9655
Epoch 24/25
 - 21s - loss: 0.1340 - acc: 0.9531 - val_loss: 0.1148 - val_acc: 0.9605
Epoch 25/25
 - 21s - loss: 0.1298 - acc: 0.9568 - val_loss: 0.1007 - val_acc: 0.9675
Test accuracy:0.812
current auc_score ------------------> 0.898
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  25  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   2592        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 34, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 34, 24, 24)   136         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 34, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   5508        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 52, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 52, 24, 24)   208         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 52, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 26, 24, 24)   1352        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 26, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 26, 12, 12)   104         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 26, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   4212        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 44, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 44, 12, 12)   176         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 44, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   7128        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 62, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 62, 12, 12)   248         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 62, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 8928)         0           activation_7[0][0]               
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            8929        flatten_1[0][0]                  
==================================================================================================
Total params: 32,289
Trainable params: 31,789
Non-trainable params: 500
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/25
 - 22s - loss: 0.4909 - acc: 0.7635 - val_loss: 0.3938 - val_acc: 0.8202
Epoch 2/25
 - 21s - loss: 0.3789 - acc: 0.8329 - val_loss: 0.3691 - val_acc: 0.8272
Epoch 3/25
 - 21s - loss: 0.3395 - acc: 0.8538 - val_loss: 0.3101 - val_acc: 0.8650
Epoch 4/25
 - 21s - loss: 0.3121 - acc: 0.8702 - val_loss: 0.2861 - val_acc: 0.8799
Epoch 5/25
 - 21s - loss: 0.2903 - acc: 0.8815 - val_loss: 0.2743 - val_acc: 0.8897
Epoch 6/25
 - 21s - loss: 0.2760 - acc: 0.8886 - val_loss: 0.2543 - val_acc: 0.8993
Epoch 7/25
 - 21s - loss: 0.2587 - acc: 0.8971 - val_loss: 0.2475 - val_acc: 0.8986
Epoch 8/25
 - 21s - loss: 0.2466 - acc: 0.9028 - val_loss: 0.2317 - val_acc: 0.9076
Epoch 9/25
 - 21s - loss: 0.2342 - acc: 0.9086 - val_loss: 0.2056 - val_acc: 0.9239
Epoch 10/25
 - 21s - loss: 0.2243 - acc: 0.9146 - val_loss: 0.2234 - val_acc: 0.9101
Epoch 11/25
 - 21s - loss: 0.2152 - acc: 0.9176 - val_loss: 0.1861 - val_acc: 0.9306
Epoch 12/25
 - 21s - loss: 0.2077 - acc: 0.9213 - val_loss: 0.1766 - val_acc: 0.9349
Epoch 13/25
 - 21s - loss: 0.1975 - acc: 0.9266 - val_loss: 0.1680 - val_acc: 0.9385
Epoch 14/25
 - 21s - loss: 0.1920 - acc: 0.9282 - val_loss: 0.1602 - val_acc: 0.9425
Epoch 15/25
 - 21s - loss: 0.1849 - acc: 0.9316 - val_loss: 0.1528 - val_acc: 0.9454
Epoch 16/25
 - 21s - loss: 0.1803 - acc: 0.9325 - val_loss: 0.1465 - val_acc: 0.9504
Epoch 17/25
 - 21s - loss: 0.1721 - acc: 0.9380 - val_loss: 0.1804 - val_acc: 0.9305
Epoch 18/25
 - 21s - loss: 0.1677 - acc: 0.9399 - val_loss: 0.1373 - val_acc: 0.9502
Epoch 19/25
 - 21s - loss: 0.1623 - acc: 0.9412 - val_loss: 0.1444 - val_acc: 0.9467
Epoch 20/25
 - 21s - loss: 0.1552 - acc: 0.9443 - val_loss: 0.1343 - val_acc: 0.9526
Epoch 21/25
 - 21s - loss: 0.1518 - acc: 0.9457 - val_loss: 0.1331 - val_acc: 0.9503
Epoch 22/25
 - 21s - loss: 0.1475 - acc: 0.9477 - val_loss: 0.1231 - val_acc: 0.9591
Epoch 23/25
 - 21s - loss: 0.1432 - acc: 0.9511 - val_loss: 0.1140 - val_acc: 0.9586
Epoch 24/25
 - 21s - loss: 0.1403 - acc: 0.9499 - val_loss: 0.1099 - val_acc: 0.9621
Epoch 25/25
 - 21s - loss: 0.1351 - acc: 0.9539 - val_loss: 0.1080 - val_acc: 0.9613
Test accuracy:0.839
current auc_score ------------------> 0.924
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  25  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   2592        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 34, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 34, 24, 24)   136         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 34, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   5508        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 52, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 52, 24, 24)   208         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 52, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 26, 24, 24)   1352        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 26, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 26, 12, 12)   104         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 26, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   4212        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 44, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 44, 12, 12)   176         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 44, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   7128        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 62, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 62, 12, 12)   248         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 62, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 8928)         0           activation_7[0][0]               
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            8929        flatten_1[0][0]                  
==================================================================================================
Total params: 32,289
Trainable params: 31,789
Non-trainable params: 500
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/25
 - 23s - loss: 0.4950 - acc: 0.7554 - val_loss: 0.4061 - val_acc: 0.8095
Epoch 2/25
 - 21s - loss: 0.3811 - acc: 0.8302 - val_loss: 0.3524 - val_acc: 0.8420
Epoch 3/25
 - 21s - loss: 0.3389 - acc: 0.8535 - val_loss: 0.3187 - val_acc: 0.8616
Epoch 4/25
 - 21s - loss: 0.3126 - acc: 0.8683 - val_loss: 0.2957 - val_acc: 0.8765
Epoch 5/25
 - 21s - loss: 0.2882 - acc: 0.8837 - val_loss: 0.2724 - val_acc: 0.8921
Epoch 6/25
 - 21s - loss: 0.2719 - acc: 0.8904 - val_loss: 0.2407 - val_acc: 0.9099
Epoch 7/25
 - 21s - loss: 0.2558 - acc: 0.8994 - val_loss: 0.2390 - val_acc: 0.9098
Epoch 8/25
 - 21s - loss: 0.2441 - acc: 0.9050 - val_loss: 0.2243 - val_acc: 0.9159
Epoch 9/25
 - 21s - loss: 0.2317 - acc: 0.9098 - val_loss: 0.2131 - val_acc: 0.9206
Epoch 10/25
 - 21s - loss: 0.2216 - acc: 0.9149 - val_loss: 0.1958 - val_acc: 0.9281
Epoch 11/25
 - 21s - loss: 0.2111 - acc: 0.9192 - val_loss: 0.1891 - val_acc: 0.9320
Epoch 12/25
 - 21s - loss: 0.2013 - acc: 0.9249 - val_loss: 0.1893 - val_acc: 0.9301
Epoch 13/25
 - 21s - loss: 0.1950 - acc: 0.9272 - val_loss: 0.1658 - val_acc: 0.9419
Epoch 14/25
 - 21s - loss: 0.1860 - acc: 0.9302 - val_loss: 0.1607 - val_acc: 0.9438
Epoch 15/25
 - 21s - loss: 0.1802 - acc: 0.9352 - val_loss: 0.1600 - val_acc: 0.9442
Epoch 16/25
 - 21s - loss: 0.1729 - acc: 0.9370 - val_loss: 0.1537 - val_acc: 0.9469
Epoch 17/25
 - 21s - loss: 0.1692 - acc: 0.9401 - val_loss: 0.1405 - val_acc: 0.9517
Epoch 18/25
 - 24s - loss: 0.1642 - acc: 0.9406 - val_loss: 0.1327 - val_acc: 0.9548
Epoch 19/25
 - 23s - loss: 0.1587 - acc: 0.9430 - val_loss: 0.1342 - val_acc: 0.9553
Epoch 20/25
 - 22s - loss: 0.1538 - acc: 0.9453 - val_loss: 0.1287 - val_acc: 0.9559
Epoch 21/25
 - 22s - loss: 0.1518 - acc: 0.9466 - val_loss: 0.1253 - val_acc: 0.9585
Epoch 22/25
 - 22s - loss: 0.1462 - acc: 0.9480 - val_loss: 0.1180 - val_acc: 0.9620
Epoch 23/25
 - 22s - loss: 0.1409 - acc: 0.9513 - val_loss: 0.1141 - val_acc: 0.9631
Epoch 24/25
 - 22s - loss: 0.1389 - acc: 0.9527 - val_loss: 0.1089 - val_acc: 0.9659
Epoch 25/25
 - 22s - loss: 0.1359 - acc: 0.9540 - val_loss: 0.1094 - val_acc: 0.9635
Test accuracy:0.837
current auc_score ------------------> 0.913
accuracies:  [0.8350806451612903, 0.7942204301075269, 0.8521505376344086, 0.8120967741935484, 0.865994623655914, 0.8384408602150538, 0.8385752688172043, 0.8120967741935484, 0.8387096774193549, 0.837231182795699]
aucs:  [0.905, 0.8969, 0.9304, 0.9156, 0.9352, 0.9138, 0.9172, 0.8977, 0.924, 0.9131]
mean and std AUC:  0.915+/-0.012  max:   0.9352
['2-2', '24', '2', '16', '0.2', '0.07', '24', 'adadelta', '0.5', 'FALSE', '64', 'flatten']
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  24  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  24  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 24, 24, 24)   3456        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 24, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 40, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 40, 24, 24)   160         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 40, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 24, 24, 24)   8640        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 64, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 64, 24, 24)   256         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 64, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 32, 24, 24)   2048        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 32, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 32, 12, 12)   128         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 32, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 24, 12, 12)   6912        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 24, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 56, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 56, 12, 12)   224         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 56, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 24, 12, 12)   12096       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 24, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 80, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 80, 12, 12)   320         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 80, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 11520)        0           activation_7[0][0]               
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            11521       flatten_1[0][0]                  
==================================================================================================
Total params: 47,457
Trainable params: 46,849
Non-trainable params: 608
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/24
 - 24s - loss: 0.4712 - acc: 0.7757 - val_loss: 0.3696 - val_acc: 0.8380
Epoch 2/24
 - 23s - loss: 0.3544 - acc: 0.8476 - val_loss: 0.3102 - val_acc: 0.8668
Epoch 3/24
 - 23s - loss: 0.3077 - acc: 0.8709 - val_loss: 0.2722 - val_acc: 0.8892
Epoch 4/24
 - 23s - loss: 0.2781 - acc: 0.8860 - val_loss: 0.2458 - val_acc: 0.9015
Epoch 5/24
 - 23s - loss: 0.2576 - acc: 0.8976 - val_loss: 0.2283 - val_acc: 0.9086
Epoch 6/24
 - 23s - loss: 0.2388 - acc: 0.9052 - val_loss: 0.2036 - val_acc: 0.9214
Epoch 7/24
 - 22s - loss: 0.2213 - acc: 0.9160 - val_loss: 0.1895 - val_acc: 0.9302
Epoch 8/24
 - 23s - loss: 0.2099 - acc: 0.9213 - val_loss: 0.1786 - val_acc: 0.9342
Epoch 9/24
 - 22s - loss: 0.1968 - acc: 0.9275 - val_loss: 0.1657 - val_acc: 0.9425
Epoch 10/24
 - 23s - loss: 0.1863 - acc: 0.9316 - val_loss: 0.1527 - val_acc: 0.9470
Epoch 11/24
 - 23s - loss: 0.1779 - acc: 0.9371 - val_loss: 0.1564 - val_acc: 0.9443
Epoch 12/24
 - 23s - loss: 0.1687 - acc: 0.9404 - val_loss: 0.1403 - val_acc: 0.9499
Epoch 13/24
 - 23s - loss: 0.1608 - acc: 0.9428 - val_loss: 0.1369 - val_acc: 0.9494
Epoch 14/24
 - 22s - loss: 0.1569 - acc: 0.9443 - val_loss: 0.1237 - val_acc: 0.9583
Epoch 15/24
 - 23s - loss: 0.1465 - acc: 0.9490 - val_loss: 0.1389 - val_acc: 0.9534
Epoch 16/24
 - 22s - loss: 0.1447 - acc: 0.9490 - val_loss: 0.1078 - val_acc: 0.9655
Epoch 17/24
 - 23s - loss: 0.1355 - acc: 0.9542 - val_loss: 0.1052 - val_acc: 0.9686
Epoch 18/24
 - 22s - loss: 0.1306 - acc: 0.9566 - val_loss: 0.1014 - val_acc: 0.9686
Epoch 19/24
 - 22s - loss: 0.1271 - acc: 0.9574 - val_loss: 0.0959 - val_acc: 0.9706
Epoch 20/24
 - 21s - loss: 0.1225 - acc: 0.9581 - val_loss: 0.0891 - val_acc: 0.9734
Epoch 21/24
 - 22s - loss: 0.1203 - acc: 0.9591 - val_loss: 0.0874 - val_acc: 0.9738
Epoch 22/24
 - 22s - loss: 0.1158 - acc: 0.9616 - val_loss: 0.0834 - val_acc: 0.9762
Epoch 23/24
 - 23s - loss: 0.1112 - acc: 0.9627 - val_loss: 0.0785 - val_acc: 0.9783
Epoch 24/24
 - 22s - loss: 0.1078 - acc: 0.9644 - val_loss: 0.0750 - val_acc: 0.9798
Test accuracy:0.829
current auc_score ------------------> 0.901
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  24  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  24  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 24, 24, 24)   3456        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 24, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 40, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 40, 24, 24)   160         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 40, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 24, 24, 24)   8640        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 64, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 64, 24, 24)   256         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 64, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 32, 24, 24)   2048        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 32, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 32, 12, 12)   128         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 32, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 24, 12, 12)   6912        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 24, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 56, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 56, 12, 12)   224         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 56, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 24, 12, 12)   12096       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 24, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 80, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 80, 12, 12)   320         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 80, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 11520)        0           activation_7[0][0]               
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            11521       flatten_1[0][0]                  
==================================================================================================
Total params: 47,457
Trainable params: 46,849
Non-trainable params: 608
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/24
 - 23s - loss: 0.4962 - acc: 0.7594 - val_loss: 0.4059 - val_acc: 0.8124
Epoch 2/24
 - 22s - loss: 0.3699 - acc: 0.8396 - val_loss: 0.3541 - val_acc: 0.8397
Epoch 3/24
 - 22s - loss: 0.3208 - acc: 0.8655 - val_loss: 0.2840 - val_acc: 0.8824
Epoch 4/24
 - 23s - loss: 0.2905 - acc: 0.8799 - val_loss: 0.2679 - val_acc: 0.8903
Epoch 5/24
 - 21s - loss: 0.2666 - acc: 0.8929 - val_loss: 0.2343 - val_acc: 0.9070
Epoch 6/24
 - 22s - loss: 0.2475 - acc: 0.9017 - val_loss: 0.2270 - val_acc: 0.9106
Epoch 7/24
 - 21s - loss: 0.2327 - acc: 0.9098 - val_loss: 0.2241 - val_acc: 0.9113
Epoch 8/24
 - 21s - loss: 0.2178 - acc: 0.9164 - val_loss: 0.1936 - val_acc: 0.9248
Epoch 9/24
 - 21s - loss: 0.2068 - acc: 0.9217 - val_loss: 0.1772 - val_acc: 0.9379
Epoch 10/24
 - 21s - loss: 0.1948 - acc: 0.9275 - val_loss: 0.1626 - val_acc: 0.9419
Epoch 11/24
 - 21s - loss: 0.1855 - acc: 0.9319 - val_loss: 0.1499 - val_acc: 0.9482
Epoch 12/24
 - 21s - loss: 0.1753 - acc: 0.9360 - val_loss: 0.1459 - val_acc: 0.9490
Epoch 13/24
 - 21s - loss: 0.1681 - acc: 0.9399 - val_loss: 0.1397 - val_acc: 0.9539
Epoch 14/24
 - 21s - loss: 0.1614 - acc: 0.9422 - val_loss: 0.1274 - val_acc: 0.9582
Epoch 15/24
 - 21s - loss: 0.1545 - acc: 0.9449 - val_loss: 0.1232 - val_acc: 0.9615
Epoch 16/24
 - 21s - loss: 0.1501 - acc: 0.9483 - val_loss: 0.1176 - val_acc: 0.9586
Epoch 17/24
 - 21s - loss: 0.1433 - acc: 0.9503 - val_loss: 0.1150 - val_acc: 0.9587
Epoch 18/24
 - 21s - loss: 0.1372 - acc: 0.9539 - val_loss: 0.1079 - val_acc: 0.9684
Epoch 19/24
 - 21s - loss: 0.1329 - acc: 0.9550 - val_loss: 0.0994 - val_acc: 0.9694
Epoch 20/24
 - 21s - loss: 0.1293 - acc: 0.9556 - val_loss: 0.0951 - val_acc: 0.9733
Epoch 21/24
 - 21s - loss: 0.1235 - acc: 0.9591 - val_loss: 0.0941 - val_acc: 0.9723
Epoch 22/24
 - 21s - loss: 0.1191 - acc: 0.9602 - val_loss: 0.1010 - val_acc: 0.9659
Epoch 23/24
 - 21s - loss: 0.1168 - acc: 0.9607 - val_loss: 0.0930 - val_acc: 0.9691
Epoch 24/24
 - 21s - loss: 0.1122 - acc: 0.9628 - val_loss: 0.0872 - val_acc: 0.9715
Epoch 00024: early stopping
Test accuracy:0.831
current auc_score ------------------> 0.896
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  24  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  24  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 24, 24, 24)   3456        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 24, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 40, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 40, 24, 24)   160         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 40, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 24, 24, 24)   8640        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 64, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 64, 24, 24)   256         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 64, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 32, 24, 24)   2048        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 32, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 32, 12, 12)   128         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 32, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 24, 12, 12)   6912        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 24, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 56, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 56, 12, 12)   224         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 56, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 24, 12, 12)   12096       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 24, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 80, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 80, 12, 12)   320         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 80, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 11520)        0           activation_7[0][0]               
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            11521       flatten_1[0][0]                  
==================================================================================================
Total params: 47,457
Trainable params: 46,849
Non-trainable params: 608
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/24
 - 23s - loss: 0.4747 - acc: 0.7717 - val_loss: 0.3631 - val_acc: 0.8357
Epoch 2/24
 - 21s - loss: 0.3523 - acc: 0.8473 - val_loss: 0.3165 - val_acc: 0.8607
Epoch 3/24
 - 21s - loss: 0.3074 - acc: 0.8725 - val_loss: 0.2728 - val_acc: 0.8869
Epoch 4/24
 - 21s - loss: 0.2776 - acc: 0.8867 - val_loss: 0.2379 - val_acc: 0.9074
Epoch 5/24
 - 21s - loss: 0.2528 - acc: 0.9002 - val_loss: 0.2271 - val_acc: 0.9114
Epoch 6/24
 - 21s - loss: 0.2331 - acc: 0.9094 - val_loss: 0.2003 - val_acc: 0.9267
Epoch 7/24
 - 21s - loss: 0.2188 - acc: 0.9184 - val_loss: 0.1998 - val_acc: 0.9253
Epoch 8/24
 - 21s - loss: 0.2054 - acc: 0.9232 - val_loss: 0.1886 - val_acc: 0.9307
Epoch 9/24
 - 21s - loss: 0.1930 - acc: 0.9288 - val_loss: 0.1595 - val_acc: 0.9443
Epoch 10/24
 - 21s - loss: 0.1814 - acc: 0.9338 - val_loss: 0.1675 - val_acc: 0.9408
Epoch 11/24
 - 21s - loss: 0.1730 - acc: 0.9383 - val_loss: 0.1415 - val_acc: 0.9554
Epoch 12/24
 - 21s - loss: 0.1636 - acc: 0.9430 - val_loss: 0.1357 - val_acc: 0.9561
Epoch 13/24
 - 21s - loss: 0.1565 - acc: 0.9460 - val_loss: 0.1320 - val_acc: 0.9534
Epoch 14/24
 - 21s - loss: 0.1480 - acc: 0.9495 - val_loss: 0.1181 - val_acc: 0.9651
Epoch 15/24
 - 21s - loss: 0.1432 - acc: 0.9502 - val_loss: 0.1128 - val_acc: 0.9656
Epoch 16/24
 - 21s - loss: 0.1366 - acc: 0.9535 - val_loss: 0.1073 - val_acc: 0.9698
Epoch 17/24
 - 21s - loss: 0.1333 - acc: 0.9552 - val_loss: 0.1015 - val_acc: 0.9715
Epoch 18/24
 - 21s - loss: 0.1277 - acc: 0.9566 - val_loss: 0.0955 - val_acc: 0.9725
Epoch 19/24
 - 21s - loss: 0.1220 - acc: 0.9589 - val_loss: 0.0962 - val_acc: 0.9735
Epoch 20/24
 - 21s - loss: 0.1184 - acc: 0.9613 - val_loss: 0.0927 - val_acc: 0.9714
Epoch 21/24
 - 21s - loss: 0.1143 - acc: 0.9624 - val_loss: 0.0950 - val_acc: 0.9746
Epoch 22/24
 - 21s - loss: 0.1098 - acc: 0.9642 - val_loss: 0.0855 - val_acc: 0.9758
Epoch 23/24
 - 21s - loss: 0.1070 - acc: 0.9654 - val_loss: 0.0800 - val_acc: 0.9769
Epoch 24/24
 - 21s - loss: 0.1038 - acc: 0.9667 - val_loss: 0.0785 - val_acc: 0.9778
Test accuracy:0.826
current auc_score ------------------> 0.913
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  24  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  24  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 24, 24, 24)   3456        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 24, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 40, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 40, 24, 24)   160         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 40, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 24, 24, 24)   8640        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 64, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 64, 24, 24)   256         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 64, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 32, 24, 24)   2048        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 32, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 32, 12, 12)   128         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 32, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 24, 12, 12)   6912        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 24, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 56, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 56, 12, 12)   224         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 56, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 24, 12, 12)   12096       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 24, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 80, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 80, 12, 12)   320         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 80, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 11520)        0           activation_7[0][0]               
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            11521       flatten_1[0][0]                  
==================================================================================================
Total params: 47,457
Trainable params: 46,849
Non-trainable params: 608
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/24
 - 23s - loss: 0.4816 - acc: 0.7662 - val_loss: 0.3867 - val_acc: 0.8296
Epoch 2/24
 - 22s - loss: 0.3660 - acc: 0.8387 - val_loss: 0.3843 - val_acc: 0.8134
Epoch 3/24
 - 24s - loss: 0.3244 - acc: 0.8613 - val_loss: 0.3243 - val_acc: 0.8553
Epoch 4/24
 - 22s - loss: 0.2946 - acc: 0.8771 - val_loss: 0.2828 - val_acc: 0.8818
Epoch 5/24
 - 22s - loss: 0.2732 - acc: 0.8897 - val_loss: 0.2393 - val_acc: 0.9081
Epoch 6/24
 - 22s - loss: 0.2544 - acc: 0.8986 - val_loss: 0.2633 - val_acc: 0.8913
Epoch 7/24
 - 23s - loss: 0.2389 - acc: 0.9069 - val_loss: 0.2423 - val_acc: 0.9019
Epoch 8/24
 - 23s - loss: 0.2237 - acc: 0.9144 - val_loss: 0.2102 - val_acc: 0.9216
Epoch 9/24
 - 22s - loss: 0.2112 - acc: 0.9197 - val_loss: 0.1822 - val_acc: 0.9345
Epoch 10/24
 - 23s - loss: 0.1996 - acc: 0.9246 - val_loss: 0.2199 - val_acc: 0.9147
Epoch 11/24
 - 23s - loss: 0.1888 - acc: 0.9299 - val_loss: 0.1938 - val_acc: 0.9286
Epoch 12/24
 - 22s - loss: 0.1791 - acc: 0.9350 - val_loss: 0.1587 - val_acc: 0.9415
Epoch 13/24
 - 22s - loss: 0.1721 - acc: 0.9383 - val_loss: 0.1521 - val_acc: 0.9480
Epoch 14/24
 - 22s - loss: 0.1629 - acc: 0.9418 - val_loss: 0.1643 - val_acc: 0.9428
Epoch 15/24
 - 23s - loss: 0.1581 - acc: 0.9444 - val_loss: 0.1347 - val_acc: 0.9558
Epoch 16/24
 - 22s - loss: 0.1493 - acc: 0.9466 - val_loss: 0.1622 - val_acc: 0.9406
Epoch 17/24
 - 23s - loss: 0.1456 - acc: 0.9498 - val_loss: 0.1389 - val_acc: 0.9532
Epoch 18/24
 - 22s - loss: 0.1388 - acc: 0.9523 - val_loss: 0.1475 - val_acc: 0.9513

Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 19/24
 - 22s - loss: 0.1322 - acc: 0.9556 - val_loss: 0.1223 - val_acc: 0.9613
Epoch 20/24
 - 22s - loss: 0.1282 - acc: 0.9574 - val_loss: 0.1193 - val_acc: 0.9649
Epoch 21/24
 - 22s - loss: 0.1289 - acc: 0.9569 - val_loss: 0.1222 - val_acc: 0.9631
Epoch 22/24
 - 22s - loss: 0.1258 - acc: 0.9580 - val_loss: 0.1131 - val_acc: 0.9667
Epoch 23/24
 - 23s - loss: 0.1243 - acc: 0.9585 - val_loss: 0.1077 - val_acc: 0.9684
Epoch 24/24
 - 22s - loss: 0.1219 - acc: 0.9602 - val_loss: 0.1013 - val_acc: 0.9705
Test accuracy:0.809
current auc_score ------------------> 0.903
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  24  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  24  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 24, 24, 24)   3456        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 24, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 40, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 40, 24, 24)   160         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 40, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 24, 24, 24)   8640        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 64, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 64, 24, 24)   256         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 64, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 32, 24, 24)   2048        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 32, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 32, 12, 12)   128         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 32, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 24, 12, 12)   6912        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 24, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 56, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 56, 12, 12)   224         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 56, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 24, 12, 12)   12096       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 24, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 80, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 80, 12, 12)   320         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 80, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 11520)        0           activation_7[0][0]               
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            11521       flatten_1[0][0]                  
==================================================================================================
Total params: 47,457
Trainable params: 46,849
Non-trainable params: 608
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/24
 - 24s - loss: 0.4731 - acc: 0.7741 - val_loss: 0.3916 - val_acc: 0.8281
Epoch 2/24
 - 22s - loss: 0.3611 - acc: 0.8433 - val_loss: 0.3262 - val_acc: 0.8604
Epoch 3/24
 - 21s - loss: 0.3163 - acc: 0.8659 - val_loss: 0.3488 - val_acc: 0.8363
Epoch 4/24
 - 22s - loss: 0.2859 - acc: 0.8825 - val_loss: 0.2674 - val_acc: 0.8898
Epoch 5/24
 - 21s - loss: 0.2629 - acc: 0.8930 - val_loss: 0.2388 - val_acc: 0.9089
Epoch 6/24
 - 21s - loss: 0.2456 - acc: 0.9047 - val_loss: 0.2135 - val_acc: 0.9203
Epoch 7/24
 - 21s - loss: 0.2307 - acc: 0.9094 - val_loss: 0.2219 - val_acc: 0.9139
Epoch 8/24
 - 21s - loss: 0.2165 - acc: 0.9179 - val_loss: 0.1963 - val_acc: 0.9291
Epoch 9/24
 - 21s - loss: 0.2028 - acc: 0.9237 - val_loss: 0.2124 - val_acc: 0.9184
Epoch 10/24
 - 21s - loss: 0.1959 - acc: 0.9272 - val_loss: 0.1883 - val_acc: 0.9287
Epoch 11/24
 - 21s - loss: 0.1855 - acc: 0.9318 - val_loss: 0.1830 - val_acc: 0.9296
Epoch 12/24
 - 21s - loss: 0.1777 - acc: 0.9347 - val_loss: 0.1578 - val_acc: 0.9454
Epoch 13/24
 - 21s - loss: 0.1684 - acc: 0.9400 - val_loss: 0.1725 - val_acc: 0.9346
Epoch 14/24
 - 21s - loss: 0.1639 - acc: 0.9412 - val_loss: 0.1819 - val_acc: 0.9266
Epoch 15/24
 - 21s - loss: 0.1585 - acc: 0.9432 - val_loss: 0.1395 - val_acc: 0.9562
Epoch 16/24
 - 21s - loss: 0.1495 - acc: 0.9487 - val_loss: 0.1221 - val_acc: 0.9601
Epoch 17/24
 - 21s - loss: 0.1430 - acc: 0.9504 - val_loss: 0.1356 - val_acc: 0.9539
Epoch 18/24
 - 21s - loss: 0.1391 - acc: 0.9525 - val_loss: 0.1299 - val_acc: 0.9561
Epoch 19/24
 - 21s - loss: 0.1352 - acc: 0.9546 - val_loss: 0.1200 - val_acc: 0.9606
Epoch 20/24
 - 21s - loss: 0.1303 - acc: 0.9558 - val_loss: 0.1193 - val_acc: 0.9606
Epoch 21/24
 - 21s - loss: 0.1284 - acc: 0.9582 - val_loss: 0.1048 - val_acc: 0.9661
Epoch 22/24
 - 21s - loss: 0.1230 - acc: 0.9590 - val_loss: 0.1011 - val_acc: 0.9672
Epoch 23/24
 - 21s - loss: 0.1211 - acc: 0.9601 - val_loss: 0.0936 - val_acc: 0.9729
Epoch 24/24
 - 21s - loss: 0.1162 - acc: 0.9613 - val_loss: 0.0999 - val_acc: 0.9695
Test accuracy:0.821
current auc_score ------------------> 0.905
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  24  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  24  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 24, 24, 24)   3456        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 24, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 40, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 40, 24, 24)   160         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 40, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 24, 24, 24)   8640        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 64, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 64, 24, 24)   256         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 64, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 32, 24, 24)   2048        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 32, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 32, 12, 12)   128         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 32, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 24, 12, 12)   6912        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 24, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 56, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 56, 12, 12)   224         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 56, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 24, 12, 12)   12096       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 24, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 80, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 80, 12, 12)   320         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 80, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 11520)        0           activation_7[0][0]               
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            11521       flatten_1[0][0]                  
==================================================================================================
Total params: 47,457
Trainable params: 46,849
Non-trainable params: 608
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/24
 - 23s - loss: 0.4777 - acc: 0.7772 - val_loss: 0.3797 - val_acc: 0.8332
Epoch 2/24
 - 21s - loss: 0.3702 - acc: 0.8428 - val_loss: 0.3368 - val_acc: 0.8562
Epoch 3/24
 - 21s - loss: 0.3246 - acc: 0.8647 - val_loss: 0.2906 - val_acc: 0.8844
Epoch 4/24
 - 21s - loss: 0.2985 - acc: 0.8791 - val_loss: 0.3374 - val_acc: 0.8453
Epoch 5/24
 - 21s - loss: 0.2748 - acc: 0.8910 - val_loss: 0.2622 - val_acc: 0.8950
Epoch 6/24
 - 21s - loss: 0.2562 - acc: 0.8978 - val_loss: 0.2490 - val_acc: 0.9027
Epoch 7/24
 - 21s - loss: 0.2409 - acc: 0.9068 - val_loss: 0.2087 - val_acc: 0.9258
Epoch 8/24
 - 21s - loss: 0.2267 - acc: 0.9133 - val_loss: 0.2142 - val_acc: 0.9199
Epoch 9/24
 - 21s - loss: 0.2152 - acc: 0.9184 - val_loss: 0.2222 - val_acc: 0.9149
Epoch 10/24
 - 21s - loss: 0.2032 - acc: 0.9244 - val_loss: 0.2180 - val_acc: 0.9144

Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 11/24
 - 21s - loss: 0.1915 - acc: 0.9297 - val_loss: 0.1770 - val_acc: 0.9380
Epoch 12/24
 - 21s - loss: 0.1895 - acc: 0.9320 - val_loss: 0.1744 - val_acc: 0.9376
Epoch 13/24
 - 21s - loss: 0.1846 - acc: 0.9320 - val_loss: 0.1743 - val_acc: 0.9391
Epoch 14/24
 - 21s - loss: 0.1825 - acc: 0.9348 - val_loss: 0.1754 - val_acc: 0.9374
Epoch 15/24
 - 21s - loss: 0.1806 - acc: 0.9347 - val_loss: 0.1643 - val_acc: 0.9425
Epoch 16/24
 - 21s - loss: 0.1781 - acc: 0.9360 - val_loss: 0.1821 - val_acc: 0.9342
Epoch 17/24
 - 21s - loss: 0.1749 - acc: 0.9362 - val_loss: 0.1666 - val_acc: 0.9430
Epoch 18/24
 - 21s - loss: 0.1722 - acc: 0.9383 - val_loss: 0.1571 - val_acc: 0.9472
Epoch 19/24
 - 21s - loss: 0.1716 - acc: 0.9382 - val_loss: 0.1536 - val_acc: 0.9493
Epoch 20/24
 - 21s - loss: 0.1682 - acc: 0.9398 - val_loss: 0.1559 - val_acc: 0.9460
Epoch 21/24
 - 21s - loss: 0.1652 - acc: 0.9407 - val_loss: 0.1654 - val_acc: 0.9425
Epoch 22/24
 - 21s - loss: 0.1634 - acc: 0.9423 - val_loss: 0.1504 - val_acc: 0.9494
Epoch 23/24
 - 21s - loss: 0.1618 - acc: 0.9429 - val_loss: 0.1500 - val_acc: 0.9499
Epoch 24/24
 - 21s - loss: 0.1594 - acc: 0.9453 - val_loss: 0.1550 - val_acc: 0.9472
Test accuracy:0.814
current auc_score ------------------> 0.915
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  24  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  24  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 24, 24, 24)   3456        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 24, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 40, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 40, 24, 24)   160         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 40, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 24, 24, 24)   8640        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 64, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 64, 24, 24)   256         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 64, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 32, 24, 24)   2048        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 32, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 32, 12, 12)   128         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 32, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 24, 12, 12)   6912        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 24, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 56, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 56, 12, 12)   224         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 56, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 24, 12, 12)   12096       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 24, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 80, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 80, 12, 12)   320         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 80, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 11520)        0           activation_7[0][0]               
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            11521       flatten_1[0][0]                  
==================================================================================================
Total params: 47,457
Trainable params: 46,849
Non-trainable params: 608
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/24
 - 23s - loss: 0.4745 - acc: 0.7715 - val_loss: 0.3778 - val_acc: 0.8337
Epoch 2/24
 - 21s - loss: 0.3571 - acc: 0.8442 - val_loss: 0.3132 - val_acc: 0.8653
Epoch 3/24
 - 21s - loss: 0.3144 - acc: 0.8661 - val_loss: 0.3120 - val_acc: 0.8631
Epoch 4/24
 - 21s - loss: 0.2837 - acc: 0.8823 - val_loss: 0.2495 - val_acc: 0.8993
Epoch 5/24
 - 21s - loss: 0.2588 - acc: 0.8944 - val_loss: 0.2260 - val_acc: 0.9095
Epoch 6/24
 - 21s - loss: 0.2423 - acc: 0.9057 - val_loss: 0.2184 - val_acc: 0.9154
Epoch 7/24
 - 21s - loss: 0.2251 - acc: 0.9118 - val_loss: 0.1935 - val_acc: 0.9281
Epoch 8/24
 - 21s - loss: 0.2105 - acc: 0.9202 - val_loss: 0.1873 - val_acc: 0.9332
Epoch 9/24
 - 21s - loss: 0.1980 - acc: 0.9262 - val_loss: 0.1960 - val_acc: 0.9227
Epoch 10/24
 - 21s - loss: 0.1875 - acc: 0.9294 - val_loss: 0.1706 - val_acc: 0.9374
Epoch 11/24
 - 21s - loss: 0.1773 - acc: 0.9353 - val_loss: 0.1601 - val_acc: 0.9449
Epoch 12/24
 - 21s - loss: 0.1692 - acc: 0.9387 - val_loss: 0.1487 - val_acc: 0.9469
Epoch 13/24
 - 21s - loss: 0.1608 - acc: 0.9429 - val_loss: 0.1326 - val_acc: 0.9552
Epoch 14/24
 - 21s - loss: 0.1563 - acc: 0.9446 - val_loss: 0.1236 - val_acc: 0.9605
Epoch 15/24
 - 21s - loss: 0.1483 - acc: 0.9483 - val_loss: 0.1266 - val_acc: 0.9549
Epoch 16/24
 - 21s - loss: 0.1427 - acc: 0.9511 - val_loss: 0.1216 - val_acc: 0.9593
Epoch 17/24
 - 21s - loss: 0.1358 - acc: 0.9541 - val_loss: 0.1096 - val_acc: 0.9622
Epoch 18/24
 - 21s - loss: 0.1308 - acc: 0.9548 - val_loss: 0.1054 - val_acc: 0.9650
Epoch 19/24
 - 21s - loss: 0.1264 - acc: 0.9569 - val_loss: 0.1095 - val_acc: 0.9654
Epoch 20/24
 - 21s - loss: 0.1228 - acc: 0.9584 - val_loss: 0.0950 - val_acc: 0.9698
Epoch 21/24
 - 21s - loss: 0.1157 - acc: 0.9606 - val_loss: 0.1008 - val_acc: 0.9650
Epoch 22/24
 - 21s - loss: 0.1150 - acc: 0.9619 - val_loss: 0.0940 - val_acc: 0.9679
Epoch 23/24
 - 21s - loss: 0.1117 - acc: 0.9639 - val_loss: 0.0941 - val_acc: 0.9705
Epoch 24/24
 - 21s - loss: 0.1075 - acc: 0.9654 - val_loss: 0.0827 - val_acc: 0.9748
Test accuracy:0.797
current auc_score ------------------> 0.900
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  24  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  24  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 24, 24, 24)   3456        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 24, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 40, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 40, 24, 24)   160         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 40, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 24, 24, 24)   8640        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 64, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 64, 24, 24)   256         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 64, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 32, 24, 24)   2048        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 32, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 32, 12, 12)   128         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 32, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 24, 12, 12)   6912        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 24, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 56, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 56, 12, 12)   224         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 56, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 24, 12, 12)   12096       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 24, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 80, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 80, 12, 12)   320         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 80, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 11520)        0           activation_7[0][0]               
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            11521       flatten_1[0][0]                  
==================================================================================================
Total params: 47,457
Trainable params: 46,849
Non-trainable params: 608
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/24
 - 23s - loss: 0.4983 - acc: 0.7595 - val_loss: 0.3956 - val_acc: 0.8277
Epoch 2/24
 - 21s - loss: 0.3697 - acc: 0.8409 - val_loss: 0.3262 - val_acc: 0.8637
Epoch 3/24
 - 21s - loss: 0.3199 - acc: 0.8663 - val_loss: 0.2946 - val_acc: 0.8753
Epoch 4/24
 - 21s - loss: 0.2873 - acc: 0.8825 - val_loss: 0.3152 - val_acc: 0.8571
Epoch 5/24
 - 21s - loss: 0.2647 - acc: 0.8932 - val_loss: 0.2379 - val_acc: 0.9075
Epoch 6/24
 - 21s - loss: 0.2458 - acc: 0.9022 - val_loss: 0.2641 - val_acc: 0.8908
Epoch 7/24
 - 21s - loss: 0.2308 - acc: 0.9101 - val_loss: 0.2092 - val_acc: 0.9201
Epoch 8/24
 - 21s - loss: 0.2167 - acc: 0.9173 - val_loss: 0.1909 - val_acc: 0.9302
Epoch 9/24
 - 21s - loss: 0.2047 - acc: 0.9226 - val_loss: 0.1813 - val_acc: 0.9383
Epoch 10/24
 - 21s - loss: 0.1969 - acc: 0.9264 - val_loss: 0.1636 - val_acc: 0.9404
Epoch 11/24
 - 21s - loss: 0.1866 - acc: 0.9304 - val_loss: 0.1582 - val_acc: 0.9436
Epoch 12/24
 - 21s - loss: 0.1779 - acc: 0.9357 - val_loss: 0.1595 - val_acc: 0.9453
Epoch 13/24
 - 21s - loss: 0.1698 - acc: 0.9393 - val_loss: 0.1411 - val_acc: 0.9570
Epoch 14/24
 - 21s - loss: 0.1645 - acc: 0.9415 - val_loss: 0.1345 - val_acc: 0.9521
Epoch 15/24
 - 21s - loss: 0.1551 - acc: 0.9454 - val_loss: 0.1289 - val_acc: 0.9572
Epoch 16/24
 - 21s - loss: 0.1495 - acc: 0.9481 - val_loss: 0.1232 - val_acc: 0.9587
Epoch 17/24
 - 21s - loss: 0.1469 - acc: 0.9487 - val_loss: 0.1159 - val_acc: 0.9634
Epoch 18/24
 - 21s - loss: 0.1410 - acc: 0.9513 - val_loss: 0.1106 - val_acc: 0.9642
Epoch 19/24
 - 21s - loss: 0.1368 - acc: 0.9524 - val_loss: 0.1062 - val_acc: 0.9667
Epoch 20/24
 - 21s - loss: 0.1333 - acc: 0.9547 - val_loss: 0.1035 - val_acc: 0.9664
Epoch 21/24
 - 21s - loss: 0.1275 - acc: 0.9564 - val_loss: 0.0998 - val_acc: 0.9685
Epoch 22/24
 - 21s - loss: 0.1234 - acc: 0.9575 - val_loss: 0.0958 - val_acc: 0.9714
Epoch 23/24
 - 21s - loss: 0.1211 - acc: 0.9582 - val_loss: 0.1028 - val_acc: 0.9657
Epoch 24/24
 - 21s - loss: 0.1166 - acc: 0.9607 - val_loss: 0.1038 - val_acc: 0.9634
Test accuracy:0.828
current auc_score ------------------> 0.907
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  24  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  24  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 24, 24, 24)   3456        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 24, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 40, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 40, 24, 24)   160         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 40, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 24, 24, 24)   8640        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 64, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 64, 24, 24)   256         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 64, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 32, 24, 24)   2048        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 32, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 32, 12, 12)   128         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 32, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 24, 12, 12)   6912        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 24, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 56, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 56, 12, 12)   224         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 56, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 24, 12, 12)   12096       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 24, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 80, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 80, 12, 12)   320         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 80, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 11520)        0           activation_7[0][0]               
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            11521       flatten_1[0][0]                  
==================================================================================================
Total params: 47,457
Trainable params: 46,849
Non-trainable params: 608
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/24
 - 23s - loss: 0.4713 - acc: 0.7778 - val_loss: 0.3815 - val_acc: 0.8304
Epoch 2/24
 - 21s - loss: 0.3632 - acc: 0.8417 - val_loss: 0.3745 - val_acc: 0.8244
Epoch 3/24
 - 21s - loss: 0.3155 - acc: 0.8693 - val_loss: 0.4266 - val_acc: 0.7913
Epoch 4/24
 - 21s - loss: 0.2849 - acc: 0.8847 - val_loss: 0.2622 - val_acc: 0.8929
Epoch 5/24
 - 21s - loss: 0.2614 - acc: 0.8972 - val_loss: 0.2888 - val_acc: 0.8746
Epoch 6/24
 - 21s - loss: 0.2426 - acc: 0.9043 - val_loss: 0.2353 - val_acc: 0.9066
Epoch 7/24
 - 21s - loss: 0.2257 - acc: 0.9128 - val_loss: 0.2013 - val_acc: 0.9249
Epoch 8/24
 - 21s - loss: 0.2124 - acc: 0.9191 - val_loss: 0.2321 - val_acc: 0.9037
Epoch 9/24
 - 21s - loss: 0.2013 - acc: 0.9240 - val_loss: 0.2137 - val_acc: 0.9144
Epoch 10/24
 - 21s - loss: 0.1896 - acc: 0.9296 - val_loss: 0.1664 - val_acc: 0.9410
Epoch 11/24
 - 21s - loss: 0.1803 - acc: 0.9341 - val_loss: 0.1571 - val_acc: 0.9468
Epoch 12/24
 - 21s - loss: 0.1722 - acc: 0.9400 - val_loss: 0.1539 - val_acc: 0.9475
Epoch 13/24
 - 21s - loss: 0.1672 - acc: 0.9399 - val_loss: 0.1526 - val_acc: 0.9470
Epoch 14/24
 - 21s - loss: 0.1593 - acc: 0.9434 - val_loss: 0.1425 - val_acc: 0.9531
Epoch 15/24
 - 21s - loss: 0.1503 - acc: 0.9481 - val_loss: 0.1290 - val_acc: 0.9587
Epoch 16/24
 - 21s - loss: 0.1450 - acc: 0.9502 - val_loss: 0.1324 - val_acc: 0.9565
Epoch 17/24
 - 21s - loss: 0.1400 - acc: 0.9515 - val_loss: 0.1109 - val_acc: 0.9641
Epoch 18/24
 - 21s - loss: 0.1353 - acc: 0.9551 - val_loss: 0.1592 - val_acc: 0.9399
Epoch 19/24
 - 21s - loss: 0.1315 - acc: 0.9550 - val_loss: 0.1164 - val_acc: 0.9616
Epoch 20/24
 - 21s - loss: 0.1270 - acc: 0.9568 - val_loss: 0.0979 - val_acc: 0.9705
Epoch 21/24
 - 21s - loss: 0.1236 - acc: 0.9579 - val_loss: 0.0922 - val_acc: 0.9743
Epoch 22/24
 - 21s - loss: 0.1195 - acc: 0.9595 - val_loss: 0.0901 - val_acc: 0.9744
Epoch 23/24
 - 21s - loss: 0.1153 - acc: 0.9613 - val_loss: 0.0840 - val_acc: 0.9765
Epoch 24/24
 - 21s - loss: 0.1113 - acc: 0.9638 - val_loss: 0.1403 - val_acc: 0.9475
Test accuracy:0.760
current auc_score ------------------> 0.896
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  24  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  24  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 24, 24, 24)   3456        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 24, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 40, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 40, 24, 24)   160         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 40, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 24, 24, 24)   8640        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 64, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 64, 24, 24)   256         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 64, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 32, 24, 24)   2048        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 32, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 32, 12, 12)   128         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 32, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 24, 12, 12)   6912        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 24, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 56, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 56, 12, 12)   224         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 56, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 24, 12, 12)   12096       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 24, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 80, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 80, 12, 12)   320         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 80, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 11520)        0           activation_7[0][0]               
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            11521       flatten_1[0][0]                  
==================================================================================================
Total params: 47,457
Trainable params: 46,849
Non-trainable params: 608
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/24
 - 24s - loss: 0.4623 - acc: 0.7849 - val_loss: 0.3662 - val_acc: 0.8439
Epoch 2/24
 - 21s - loss: 0.3558 - acc: 0.8506 - val_loss: 0.3429 - val_acc: 0.8454
Epoch 3/24
 - 21s - loss: 0.3111 - acc: 0.8709 - val_loss: 0.2952 - val_acc: 0.8781
Epoch 4/24
 - 21s - loss: 0.2824 - acc: 0.8860 - val_loss: 0.2660 - val_acc: 0.8957
Epoch 5/24
 - 21s - loss: 0.2571 - acc: 0.8988 - val_loss: 0.2359 - val_acc: 0.9123
Epoch 6/24
 - 21s - loss: 0.2380 - acc: 0.9076 - val_loss: 0.2069 - val_acc: 0.9262
Epoch 7/24
 - 21s - loss: 0.2238 - acc: 0.9139 - val_loss: 0.1911 - val_acc: 0.9329
Epoch 8/24
 - 21s - loss: 0.2081 - acc: 0.9217 - val_loss: 0.1926 - val_acc: 0.9291
Epoch 9/24
 - 21s - loss: 0.1969 - acc: 0.9280 - val_loss: 0.2083 - val_acc: 0.9152
Epoch 10/24
 - 21s - loss: 0.1871 - acc: 0.9316 - val_loss: 0.1923 - val_acc: 0.9267

Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 11/24
 - 22s - loss: 0.1744 - acc: 0.9389 - val_loss: 0.1576 - val_acc: 0.9495
Epoch 12/24
 - 23s - loss: 0.1725 - acc: 0.9383 - val_loss: 0.1519 - val_acc: 0.9507
Epoch 13/24
 - 22s - loss: 0.1690 - acc: 0.9405 - val_loss: 0.1450 - val_acc: 0.9503
Epoch 14/24
 - 21s - loss: 0.1664 - acc: 0.9417 - val_loss: 0.1396 - val_acc: 0.9521
Epoch 15/24
 - 21s - loss: 0.1635 - acc: 0.9429 - val_loss: 0.1413 - val_acc: 0.9561
Epoch 16/24
 - 21s - loss: 0.1608 - acc: 0.9437 - val_loss: 0.1355 - val_acc: 0.9552
Epoch 17/24
 - 21s - loss: 0.1566 - acc: 0.9458 - val_loss: 0.1343 - val_acc: 0.9563
Epoch 18/24
 - 21s - loss: 0.1555 - acc: 0.9457 - val_loss: 0.1306 - val_acc: 0.9595
Epoch 19/24
 - 23s - loss: 0.1531 - acc: 0.9473 - val_loss: 0.1283 - val_acc: 0.9596
Epoch 20/24
 - 23s - loss: 0.1514 - acc: 0.9480 - val_loss: 0.1267 - val_acc: 0.9552
Epoch 21/24
 - 23s - loss: 0.1493 - acc: 0.9484 - val_loss: 0.1225 - val_acc: 0.9616
Epoch 22/24
 - 23s - loss: 0.1475 - acc: 0.9496 - val_loss: 0.1213 - val_acc: 0.9632
Epoch 23/24
 - 23s - loss: 0.1445 - acc: 0.9507 - val_loss: 0.1179 - val_acc: 0.9626
Epoch 24/24
 - 23s - loss: 0.1416 - acc: 0.9511 - val_loss: 0.1175 - val_acc: 0.9655
Test accuracy:0.840
current auc_score ------------------> 0.924
accuracies:  [0.8294354838709678, 0.8311827956989247, 0.8259408602150538, 0.8094086021505377, 0.8211021505376344, 0.8138440860215054, 0.7973118279569893, 0.8283602150537634, 0.7603494623655914, 0.8400537634408602]
aucs:  [0.9009, 0.8962, 0.9131, 0.9031, 0.9048, 0.9151, 0.9003, 0.9074, 0.8958, 0.9244]
mean and std AUC:  0.906+/-0.009  max:   0.9244
['2-2', '30', '2', '16', '0.2', '0.07', '23', 'adadelta', '0.5', 'FALSE', '64', 'flatten']
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  23  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_7[0][0]               
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            14113       flatten_1[0][0]                  
==================================================================================================
Total params: 65,361
Trainable params: 64,645
Non-trainable params: 716
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/23
 - 27s - loss: 0.4763 - acc: 0.7758 - val_loss: 0.3765 - val_acc: 0.8360
Epoch 2/23
 - 25s - loss: 0.3538 - acc: 0.8477 - val_loss: 0.3284 - val_acc: 0.8555
Epoch 3/23
 - 25s - loss: 0.3030 - acc: 0.8748 - val_loss: 0.2934 - val_acc: 0.8691
Epoch 4/23
 - 25s - loss: 0.2718 - acc: 0.8897 - val_loss: 0.2285 - val_acc: 0.9144
Epoch 5/23
 - 25s - loss: 0.2464 - acc: 0.9033 - val_loss: 0.2109 - val_acc: 0.9213
Epoch 6/23
 - 25s - loss: 0.2270 - acc: 0.9123 - val_loss: 0.2230 - val_acc: 0.9095
Epoch 7/23
 - 25s - loss: 0.2124 - acc: 0.9198 - val_loss: 0.1823 - val_acc: 0.9357
Epoch 8/23
 - 24s - loss: 0.1986 - acc: 0.9263 - val_loss: 0.1636 - val_acc: 0.9430
Epoch 9/23
 - 24s - loss: 0.1867 - acc: 0.9326 - val_loss: 0.1490 - val_acc: 0.9518
Epoch 10/23
 - 25s - loss: 0.1761 - acc: 0.9375 - val_loss: 0.1460 - val_acc: 0.9524
Epoch 11/23
 - 25s - loss: 0.1673 - acc: 0.9388 - val_loss: 0.1313 - val_acc: 0.9607
Epoch 12/23
 - 25s - loss: 0.1602 - acc: 0.9439 - val_loss: 0.1279 - val_acc: 0.9607
Epoch 13/23
 - 25s - loss: 0.1547 - acc: 0.9459 - val_loss: 0.1222 - val_acc: 0.9621
Epoch 14/23
 - 25s - loss: 0.1442 - acc: 0.9516 - val_loss: 0.1133 - val_acc: 0.9646
Epoch 15/23
 - 25s - loss: 0.1385 - acc: 0.9532 - val_loss: 0.1104 - val_acc: 0.9660
Epoch 16/23
 - 25s - loss: 0.1321 - acc: 0.9554 - val_loss: 0.1041 - val_acc: 0.9688
Epoch 17/23
 - 25s - loss: 0.1258 - acc: 0.9574 - val_loss: 0.1019 - val_acc: 0.9695
Epoch 18/23
 - 24s - loss: 0.1236 - acc: 0.9597 - val_loss: 0.0935 - val_acc: 0.9723
Epoch 19/23
 - 24s - loss: 0.1179 - acc: 0.9620 - val_loss: 0.0948 - val_acc: 0.9716
Epoch 20/23
 - 24s - loss: 0.1148 - acc: 0.9624 - val_loss: 0.0894 - val_acc: 0.9706
Epoch 21/23
 - 24s - loss: 0.1097 - acc: 0.9643 - val_loss: 0.0827 - val_acc: 0.9743
Epoch 22/23
 - 24s - loss: 0.1068 - acc: 0.9660 - val_loss: 0.0827 - val_acc: 0.9765
Epoch 23/23
 - 24s - loss: 0.1014 - acc: 0.9675 - val_loss: 0.0740 - val_acc: 0.9783
Test accuracy:0.842
current auc_score ------------------> 0.912
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  23  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_7[0][0]               
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            14113       flatten_1[0][0]                  
==================================================================================================
Total params: 65,361
Trainable params: 64,645
Non-trainable params: 716
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/23
 - 25s - loss: 0.4681 - acc: 0.7798 - val_loss: 0.3721 - val_acc: 0.8366
Epoch 2/23
 - 24s - loss: 0.3571 - acc: 0.8465 - val_loss: 0.3460 - val_acc: 0.8414
Epoch 3/23
 - 24s - loss: 0.3076 - acc: 0.8726 - val_loss: 0.2702 - val_acc: 0.8874
Epoch 4/23
 - 24s - loss: 0.2740 - acc: 0.8891 - val_loss: 0.2702 - val_acc: 0.8865
Epoch 5/23
 - 24s - loss: 0.2451 - acc: 0.9037 - val_loss: 0.2204 - val_acc: 0.9172
Epoch 6/23
 - 24s - loss: 0.2251 - acc: 0.9139 - val_loss: 0.3000 - val_acc: 0.8655
Epoch 7/23
 - 24s - loss: 0.2087 - acc: 0.9201 - val_loss: 0.1812 - val_acc: 0.9325
Epoch 8/23
 - 24s - loss: 0.1936 - acc: 0.9285 - val_loss: 0.1647 - val_acc: 0.9416
Epoch 9/23
 - 24s - loss: 0.1812 - acc: 0.9352 - val_loss: 0.1523 - val_acc: 0.9498
Epoch 10/23
 - 24s - loss: 0.1700 - acc: 0.9395 - val_loss: 0.1640 - val_acc: 0.9416
Epoch 11/23
 - 24s - loss: 0.1605 - acc: 0.9432 - val_loss: 0.1401 - val_acc: 0.9546
Epoch 12/23
 - 24s - loss: 0.1536 - acc: 0.9473 - val_loss: 0.1229 - val_acc: 0.9608
Epoch 13/23
 - 24s - loss: 0.1435 - acc: 0.9513 - val_loss: 0.1140 - val_acc: 0.9656
Epoch 14/23
 - 24s - loss: 0.1380 - acc: 0.9539 - val_loss: 0.1068 - val_acc: 0.9664
Epoch 15/23
 - 24s - loss: 0.1305 - acc: 0.9567 - val_loss: 0.1004 - val_acc: 0.9679
Epoch 16/23
 - 24s - loss: 0.1263 - acc: 0.9588 - val_loss: 0.1061 - val_acc: 0.9671
Epoch 17/23
 - 24s - loss: 0.1213 - acc: 0.9594 - val_loss: 0.0911 - val_acc: 0.9736
Epoch 18/23
 - 24s - loss: 0.1157 - acc: 0.9627 - val_loss: 0.0923 - val_acc: 0.9729
Epoch 19/23
 - 24s - loss: 0.1104 - acc: 0.9645 - val_loss: 0.0862 - val_acc: 0.9744
Epoch 20/23
 - 24s - loss: 0.1071 - acc: 0.9655 - val_loss: 0.0820 - val_acc: 0.9772
Epoch 21/23
 - 24s - loss: 0.1020 - acc: 0.9678 - val_loss: 0.0777 - val_acc: 0.9777
Epoch 22/23
 - 24s - loss: 0.1011 - acc: 0.9670 - val_loss: 0.0726 - val_acc: 0.9805
Epoch 23/23
 - 24s - loss: 0.0970 - acc: 0.9696 - val_loss: 0.0771 - val_acc: 0.9744
Test accuracy:0.828
current auc_score ------------------> 0.900
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  23  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_7[0][0]               
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            14113       flatten_1[0][0]                  
==================================================================================================
Total params: 65,361
Trainable params: 64,645
Non-trainable params: 716
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/23
 - 26s - loss: 0.4694 - acc: 0.7787 - val_loss: 0.3629 - val_acc: 0.8382
Epoch 2/23
 - 24s - loss: 0.3561 - acc: 0.8482 - val_loss: 0.3037 - val_acc: 0.8722
Epoch 3/23
 - 24s - loss: 0.3065 - acc: 0.8744 - val_loss: 0.2740 - val_acc: 0.8904
Epoch 4/23
 - 24s - loss: 0.2726 - acc: 0.8931 - val_loss: 0.2311 - val_acc: 0.9129
Epoch 5/23
 - 24s - loss: 0.2483 - acc: 0.9042 - val_loss: 0.2149 - val_acc: 0.9204
Epoch 6/23
 - 24s - loss: 0.2265 - acc: 0.9152 - val_loss: 0.1910 - val_acc: 0.9327
Epoch 7/23
 - 24s - loss: 0.2104 - acc: 0.9221 - val_loss: 0.1748 - val_acc: 0.9406
Epoch 8/23
 - 24s - loss: 0.1965 - acc: 0.9284 - val_loss: 0.1582 - val_acc: 0.9464
Epoch 9/23
 - 24s - loss: 0.1856 - acc: 0.9316 - val_loss: 0.1512 - val_acc: 0.9483
Epoch 10/23
 - 24s - loss: 0.1753 - acc: 0.9372 - val_loss: 0.1423 - val_acc: 0.9539
Epoch 11/23
 - 24s - loss: 0.1651 - acc: 0.9420 - val_loss: 0.1552 - val_acc: 0.9478
Epoch 12/23
 - 24s - loss: 0.1565 - acc: 0.9456 - val_loss: 0.1218 - val_acc: 0.9613
Epoch 13/23
 - 24s - loss: 0.1484 - acc: 0.9499 - val_loss: 0.1325 - val_acc: 0.9541
Epoch 14/23
 - 24s - loss: 0.1410 - acc: 0.9515 - val_loss: 0.1331 - val_acc: 0.9547
Epoch 15/23
 - 24s - loss: 0.1365 - acc: 0.9541 - val_loss: 0.1025 - val_acc: 0.9705
Epoch 16/23
 - 24s - loss: 0.1295 - acc: 0.9563 - val_loss: 0.0968 - val_acc: 0.9729
Epoch 17/23
 - 24s - loss: 0.1249 - acc: 0.9586 - val_loss: 0.0926 - val_acc: 0.9753
Epoch 18/23
 - 24s - loss: 0.1201 - acc: 0.9610 - val_loss: 0.0900 - val_acc: 0.9721
Epoch 19/23
 - 24s - loss: 0.1136 - acc: 0.9635 - val_loss: 0.0842 - val_acc: 0.9759
Epoch 20/23
 - 24s - loss: 0.1093 - acc: 0.9654 - val_loss: 0.0825 - val_acc: 0.9793
Epoch 21/23
 - 24s - loss: 0.1066 - acc: 0.9652 - val_loss: 0.0799 - val_acc: 0.9774
Epoch 22/23
 - 24s - loss: 0.1035 - acc: 0.9672 - val_loss: 0.0841 - val_acc: 0.9778
Epoch 23/23
 - 24s - loss: 0.0994 - acc: 0.9689 - val_loss: 0.0715 - val_acc: 0.9813
Test accuracy:0.796
current auc_score ------------------> 0.896
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  23  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_7[0][0]               
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            14113       flatten_1[0][0]                  
==================================================================================================
Total params: 65,361
Trainable params: 64,645
Non-trainable params: 716
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/23
 - 25s - loss: 0.4624 - acc: 0.7834 - val_loss: 0.3575 - val_acc: 0.8465
Epoch 2/23
 - 24s - loss: 0.3442 - acc: 0.8537 - val_loss: 0.2996 - val_acc: 0.8784
Epoch 3/23
 - 24s - loss: 0.2987 - acc: 0.8763 - val_loss: 0.2610 - val_acc: 0.8968
Epoch 4/23
 - 24s - loss: 0.2649 - acc: 0.8936 - val_loss: 0.2277 - val_acc: 0.9142
Epoch 5/23
 - 24s - loss: 0.2412 - acc: 0.9046 - val_loss: 0.2030 - val_acc: 0.9278
Epoch 6/23
 - 24s - loss: 0.2206 - acc: 0.9153 - val_loss: 0.1998 - val_acc: 0.9263
Epoch 7/23
 - 24s - loss: 0.2053 - acc: 0.9220 - val_loss: 0.1823 - val_acc: 0.9361
Epoch 8/23
 - 24s - loss: 0.1925 - acc: 0.9301 - val_loss: 0.1656 - val_acc: 0.9386
Epoch 9/23
 - 24s - loss: 0.1798 - acc: 0.9358 - val_loss: 0.1543 - val_acc: 0.9420
Epoch 10/23
 - 24s - loss: 0.1697 - acc: 0.9386 - val_loss: 0.1408 - val_acc: 0.9527
Epoch 11/23
 - 24s - loss: 0.1625 - acc: 0.9431 - val_loss: 0.1287 - val_acc: 0.9575
Epoch 12/23
 - 24s - loss: 0.1522 - acc: 0.9461 - val_loss: 0.1160 - val_acc: 0.9647
Epoch 13/23
 - 24s - loss: 0.1445 - acc: 0.9506 - val_loss: 0.1277 - val_acc: 0.9585
Epoch 14/23
 - 24s - loss: 0.1388 - acc: 0.9527 - val_loss: 0.1238 - val_acc: 0.9548
Epoch 15/23
 - 24s - loss: 0.1329 - acc: 0.9550 - val_loss: 0.1103 - val_acc: 0.9625
Epoch 16/23
 - 24s - loss: 0.1278 - acc: 0.9576 - val_loss: 0.1022 - val_acc: 0.9686
Epoch 17/23
 - 24s - loss: 0.1222 - acc: 0.9591 - val_loss: 0.0886 - val_acc: 0.9735
Epoch 18/23
 - 24s - loss: 0.1171 - acc: 0.9617 - val_loss: 0.0845 - val_acc: 0.9745
Epoch 19/23
 - 24s - loss: 0.1138 - acc: 0.9630 - val_loss: 0.0819 - val_acc: 0.9763
Epoch 20/23
 - 24s - loss: 0.1088 - acc: 0.9652 - val_loss: 0.0777 - val_acc: 0.9790
Epoch 21/23
 - 24s - loss: 0.1047 - acc: 0.9660 - val_loss: 0.0745 - val_acc: 0.9778
Epoch 22/23
 - 24s - loss: 0.1034 - acc: 0.9673 - val_loss: 0.0795 - val_acc: 0.9730
Epoch 23/23
 - 25s - loss: 0.0980 - acc: 0.9692 - val_loss: 0.0686 - val_acc: 0.9814
Test accuracy:0.833
current auc_score ------------------> 0.908
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  23  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_7[0][0]               
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            14113       flatten_1[0][0]                  
==================================================================================================
Total params: 65,361
Trainable params: 64,645
Non-trainable params: 716
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/23
 - 28s - loss: 0.4763 - acc: 0.7739 - val_loss: 0.3769 - val_acc: 0.8333
Epoch 2/23
 - 25s - loss: 0.3591 - acc: 0.8470 - val_loss: 0.3469 - val_acc: 0.8436
Epoch 3/23
 - 25s - loss: 0.3157 - acc: 0.8682 - val_loss: 0.3045 - val_acc: 0.8709
Epoch 4/23
 - 25s - loss: 0.2847 - acc: 0.8859 - val_loss: 0.2872 - val_acc: 0.8837
Epoch 5/23
 - 25s - loss: 0.2600 - acc: 0.8976 - val_loss: 0.2462 - val_acc: 0.9031
Epoch 6/23
 - 25s - loss: 0.2416 - acc: 0.9075 - val_loss: 0.2785 - val_acc: 0.8823
Epoch 7/23
 - 25s - loss: 0.2237 - acc: 0.9159 - val_loss: 0.1915 - val_acc: 0.9324
Epoch 8/23
 - 25s - loss: 0.2101 - acc: 0.9224 - val_loss: 0.2702 - val_acc: 0.8852
Epoch 9/23
 - 25s - loss: 0.1987 - acc: 0.9277 - val_loss: 0.1741 - val_acc: 0.9416
Epoch 10/23
 - 25s - loss: 0.1867 - acc: 0.9329 - val_loss: 0.2356 - val_acc: 0.9065
Epoch 11/23
 - 25s - loss: 0.1755 - acc: 0.9374 - val_loss: 0.1717 - val_acc: 0.9369
Epoch 12/23
 - 25s - loss: 0.1655 - acc: 0.9419 - val_loss: 0.1484 - val_acc: 0.9460
Epoch 13/23
 - 24s - loss: 0.1607 - acc: 0.9450 - val_loss: 0.1269 - val_acc: 0.9586
Epoch 14/23
 - 25s - loss: 0.1500 - acc: 0.9476 - val_loss: 0.1267 - val_acc: 0.9572
Epoch 15/23
 - 24s - loss: 0.1433 - acc: 0.9518 - val_loss: 0.1227 - val_acc: 0.9588
Epoch 16/23
 - 24s - loss: 0.1398 - acc: 0.9520 - val_loss: 0.1121 - val_acc: 0.9632
Epoch 17/23
 - 24s - loss: 0.1327 - acc: 0.9564 - val_loss: 0.1085 - val_acc: 0.9652
Epoch 18/23
 - 24s - loss: 0.1273 - acc: 0.9573 - val_loss: 0.1213 - val_acc: 0.9592
Epoch 19/23
 - 24s - loss: 0.1222 - acc: 0.9603 - val_loss: 0.0988 - val_acc: 0.9690
Epoch 20/23
 - 24s - loss: 0.1198 - acc: 0.9603 - val_loss: 0.0890 - val_acc: 0.9746
Epoch 21/23
 - 24s - loss: 0.1144 - acc: 0.9637 - val_loss: 0.0851 - val_acc: 0.9767
Epoch 22/23
 - 24s - loss: 0.1112 - acc: 0.9641 - val_loss: 0.0828 - val_acc: 0.9774
Epoch 23/23
 - 24s - loss: 0.1061 - acc: 0.9662 - val_loss: 0.0779 - val_acc: 0.9789
Test accuracy:0.841
current auc_score ------------------> 0.913
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  23  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_7[0][0]               
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            14113       flatten_1[0][0]                  
==================================================================================================
Total params: 65,361
Trainable params: 64,645
Non-trainable params: 716
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/23
 - 26s - loss: 0.4647 - acc: 0.7830 - val_loss: 0.3639 - val_acc: 0.8396
Epoch 2/23
 - 24s - loss: 0.3481 - acc: 0.8526 - val_loss: 0.3066 - val_acc: 0.8725
Epoch 3/23
 - 24s - loss: 0.2993 - acc: 0.8772 - val_loss: 0.2836 - val_acc: 0.8815
Epoch 4/23
 - 24s - loss: 0.2675 - acc: 0.8928 - val_loss: 0.2333 - val_acc: 0.9094
Epoch 5/23
 - 24s - loss: 0.2421 - acc: 0.9056 - val_loss: 0.2043 - val_acc: 0.9219
Epoch 6/23
 - 24s - loss: 0.2210 - acc: 0.9152 - val_loss: 0.2157 - val_acc: 0.9160
Epoch 7/23
 - 24s - loss: 0.2059 - acc: 0.9228 - val_loss: 0.1733 - val_acc: 0.9378
Epoch 8/23
 - 24s - loss: 0.1908 - acc: 0.9306 - val_loss: 0.1935 - val_acc: 0.9275
Epoch 9/23
 - 24s - loss: 0.1808 - acc: 0.9343 - val_loss: 0.1643 - val_acc: 0.9468
Epoch 10/23
 - 24s - loss: 0.1696 - acc: 0.9394 - val_loss: 0.1371 - val_acc: 0.9549
Epoch 11/23
 - 24s - loss: 0.1610 - acc: 0.9421 - val_loss: 0.1356 - val_acc: 0.9573
Epoch 12/23
 - 24s - loss: 0.1538 - acc: 0.9450 - val_loss: 0.1258 - val_acc: 0.9620
Epoch 13/23
 - 24s - loss: 0.1456 - acc: 0.9500 - val_loss: 0.1184 - val_acc: 0.9639
Epoch 14/23
 - 24s - loss: 0.1383 - acc: 0.9524 - val_loss: 0.1108 - val_acc: 0.9672
Epoch 15/23
 - 24s - loss: 0.1330 - acc: 0.9547 - val_loss: 0.1083 - val_acc: 0.9686
Epoch 16/23
 - 24s - loss: 0.1270 - acc: 0.9574 - val_loss: 0.0989 - val_acc: 0.9718
Epoch 17/23
 - 24s - loss: 0.1228 - acc: 0.9586 - val_loss: 0.0955 - val_acc: 0.9698
Epoch 18/23
 - 24s - loss: 0.1167 - acc: 0.9619 - val_loss: 0.0889 - val_acc: 0.9753
Epoch 19/23
 - 24s - loss: 0.1126 - acc: 0.9627 - val_loss: 0.0840 - val_acc: 0.9752
Epoch 20/23
 - 24s - loss: 0.1079 - acc: 0.9647 - val_loss: 0.0876 - val_acc: 0.9705
Epoch 21/23
 - 24s - loss: 0.1041 - acc: 0.9664 - val_loss: 0.0808 - val_acc: 0.9730
Epoch 22/23
 - 24s - loss: 0.1033 - acc: 0.9672 - val_loss: 0.0713 - val_acc: 0.9805
Epoch 23/23
 - 24s - loss: 0.0971 - acc: 0.9688 - val_loss: 0.0676 - val_acc: 0.9832
Test accuracy:0.821
current auc_score ------------------> 0.919
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  23  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_7[0][0]               
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            14113       flatten_1[0][0]                  
==================================================================================================
Total params: 65,361
Trainable params: 64,645
Non-trainable params: 716
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/23
 - 26s - loss: 0.4764 - acc: 0.7758 - val_loss: 0.3769 - val_acc: 0.8377
Epoch 2/23
 - 24s - loss: 0.3562 - acc: 0.8485 - val_loss: 0.3977 - val_acc: 0.8112
Epoch 3/23
 - 24s - loss: 0.3079 - acc: 0.8739 - val_loss: 0.2678 - val_acc: 0.8926
Epoch 4/23
 - 24s - loss: 0.2740 - acc: 0.8913 - val_loss: 0.2886 - val_acc: 0.8763
Epoch 5/23
 - 24s - loss: 0.2526 - acc: 0.9010 - val_loss: 0.2182 - val_acc: 0.9167
Epoch 6/23
 - 24s - loss: 0.2312 - acc: 0.9132 - val_loss: 0.2020 - val_acc: 0.9249
Epoch 7/23
 - 24s - loss: 0.2133 - acc: 0.9211 - val_loss: 0.2162 - val_acc: 0.9168
Epoch 8/23
 - 24s - loss: 0.1995 - acc: 0.9265 - val_loss: 0.1648 - val_acc: 0.9408
Epoch 9/23
 - 24s - loss: 0.1860 - acc: 0.9326 - val_loss: 0.1526 - val_acc: 0.9460
Epoch 10/23
 - 27s - loss: 0.1749 - acc: 0.9381 - val_loss: 0.1581 - val_acc: 0.9473
Epoch 11/23
 - 25s - loss: 0.1654 - acc: 0.9419 - val_loss: 0.1362 - val_acc: 0.9539
Epoch 12/23
 - 25s - loss: 0.1562 - acc: 0.9451 - val_loss: 0.1257 - val_acc: 0.9590
Epoch 13/23
 - 25s - loss: 0.1489 - acc: 0.9485 - val_loss: 0.1160 - val_acc: 0.9641
Epoch 14/23
 - 24s - loss: 0.1438 - acc: 0.9507 - val_loss: 0.1442 - val_acc: 0.9489
Epoch 15/23
 - 25s - loss: 0.1345 - acc: 0.9549 - val_loss: 0.1032 - val_acc: 0.9693
Epoch 16/23
 - 25s - loss: 0.1290 - acc: 0.9572 - val_loss: 0.0992 - val_acc: 0.9700
Epoch 17/23
 - 25s - loss: 0.1244 - acc: 0.9590 - val_loss: 0.0967 - val_acc: 0.9706
Epoch 18/23
 - 25s - loss: 0.1182 - acc: 0.9619 - val_loss: 0.0898 - val_acc: 0.9730
Epoch 19/23
 - 25s - loss: 0.1153 - acc: 0.9631 - val_loss: 0.0842 - val_acc: 0.9759
Epoch 20/23
 - 25s - loss: 0.1122 - acc: 0.9642 - val_loss: 0.0803 - val_acc: 0.9788
Epoch 21/23
 - 25s - loss: 0.1072 - acc: 0.9653 - val_loss: 0.0837 - val_acc: 0.9738
Epoch 22/23
 - 25s - loss: 0.1031 - acc: 0.9684 - val_loss: 0.0736 - val_acc: 0.9792
Epoch 23/23
 - 25s - loss: 0.1001 - acc: 0.9696 - val_loss: 0.0761 - val_acc: 0.9789
Test accuracy:0.832
current auc_score ------------------> 0.904
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  23  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_7[0][0]               
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            14113       flatten_1[0][0]                  
==================================================================================================
Total params: 65,361
Trainable params: 64,645
Non-trainable params: 716
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/23
 - 27s - loss: 0.4719 - acc: 0.7746 - val_loss: 0.3687 - val_acc: 0.8381
Epoch 2/23
 - 25s - loss: 0.3559 - acc: 0.8480 - val_loss: 0.3103 - val_acc: 0.8697
Epoch 3/23
 - 25s - loss: 0.3131 - acc: 0.8693 - val_loss: 0.3032 - val_acc: 0.8712
Epoch 4/23
 - 25s - loss: 0.2817 - acc: 0.8832 - val_loss: 0.2698 - val_acc: 0.8902
Epoch 5/23
 - 24s - loss: 0.2600 - acc: 0.8953 - val_loss: 0.2750 - val_acc: 0.8849
Epoch 6/23
 - 24s - loss: 0.2419 - acc: 0.9045 - val_loss: 0.2281 - val_acc: 0.9105
Epoch 7/23
 - 25s - loss: 0.2271 - acc: 0.9131 - val_loss: 0.1927 - val_acc: 0.9248
Epoch 8/23
 - 25s - loss: 0.2126 - acc: 0.9191 - val_loss: 0.2241 - val_acc: 0.9121
Epoch 9/23
 - 25s - loss: 0.2008 - acc: 0.9243 - val_loss: 0.1759 - val_acc: 0.9379
Epoch 10/23
 - 25s - loss: 0.1907 - acc: 0.9293 - val_loss: 0.1735 - val_acc: 0.9372
Epoch 11/23
 - 25s - loss: 0.1803 - acc: 0.9343 - val_loss: 0.1509 - val_acc: 0.9490
Epoch 12/23
 - 24s - loss: 0.1729 - acc: 0.9392 - val_loss: 0.1543 - val_acc: 0.9478
Epoch 13/23
 - 24s - loss: 0.1661 - acc: 0.9413 - val_loss: 0.1319 - val_acc: 0.9572
Epoch 14/23
 - 25s - loss: 0.1598 - acc: 0.9437 - val_loss: 0.1395 - val_acc: 0.9557
Epoch 15/23
 - 24s - loss: 0.1505 - acc: 0.9479 - val_loss: 0.1243 - val_acc: 0.9563
Epoch 16/23
 - 24s - loss: 0.1455 - acc: 0.9489 - val_loss: 0.1163 - val_acc: 0.9611
Epoch 17/23
 - 24s - loss: 0.1416 - acc: 0.9507 - val_loss: 0.1067 - val_acc: 0.9664
Epoch 18/23
 - 25s - loss: 0.1355 - acc: 0.9543 - val_loss: 0.1019 - val_acc: 0.9689
Epoch 19/23
 - 24s - loss: 0.1310 - acc: 0.9547 - val_loss: 0.1038 - val_acc: 0.9685
Epoch 20/23
 - 24s - loss: 0.1252 - acc: 0.9579 - val_loss: 0.1009 - val_acc: 0.9660
Epoch 21/23
 - 24s - loss: 0.1221 - acc: 0.9587 - val_loss: 0.0883 - val_acc: 0.9739
Epoch 22/23
 - 24s - loss: 0.1174 - acc: 0.9611 - val_loss: 0.0848 - val_acc: 0.9754
Epoch 23/23
 - 26s - loss: 0.1154 - acc: 0.9619 - val_loss: 0.0824 - val_acc: 0.9774
Test accuracy:0.825
current auc_score ------------------> 0.914
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  23  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_7[0][0]               
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            14113       flatten_1[0][0]                  
==================================================================================================
Total params: 65,361
Trainable params: 64,645
Non-trainable params: 716
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/23
 - 27s - loss: 0.4736 - acc: 0.7741 - val_loss: 0.4013 - val_acc: 0.8146
Epoch 2/23
 - 25s - loss: 0.3520 - acc: 0.8483 - val_loss: 0.3098 - val_acc: 0.8701
Epoch 3/23
 - 25s - loss: 0.3019 - acc: 0.8760 - val_loss: 0.2732 - val_acc: 0.8869
Epoch 4/23
 - 25s - loss: 0.2713 - acc: 0.8906 - val_loss: 0.2837 - val_acc: 0.8737
Epoch 5/23
 - 25s - loss: 0.2490 - acc: 0.9023 - val_loss: 0.2109 - val_acc: 0.9212
Epoch 6/23
 - 25s - loss: 0.2259 - acc: 0.9137 - val_loss: 0.2117 - val_acc: 0.9173
Epoch 7/23
 - 25s - loss: 0.2128 - acc: 0.9189 - val_loss: 0.1771 - val_acc: 0.9379
Epoch 8/23
 - 25s - loss: 0.1982 - acc: 0.9263 - val_loss: 0.1918 - val_acc: 0.9293
Epoch 9/23
 - 25s - loss: 0.1870 - acc: 0.9335 - val_loss: 0.1538 - val_acc: 0.9477
Epoch 10/23
 - 25s - loss: 0.1745 - acc: 0.9361 - val_loss: 0.1390 - val_acc: 0.9527
Epoch 11/23
 - 25s - loss: 0.1659 - acc: 0.9414 - val_loss: 0.1405 - val_acc: 0.9495
Epoch 12/23
 - 25s - loss: 0.1592 - acc: 0.9445 - val_loss: 0.1319 - val_acc: 0.9565
Epoch 13/23
 - 25s - loss: 0.1506 - acc: 0.9487 - val_loss: 0.1204 - val_acc: 0.9618
Epoch 14/23
 - 25s - loss: 0.1429 - acc: 0.9508 - val_loss: 0.1146 - val_acc: 0.9629
Epoch 15/23
 - 25s - loss: 0.1372 - acc: 0.9533 - val_loss: 0.1154 - val_acc: 0.9626
Epoch 16/23
 - 25s - loss: 0.1299 - acc: 0.9558 - val_loss: 0.1091 - val_acc: 0.9667
Epoch 17/23
 - 25s - loss: 0.1249 - acc: 0.9582 - val_loss: 0.0950 - val_acc: 0.9716
Epoch 18/23
 - 24s - loss: 0.1199 - acc: 0.9603 - val_loss: 0.0904 - val_acc: 0.9721
Epoch 19/23
 - 24s - loss: 0.1163 - acc: 0.9613 - val_loss: 0.0915 - val_acc: 0.9733
Epoch 20/23
 - 24s - loss: 0.1135 - acc: 0.9629 - val_loss: 0.0838 - val_acc: 0.9743
Epoch 21/23
 - 24s - loss: 0.1071 - acc: 0.9663 - val_loss: 0.0806 - val_acc: 0.9780
Epoch 22/23
 - 24s - loss: 0.1035 - acc: 0.9673 - val_loss: 0.0738 - val_acc: 0.9782
Epoch 23/23
 - 24s - loss: 0.1000 - acc: 0.9689 - val_loss: 0.0704 - val_acc: 0.9799
Test accuracy:0.852
current auc_score ------------------> 0.935
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  23  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   10260       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_7[0][0]               
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            14113       flatten_1[0][0]                  
==================================================================================================
Total params: 65,361
Trainable params: 64,645
Non-trainable params: 716
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/23
 - 26s - loss: 0.4784 - acc: 0.7724 - val_loss: 0.4670 - val_acc: 0.7712
Epoch 2/23
 - 24s - loss: 0.3621 - acc: 0.8443 - val_loss: 0.3194 - val_acc: 0.8635
Epoch 3/23
 - 24s - loss: 0.3106 - acc: 0.8712 - val_loss: 0.2769 - val_acc: 0.8919
Epoch 4/23
 - 24s - loss: 0.2812 - acc: 0.8869 - val_loss: 0.2573 - val_acc: 0.9004
Epoch 5/23
 - 24s - loss: 0.2582 - acc: 0.8992 - val_loss: 0.2753 - val_acc: 0.8819
Epoch 6/23
 - 24s - loss: 0.2358 - acc: 0.9094 - val_loss: 0.2339 - val_acc: 0.9091
Epoch 7/23
 - 24s - loss: 0.2227 - acc: 0.9167 - val_loss: 0.1905 - val_acc: 0.9310
Epoch 8/23
 - 24s - loss: 0.2070 - acc: 0.9228 - val_loss: 0.1815 - val_acc: 0.9361
Epoch 9/23
 - 24s - loss: 0.1957 - acc: 0.9301 - val_loss: 0.1638 - val_acc: 0.9447
Epoch 10/23
 - 24s - loss: 0.1853 - acc: 0.9330 - val_loss: 0.1847 - val_acc: 0.9310
Epoch 11/23
 - 24s - loss: 0.1755 - acc: 0.9372 - val_loss: 0.1636 - val_acc: 0.9419
Epoch 12/23
 - 24s - loss: 0.1656 - acc: 0.9410 - val_loss: 0.1466 - val_acc: 0.9460
Epoch 13/23
 - 24s - loss: 0.1565 - acc: 0.9456 - val_loss: 0.1235 - val_acc: 0.9598
Epoch 14/23
 - 24s - loss: 0.1507 - acc: 0.9483 - val_loss: 0.1302 - val_acc: 0.9552
Epoch 15/23
 - 24s - loss: 0.1441 - acc: 0.9504 - val_loss: 0.1134 - val_acc: 0.9641
Epoch 16/23
 - 24s - loss: 0.1380 - acc: 0.9528 - val_loss: 0.1042 - val_acc: 0.9674
Epoch 17/23
 - 24s - loss: 0.1327 - acc: 0.9561 - val_loss: 0.1167 - val_acc: 0.9596
Epoch 18/23
 - 24s - loss: 0.1280 - acc: 0.9579 - val_loss: 0.1078 - val_acc: 0.9675
Epoch 19/23
 - 24s - loss: 0.1226 - acc: 0.9598 - val_loss: 0.1002 - val_acc: 0.9689
Epoch 20/23
 - 24s - loss: 0.1173 - acc: 0.9621 - val_loss: 0.0913 - val_acc: 0.9713
Epoch 21/23
 - 24s - loss: 0.1136 - acc: 0.9630 - val_loss: 0.0861 - val_acc: 0.9735
Epoch 22/23
 - 24s - loss: 0.1097 - acc: 0.9639 - val_loss: 0.0840 - val_acc: 0.9733
Epoch 23/23
 - 24s - loss: 0.1062 - acc: 0.9657 - val_loss: 0.0769 - val_acc: 0.9779
Test accuracy:0.840
current auc_score ------------------> 0.916
accuracies:  [0.8415322580645161, 0.8275537634408602, 0.7958333333333333, 0.8329301075268817, 0.8409946236559139, 0.8205645161290323, 0.8317204301075268, 0.825, 0.851747311827957, 0.8396505376344086]
aucs:  [0.9122, 0.9003, 0.896, 0.9078, 0.9129, 0.9193, 0.9039, 0.914, 0.935, 0.916]
mean and std AUC:  0.912+/-0.01  max:   0.935
['4-4', '12', '2', '16', '0.2', '0.07', '26', 'adadelta', '0.5', 'FALSE', '64', 'flatten']
------------------------ current config for the test -------------------------
Layers:  [4, 4]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  26  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 12, 24, 24)   1728        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 12, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 28, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 28, 24, 24)   112         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 28, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 12, 24, 24)   3024        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 12, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 40, 24, 24)   160         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 24, 24)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 12, 24, 24)   4320        activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 12, 24, 24)   0           dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 52, 24, 24)   0           concatenate_2[0][0]              
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 52, 24, 24)   208         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 52, 24, 24)   0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 12, 24, 24)   5616        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 12, 24, 24)   0           dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 64, 24, 24)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 64, 24, 24)   256         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 64, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 32, 24, 24)   2048        activation_6[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 32, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 32, 12, 12)   128         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 32, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 12, 12, 12)   3456        activation_7[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 12, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 44, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 44, 12, 12)   176         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 44, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 12, 12, 12)   4752        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 12, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 56, 12, 12)   0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 56, 12, 12)   224         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 56, 12, 12)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 12, 12, 12)   6048        activation_9[0][0]               
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 12, 12, 12)   0           dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 68, 12, 12)   0           concatenate_6[0][0]              
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_7[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 68, 12, 12)   0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 12, 12, 12)   7344        activation_10[0][0]              
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 12, 12, 12)   0           dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 80, 12, 12)   0           concatenate_7[0][0]              
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 80, 12, 12)   320         concatenate_8[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 80, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 11520)        0           activation_11[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            11521       flatten_1[0][0]                  
==================================================================================================
Total params: 53,409
Trainable params: 52,417
Non-trainable params: 992
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/26
 - 33s - loss: 0.4809 - acc: 0.7677 - val_loss: 0.3864 - val_acc: 0.8190
Epoch 2/26
 - 31s - loss: 0.3714 - acc: 0.8360 - val_loss: 0.3530 - val_acc: 0.8422
Epoch 3/26
 - 30s - loss: 0.3214 - acc: 0.8649 - val_loss: 0.3140 - val_acc: 0.8608
Epoch 4/26
 - 31s - loss: 0.2882 - acc: 0.8816 - val_loss: 0.2522 - val_acc: 0.9002
Epoch 5/26
 - 31s - loss: 0.2671 - acc: 0.8930 - val_loss: 0.2367 - val_acc: 0.9039
Epoch 6/26
 - 30s - loss: 0.2440 - acc: 0.9034 - val_loss: 0.2575 - val_acc: 0.8886
Epoch 7/26
 - 31s - loss: 0.2273 - acc: 0.9112 - val_loss: 0.2586 - val_acc: 0.8853
Epoch 8/26
 - 30s - loss: 0.2112 - acc: 0.9199 - val_loss: 0.2067 - val_acc: 0.9159
Epoch 9/26
 - 31s - loss: 0.2011 - acc: 0.9241 - val_loss: 0.2039 - val_acc: 0.9169
Epoch 10/26
 - 30s - loss: 0.1901 - acc: 0.9294 - val_loss: 0.1882 - val_acc: 0.9266
Epoch 11/26
 - 30s - loss: 0.1785 - acc: 0.9350 - val_loss: 0.1717 - val_acc: 0.9347
Epoch 12/26
 - 30s - loss: 0.1699 - acc: 0.9384 - val_loss: 0.1582 - val_acc: 0.9394
Epoch 13/26
 - 30s - loss: 0.1631 - acc: 0.9412 - val_loss: 0.1497 - val_acc: 0.9465
Epoch 14/26
 - 30s - loss: 0.1564 - acc: 0.9450 - val_loss: 0.1249 - val_acc: 0.9561
Epoch 15/26
 - 30s - loss: 0.1482 - acc: 0.9490 - val_loss: 0.1243 - val_acc: 0.9575
Epoch 16/26
 - 30s - loss: 0.1429 - acc: 0.9509 - val_loss: 0.1208 - val_acc: 0.9565
Epoch 17/26
 - 30s - loss: 0.1383 - acc: 0.9523 - val_loss: 0.1111 - val_acc: 0.9632
Epoch 18/26
 - 31s - loss: 0.1330 - acc: 0.9549 - val_loss: 0.1044 - val_acc: 0.9661
Epoch 19/26
 - 33s - loss: 0.1283 - acc: 0.9566 - val_loss: 0.1181 - val_acc: 0.9572
Epoch 20/26
 - 32s - loss: 0.1243 - acc: 0.9585 - val_loss: 0.1122 - val_acc: 0.9621
Epoch 21/26
 - 32s - loss: 0.1203 - acc: 0.9600 - val_loss: 0.0928 - val_acc: 0.9719
Epoch 22/26
 - 32s - loss: 0.1153 - acc: 0.9616 - val_loss: 0.0891 - val_acc: 0.9745
Epoch 23/26
 - 32s - loss: 0.1126 - acc: 0.9631 - val_loss: 0.0849 - val_acc: 0.9745
Epoch 24/26
 - 32s - loss: 0.1099 - acc: 0.9640 - val_loss: 0.1253 - val_acc: 0.9537
Epoch 25/26
 - 32s - loss: 0.1041 - acc: 0.9658 - val_loss: 0.0825 - val_acc: 0.9749
Epoch 26/26
 - 32s - loss: 0.1026 - acc: 0.9670 - val_loss: 0.0722 - val_acc: 0.9785
Test accuracy:0.825
current auc_score ------------------> 0.913
------------------------ current config for the test -------------------------
Layers:  [4, 4]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  26  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 12, 24, 24)   1728        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 12, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 28, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 28, 24, 24)   112         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 28, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 12, 24, 24)   3024        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 12, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 40, 24, 24)   160         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 24, 24)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 12, 24, 24)   4320        activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 12, 24, 24)   0           dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 52, 24, 24)   0           concatenate_2[0][0]              
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 52, 24, 24)   208         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 52, 24, 24)   0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 12, 24, 24)   5616        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 12, 24, 24)   0           dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 64, 24, 24)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 64, 24, 24)   256         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 64, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 32, 24, 24)   2048        activation_6[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 32, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 32, 12, 12)   128         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 32, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 12, 12, 12)   3456        activation_7[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 12, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 44, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 44, 12, 12)   176         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 44, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 12, 12, 12)   4752        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 12, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 56, 12, 12)   0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 56, 12, 12)   224         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 56, 12, 12)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 12, 12, 12)   6048        activation_9[0][0]               
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 12, 12, 12)   0           dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 68, 12, 12)   0           concatenate_6[0][0]              
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_7[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 68, 12, 12)   0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 12, 12, 12)   7344        activation_10[0][0]              
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 12, 12, 12)   0           dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 80, 12, 12)   0           concatenate_7[0][0]              
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 80, 12, 12)   320         concatenate_8[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 80, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 11520)        0           activation_11[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            11521       flatten_1[0][0]                  
==================================================================================================
Total params: 53,409
Trainable params: 52,417
Non-trainable params: 992
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/26
 - 34s - loss: 0.4781 - acc: 0.7694 - val_loss: 0.3854 - val_acc: 0.8282
Epoch 2/26
 - 32s - loss: 0.3687 - acc: 0.8401 - val_loss: 0.3231 - val_acc: 0.8571
Epoch 3/26
 - 32s - loss: 0.3218 - acc: 0.8637 - val_loss: 0.2747 - val_acc: 0.8884
Epoch 4/26
 - 32s - loss: 0.2871 - acc: 0.8816 - val_loss: 0.2725 - val_acc: 0.8888
Epoch 5/26
 - 32s - loss: 0.2624 - acc: 0.8951 - val_loss: 0.2264 - val_acc: 0.9125
Epoch 6/26
 - 32s - loss: 0.2408 - acc: 0.9064 - val_loss: 0.2192 - val_acc: 0.9168
Epoch 7/26
 - 32s - loss: 0.2231 - acc: 0.9136 - val_loss: 0.2031 - val_acc: 0.9255
Epoch 8/26
 - 31s - loss: 0.2097 - acc: 0.9211 - val_loss: 0.1739 - val_acc: 0.9337
Epoch 9/26
 - 32s - loss: 0.1963 - acc: 0.9266 - val_loss: 0.1682 - val_acc: 0.9391
Epoch 10/26
 - 32s - loss: 0.1843 - acc: 0.9311 - val_loss: 0.1491 - val_acc: 0.9440
Epoch 11/26
 - 31s - loss: 0.1755 - acc: 0.9359 - val_loss: 0.1552 - val_acc: 0.9404
Epoch 12/26
 - 32s - loss: 0.1659 - acc: 0.9405 - val_loss: 0.1807 - val_acc: 0.9300
Epoch 13/26
 - 32s - loss: 0.1613 - acc: 0.9424 - val_loss: 0.1548 - val_acc: 0.9424

Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 14/26
 - 32s - loss: 0.1487 - acc: 0.9490 - val_loss: 0.1209 - val_acc: 0.9568
Epoch 15/26
 - 32s - loss: 0.1461 - acc: 0.9496 - val_loss: 0.1274 - val_acc: 0.9557
Epoch 16/26
 - 32s - loss: 0.1437 - acc: 0.9513 - val_loss: 0.1235 - val_acc: 0.9556
Epoch 17/26
 - 32s - loss: 0.1422 - acc: 0.9523 - val_loss: 0.1162 - val_acc: 0.9593
Epoch 18/26
 - 30s - loss: 0.1383 - acc: 0.9528 - val_loss: 0.1127 - val_acc: 0.9591
Epoch 19/26
 - 30s - loss: 0.1381 - acc: 0.9534 - val_loss: 0.1151 - val_acc: 0.9587
Epoch 20/26
 - 31s - loss: 0.1350 - acc: 0.9548 - val_loss: 0.1143 - val_acc: 0.9610
Epoch 21/26
 - 30s - loss: 0.1348 - acc: 0.9531 - val_loss: 0.1089 - val_acc: 0.9625
Epoch 22/26
 - 30s - loss: 0.1318 - acc: 0.9555 - val_loss: 0.1043 - val_acc: 0.9655
Epoch 23/26
 - 30s - loss: 0.1303 - acc: 0.9555 - val_loss: 0.1049 - val_acc: 0.9660
Epoch 24/26
 - 31s - loss: 0.1287 - acc: 0.9570 - val_loss: 0.1033 - val_acc: 0.9665
Epoch 25/26
 - 31s - loss: 0.1252 - acc: 0.9582 - val_loss: 0.1000 - val_acc: 0.9656
Epoch 26/26
 - 30s - loss: 0.1252 - acc: 0.9579 - val_loss: 0.0998 - val_acc: 0.9681
Test accuracy:0.822
current auc_score ------------------> 0.900
------------------------ current config for the test -------------------------
Layers:  [4, 4]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  26  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 12, 24, 24)   1728        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 12, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 28, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 28, 24, 24)   112         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 28, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 12, 24, 24)   3024        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 12, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 40, 24, 24)   160         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 24, 24)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 12, 24, 24)   4320        activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 12, 24, 24)   0           dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 52, 24, 24)   0           concatenate_2[0][0]              
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 52, 24, 24)   208         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 52, 24, 24)   0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 12, 24, 24)   5616        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 12, 24, 24)   0           dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 64, 24, 24)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 64, 24, 24)   256         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 64, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 32, 24, 24)   2048        activation_6[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 32, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 32, 12, 12)   128         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 32, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 12, 12, 12)   3456        activation_7[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 12, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 44, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 44, 12, 12)   176         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 44, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 12, 12, 12)   4752        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 12, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 56, 12, 12)   0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 56, 12, 12)   224         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 56, 12, 12)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 12, 12, 12)   6048        activation_9[0][0]               
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 12, 12, 12)   0           dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 68, 12, 12)   0           concatenate_6[0][0]              
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_7[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 68, 12, 12)   0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 12, 12, 12)   7344        activation_10[0][0]              
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 12, 12, 12)   0           dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 80, 12, 12)   0           concatenate_7[0][0]              
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 80, 12, 12)   320         concatenate_8[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 80, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 11520)        0           activation_11[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            11521       flatten_1[0][0]                  
==================================================================================================
Total params: 53,409
Trainable params: 52,417
Non-trainable params: 992
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/26
 - 34s - loss: 0.4850 - acc: 0.7685 - val_loss: 0.3890 - val_acc: 0.8244
Epoch 2/26
 - 31s - loss: 0.3587 - acc: 0.8460 - val_loss: 0.3439 - val_acc: 0.8514
Epoch 3/26
 - 31s - loss: 0.3112 - acc: 0.8721 - val_loss: 0.2787 - val_acc: 0.8886
Epoch 4/26
 - 30s - loss: 0.2820 - acc: 0.8855 - val_loss: 0.2699 - val_acc: 0.8919
Epoch 5/26
 - 30s - loss: 0.2578 - acc: 0.8998 - val_loss: 0.2277 - val_acc: 0.9142
Epoch 6/26
 - 30s - loss: 0.2390 - acc: 0.9061 - val_loss: 0.2016 - val_acc: 0.9257
Epoch 7/26
 - 31s - loss: 0.2228 - acc: 0.9133 - val_loss: 0.1943 - val_acc: 0.9310
Epoch 8/26
 - 30s - loss: 0.2086 - acc: 0.9205 - val_loss: 0.1799 - val_acc: 0.9337
Epoch 9/26
 - 31s - loss: 0.1968 - acc: 0.9282 - val_loss: 0.1762 - val_acc: 0.9388
Epoch 10/26
 - 30s - loss: 0.1885 - acc: 0.9306 - val_loss: 0.2048 - val_acc: 0.9231
Epoch 11/26
 - 31s - loss: 0.1768 - acc: 0.9350 - val_loss: 0.1526 - val_acc: 0.9450
Epoch 12/26
 - 30s - loss: 0.1664 - acc: 0.9405 - val_loss: 0.1373 - val_acc: 0.9532
Epoch 13/26
 - 30s - loss: 0.1589 - acc: 0.9431 - val_loss: 0.1354 - val_acc: 0.9526
Epoch 14/26
 - 31s - loss: 0.1529 - acc: 0.9462 - val_loss: 0.1218 - val_acc: 0.9601
Epoch 15/26
 - 33s - loss: 0.1467 - acc: 0.9483 - val_loss: 0.1183 - val_acc: 0.9629
Epoch 16/26
 - 32s - loss: 0.1413 - acc: 0.9515 - val_loss: 0.1145 - val_acc: 0.9642
Epoch 17/26
 - 32s - loss: 0.1367 - acc: 0.9528 - val_loss: 0.1029 - val_acc: 0.9667
Epoch 18/26
 - 31s - loss: 0.1302 - acc: 0.9553 - val_loss: 0.1399 - val_acc: 0.9528
Epoch 19/26
 - 32s - loss: 0.1265 - acc: 0.9565 - val_loss: 0.0962 - val_acc: 0.9685
Epoch 20/26
 - 32s - loss: 0.1216 - acc: 0.9594 - val_loss: 0.0914 - val_acc: 0.9733
Epoch 21/26
 - 32s - loss: 0.1171 - acc: 0.9611 - val_loss: 0.0889 - val_acc: 0.9721
Epoch 22/26
 - 32s - loss: 0.1167 - acc: 0.9612 - val_loss: 0.1180 - val_acc: 0.9612
Epoch 23/26
 - 31s - loss: 0.1106 - acc: 0.9631 - val_loss: 0.0868 - val_acc: 0.9762
Epoch 24/26
 - 31s - loss: 0.1066 - acc: 0.9651 - val_loss: 0.0783 - val_acc: 0.9760
Epoch 25/26
 - 32s - loss: 0.1053 - acc: 0.9651 - val_loss: 0.0746 - val_acc: 0.9792
Epoch 26/26
 - 31s - loss: 0.1002 - acc: 0.9680 - val_loss: 0.0746 - val_acc: 0.9775
Test accuracy:0.762
current auc_score ------------------> 0.893
------------------------ current config for the test -------------------------
Layers:  [4, 4]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  26  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 12, 24, 24)   1728        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 12, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 28, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 28, 24, 24)   112         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 28, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 12, 24, 24)   3024        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 12, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 40, 24, 24)   160         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 24, 24)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 12, 24, 24)   4320        activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 12, 24, 24)   0           dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 52, 24, 24)   0           concatenate_2[0][0]              
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 52, 24, 24)   208         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 52, 24, 24)   0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 12, 24, 24)   5616        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 12, 24, 24)   0           dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 64, 24, 24)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 64, 24, 24)   256         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 64, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 32, 24, 24)   2048        activation_6[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 32, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 32, 12, 12)   128         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 32, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 12, 12, 12)   3456        activation_7[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 12, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 44, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 44, 12, 12)   176         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 44, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 12, 12, 12)   4752        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 12, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 56, 12, 12)   0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 56, 12, 12)   224         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 56, 12, 12)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 12, 12, 12)   6048        activation_9[0][0]               
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 12, 12, 12)   0           dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 68, 12, 12)   0           concatenate_6[0][0]              
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_7[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 68, 12, 12)   0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 12, 12, 12)   7344        activation_10[0][0]              
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 12, 12, 12)   0           dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 80, 12, 12)   0           concatenate_7[0][0]              
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 80, 12, 12)   320         concatenate_8[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 80, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 11520)        0           activation_11[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            11521       flatten_1[0][0]                  
==================================================================================================
Total params: 53,409
Trainable params: 52,417
Non-trainable params: 992
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/26
 - 34s - loss: 0.4839 - acc: 0.7676 - val_loss: 0.3884 - val_acc: 0.8272
Epoch 2/26
 - 32s - loss: 0.3671 - acc: 0.8404 - val_loss: 0.3497 - val_acc: 0.8371
Epoch 3/26
 - 32s - loss: 0.3198 - acc: 0.8645 - val_loss: 0.2977 - val_acc: 0.8719
Epoch 4/26
 - 32s - loss: 0.2895 - acc: 0.8810 - val_loss: 0.2521 - val_acc: 0.8963
Epoch 5/26
 - 32s - loss: 0.2642 - acc: 0.8949 - val_loss: 0.2379 - val_acc: 0.9029
Epoch 6/26
 - 31s - loss: 0.2436 - acc: 0.9033 - val_loss: 0.2090 - val_acc: 0.9185
Epoch 7/26
 - 31s - loss: 0.2258 - acc: 0.9134 - val_loss: 0.1922 - val_acc: 0.9301
Epoch 8/26
 - 32s - loss: 0.2093 - acc: 0.9214 - val_loss: 0.1859 - val_acc: 0.9290
Epoch 9/26
 - 31s - loss: 0.1972 - acc: 0.9266 - val_loss: 0.1620 - val_acc: 0.9423
Epoch 10/26
 - 31s - loss: 0.1854 - acc: 0.9322 - val_loss: 0.1760 - val_acc: 0.9317
Epoch 11/26
 - 31s - loss: 0.1738 - acc: 0.9369 - val_loss: 0.1765 - val_acc: 0.9315
Epoch 12/26
 - 31s - loss: 0.1672 - acc: 0.9391 - val_loss: 0.1406 - val_acc: 0.9494
Epoch 13/26
 - 31s - loss: 0.1573 - acc: 0.9440 - val_loss: 0.1651 - val_acc: 0.9396
Epoch 14/26
 - 31s - loss: 0.1499 - acc: 0.9470 - val_loss: 0.1298 - val_acc: 0.9575
Epoch 15/26
 - 31s - loss: 0.1429 - acc: 0.9510 - val_loss: 0.1543 - val_acc: 0.9415
Epoch 16/26
 - 31s - loss: 0.1382 - acc: 0.9518 - val_loss: 0.1149 - val_acc: 0.9625
Epoch 17/26
 - 31s - loss: 0.1310 - acc: 0.9553 - val_loss: 0.1271 - val_acc: 0.9553
Epoch 18/26
 - 33s - loss: 0.1269 - acc: 0.9578 - val_loss: 0.1007 - val_acc: 0.9691
Epoch 19/26
 - 31s - loss: 0.1241 - acc: 0.9581 - val_loss: 0.1016 - val_acc: 0.9665
Epoch 20/26
 - 30s - loss: 0.1186 - acc: 0.9599 - val_loss: 0.1247 - val_acc: 0.9549
Epoch 21/26
 - 31s - loss: 0.1141 - acc: 0.9632 - val_loss: 0.0842 - val_acc: 0.9757
Epoch 22/26
 - 30s - loss: 0.1107 - acc: 0.9639 - val_loss: 0.1134 - val_acc: 0.9626
Epoch 23/26
 - 31s - loss: 0.1057 - acc: 0.9664 - val_loss: 0.0841 - val_acc: 0.9752
Epoch 24/26
 - 30s - loss: 0.1034 - acc: 0.9667 - val_loss: 0.1162 - val_acc: 0.9603

Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 25/26
 - 30s - loss: 0.0964 - acc: 0.9697 - val_loss: 0.0826 - val_acc: 0.9764
Epoch 26/26
 - 30s - loss: 0.0978 - acc: 0.9695 - val_loss: 0.0791 - val_acc: 0.9775
Test accuracy:0.821
current auc_score ------------------> 0.913
------------------------ current config for the test -------------------------
Layers:  [4, 4]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  26  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 12, 24, 24)   1728        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 12, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 28, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 28, 24, 24)   112         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 28, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 12, 24, 24)   3024        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 12, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 40, 24, 24)   160         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 24, 24)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 12, 24, 24)   4320        activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 12, 24, 24)   0           dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 52, 24, 24)   0           concatenate_2[0][0]              
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 52, 24, 24)   208         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 52, 24, 24)   0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 12, 24, 24)   5616        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 12, 24, 24)   0           dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 64, 24, 24)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 64, 24, 24)   256         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 64, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 32, 24, 24)   2048        activation_6[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 32, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 32, 12, 12)   128         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 32, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 12, 12, 12)   3456        activation_7[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 12, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 44, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 44, 12, 12)   176         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 44, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 12, 12, 12)   4752        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 12, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 56, 12, 12)   0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 56, 12, 12)   224         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 56, 12, 12)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 12, 12, 12)   6048        activation_9[0][0]               
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 12, 12, 12)   0           dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 68, 12, 12)   0           concatenate_6[0][0]              
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_7[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 68, 12, 12)   0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 12, 12, 12)   7344        activation_10[0][0]              
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 12, 12, 12)   0           dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 80, 12, 12)   0           concatenate_7[0][0]              
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 80, 12, 12)   320         concatenate_8[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 80, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 11520)        0           activation_11[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            11521       flatten_1[0][0]                  
==================================================================================================
Total params: 53,409
Trainable params: 52,417
Non-trainable params: 992
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/26
 - 33s - loss: 0.4857 - acc: 0.7597 - val_loss: 0.4608 - val_acc: 0.7696
Epoch 2/26
 - 30s - loss: 0.3646 - acc: 0.8381 - val_loss: 0.3610 - val_acc: 0.8321
Epoch 3/26
 - 30s - loss: 0.3165 - acc: 0.8668 - val_loss: 0.3689 - val_acc: 0.8240
Epoch 4/26
 - 30s - loss: 0.2857 - acc: 0.8826 - val_loss: 0.2641 - val_acc: 0.8886
Epoch 5/26
 - 30s - loss: 0.2612 - acc: 0.8942 - val_loss: 0.2616 - val_acc: 0.8874
Epoch 6/26
 - 30s - loss: 0.2392 - acc: 0.9055 - val_loss: 0.2254 - val_acc: 0.9078
Epoch 7/26
 - 31s - loss: 0.2246 - acc: 0.9123 - val_loss: 0.1983 - val_acc: 0.9246
Epoch 8/26
 - 30s - loss: 0.2117 - acc: 0.9195 - val_loss: 0.1984 - val_acc: 0.9219
Epoch 9/26
 - 30s - loss: 0.1985 - acc: 0.9263 - val_loss: 0.2089 - val_acc: 0.9094
Epoch 10/26
 - 30s - loss: 0.1859 - acc: 0.9318 - val_loss: 0.1769 - val_acc: 0.9300
Epoch 11/26
 - 31s - loss: 0.1763 - acc: 0.9365 - val_loss: 0.1683 - val_acc: 0.9361
Epoch 12/26
 - 30s - loss: 0.1703 - acc: 0.9387 - val_loss: 0.1502 - val_acc: 0.9443
Epoch 13/26
 - 30s - loss: 0.1602 - acc: 0.9430 - val_loss: 0.1287 - val_acc: 0.9581
Epoch 14/26
 - 31s - loss: 0.1561 - acc: 0.9442 - val_loss: 0.1302 - val_acc: 0.9561
Epoch 15/26
 - 31s - loss: 0.1485 - acc: 0.9486 - val_loss: 0.1295 - val_acc: 0.9546
Epoch 16/26
 - 30s - loss: 0.1426 - acc: 0.9506 - val_loss: 0.1104 - val_acc: 0.9626
Epoch 17/26
 - 30s - loss: 0.1379 - acc: 0.9534 - val_loss: 0.1176 - val_acc: 0.9603
Epoch 18/26
 - 30s - loss: 0.1320 - acc: 0.9545 - val_loss: 0.1044 - val_acc: 0.9689
Epoch 19/26
 - 30s - loss: 0.1271 - acc: 0.9578 - val_loss: 0.1066 - val_acc: 0.9651
Epoch 20/26
 - 31s - loss: 0.1228 - acc: 0.9586 - val_loss: 0.0954 - val_acc: 0.9720
Epoch 21/26
 - 30s - loss: 0.1188 - acc: 0.9612 - val_loss: 0.0923 - val_acc: 0.9706
Epoch 22/26
 - 30s - loss: 0.1173 - acc: 0.9599 - val_loss: 0.1327 - val_acc: 0.9498
Epoch 23/26
 - 31s - loss: 0.1129 - acc: 0.9634 - val_loss: 0.0918 - val_acc: 0.9714
Epoch 24/26
 - 30s - loss: 0.1098 - acc: 0.9644 - val_loss: 0.0886 - val_acc: 0.9723
Epoch 25/26
 - 30s - loss: 0.1056 - acc: 0.9648 - val_loss: 0.0826 - val_acc: 0.9734
Epoch 26/26
 - 30s - loss: 0.1021 - acc: 0.9672 - val_loss: 0.0952 - val_acc: 0.9677
Test accuracy:0.793
current auc_score ------------------> 0.910
------------------------ current config for the test -------------------------
Layers:  [4, 4]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  26  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 12, 24, 24)   1728        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 12, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 28, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 28, 24, 24)   112         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 28, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 12, 24, 24)   3024        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 12, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 40, 24, 24)   160         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 24, 24)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 12, 24, 24)   4320        activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 12, 24, 24)   0           dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 52, 24, 24)   0           concatenate_2[0][0]              
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 52, 24, 24)   208         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 52, 24, 24)   0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 12, 24, 24)   5616        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 12, 24, 24)   0           dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 64, 24, 24)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 64, 24, 24)   256         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 64, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 32, 24, 24)   2048        activation_6[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 32, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 32, 12, 12)   128         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 32, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 12, 12, 12)   3456        activation_7[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 12, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 44, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 44, 12, 12)   176         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 44, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 12, 12, 12)   4752        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 12, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 56, 12, 12)   0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 56, 12, 12)   224         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 56, 12, 12)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 12, 12, 12)   6048        activation_9[0][0]               
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 12, 12, 12)   0           dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 68, 12, 12)   0           concatenate_6[0][0]              
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_7[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 68, 12, 12)   0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 12, 12, 12)   7344        activation_10[0][0]              
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 12, 12, 12)   0           dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 80, 12, 12)   0           concatenate_7[0][0]              
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 80, 12, 12)   320         concatenate_8[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 80, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 11520)        0           activation_11[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            11521       flatten_1[0][0]                  
==================================================================================================
Total params: 53,409
Trainable params: 52,417
Non-trainable params: 992
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/26
 - 32s - loss: 0.4652 - acc: 0.7797 - val_loss: 0.4075 - val_acc: 0.8086
Epoch 2/26
 - 30s - loss: 0.3504 - acc: 0.8474 - val_loss: 0.3442 - val_acc: 0.8464
Epoch 3/26
 - 30s - loss: 0.3069 - acc: 0.8714 - val_loss: 0.2701 - val_acc: 0.8881
Epoch 4/26
 - 30s - loss: 0.2782 - acc: 0.8866 - val_loss: 0.2435 - val_acc: 0.9044
Epoch 5/26
 - 30s - loss: 0.2558 - acc: 0.8971 - val_loss: 0.2415 - val_acc: 0.8996
Epoch 6/26
 - 30s - loss: 0.2388 - acc: 0.9060 - val_loss: 0.2139 - val_acc: 0.9142
Epoch 7/26
 - 30s - loss: 0.2237 - acc: 0.9142 - val_loss: 0.1994 - val_acc: 0.9221
Epoch 8/26
 - 30s - loss: 0.2115 - acc: 0.9186 - val_loss: 0.1748 - val_acc: 0.9359
Epoch 9/26
 - 30s - loss: 0.1957 - acc: 0.9259 - val_loss: 0.1644 - val_acc: 0.9396
Epoch 10/26
 - 30s - loss: 0.1861 - acc: 0.9315 - val_loss: 0.1514 - val_acc: 0.9474
Epoch 11/26
 - 30s - loss: 0.1762 - acc: 0.9347 - val_loss: 0.1489 - val_acc: 0.9468
Epoch 12/26
 - 30s - loss: 0.1685 - acc: 0.9389 - val_loss: 0.1452 - val_acc: 0.9460
Epoch 13/26
 - 30s - loss: 0.1616 - acc: 0.9417 - val_loss: 0.1360 - val_acc: 0.9497
Epoch 14/26
 - 30s - loss: 0.1537 - acc: 0.9460 - val_loss: 0.1237 - val_acc: 0.9591
Epoch 15/26
 - 30s - loss: 0.1465 - acc: 0.9484 - val_loss: 0.1266 - val_acc: 0.9562
Epoch 16/26
 - 30s - loss: 0.1406 - acc: 0.9504 - val_loss: 0.1339 - val_acc: 0.9497
Epoch 17/26
 - 30s - loss: 0.1341 - acc: 0.9539 - val_loss: 0.1045 - val_acc: 0.9659
Epoch 18/26
 - 30s - loss: 0.1306 - acc: 0.9549 - val_loss: 0.1211 - val_acc: 0.9531
Epoch 19/26
 - 30s - loss: 0.1254 - acc: 0.9570 - val_loss: 0.1025 - val_acc: 0.9646
Epoch 20/26
 - 30s - loss: 0.1222 - acc: 0.9570 - val_loss: 0.1045 - val_acc: 0.9640
Epoch 21/26
 - 30s - loss: 0.1177 - acc: 0.9600 - val_loss: 0.0966 - val_acc: 0.9650
Epoch 00021: early stopping
Test accuracy:0.827
current auc_score ------------------> 0.878
------------------------ current config for the test -------------------------
Layers:  [4, 4]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  26  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 12, 24, 24)   1728        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 12, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 28, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 28, 24, 24)   112         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 28, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 12, 24, 24)   3024        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 12, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 40, 24, 24)   160         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 24, 24)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 12, 24, 24)   4320        activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 12, 24, 24)   0           dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 52, 24, 24)   0           concatenate_2[0][0]              
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 52, 24, 24)   208         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 52, 24, 24)   0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 12, 24, 24)   5616        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 12, 24, 24)   0           dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 64, 24, 24)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 64, 24, 24)   256         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 64, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 32, 24, 24)   2048        activation_6[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 32, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 32, 12, 12)   128         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 32, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 12, 12, 12)   3456        activation_7[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 12, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 44, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 44, 12, 12)   176         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 44, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 12, 12, 12)   4752        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 12, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 56, 12, 12)   0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 56, 12, 12)   224         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 56, 12, 12)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 12, 12, 12)   6048        activation_9[0][0]               
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 12, 12, 12)   0           dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 68, 12, 12)   0           concatenate_6[0][0]              
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_7[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 68, 12, 12)   0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 12, 12, 12)   7344        activation_10[0][0]              
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 12, 12, 12)   0           dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 80, 12, 12)   0           concatenate_7[0][0]              
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 80, 12, 12)   320         concatenate_8[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 80, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 11520)        0           activation_11[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            11521       flatten_1[0][0]                  
==================================================================================================
Total params: 53,409
Trainable params: 52,417
Non-trainable params: 992
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/26
 - 32s - loss: 0.4870 - acc: 0.7634 - val_loss: 0.3844 - val_acc: 0.8286
Epoch 2/26
 - 30s - loss: 0.3655 - acc: 0.8400 - val_loss: 0.3151 - val_acc: 0.8672
Epoch 3/26
 - 31s - loss: 0.3160 - acc: 0.8669 - val_loss: 0.2771 - val_acc: 0.8835
Epoch 4/26
 - 30s - loss: 0.2840 - acc: 0.8836 - val_loss: 0.2465 - val_acc: 0.9029
Epoch 5/26
 - 30s - loss: 0.2585 - acc: 0.8966 - val_loss: 0.2393 - val_acc: 0.9051
Epoch 6/26
 - 30s - loss: 0.2408 - acc: 0.9042 - val_loss: 0.2525 - val_acc: 0.8924
Epoch 7/26
 - 30s - loss: 0.2245 - acc: 0.9133 - val_loss: 0.2050 - val_acc: 0.9174
Epoch 8/26
 - 30s - loss: 0.2060 - acc: 0.9229 - val_loss: 0.2205 - val_acc: 0.9111
Epoch 9/26
 - 30s - loss: 0.1967 - acc: 0.9273 - val_loss: 0.1683 - val_acc: 0.9384
Epoch 10/26
 - 30s - loss: 0.1870 - acc: 0.9313 - val_loss: 0.1621 - val_acc: 0.9403
Epoch 11/26
 - 30s - loss: 0.1765 - acc: 0.9356 - val_loss: 0.1445 - val_acc: 0.9497
Epoch 12/26
 - 30s - loss: 0.1696 - acc: 0.9377 - val_loss: 0.1478 - val_acc: 0.9447
Epoch 13/26
 - 30s - loss: 0.1614 - acc: 0.9426 - val_loss: 0.1254 - val_acc: 0.9591
Epoch 14/26
 - 30s - loss: 0.1540 - acc: 0.9449 - val_loss: 0.1202 - val_acc: 0.9608
Epoch 15/26
 - 30s - loss: 0.1493 - acc: 0.9490 - val_loss: 0.1287 - val_acc: 0.9572
Epoch 16/26
 - 30s - loss: 0.1412 - acc: 0.9517 - val_loss: 0.1361 - val_acc: 0.9518
Epoch 17/26
 - 30s - loss: 0.1355 - acc: 0.9534 - val_loss: 0.1118 - val_acc: 0.9650
Epoch 18/26
 - 30s - loss: 0.1301 - acc: 0.9561 - val_loss: 0.1090 - val_acc: 0.9646
Epoch 19/26
 - 30s - loss: 0.1251 - acc: 0.9574 - val_loss: 0.0967 - val_acc: 0.9710
Epoch 20/26
 - 30s - loss: 0.1226 - acc: 0.9589 - val_loss: 0.0934 - val_acc: 0.9711
Epoch 21/26
 - 30s - loss: 0.1170 - acc: 0.9601 - val_loss: 0.0918 - val_acc: 0.9720
Epoch 22/26
 - 30s - loss: 0.1142 - acc: 0.9632 - val_loss: 0.0915 - val_acc: 0.9714
Epoch 23/26
 - 30s - loss: 0.1094 - acc: 0.9645 - val_loss: 0.1006 - val_acc: 0.9660
Epoch 24/26
 - 30s - loss: 0.1060 - acc: 0.9658 - val_loss: 0.0965 - val_acc: 0.9690
Epoch 25/26
 - 30s - loss: 0.1055 - acc: 0.9648 - val_loss: 0.0847 - val_acc: 0.9725
Epoch 26/26
 - 30s - loss: 0.1011 - acc: 0.9674 - val_loss: 0.0814 - val_acc: 0.9744
Test accuracy:0.785
current auc_score ------------------> 0.900
------------------------ current config for the test -------------------------
Layers:  [4, 4]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  26  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 12, 24, 24)   1728        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 12, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 28, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 28, 24, 24)   112         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 28, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 12, 24, 24)   3024        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 12, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 40, 24, 24)   160         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 24, 24)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 12, 24, 24)   4320        activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 12, 24, 24)   0           dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 52, 24, 24)   0           concatenate_2[0][0]              
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 52, 24, 24)   208         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 52, 24, 24)   0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 12, 24, 24)   5616        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 12, 24, 24)   0           dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 64, 24, 24)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 64, 24, 24)   256         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 64, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 32, 24, 24)   2048        activation_6[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 32, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 32, 12, 12)   128         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 32, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 12, 12, 12)   3456        activation_7[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 12, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 44, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 44, 12, 12)   176         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 44, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 12, 12, 12)   4752        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 12, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 56, 12, 12)   0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 56, 12, 12)   224         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 56, 12, 12)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 12, 12, 12)   6048        activation_9[0][0]               
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 12, 12, 12)   0           dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 68, 12, 12)   0           concatenate_6[0][0]              
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_7[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 68, 12, 12)   0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 12, 12, 12)   7344        activation_10[0][0]              
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 12, 12, 12)   0           dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 80, 12, 12)   0           concatenate_7[0][0]              
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 80, 12, 12)   320         concatenate_8[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 80, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 11520)        0           activation_11[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            11521       flatten_1[0][0]                  
==================================================================================================
Total params: 53,409
Trainable params: 52,417
Non-trainable params: 992
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/26
 - 33s - loss: 0.4814 - acc: 0.7690 - val_loss: 0.3898 - val_acc: 0.8272
Epoch 2/26
 - 30s - loss: 0.3669 - acc: 0.8412 - val_loss: 0.3161 - val_acc: 0.8680
Epoch 3/26
 - 29s - loss: 0.3189 - acc: 0.8662 - val_loss: 0.2833 - val_acc: 0.8823
Epoch 4/26
 - 30s - loss: 0.2875 - acc: 0.8827 - val_loss: 0.2481 - val_acc: 0.9007
Epoch 5/26
 - 30s - loss: 0.2640 - acc: 0.8935 - val_loss: 0.2375 - val_acc: 0.9079
Epoch 6/26
 - 30s - loss: 0.2444 - acc: 0.9041 - val_loss: 0.2148 - val_acc: 0.9222
Epoch 7/26
 - 29s - loss: 0.2271 - acc: 0.9124 - val_loss: 0.1945 - val_acc: 0.9305
Epoch 8/26
 - 30s - loss: 0.2128 - acc: 0.9192 - val_loss: 0.1909 - val_acc: 0.9282
Epoch 9/26
 - 30s - loss: 0.2023 - acc: 0.9236 - val_loss: 0.1776 - val_acc: 0.9365
Epoch 10/26
 - 30s - loss: 0.1927 - acc: 0.9281 - val_loss: 0.1732 - val_acc: 0.9346
Epoch 11/26
 - 30s - loss: 0.1823 - acc: 0.9331 - val_loss: 0.1582 - val_acc: 0.9465
Epoch 12/26
 - 29s - loss: 0.1770 - acc: 0.9357 - val_loss: 0.1490 - val_acc: 0.9494
Epoch 13/26
 - 30s - loss: 0.1652 - acc: 0.9405 - val_loss: 0.1394 - val_acc: 0.9541
Epoch 14/26
 - 30s - loss: 0.1616 - acc: 0.9409 - val_loss: 0.1280 - val_acc: 0.9590
Epoch 15/26
 - 30s - loss: 0.1541 - acc: 0.9450 - val_loss: 0.1234 - val_acc: 0.9586
Epoch 16/26
 - 30s - loss: 0.1455 - acc: 0.9492 - val_loss: 0.1204 - val_acc: 0.9622
Epoch 17/26
 - 30s - loss: 0.1430 - acc: 0.9507 - val_loss: 0.1143 - val_acc: 0.9622
Epoch 18/26
 - 30s - loss: 0.1380 - acc: 0.9522 - val_loss: 0.1134 - val_acc: 0.9627
Epoch 19/26
 - 30s - loss: 0.1340 - acc: 0.9535 - val_loss: 0.1071 - val_acc: 0.9690
Epoch 20/26
 - 30s - loss: 0.1294 - acc: 0.9558 - val_loss: 0.0960 - val_acc: 0.9725
Epoch 21/26
 - 30s - loss: 0.1245 - acc: 0.9585 - val_loss: 0.1063 - val_acc: 0.9650
Epoch 22/26
 - 30s - loss: 0.1215 - acc: 0.9595 - val_loss: 0.0873 - val_acc: 0.9734
Epoch 23/26
 - 30s - loss: 0.1175 - acc: 0.9603 - val_loss: 0.0933 - val_acc: 0.9718
Epoch 24/26
 - 30s - loss: 0.1142 - acc: 0.9612 - val_loss: 0.0953 - val_acc: 0.9720
Epoch 25/26
 - 30s - loss: 0.1103 - acc: 0.9628 - val_loss: 0.0818 - val_acc: 0.9777
Epoch 26/26
 - 30s - loss: 0.1094 - acc: 0.9640 - val_loss: 0.0797 - val_acc: 0.9754
Test accuracy:0.823
current auc_score ------------------> 0.891
------------------------ current config for the test -------------------------
Layers:  [4, 4]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  26  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 12, 24, 24)   1728        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 12, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 28, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 28, 24, 24)   112         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 28, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 12, 24, 24)   3024        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 12, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 40, 24, 24)   160         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 24, 24)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 12, 24, 24)   4320        activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 12, 24, 24)   0           dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 52, 24, 24)   0           concatenate_2[0][0]              
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 52, 24, 24)   208         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 52, 24, 24)   0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 12, 24, 24)   5616        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 12, 24, 24)   0           dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 64, 24, 24)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 64, 24, 24)   256         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 64, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 32, 24, 24)   2048        activation_6[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 32, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 32, 12, 12)   128         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 32, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 12, 12, 12)   3456        activation_7[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 12, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 44, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 44, 12, 12)   176         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 44, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 12, 12, 12)   4752        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 12, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 56, 12, 12)   0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 56, 12, 12)   224         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 56, 12, 12)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 12, 12, 12)   6048        activation_9[0][0]               
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 12, 12, 12)   0           dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 68, 12, 12)   0           concatenate_6[0][0]              
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_7[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 68, 12, 12)   0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 12, 12, 12)   7344        activation_10[0][0]              
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 12, 12, 12)   0           dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 80, 12, 12)   0           concatenate_7[0][0]              
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 80, 12, 12)   320         concatenate_8[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 80, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 11520)        0           activation_11[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            11521       flatten_1[0][0]                  
==================================================================================================
Total params: 53,409
Trainable params: 52,417
Non-trainable params: 992
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/26
 - 33s - loss: 0.4799 - acc: 0.7733 - val_loss: 0.3818 - val_acc: 0.8330
Epoch 2/26
 - 30s - loss: 0.3676 - acc: 0.8400 - val_loss: 0.3339 - val_acc: 0.8572
Epoch 3/26
 - 30s - loss: 0.3192 - acc: 0.8672 - val_loss: 0.2965 - val_acc: 0.8758
Epoch 4/26
 - 30s - loss: 0.2919 - acc: 0.8807 - val_loss: 0.2908 - val_acc: 0.8776
Epoch 5/26
 - 30s - loss: 0.2669 - acc: 0.8932 - val_loss: 0.2373 - val_acc: 0.9086
Epoch 6/26
 - 30s - loss: 0.2461 - acc: 0.9039 - val_loss: 0.2231 - val_acc: 0.9137
Epoch 7/26
 - 30s - loss: 0.2314 - acc: 0.9101 - val_loss: 0.2086 - val_acc: 0.9218
Epoch 8/26
 - 30s - loss: 0.2164 - acc: 0.9174 - val_loss: 0.2083 - val_acc: 0.9177
Epoch 9/26
 - 30s - loss: 0.2045 - acc: 0.9233 - val_loss: 0.1784 - val_acc: 0.9352
Epoch 10/26
 - 30s - loss: 0.1938 - acc: 0.9280 - val_loss: 0.1631 - val_acc: 0.9439
Epoch 11/26
 - 30s - loss: 0.1841 - acc: 0.9324 - val_loss: 0.1672 - val_acc: 0.9385
Epoch 12/26
 - 30s - loss: 0.1766 - acc: 0.9369 - val_loss: 0.1515 - val_acc: 0.9439
Epoch 13/26
 - 30s - loss: 0.1663 - acc: 0.9404 - val_loss: 0.1369 - val_acc: 0.9544
Epoch 14/26
 - 30s - loss: 0.1584 - acc: 0.9421 - val_loss: 0.1389 - val_acc: 0.9511
Epoch 15/26
 - 30s - loss: 0.1521 - acc: 0.9466 - val_loss: 0.1300 - val_acc: 0.9553
Epoch 16/26
 - 30s - loss: 0.1461 - acc: 0.9480 - val_loss: 0.1456 - val_acc: 0.9442
Epoch 17/26
 - 30s - loss: 0.1401 - acc: 0.9518 - val_loss: 0.1089 - val_acc: 0.9639
Epoch 18/26
 - 30s - loss: 0.1368 - acc: 0.9522 - val_loss: 0.1142 - val_acc: 0.9613
Epoch 19/26
 - 30s - loss: 0.1307 - acc: 0.9560 - val_loss: 0.1047 - val_acc: 0.9670
Epoch 20/26
 - 30s - loss: 0.1261 - acc: 0.9574 - val_loss: 0.1145 - val_acc: 0.9583
Epoch 21/26
 - 30s - loss: 0.1242 - acc: 0.9576 - val_loss: 0.1079 - val_acc: 0.9641
Epoch 22/26
 - 30s - loss: 0.1190 - acc: 0.9605 - val_loss: 0.0874 - val_acc: 0.9744
Epoch 23/26
 - 32s - loss: 0.1134 - acc: 0.9628 - val_loss: 0.1031 - val_acc: 0.9651
Epoch 24/26
 - 31s - loss: 0.1124 - acc: 0.9630 - val_loss: 0.1006 - val_acc: 0.9660
Epoch 25/26
 - 30s - loss: 0.1088 - acc: 0.9642 - val_loss: 0.0816 - val_acc: 0.9750
Epoch 26/26
 - 31s - loss: 0.1052 - acc: 0.9657 - val_loss: 0.0860 - val_acc: 0.9703
Test accuracy:0.833
current auc_score ------------------> 0.914
------------------------ current config for the test -------------------------
Layers:  [4, 4]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  26  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 12, 24, 24)   1728        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 12, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 28, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 28, 24, 24)   112         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 28, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 12, 24, 24)   3024        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 12, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 40, 24, 24)   160         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 24, 24)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 12, 24, 24)   4320        activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 12, 24, 24)   0           dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 52, 24, 24)   0           concatenate_2[0][0]              
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 52, 24, 24)   208         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 52, 24, 24)   0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 12, 24, 24)   5616        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 12, 24, 24)   0           dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 64, 24, 24)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 64, 24, 24)   256         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 64, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 32, 24, 24)   2048        activation_6[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 32, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 32, 12, 12)   128         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 32, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 12, 12, 12)   3456        activation_7[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 12, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 44, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 44, 12, 12)   176         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 44, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 12, 12, 12)   4752        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 12, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 56, 12, 12)   0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 56, 12, 12)   224         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 56, 12, 12)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 12, 12, 12)   6048        activation_9[0][0]               
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 12, 12, 12)   0           dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 68, 12, 12)   0           concatenate_6[0][0]              
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_7[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 68, 12, 12)   0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 12, 12, 12)   7344        activation_10[0][0]              
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 12, 12, 12)   0           dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 80, 12, 12)   0           concatenate_7[0][0]              
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 80, 12, 12)   320         concatenate_8[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 80, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 11520)        0           activation_11[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            11521       flatten_1[0][0]                  
==================================================================================================
Total params: 53,409
Trainable params: 52,417
Non-trainable params: 992
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/26
 - 33s - loss: 0.4948 - acc: 0.7604 - val_loss: 0.4211 - val_acc: 0.7951
Epoch 2/26
 - 31s - loss: 0.3694 - acc: 0.8377 - val_loss: 0.4383 - val_acc: 0.7711
Epoch 3/26
 - 31s - loss: 0.3191 - acc: 0.8651 - val_loss: 0.2831 - val_acc: 0.8855
Epoch 4/26
 - 31s - loss: 0.2874 - acc: 0.8815 - val_loss: 0.2578 - val_acc: 0.8941
Epoch 5/26
 - 31s - loss: 0.2608 - acc: 0.8953 - val_loss: 0.2337 - val_acc: 0.9084
Epoch 6/26
 - 31s - loss: 0.2431 - acc: 0.9046 - val_loss: 0.2043 - val_acc: 0.9227
Epoch 7/26
 - 31s - loss: 0.2261 - acc: 0.9117 - val_loss: 0.2152 - val_acc: 0.9111
Epoch 8/26
 - 31s - loss: 0.2143 - acc: 0.9198 - val_loss: 0.1763 - val_acc: 0.9365
Epoch 9/26
 - 31s - loss: 0.2033 - acc: 0.9215 - val_loss: 0.1691 - val_acc: 0.9379
Epoch 10/26
 - 31s - loss: 0.1911 - acc: 0.9309 - val_loss: 0.1685 - val_acc: 0.9390
Epoch 11/26
 - 31s - loss: 0.1818 - acc: 0.9337 - val_loss: 0.1502 - val_acc: 0.9469
Epoch 12/26
 - 31s - loss: 0.1746 - acc: 0.9369 - val_loss: 0.1408 - val_acc: 0.9509
Epoch 13/26
 - 31s - loss: 0.1665 - acc: 0.9404 - val_loss: 0.1392 - val_acc: 0.9501
Epoch 14/26
 - 31s - loss: 0.1604 - acc: 0.9426 - val_loss: 0.1425 - val_acc: 0.9506
Epoch 15/26
 - 31s - loss: 0.1511 - acc: 0.9470 - val_loss: 0.1835 - val_acc: 0.9271
Epoch 16/26
 - 31s - loss: 0.1459 - acc: 0.9490 - val_loss: 0.1191 - val_acc: 0.9610
Epoch 17/26
 - 31s - loss: 0.1419 - acc: 0.9495 - val_loss: 0.1097 - val_acc: 0.9651
Epoch 18/26
 - 31s - loss: 0.1377 - acc: 0.9518 - val_loss: 0.1047 - val_acc: 0.9662
Epoch 19/26
 - 31s - loss: 0.1323 - acc: 0.9553 - val_loss: 0.1002 - val_acc: 0.9688
Epoch 20/26
 - 31s - loss: 0.1272 - acc: 0.9567 - val_loss: 0.1143 - val_acc: 0.9612
Epoch 21/26
 - 31s - loss: 0.1253 - acc: 0.9572 - val_loss: 0.0998 - val_acc: 0.9706
Epoch 22/26
 - 31s - loss: 0.1193 - acc: 0.9596 - val_loss: 0.1199 - val_acc: 0.9616
Epoch 23/26
 - 31s - loss: 0.1165 - acc: 0.9616 - val_loss: 0.0959 - val_acc: 0.9711
Epoch 24/26
 - 31s - loss: 0.1124 - acc: 0.9623 - val_loss: 0.0908 - val_acc: 0.9718
Epoch 25/26
 - 31s - loss: 0.1126 - acc: 0.9617 - val_loss: 0.0893 - val_acc: 0.9721
Epoch 26/26
 - 31s - loss: 0.1076 - acc: 0.9644 - val_loss: 0.0921 - val_acc: 0.9726
Test accuracy:0.765
current auc_score ------------------> 0.918
accuracies:  [0.825, 0.8224462365591397, 0.7618279569892473, 0.8209677419354838, 0.7931451612903225, 0.8271505376344086, 0.7850806451612903, 0.8228494623655914, 0.8327956989247312, 0.7653225806451613]
aucs:  [0.9134, 0.8998, 0.893, 0.9133, 0.9099, 0.8778, 0.8999, 0.8914, 0.9145, 0.9176]
mean and std AUC:  0.903+/-0.012  max:   0.9176
['4-4', '18', '2', '16', '0.2', '0.07', '24', 'adadelta', '0.5', 'FALSE', '64', 'flatten']
------------------------ current config for the test -------------------------
Layers:  [4, 4]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  24  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   2592        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 34, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 34, 24, 24)   136         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 34, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   5508        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 52, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 52, 24, 24)   208         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 52, 24, 24)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 18, 24, 24)   8424        activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 24, 24)   0           dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 70, 24, 24)   0           concatenate_2[0][0]              
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 70, 24, 24)   280         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 70, 24, 24)   0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 18, 24, 24)   11340       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 24, 24)   0           dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 88, 24, 24)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 88, 24, 24)   352         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 88, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 44, 24, 24)   3872        activation_6[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 44, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 44, 12, 12)   176         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 44, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   7128        activation_7[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 62, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 62, 12, 12)   248         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 62, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   10044       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 80, 12, 12)   0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 80, 12, 12)   320         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 80, 12, 12)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 18, 12, 12)   12960       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 18, 12, 12)   0           dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 98, 12, 12)   0           concatenate_6[0][0]              
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 98, 12, 12)   392         concatenate_7[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 98, 12, 12)   0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 18, 12, 12)   15876       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 18, 12, 12)   0           dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 116, 12, 12)  0           concatenate_7[0][0]              
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 116, 12, 12)  464         concatenate_8[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 116, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 16704)        0           activation_11[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            16705       flatten_1[0][0]                  
==================================================================================================
Total params: 98,721
Trainable params: 97,369
Non-trainable params: 1,352
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/24
 - 40s - loss: 0.4631 - acc: 0.7803 - val_loss: 0.4222 - val_acc: 0.7974
Epoch 2/24
 - 38s - loss: 0.3399 - acc: 0.8550 - val_loss: 0.4121 - val_acc: 0.7991
Epoch 3/24
 - 38s - loss: 0.2900 - acc: 0.8823 - val_loss: 0.2671 - val_acc: 0.8899
Epoch 4/24
 - 38s - loss: 0.2572 - acc: 0.8978 - val_loss: 0.4493 - val_acc: 0.7838
Epoch 5/24
 - 38s - loss: 0.2269 - acc: 0.9123 - val_loss: 0.1873 - val_acc: 0.9331
Epoch 6/24
 - 38s - loss: 0.2077 - acc: 0.9200 - val_loss: 0.1744 - val_acc: 0.9371
Epoch 7/24
 - 38s - loss: 0.1909 - acc: 0.9313 - val_loss: 0.1639 - val_acc: 0.9447
Epoch 8/24
 - 38s - loss: 0.1755 - acc: 0.9366 - val_loss: 0.1398 - val_acc: 0.9532
Epoch 9/24
 - 38s - loss: 0.1616 - acc: 0.9428 - val_loss: 0.1325 - val_acc: 0.9547
Epoch 10/24
 - 38s - loss: 0.1490 - acc: 0.9487 - val_loss: 0.1274 - val_acc: 0.9620
Epoch 11/24
 - 38s - loss: 0.1402 - acc: 0.9532 - val_loss: 0.1231 - val_acc: 0.9613
Epoch 12/24
 - 38s - loss: 0.1313 - acc: 0.9570 - val_loss: 0.1027 - val_acc: 0.9714
Epoch 13/24
 - 38s - loss: 0.1242 - acc: 0.9597 - val_loss: 0.0912 - val_acc: 0.9770
Epoch 14/24
 - 39s - loss: 0.1178 - acc: 0.9626 - val_loss: 0.1651 - val_acc: 0.9341
Epoch 15/24
 - 39s - loss: 0.1122 - acc: 0.9638 - val_loss: 0.0900 - val_acc: 0.9743
Epoch 16/24
 - 38s - loss: 0.1053 - acc: 0.9668 - val_loss: 0.1424 - val_acc: 0.9460
Epoch 17/24
 - 38s - loss: 0.1003 - acc: 0.9684 - val_loss: 0.0806 - val_acc: 0.9790
Epoch 18/24
 - 38s - loss: 0.0968 - acc: 0.9708 - val_loss: 0.0697 - val_acc: 0.9836
Epoch 19/24
 - 38s - loss: 0.0928 - acc: 0.9713 - val_loss: 0.0710 - val_acc: 0.9816
Epoch 20/24
 - 39s - loss: 0.0878 - acc: 0.9739 - val_loss: 0.0623 - val_acc: 0.9863
Epoch 21/24
 - 38s - loss: 0.0837 - acc: 0.9758 - val_loss: 0.0617 - val_acc: 0.9839
Epoch 22/24
 - 38s - loss: 0.0812 - acc: 0.9757 - val_loss: 0.0633 - val_acc: 0.9848
Epoch 23/24
 - 37s - loss: 0.0782 - acc: 0.9768 - val_loss: 0.0627 - val_acc: 0.9853
Epoch 24/24
 - 37s - loss: 0.0761 - acc: 0.9771 - val_loss: 0.0506 - val_acc: 0.9892
Test accuracy:0.793
current auc_score ------------------> 0.909
------------------------ current config for the test -------------------------
Layers:  [4, 4]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  24  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   2592        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 34, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 34, 24, 24)   136         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 34, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   5508        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 52, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 52, 24, 24)   208         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 52, 24, 24)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 18, 24, 24)   8424        activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 24, 24)   0           dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 70, 24, 24)   0           concatenate_2[0][0]              
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 70, 24, 24)   280         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 70, 24, 24)   0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 18, 24, 24)   11340       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 24, 24)   0           dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 88, 24, 24)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 88, 24, 24)   352         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 88, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 44, 24, 24)   3872        activation_6[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 44, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 44, 12, 12)   176         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 44, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   7128        activation_7[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 62, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 62, 12, 12)   248         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 62, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   10044       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 80, 12, 12)   0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 80, 12, 12)   320         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 80, 12, 12)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 18, 12, 12)   12960       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 18, 12, 12)   0           dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 98, 12, 12)   0           concatenate_6[0][0]              
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 98, 12, 12)   392         concatenate_7[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 98, 12, 12)   0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 18, 12, 12)   15876       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 18, 12, 12)   0           dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 116, 12, 12)  0           concatenate_7[0][0]              
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 116, 12, 12)  464         concatenate_8[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 116, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 16704)        0           activation_11[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            16705       flatten_1[0][0]                  
==================================================================================================
Total params: 98,721
Trainable params: 97,369
Non-trainable params: 1,352
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/24
 - 40s - loss: 0.4619 - acc: 0.7823 - val_loss: 0.3712 - val_acc: 0.8335
Epoch 2/24
 - 38s - loss: 0.3419 - acc: 0.8560 - val_loss: 0.3565 - val_acc: 0.8363
Epoch 3/24
 - 38s - loss: 0.2925 - acc: 0.8825 - val_loss: 0.2631 - val_acc: 0.8958
Epoch 4/24
 - 38s - loss: 0.2609 - acc: 0.8971 - val_loss: 0.2182 - val_acc: 0.9197
Epoch 5/24
 - 38s - loss: 0.2358 - acc: 0.9099 - val_loss: 0.2065 - val_acc: 0.9227
Epoch 6/24
 - 38s - loss: 0.2163 - acc: 0.9204 - val_loss: 0.1857 - val_acc: 0.9315
Epoch 7/24
 - 38s - loss: 0.2025 - acc: 0.9251 - val_loss: 0.1602 - val_acc: 0.9457
Epoch 8/24
 - 37s - loss: 0.1853 - acc: 0.9335 - val_loss: 0.1453 - val_acc: 0.9516
Epoch 9/24
 - 38s - loss: 0.1727 - acc: 0.9394 - val_loss: 0.1412 - val_acc: 0.9547
Epoch 10/24
 - 38s - loss: 0.1623 - acc: 0.9444 - val_loss: 0.1258 - val_acc: 0.9606
Epoch 11/24
 - 38s - loss: 0.1525 - acc: 0.9468 - val_loss: 0.1195 - val_acc: 0.9631
Epoch 12/24
 - 38s - loss: 0.1418 - acc: 0.9520 - val_loss: 0.1206 - val_acc: 0.9572
Epoch 13/24
 - 38s - loss: 0.1355 - acc: 0.9540 - val_loss: 0.1415 - val_acc: 0.9458
Epoch 14/24
 - 38s - loss: 0.1282 - acc: 0.9578 - val_loss: 0.0962 - val_acc: 0.9716
Epoch 15/24
 - 38s - loss: 0.1216 - acc: 0.9612 - val_loss: 0.0888 - val_acc: 0.9733
Epoch 16/24
 - 38s - loss: 0.1148 - acc: 0.9626 - val_loss: 0.0877 - val_acc: 0.9710
Epoch 17/24
 - 38s - loss: 0.1112 - acc: 0.9647 - val_loss: 0.0820 - val_acc: 0.9757
Epoch 18/24
 - 38s - loss: 0.1064 - acc: 0.9659 - val_loss: 0.0854 - val_acc: 0.9749
Epoch 19/24
 - 38s - loss: 0.1021 - acc: 0.9679 - val_loss: 0.0811 - val_acc: 0.9745
Epoch 20/24
 - 38s - loss: 0.0978 - acc: 0.9700 - val_loss: 0.0707 - val_acc: 0.9803
Epoch 21/24
 - 37s - loss: 0.0943 - acc: 0.9710 - val_loss: 0.0714 - val_acc: 0.9782
Epoch 22/24
 - 38s - loss: 0.0898 - acc: 0.9730 - val_loss: 0.0670 - val_acc: 0.9798
Epoch 23/24
 - 38s - loss: 0.0873 - acc: 0.9736 - val_loss: 0.0612 - val_acc: 0.9841
Epoch 24/24
 - 38s - loss: 0.0828 - acc: 0.9748 - val_loss: 0.0628 - val_acc: 0.9837
Test accuracy:0.833
current auc_score ------------------> 0.914
------------------------ current config for the test -------------------------
Layers:  [4, 4]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  24  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   2592        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 34, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 34, 24, 24)   136         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 34, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   5508        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 52, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 52, 24, 24)   208         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 52, 24, 24)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 18, 24, 24)   8424        activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 24, 24)   0           dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 70, 24, 24)   0           concatenate_2[0][0]              
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 70, 24, 24)   280         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 70, 24, 24)   0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 18, 24, 24)   11340       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 24, 24)   0           dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 88, 24, 24)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 88, 24, 24)   352         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 88, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 44, 24, 24)   3872        activation_6[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 44, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 44, 12, 12)   176         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 44, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   7128        activation_7[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 62, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 62, 12, 12)   248         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 62, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   10044       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 80, 12, 12)   0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 80, 12, 12)   320         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 80, 12, 12)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 18, 12, 12)   12960       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 18, 12, 12)   0           dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 98, 12, 12)   0           concatenate_6[0][0]              
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 98, 12, 12)   392         concatenate_7[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 98, 12, 12)   0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 18, 12, 12)   15876       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 18, 12, 12)   0           dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 116, 12, 12)  0           concatenate_7[0][0]              
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 116, 12, 12)  464         concatenate_8[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 116, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 16704)        0           activation_11[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            16705       flatten_1[0][0]                  
==================================================================================================
Total params: 98,721
Trainable params: 97,369
Non-trainable params: 1,352
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/24
 - 40s - loss: 0.4723 - acc: 0.7742 - val_loss: 0.4730 - val_acc: 0.7554
Epoch 2/24
 - 37s - loss: 0.3511 - acc: 0.8487 - val_loss: 0.3659 - val_acc: 0.8312
Epoch 3/24
 - 38s - loss: 0.3035 - acc: 0.8739 - val_loss: 0.3106 - val_acc: 0.8616
Epoch 4/24
 - 38s - loss: 0.2699 - acc: 0.8932 - val_loss: 0.3053 - val_acc: 0.8683
Epoch 5/24
 - 37s - loss: 0.2444 - acc: 0.9044 - val_loss: 0.2800 - val_acc: 0.8820
Epoch 6/24
 - 38s - loss: 0.2227 - acc: 0.9154 - val_loss: 0.2014 - val_acc: 0.9286
Epoch 7/24
 - 37s - loss: 0.2052 - acc: 0.9241 - val_loss: 0.1866 - val_acc: 0.9369
Epoch 8/24
 - 37s - loss: 0.1896 - acc: 0.9307 - val_loss: 0.2555 - val_acc: 0.8923
Epoch 9/24
 - 38s - loss: 0.1756 - acc: 0.9370 - val_loss: 0.2025 - val_acc: 0.9228
Epoch 10/24
 - 38s - loss: 0.1659 - acc: 0.9416 - val_loss: 0.1449 - val_acc: 0.9506
Epoch 11/24
 - 38s - loss: 0.1539 - acc: 0.9466 - val_loss: 0.1717 - val_acc: 0.9360
Epoch 12/24
 - 37s - loss: 0.1471 - acc: 0.9482 - val_loss: 0.1644 - val_acc: 0.9372
Epoch 13/24
 - 37s - loss: 0.1378 - acc: 0.9546 - val_loss: 0.1305 - val_acc: 0.9553
Epoch 14/24
 - 38s - loss: 0.1306 - acc: 0.9564 - val_loss: 0.1285 - val_acc: 0.9565
Epoch 15/24
 - 38s - loss: 0.1248 - acc: 0.9581 - val_loss: 0.1026 - val_acc: 0.9686
Epoch 16/24
 - 38s - loss: 0.1184 - acc: 0.9609 - val_loss: 0.1430 - val_acc: 0.9482
Epoch 17/24
 - 38s - loss: 0.1142 - acc: 0.9626 - val_loss: 0.1250 - val_acc: 0.9562
Epoch 18/24
 - 38s - loss: 0.1072 - acc: 0.9664 - val_loss: 0.0975 - val_acc: 0.9688
Epoch 19/24
 - 38s - loss: 0.1029 - acc: 0.9679 - val_loss: 0.1009 - val_acc: 0.9660
Epoch 20/24
 - 37s - loss: 0.1005 - acc: 0.9680 - val_loss: 0.0780 - val_acc: 0.9773
Epoch 21/24
 - 37s - loss: 0.0949 - acc: 0.9703 - val_loss: 0.0737 - val_acc: 0.9775
Epoch 22/24
 - 37s - loss: 0.0904 - acc: 0.9719 - val_loss: 0.1083 - val_acc: 0.9597
Epoch 23/24
 - 38s - loss: 0.0869 - acc: 0.9738 - val_loss: 0.0612 - val_acc: 0.9846
Epoch 24/24
 - 38s - loss: 0.0840 - acc: 0.9748 - val_loss: 0.0621 - val_acc: 0.9827
Test accuracy:0.770
current auc_score ------------------> 0.894
------------------------ current config for the test -------------------------
Layers:  [4, 4]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  24  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   2592        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 34, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 34, 24, 24)   136         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 34, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   5508        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 52, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 52, 24, 24)   208         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 52, 24, 24)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 18, 24, 24)   8424        activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 24, 24)   0           dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 70, 24, 24)   0           concatenate_2[0][0]              
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 70, 24, 24)   280         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 70, 24, 24)   0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 18, 24, 24)   11340       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 24, 24)   0           dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 88, 24, 24)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 88, 24, 24)   352         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 88, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 44, 24, 24)   3872        activation_6[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 44, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 44, 12, 12)   176         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 44, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   7128        activation_7[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 62, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 62, 12, 12)   248         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 62, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   10044       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 80, 12, 12)   0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 80, 12, 12)   320         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 80, 12, 12)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 18, 12, 12)   12960       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 18, 12, 12)   0           dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 98, 12, 12)   0           concatenate_6[0][0]              
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 98, 12, 12)   392         concatenate_7[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 98, 12, 12)   0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 18, 12, 12)   15876       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 18, 12, 12)   0           dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 116, 12, 12)  0           concatenate_7[0][0]              
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 116, 12, 12)  464         concatenate_8[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 116, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 16704)        0           activation_11[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            16705       flatten_1[0][0]                  
==================================================================================================
Total params: 98,721
Trainable params: 97,369
Non-trainable params: 1,352
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/24
 - 40s - loss: 0.4633 - acc: 0.7807 - val_loss: 0.3767 - val_acc: 0.8261
Epoch 2/24
 - 37s - loss: 0.3440 - acc: 0.8533 - val_loss: 0.3361 - val_acc: 0.8454
Epoch 3/24
 - 37s - loss: 0.2960 - acc: 0.8766 - val_loss: 0.2493 - val_acc: 0.9027
Epoch 4/24
 - 37s - loss: 0.2627 - acc: 0.8947 - val_loss: 0.2277 - val_acc: 0.9127
Epoch 5/24
 - 37s - loss: 0.2356 - acc: 0.9078 - val_loss: 0.1920 - val_acc: 0.9314
Epoch 6/24
 - 37s - loss: 0.2152 - acc: 0.9183 - val_loss: 0.2198 - val_acc: 0.9081
Epoch 7/24
 - 37s - loss: 0.1996 - acc: 0.9264 - val_loss: 0.1609 - val_acc: 0.9434
Epoch 8/24
 - 37s - loss: 0.1823 - acc: 0.9353 - val_loss: 0.1452 - val_acc: 0.9482
Epoch 9/24
 - 37s - loss: 0.1705 - acc: 0.9383 - val_loss: 0.1646 - val_acc: 0.9378
Epoch 10/24
 - 37s - loss: 0.1614 - acc: 0.9423 - val_loss: 0.1192 - val_acc: 0.9615
Epoch 11/24
 - 37s - loss: 0.1512 - acc: 0.9470 - val_loss: 0.1180 - val_acc: 0.9605
Epoch 12/24
 - 37s - loss: 0.1408 - acc: 0.9518 - val_loss: 0.1085 - val_acc: 0.9662
Epoch 13/24
 - 37s - loss: 0.1347 - acc: 0.9548 - val_loss: 0.1000 - val_acc: 0.9677
Epoch 14/24
 - 37s - loss: 0.1272 - acc: 0.9576 - val_loss: 0.0937 - val_acc: 0.9703
Epoch 15/24
 - 37s - loss: 0.1225 - acc: 0.9592 - val_loss: 0.0944 - val_acc: 0.9716
Epoch 16/24
 - 37s - loss: 0.1151 - acc: 0.9612 - val_loss: 0.0821 - val_acc: 0.9769
Epoch 17/24
 - 37s - loss: 0.1107 - acc: 0.9642 - val_loss: 0.0778 - val_acc: 0.9759
Epoch 18/24
 - 37s - loss: 0.1067 - acc: 0.9647 - val_loss: 0.0783 - val_acc: 0.9758
Epoch 19/24
 - 37s - loss: 0.1032 - acc: 0.9666 - val_loss: 0.0919 - val_acc: 0.9701
Epoch 20/24
 - 37s - loss: 0.0980 - acc: 0.9692 - val_loss: 0.1097 - val_acc: 0.9630

Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 00020: early stopping
Test accuracy:0.784
current auc_score ------------------> 0.904
------------------------ current config for the test -------------------------
Layers:  [4, 4]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  24  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   2592        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 34, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 34, 24, 24)   136         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 34, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   5508        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 52, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 52, 24, 24)   208         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 52, 24, 24)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 18, 24, 24)   8424        activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 24, 24)   0           dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 70, 24, 24)   0           concatenate_2[0][0]              
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 70, 24, 24)   280         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 70, 24, 24)   0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 18, 24, 24)   11340       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 24, 24)   0           dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 88, 24, 24)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 88, 24, 24)   352         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 88, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 44, 24, 24)   3872        activation_6[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 44, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 44, 12, 12)   176         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 44, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   7128        activation_7[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 62, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 62, 12, 12)   248         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 62, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   10044       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 80, 12, 12)   0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 80, 12, 12)   320         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 80, 12, 12)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 18, 12, 12)   12960       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 18, 12, 12)   0           dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 98, 12, 12)   0           concatenate_6[0][0]              
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 98, 12, 12)   392         concatenate_7[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 98, 12, 12)   0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 18, 12, 12)   15876       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 18, 12, 12)   0           dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 116, 12, 12)  0           concatenate_7[0][0]              
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 116, 12, 12)  464         concatenate_8[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 116, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 16704)        0           activation_11[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            16705       flatten_1[0][0]                  
==================================================================================================
Total params: 98,721
Trainable params: 97,369
Non-trainable params: 1,352
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/24
 - 41s - loss: 0.4630 - acc: 0.7814 - val_loss: 0.4312 - val_acc: 0.7904
Epoch 2/24
 - 38s - loss: 0.3391 - acc: 0.8536 - val_loss: 0.3222 - val_acc: 0.8525
Epoch 3/24
 - 38s - loss: 0.2903 - acc: 0.8815 - val_loss: 0.2592 - val_acc: 0.8947
Epoch 4/24
 - 39s - loss: 0.2589 - acc: 0.8968 - val_loss: 0.2145 - val_acc: 0.9162
Epoch 5/24
 - 38s - loss: 0.2348 - acc: 0.9086 - val_loss: 0.2403 - val_acc: 0.9010
Epoch 6/24
 - 38s - loss: 0.2156 - acc: 0.9185 - val_loss: 0.2122 - val_acc: 0.9168
Epoch 7/24
 - 38s - loss: 0.2002 - acc: 0.9239 - val_loss: 0.1828 - val_acc: 0.9312
Epoch 8/24
 - 38s - loss: 0.1842 - acc: 0.9320 - val_loss: 0.1443 - val_acc: 0.9499
Epoch 9/24
 - 38s - loss: 0.1722 - acc: 0.9378 - val_loss: 0.1420 - val_acc: 0.9499
Epoch 10/24
 - 38s - loss: 0.1625 - acc: 0.9430 - val_loss: 0.1240 - val_acc: 0.9582
Epoch 11/24
 - 38s - loss: 0.1529 - acc: 0.9461 - val_loss: 0.1215 - val_acc: 0.9620
Epoch 12/24
 - 38s - loss: 0.1432 - acc: 0.9505 - val_loss: 0.1085 - val_acc: 0.9639
Epoch 13/24
 - 37s - loss: 0.1357 - acc: 0.9539 - val_loss: 0.1095 - val_acc: 0.9660
Epoch 14/24
 - 38s - loss: 0.1296 - acc: 0.9562 - val_loss: 0.1012 - val_acc: 0.9680
Epoch 15/24
 - 38s - loss: 0.1211 - acc: 0.9599 - val_loss: 0.0907 - val_acc: 0.9736
Epoch 16/24
 - 37s - loss: 0.1153 - acc: 0.9635 - val_loss: 0.0874 - val_acc: 0.9709
Epoch 17/24
 - 37s - loss: 0.1103 - acc: 0.9645 - val_loss: 0.0899 - val_acc: 0.9743
Epoch 18/24
 - 37s - loss: 0.1078 - acc: 0.9649 - val_loss: 0.0924 - val_acc: 0.9716
Epoch 19/24
 - 38s - loss: 0.1020 - acc: 0.9679 - val_loss: 0.0835 - val_acc: 0.9755
Epoch 20/24
 - 38s - loss: 0.0971 - acc: 0.9688 - val_loss: 0.0739 - val_acc: 0.9785
Epoch 21/24
 - 37s - loss: 0.0927 - acc: 0.9716 - val_loss: 0.0883 - val_acc: 0.9681
Epoch 22/24
 - 38s - loss: 0.0896 - acc: 0.9724 - val_loss: 0.0660 - val_acc: 0.9817
Epoch 23/24
 - 38s - loss: 0.0835 - acc: 0.9742 - val_loss: 0.0577 - val_acc: 0.9864
Epoch 24/24
 - 37s - loss: 0.0830 - acc: 0.9749 - val_loss: 0.0563 - val_acc: 0.9849
Test accuracy:0.828
current auc_score ------------------> 0.912
------------------------ current config for the test -------------------------
Layers:  [4, 4]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  24  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   2592        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 34, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 34, 24, 24)   136         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 34, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   5508        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 52, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 52, 24, 24)   208         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 52, 24, 24)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 18, 24, 24)   8424        activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 24, 24)   0           dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 70, 24, 24)   0           concatenate_2[0][0]              
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 70, 24, 24)   280         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 70, 24, 24)   0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 18, 24, 24)   11340       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 24, 24)   0           dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 88, 24, 24)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 88, 24, 24)   352         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 88, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 44, 24, 24)   3872        activation_6[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 44, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 44, 12, 12)   176         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 44, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   7128        activation_7[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 62, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 62, 12, 12)   248         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 62, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   10044       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 80, 12, 12)   0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 80, 12, 12)   320         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 80, 12, 12)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 18, 12, 12)   12960       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 18, 12, 12)   0           dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 98, 12, 12)   0           concatenate_6[0][0]              
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 98, 12, 12)   392         concatenate_7[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 98, 12, 12)   0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 18, 12, 12)   15876       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 18, 12, 12)   0           dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 116, 12, 12)  0           concatenate_7[0][0]              
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 116, 12, 12)  464         concatenate_8[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 116, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 16704)        0           activation_11[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            16705       flatten_1[0][0]                  
==================================================================================================
Total params: 98,721
Trainable params: 97,369
Non-trainable params: 1,352
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/24
 - 40s - loss: 0.4708 - acc: 0.7800 - val_loss: 0.4112 - val_acc: 0.8100
Epoch 2/24
 - 39s - loss: 0.3433 - acc: 0.8555 - val_loss: 0.3352 - val_acc: 0.8523
Epoch 3/24
 - 38s - loss: 0.2914 - acc: 0.8807 - val_loss: 0.3485 - val_acc: 0.8379
Epoch 4/24
 - 38s - loss: 0.2541 - acc: 0.8993 - val_loss: 0.3898 - val_acc: 0.8109
Epoch 5/24
 - 38s - loss: 0.2300 - acc: 0.9116 - val_loss: 0.2252 - val_acc: 0.9104
Epoch 6/24
 - 38s - loss: 0.2086 - acc: 0.9223 - val_loss: 0.3968 - val_acc: 0.8148
Epoch 7/24
 - 38s - loss: 0.1930 - acc: 0.9290 - val_loss: 0.1579 - val_acc: 0.9457
Epoch 8/24
 - 38s - loss: 0.1766 - acc: 0.9369 - val_loss: 0.1660 - val_acc: 0.9419
Epoch 9/24
 - 38s - loss: 0.1658 - acc: 0.9417 - val_loss: 0.1293 - val_acc: 0.9573
Epoch 10/24
 - 38s - loss: 0.1542 - acc: 0.9467 - val_loss: 0.1412 - val_acc: 0.9544
Epoch 11/24
 - 38s - loss: 0.1463 - acc: 0.9514 - val_loss: 0.1162 - val_acc: 0.9625
Epoch 12/24
 - 38s - loss: 0.1371 - acc: 0.9538 - val_loss: 0.1262 - val_acc: 0.9592
Epoch 13/24
 - 38s - loss: 0.1263 - acc: 0.9583 - val_loss: 0.0956 - val_acc: 0.9703
Epoch 14/24
 - 38s - loss: 0.1200 - acc: 0.9610 - val_loss: 0.0906 - val_acc: 0.9715
Epoch 15/24
 - 38s - loss: 0.1153 - acc: 0.9631 - val_loss: 0.0972 - val_acc: 0.9685
Epoch 16/24
 - 39s - loss: 0.1085 - acc: 0.9649 - val_loss: 0.0923 - val_acc: 0.9726
Epoch 17/24
 - 37s - loss: 0.1041 - acc: 0.9671 - val_loss: 0.0847 - val_acc: 0.9726
Epoch 18/24
 - 38s - loss: 0.1007 - acc: 0.9672 - val_loss: 0.0688 - val_acc: 0.9822
Epoch 19/24
 - 39s - loss: 0.0936 - acc: 0.9718 - val_loss: 0.0625 - val_acc: 0.9849
Epoch 20/24
 - 38s - loss: 0.0903 - acc: 0.9727 - val_loss: 0.0698 - val_acc: 0.9793
Epoch 21/24
 - 38s - loss: 0.0856 - acc: 0.9737 - val_loss: 0.0586 - val_acc: 0.9847
Epoch 22/24
 - 38s - loss: 0.0824 - acc: 0.9763 - val_loss: 0.0583 - val_acc: 0.9837
Epoch 23/24
 - 38s - loss: 0.0796 - acc: 0.9759 - val_loss: 0.0518 - val_acc: 0.9877
Epoch 24/24
 - 38s - loss: 0.0781 - acc: 0.9765 - val_loss: 0.0488 - val_acc: 0.9891
Test accuracy:0.833
current auc_score ------------------> 0.909
------------------------ current config for the test -------------------------
Layers:  [4, 4]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  24  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   2592        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 34, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 34, 24, 24)   136         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 34, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   5508        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 52, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 52, 24, 24)   208         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 52, 24, 24)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 18, 24, 24)   8424        activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 24, 24)   0           dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 70, 24, 24)   0           concatenate_2[0][0]              
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 70, 24, 24)   280         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 70, 24, 24)   0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 18, 24, 24)   11340       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 24, 24)   0           dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 88, 24, 24)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 88, 24, 24)   352         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 88, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 44, 24, 24)   3872        activation_6[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 44, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 44, 12, 12)   176         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 44, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   7128        activation_7[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 62, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 62, 12, 12)   248         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 62, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   10044       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 80, 12, 12)   0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 80, 12, 12)   320         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 80, 12, 12)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 18, 12, 12)   12960       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 18, 12, 12)   0           dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 98, 12, 12)   0           concatenate_6[0][0]              
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 98, 12, 12)   392         concatenate_7[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 98, 12, 12)   0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 18, 12, 12)   15876       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 18, 12, 12)   0           dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 116, 12, 12)  0           concatenate_7[0][0]              
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 116, 12, 12)  464         concatenate_8[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 116, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 16704)        0           activation_11[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            16705       flatten_1[0][0]                  
==================================================================================================
Total params: 98,721
Trainable params: 97,369
Non-trainable params: 1,352
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/24
 - 41s - loss: 0.4632 - acc: 0.7831 - val_loss: 0.3615 - val_acc: 0.8367
Epoch 2/24
 - 39s - loss: 0.3396 - acc: 0.8543 - val_loss: 0.3612 - val_acc: 0.8299
Epoch 3/24
 - 39s - loss: 0.2937 - acc: 0.8785 - val_loss: 0.2902 - val_acc: 0.8773
Epoch 4/24
 - 38s - loss: 0.2601 - acc: 0.8962 - val_loss: 0.2306 - val_acc: 0.9105
Epoch 5/24
 - 39s - loss: 0.2335 - acc: 0.9091 - val_loss: 0.2501 - val_acc: 0.8943
Epoch 6/24
 - 39s - loss: 0.2130 - acc: 0.9194 - val_loss: 0.1907 - val_acc: 0.9263
Epoch 7/24
 - 39s - loss: 0.1943 - acc: 0.9286 - val_loss: 0.1905 - val_acc: 0.9262
Epoch 8/24
 - 39s - loss: 0.1821 - acc: 0.9339 - val_loss: 0.1576 - val_acc: 0.9454
Epoch 9/24
 - 39s - loss: 0.1668 - acc: 0.9413 - val_loss: 0.1326 - val_acc: 0.9539
Epoch 10/24
 - 39s - loss: 0.1554 - acc: 0.9455 - val_loss: 0.1250 - val_acc: 0.9588
Epoch 11/24
 - 39s - loss: 0.1460 - acc: 0.9512 - val_loss: 0.1220 - val_acc: 0.9597
Epoch 12/24
 - 39s - loss: 0.1400 - acc: 0.9526 - val_loss: 0.1058 - val_acc: 0.9639
Epoch 13/24
 - 38s - loss: 0.1305 - acc: 0.9571 - val_loss: 0.1015 - val_acc: 0.9681
Epoch 14/24
 - 38s - loss: 0.1234 - acc: 0.9590 - val_loss: 0.0998 - val_acc: 0.9654
Epoch 15/24
 - 39s - loss: 0.1181 - acc: 0.9615 - val_loss: 0.0912 - val_acc: 0.9724
Epoch 16/24
 - 39s - loss: 0.1125 - acc: 0.9644 - val_loss: 0.0780 - val_acc: 0.9785
Epoch 17/24
 - 39s - loss: 0.1063 - acc: 0.9666 - val_loss: 0.0744 - val_acc: 0.9788
Epoch 18/24
 - 39s - loss: 0.1014 - acc: 0.9676 - val_loss: 0.0951 - val_acc: 0.9674
Epoch 19/24
 - 39s - loss: 0.0956 - acc: 0.9703 - val_loss: 0.0730 - val_acc: 0.9790
Epoch 20/24
 - 39s - loss: 0.0931 - acc: 0.9709 - val_loss: 0.0669 - val_acc: 0.9822
Epoch 21/24
 - 39s - loss: 0.0909 - acc: 0.9725 - val_loss: 0.0738 - val_acc: 0.9773
Epoch 22/24
 - 39s - loss: 0.0865 - acc: 0.9737 - val_loss: 0.0821 - val_acc: 0.9716
Epoch 23/24
 - 39s - loss: 0.0813 - acc: 0.9756 - val_loss: 0.0545 - val_acc: 0.9871
Epoch 24/24
 - 39s - loss: 0.0787 - acc: 0.9766 - val_loss: 0.0552 - val_acc: 0.9857
Test accuracy:0.862
current auc_score ------------------> 0.929
------------------------ current config for the test -------------------------
Layers:  [4, 4]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  24  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   2592        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 34, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 34, 24, 24)   136         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 34, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   5508        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 52, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 52, 24, 24)   208         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 52, 24, 24)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 18, 24, 24)   8424        activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 24, 24)   0           dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 70, 24, 24)   0           concatenate_2[0][0]              
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 70, 24, 24)   280         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 70, 24, 24)   0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 18, 24, 24)   11340       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 24, 24)   0           dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 88, 24, 24)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 88, 24, 24)   352         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 88, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 44, 24, 24)   3872        activation_6[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 44, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 44, 12, 12)   176         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 44, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   7128        activation_7[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 62, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 62, 12, 12)   248         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 62, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   10044       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 80, 12, 12)   0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 80, 12, 12)   320         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 80, 12, 12)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 18, 12, 12)   12960       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 18, 12, 12)   0           dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 98, 12, 12)   0           concatenate_6[0][0]              
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 98, 12, 12)   392         concatenate_7[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 98, 12, 12)   0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 18, 12, 12)   15876       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 18, 12, 12)   0           dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 116, 12, 12)  0           concatenate_7[0][0]              
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 116, 12, 12)  464         concatenate_8[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 116, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 16704)        0           activation_11[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            16705       flatten_1[0][0]                  
==================================================================================================
Total params: 98,721
Trainable params: 97,369
Non-trainable params: 1,352
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/24
 - 40s - loss: 0.4642 - acc: 0.7805 - val_loss: 0.3555 - val_acc: 0.8438
Epoch 2/24
 - 38s - loss: 0.3522 - acc: 0.8497 - val_loss: 0.3201 - val_acc: 0.8611
Epoch 3/24
 - 38s - loss: 0.3010 - acc: 0.8749 - val_loss: 0.2870 - val_acc: 0.8808
Epoch 4/24
 - 38s - loss: 0.2697 - acc: 0.8924 - val_loss: 0.2285 - val_acc: 0.9169
Epoch 5/24
 - 38s - loss: 0.2420 - acc: 0.9055 - val_loss: 0.2048 - val_acc: 0.9242
Epoch 6/24
 - 37s - loss: 0.2200 - acc: 0.9175 - val_loss: 0.2836 - val_acc: 0.8750
Epoch 7/24
 - 37s - loss: 0.2019 - acc: 0.9250 - val_loss: 0.1793 - val_acc: 0.9383
Epoch 8/24
 - 37s - loss: 0.1875 - acc: 0.9330 - val_loss: 0.1629 - val_acc: 0.9423
Epoch 9/24
 - 37s - loss: 0.1715 - acc: 0.9392 - val_loss: 0.1492 - val_acc: 0.9492
Epoch 10/24
 - 37s - loss: 0.1598 - acc: 0.9432 - val_loss: 0.1351 - val_acc: 0.9556
Epoch 11/24
 - 37s - loss: 0.1520 - acc: 0.9476 - val_loss: 0.1667 - val_acc: 0.9334
Epoch 12/24
 - 37s - loss: 0.1433 - acc: 0.9504 - val_loss: 0.1549 - val_acc: 0.9399
Epoch 13/24
 - 37s - loss: 0.1352 - acc: 0.9547 - val_loss: 0.0993 - val_acc: 0.9711
Epoch 14/24
 - 37s - loss: 0.1279 - acc: 0.9583 - val_loss: 0.1105 - val_acc: 0.9652
Epoch 15/24
 - 37s - loss: 0.1217 - acc: 0.9597 - val_loss: 0.1015 - val_acc: 0.9690
Epoch 16/24
 - 37s - loss: 0.1157 - acc: 0.9620 - val_loss: 0.0821 - val_acc: 0.9779
Epoch 17/24
 - 37s - loss: 0.1086 - acc: 0.9652 - val_loss: 0.0862 - val_acc: 0.9736
Epoch 18/24
 - 37s - loss: 0.1039 - acc: 0.9676 - val_loss: 0.0757 - val_acc: 0.9797
Epoch 19/24
 - 37s - loss: 0.0998 - acc: 0.9683 - val_loss: 0.0785 - val_acc: 0.9780
Epoch 20/24
 - 37s - loss: 0.0945 - acc: 0.9702 - val_loss: 0.0901 - val_acc: 0.9713
Epoch 21/24
 - 37s - loss: 0.0908 - acc: 0.9721 - val_loss: 0.1188 - val_acc: 0.9568

Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 22/24
 - 37s - loss: 0.0847 - acc: 0.9743 - val_loss: 0.0606 - val_acc: 0.9841
Epoch 23/24
 - 37s - loss: 0.0828 - acc: 0.9749 - val_loss: 0.0664 - val_acc: 0.9807
Epoch 24/24
 - 37s - loss: 0.0820 - acc: 0.9757 - val_loss: 0.0586 - val_acc: 0.9846
Test accuracy:0.832
current auc_score ------------------> 0.916
------------------------ current config for the test -------------------------
Layers:  [4, 4]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  24  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   2592        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 34, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 34, 24, 24)   136         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 34, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   5508        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 52, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 52, 24, 24)   208         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 52, 24, 24)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 18, 24, 24)   8424        activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 24, 24)   0           dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 70, 24, 24)   0           concatenate_2[0][0]              
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 70, 24, 24)   280         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 70, 24, 24)   0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 18, 24, 24)   11340       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 24, 24)   0           dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 88, 24, 24)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 88, 24, 24)   352         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 88, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 44, 24, 24)   3872        activation_6[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 44, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 44, 12, 12)   176         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 44, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   7128        activation_7[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 62, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 62, 12, 12)   248         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 62, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   10044       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 80, 12, 12)   0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 80, 12, 12)   320         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 80, 12, 12)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 18, 12, 12)   12960       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 18, 12, 12)   0           dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 98, 12, 12)   0           concatenate_6[0][0]              
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 98, 12, 12)   392         concatenate_7[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 98, 12, 12)   0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 18, 12, 12)   15876       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 18, 12, 12)   0           dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 116, 12, 12)  0           concatenate_7[0][0]              
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 116, 12, 12)  464         concatenate_8[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 116, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 16704)        0           activation_11[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            16705       flatten_1[0][0]                  
==================================================================================================
Total params: 98,721
Trainable params: 97,369
Non-trainable params: 1,352
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/24
 - 40s - loss: 0.4620 - acc: 0.7833 - val_loss: 0.3725 - val_acc: 0.8279
Epoch 2/24
 - 37s - loss: 0.3431 - acc: 0.8525 - val_loss: 0.3363 - val_acc: 0.8505
Epoch 3/24
 - 37s - loss: 0.2920 - acc: 0.8804 - val_loss: 0.2500 - val_acc: 0.9029
Epoch 4/24
 - 37s - loss: 0.2630 - acc: 0.8951 - val_loss: 0.2412 - val_acc: 0.9037
Epoch 5/24
 - 37s - loss: 0.2346 - acc: 0.9091 - val_loss: 0.2042 - val_acc: 0.9223
Epoch 6/24
 - 38s - loss: 0.2142 - acc: 0.9186 - val_loss: 0.1996 - val_acc: 0.9273
Epoch 7/24
 - 38s - loss: 0.1964 - acc: 0.9287 - val_loss: 0.1620 - val_acc: 0.9420
Epoch 8/24
 - 38s - loss: 0.1806 - acc: 0.9356 - val_loss: 0.1470 - val_acc: 0.9504
Epoch 9/24
 - 38s - loss: 0.1713 - acc: 0.9401 - val_loss: 0.1525 - val_acc: 0.9454
Epoch 10/24
 - 38s - loss: 0.1590 - acc: 0.9437 - val_loss: 0.1223 - val_acc: 0.9596
Epoch 11/24
 - 37s - loss: 0.1475 - acc: 0.9484 - val_loss: 0.1135 - val_acc: 0.9631
Epoch 12/24
 - 37s - loss: 0.1403 - acc: 0.9512 - val_loss: 0.1123 - val_acc: 0.9627
Epoch 13/24
 - 38s - loss: 0.1316 - acc: 0.9554 - val_loss: 0.1054 - val_acc: 0.9641
Epoch 14/24
 - 38s - loss: 0.1260 - acc: 0.9581 - val_loss: 0.1068 - val_acc: 0.9660
Epoch 15/24
 - 38s - loss: 0.1199 - acc: 0.9601 - val_loss: 0.0855 - val_acc: 0.9748
Epoch 16/24
 - 38s - loss: 0.1137 - acc: 0.9625 - val_loss: 0.0835 - val_acc: 0.9752
Epoch 17/24
 - 38s - loss: 0.1092 - acc: 0.9653 - val_loss: 0.1068 - val_acc: 0.9654
Epoch 18/24
 - 37s - loss: 0.1025 - acc: 0.9673 - val_loss: 0.0838 - val_acc: 0.9746
Epoch 19/24
 - 38s - loss: 0.0985 - acc: 0.9684 - val_loss: 0.0886 - val_acc: 0.9695

Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 20/24
 - 37s - loss: 0.0929 - acc: 0.9718 - val_loss: 0.0674 - val_acc: 0.9814
Epoch 21/24
 - 38s - loss: 0.0898 - acc: 0.9730 - val_loss: 0.0695 - val_acc: 0.9793
Epoch 22/24
 - 38s - loss: 0.0891 - acc: 0.9728 - val_loss: 0.0666 - val_acc: 0.9812
Epoch 23/24
 - 38s - loss: 0.0875 - acc: 0.9741 - val_loss: 0.0654 - val_acc: 0.9823
Epoch 24/24
 - 37s - loss: 0.0856 - acc: 0.9740 - val_loss: 0.0616 - val_acc: 0.9823
Test accuracy:0.833
current auc_score ------------------> 0.908
------------------------ current config for the test -------------------------
Layers:  [4, 4]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  24  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   2592        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 34, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 34, 24, 24)   136         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 34, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   5508        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 52, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 52, 24, 24)   208         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 52, 24, 24)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 18, 24, 24)   8424        activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 24, 24)   0           dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 70, 24, 24)   0           concatenate_2[0][0]              
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 70, 24, 24)   280         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 70, 24, 24)   0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 18, 24, 24)   11340       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 24, 24)   0           dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 88, 24, 24)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 88, 24, 24)   352         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 88, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 44, 24, 24)   3872        activation_6[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 44, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 44, 12, 12)   176         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 44, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   7128        activation_7[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 62, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 62, 12, 12)   248         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 62, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   10044       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 80, 12, 12)   0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 80, 12, 12)   320         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 80, 12, 12)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 18, 12, 12)   12960       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 18, 12, 12)   0           dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 98, 12, 12)   0           concatenate_6[0][0]              
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 98, 12, 12)   392         concatenate_7[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 98, 12, 12)   0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 18, 12, 12)   15876       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 18, 12, 12)   0           dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 116, 12, 12)  0           concatenate_7[0][0]              
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 116, 12, 12)  464         concatenate_8[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 116, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 16704)        0           activation_11[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            16705       flatten_1[0][0]                  
==================================================================================================
Total params: 98,721
Trainable params: 97,369
Non-trainable params: 1,352
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/24
 - 40s - loss: 0.4672 - acc: 0.7794 - val_loss: 0.3686 - val_acc: 0.8392
Epoch 2/24
 - 37s - loss: 0.3402 - acc: 0.8538 - val_loss: 0.3290 - val_acc: 0.8512
Epoch 3/24
 - 38s - loss: 0.2891 - acc: 0.8803 - val_loss: 0.2435 - val_acc: 0.9054
Epoch 4/24
 - 38s - loss: 0.2525 - acc: 0.8998 - val_loss: 0.2323 - val_acc: 0.9094
Epoch 5/24
 - 37s - loss: 0.2270 - acc: 0.9140 - val_loss: 0.2545 - val_acc: 0.8933
Epoch 6/24
 - 37s - loss: 0.2062 - acc: 0.9237 - val_loss: 0.1725 - val_acc: 0.9383
Epoch 7/24
 - 38s - loss: 0.1885 - acc: 0.9306 - val_loss: 0.1828 - val_acc: 0.9347
Epoch 8/24
 - 37s - loss: 0.1751 - acc: 0.9384 - val_loss: 0.2005 - val_acc: 0.9252
Epoch 9/24
 - 38s - loss: 0.1637 - acc: 0.9429 - val_loss: 0.1686 - val_acc: 0.9390
Epoch 10/24
 - 38s - loss: 0.1525 - acc: 0.9473 - val_loss: 0.1304 - val_acc: 0.9586
Epoch 11/24
 - 38s - loss: 0.1430 - acc: 0.9515 - val_loss: 0.1144 - val_acc: 0.9647
Epoch 12/24
 - 37s - loss: 0.1348 - acc: 0.9549 - val_loss: 0.1035 - val_acc: 0.9674
Epoch 13/24
 - 38s - loss: 0.1272 - acc: 0.9573 - val_loss: 0.1003 - val_acc: 0.9695
Epoch 14/24
 - 38s - loss: 0.1182 - acc: 0.9616 - val_loss: 0.0864 - val_acc: 0.9739
Epoch 15/24
 - 38s - loss: 0.1143 - acc: 0.9629 - val_loss: 0.1027 - val_acc: 0.9640
Epoch 16/24
 - 38s - loss: 0.1080 - acc: 0.9647 - val_loss: 0.0771 - val_acc: 0.9769
Epoch 17/24
 - 38s - loss: 0.1040 - acc: 0.9676 - val_loss: 0.0994 - val_acc: 0.9674
Epoch 18/24
 - 38s - loss: 0.0991 - acc: 0.9687 - val_loss: 0.0703 - val_acc: 0.9785
Epoch 19/24
 - 38s - loss: 0.0959 - acc: 0.9699 - val_loss: 0.0803 - val_acc: 0.9721
Epoch 20/24
 - 38s - loss: 0.0917 - acc: 0.9715 - val_loss: 0.0702 - val_acc: 0.9763
Epoch 21/24
 - 38s - loss: 0.0865 - acc: 0.9731 - val_loss: 0.0839 - val_acc: 0.9706
Epoch 22/24
 - 37s - loss: 0.0843 - acc: 0.9737 - val_loss: 0.0579 - val_acc: 0.9834
Epoch 23/24
 - 38s - loss: 0.0789 - acc: 0.9759 - val_loss: 0.0659 - val_acc: 0.9774
Epoch 24/24
 - 37s - loss: 0.0770 - acc: 0.9773 - val_loss: 0.0588 - val_acc: 0.9823
Test accuracy:0.840
current auc_score ------------------> 0.916
accuracies:  [0.7932795698924732, 0.8325268817204301, 0.7696236559139785, 0.7841397849462366, 0.8280913978494624, 0.8327956989247312, 0.8622311827956989, 0.8321236559139785, 0.8334677419354839, 0.8396505376344086]
aucs:  [0.9094, 0.9138, 0.8945, 0.904, 0.9116, 0.9089, 0.9289, 0.9159, 0.9084, 0.9161]
mean and std AUC:  0.911+/-0.008  max:   0.9289
['4-4', '24', '2', '16', '0.2', '0.07', '22', 'adadelta', '0.5', 'FALSE', '64', 'flatten']
------------------------ current config for the test -------------------------
Layers:  [4, 4]  Growth_rate:  24  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  22  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 24, 24, 24)   3456        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 24, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 40, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 40, 24, 24)   160         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 40, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 24, 24, 24)   8640        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 64, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 64, 24, 24)   256         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 64, 24, 24)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 24, 24, 24)   13824       activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 24, 24, 24)   0           dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 88, 24, 24)   0           concatenate_2[0][0]              
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 88, 24, 24)   352         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 88, 24, 24)   0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 24, 24, 24)   19008       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 24, 24, 24)   0           dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 112, 24, 24)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 112, 24, 24)  448         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 112, 24, 24)  0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 56, 24, 24)   6272        activation_6[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 56, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 56, 12, 12)   224         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 56, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 24, 12, 12)   12096       activation_7[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 24, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 80, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 80, 12, 12)   320         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 80, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 24, 12, 12)   17280       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 24, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 104, 12, 12)  0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 104, 12, 12)  416         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 104, 12, 12)  0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 24, 12, 12)   22464       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 24, 12, 12)   0           dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 128, 12, 12)  0           concatenate_6[0][0]              
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 128, 12, 12)  512         concatenate_7[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 128, 12, 12)  0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 24, 12, 12)   27648       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 24, 12, 12)   0           dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 152, 12, 12)  0           concatenate_7[0][0]              
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 152, 12, 12)  608         concatenate_8[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 152, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 21888)        0           activation_11[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            21889       flatten_1[0][0]                  
==================================================================================================
Total params: 157,569
Trainable params: 155,857
Non-trainable params: 1,712
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/22
 - 44s - loss: 0.4561 - acc: 0.7911 - val_loss: 0.3348 - val_acc: 0.8613
Epoch 2/22
 - 42s - loss: 0.3285 - acc: 0.8657 - val_loss: 0.2998 - val_acc: 0.8741
Epoch 3/22
 - 41s - loss: 0.2753 - acc: 0.8917 - val_loss: 0.2292 - val_acc: 0.9119
Epoch 4/22
 - 41s - loss: 0.2417 - acc: 0.9060 - val_loss: 0.2464 - val_acc: 0.8983
Epoch 5/22
 - 42s - loss: 0.2134 - acc: 0.9214 - val_loss: 0.1916 - val_acc: 0.9282
Epoch 6/22
 - 41s - loss: 0.1924 - acc: 0.9294 - val_loss: 0.1706 - val_acc: 0.9364
Epoch 7/22
 - 41s - loss: 0.1756 - acc: 0.9382 - val_loss: 0.1407 - val_acc: 0.9539
Epoch 8/22
 - 41s - loss: 0.1584 - acc: 0.9459 - val_loss: 0.1371 - val_acc: 0.9547
Epoch 9/22
 - 43s - loss: 0.1453 - acc: 0.9512 - val_loss: 0.1093 - val_acc: 0.9647
Epoch 10/22
 - 41s - loss: 0.1357 - acc: 0.9549 - val_loss: 0.1018 - val_acc: 0.9690
Epoch 11/22
 - 42s - loss: 0.1247 - acc: 0.9595 - val_loss: 0.1157 - val_acc: 0.9623
Epoch 12/22
 - 41s - loss: 0.1169 - acc: 0.9630 - val_loss: 0.0842 - val_acc: 0.9753
Epoch 13/22
 - 41s - loss: 0.1093 - acc: 0.9665 - val_loss: 0.0825 - val_acc: 0.9768
Epoch 14/22
 - 41s - loss: 0.1035 - acc: 0.9684 - val_loss: 0.0724 - val_acc: 0.9809
Epoch 15/22
 - 41s - loss: 0.0978 - acc: 0.9708 - val_loss: 0.0668 - val_acc: 0.9816
Epoch 16/22
 - 41s - loss: 0.0919 - acc: 0.9719 - val_loss: 0.0976 - val_acc: 0.9685
Epoch 17/22
 - 41s - loss: 0.0876 - acc: 0.9750 - val_loss: 0.0763 - val_acc: 0.9782
Epoch 18/22
 - 41s - loss: 0.0821 - acc: 0.9768 - val_loss: 0.0869 - val_acc: 0.9720

Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 19/22
 - 41s - loss: 0.0744 - acc: 0.9796 - val_loss: 0.0502 - val_acc: 0.9885
Epoch 20/22
 - 41s - loss: 0.0719 - acc: 0.9809 - val_loss: 0.0478 - val_acc: 0.9890
Epoch 21/22
 - 41s - loss: 0.0699 - acc: 0.9816 - val_loss: 0.0461 - val_acc: 0.9896
Epoch 22/22
 - 41s - loss: 0.0707 - acc: 0.9810 - val_loss: 0.0485 - val_acc: 0.9883
Test accuracy:0.866
current auc_score ------------------> 0.937
------------------------ current config for the test -------------------------
Layers:  [4, 4]  Growth_rate:  24  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  22  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 24, 24, 24)   3456        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 24, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 40, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 40, 24, 24)   160         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 40, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 24, 24, 24)   8640        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 64, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 64, 24, 24)   256         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 64, 24, 24)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 24, 24, 24)   13824       activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 24, 24, 24)   0           dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 88, 24, 24)   0           concatenate_2[0][0]              
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 88, 24, 24)   352         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 88, 24, 24)   0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 24, 24, 24)   19008       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 24, 24, 24)   0           dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 112, 24, 24)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 112, 24, 24)  448         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 112, 24, 24)  0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 56, 24, 24)   6272        activation_6[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 56, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 56, 12, 12)   224         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 56, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 24, 12, 12)   12096       activation_7[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 24, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 80, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 80, 12, 12)   320         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 80, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 24, 12, 12)   17280       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 24, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 104, 12, 12)  0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 104, 12, 12)  416         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 104, 12, 12)  0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 24, 12, 12)   22464       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 24, 12, 12)   0           dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 128, 12, 12)  0           concatenate_6[0][0]              
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 128, 12, 12)  512         concatenate_7[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 128, 12, 12)  0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 24, 12, 12)   27648       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 24, 12, 12)   0           dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 152, 12, 12)  0           concatenate_7[0][0]              
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 152, 12, 12)  608         concatenate_8[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 152, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 21888)        0           activation_11[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            21889       flatten_1[0][0]                  
==================================================================================================
Total params: 157,569
Trainable params: 155,857
Non-trainable params: 1,712
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/22
 - 44s - loss: 0.4662 - acc: 0.7843 - val_loss: 0.5301 - val_acc: 0.7349
Epoch 2/22
 - 42s - loss: 0.3271 - acc: 0.8645 - val_loss: 0.4389 - val_acc: 0.7943
Epoch 3/22
 - 42s - loss: 0.2702 - acc: 0.8936 - val_loss: 0.3474 - val_acc: 0.8438
Epoch 4/22
 - 42s - loss: 0.2353 - acc: 0.9100 - val_loss: 0.1957 - val_acc: 0.9278
Epoch 5/22
 - 42s - loss: 0.2111 - acc: 0.9214 - val_loss: 0.1959 - val_acc: 0.9261
Epoch 6/22
 - 42s - loss: 0.1895 - acc: 0.9335 - val_loss: 0.1758 - val_acc: 0.9366
Epoch 7/22
 - 42s - loss: 0.1750 - acc: 0.9386 - val_loss: 0.1371 - val_acc: 0.9563
Epoch 8/22
 - 41s - loss: 0.1601 - acc: 0.9455 - val_loss: 0.1621 - val_acc: 0.9424
Epoch 9/22
 - 42s - loss: 0.1486 - acc: 0.9508 - val_loss: 0.1185 - val_acc: 0.9650
Epoch 10/22
 - 41s - loss: 0.1376 - acc: 0.9547 - val_loss: 0.1080 - val_acc: 0.9659
Epoch 11/22
 - 41s - loss: 0.1282 - acc: 0.9587 - val_loss: 0.0994 - val_acc: 0.9706
Epoch 12/22
 - 41s - loss: 0.1196 - acc: 0.9622 - val_loss: 0.0803 - val_acc: 0.9797
Epoch 13/22
 - 42s - loss: 0.1120 - acc: 0.9650 - val_loss: 0.0853 - val_acc: 0.9768
Epoch 14/22
 - 42s - loss: 0.1051 - acc: 0.9673 - val_loss: 0.0899 - val_acc: 0.9741
Epoch 15/22
 - 42s - loss: 0.0990 - acc: 0.9705 - val_loss: 0.0674 - val_acc: 0.9832
Epoch 16/22
 - 42s - loss: 0.0938 - acc: 0.9719 - val_loss: 0.0681 - val_acc: 0.9824
Epoch 17/22
 - 42s - loss: 0.0896 - acc: 0.9746 - val_loss: 0.0693 - val_acc: 0.9794
Epoch 18/22
 - 41s - loss: 0.0838 - acc: 0.9758 - val_loss: 0.0550 - val_acc: 0.9863
Epoch 19/22
 - 42s - loss: 0.0810 - acc: 0.9769 - val_loss: 0.0501 - val_acc: 0.9888
Epoch 20/22
 - 42s - loss: 0.0763 - acc: 0.9792 - val_loss: 0.0500 - val_acc: 0.9886
Epoch 21/22
 - 42s - loss: 0.0720 - acc: 0.9799 - val_loss: 0.0513 - val_acc: 0.9873
Epoch 22/22
 - 44s - loss: 0.0707 - acc: 0.9806 - val_loss: 0.0430 - val_acc: 0.9922
Test accuracy:0.792
current auc_score ------------------> 0.900
------------------------ current config for the test -------------------------
Layers:  [4, 4]  Growth_rate:  24  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  22  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 24, 24, 24)   3456        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 24, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 40, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 40, 24, 24)   160         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 40, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 24, 24, 24)   8640        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 64, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 64, 24, 24)   256         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 64, 24, 24)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 24, 24, 24)   13824       activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 24, 24, 24)   0           dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 88, 24, 24)   0           concatenate_2[0][0]              
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 88, 24, 24)   352         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 88, 24, 24)   0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 24, 24, 24)   19008       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 24, 24, 24)   0           dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 112, 24, 24)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 112, 24, 24)  448         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 112, 24, 24)  0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 56, 24, 24)   6272        activation_6[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 56, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 56, 12, 12)   224         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 56, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 24, 12, 12)   12096       activation_7[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 24, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 80, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 80, 12, 12)   320         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 80, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 24, 12, 12)   17280       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 24, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 104, 12, 12)  0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 104, 12, 12)  416         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 104, 12, 12)  0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 24, 12, 12)   22464       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 24, 12, 12)   0           dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 128, 12, 12)  0           concatenate_6[0][0]              
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 128, 12, 12)  512         concatenate_7[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 128, 12, 12)  0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 24, 12, 12)   27648       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 24, 12, 12)   0           dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 152, 12, 12)  0           concatenate_7[0][0]              
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 152, 12, 12)  608         concatenate_8[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 152, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 21888)        0           activation_11[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            21889       flatten_1[0][0]                  
==================================================================================================
Total params: 157,569
Trainable params: 155,857
Non-trainable params: 1,712
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/22
 - 45s - loss: 0.4653 - acc: 0.7828 - val_loss: 0.3815 - val_acc: 0.8283
Epoch 2/22
 - 43s - loss: 0.3295 - acc: 0.8629 - val_loss: 0.2801 - val_acc: 0.8832
Epoch 3/22
 - 43s - loss: 0.2746 - acc: 0.8923 - val_loss: 0.2357 - val_acc: 0.9118
Epoch 4/22
 - 43s - loss: 0.2408 - acc: 0.9073 - val_loss: 0.2289 - val_acc: 0.9127
Epoch 5/22
 - 43s - loss: 0.2121 - acc: 0.9223 - val_loss: 0.2210 - val_acc: 0.9113
Epoch 6/22
 - 43s - loss: 0.1933 - acc: 0.9310 - val_loss: 0.1705 - val_acc: 0.9418
Epoch 7/22
 - 43s - loss: 0.1756 - acc: 0.9382 - val_loss: 0.1529 - val_acc: 0.9494
Epoch 8/22
 - 43s - loss: 0.1605 - acc: 0.9450 - val_loss: 0.1316 - val_acc: 0.9568
Epoch 9/22
 - 43s - loss: 0.1491 - acc: 0.9503 - val_loss: 0.1231 - val_acc: 0.9612
Epoch 10/22
 - 43s - loss: 0.1381 - acc: 0.9541 - val_loss: 0.1172 - val_acc: 0.9630
Epoch 11/22
 - 43s - loss: 0.1304 - acc: 0.9580 - val_loss: 0.1423 - val_acc: 0.9503
Epoch 12/22
 - 43s - loss: 0.1226 - acc: 0.9610 - val_loss: 0.1014 - val_acc: 0.9679
Epoch 13/22
 - 43s - loss: 0.1146 - acc: 0.9633 - val_loss: 0.1227 - val_acc: 0.9607
Epoch 14/22
 - 43s - loss: 0.1069 - acc: 0.9671 - val_loss: 0.1300 - val_acc: 0.9542
Epoch 15/22
 - 43s - loss: 0.1016 - acc: 0.9681 - val_loss: 0.0803 - val_acc: 0.9779
Epoch 16/22
 - 43s - loss: 0.0964 - acc: 0.9704 - val_loss: 0.0777 - val_acc: 0.9769
Epoch 17/22
 - 43s - loss: 0.0922 - acc: 0.9720 - val_loss: 0.0651 - val_acc: 0.9836
Epoch 18/22
 - 43s - loss: 0.0859 - acc: 0.9742 - val_loss: 0.0718 - val_acc: 0.9813
Epoch 19/22
 - 43s - loss: 0.0824 - acc: 0.9756 - val_loss: 0.0588 - val_acc: 0.9852
Epoch 20/22
 - 43s - loss: 0.0783 - acc: 0.9776 - val_loss: 0.0691 - val_acc: 0.9784
Epoch 21/22
 - 45s - loss: 0.0736 - acc: 0.9796 - val_loss: 0.0589 - val_acc: 0.9847
Epoch 22/22
 - 43s - loss: 0.0720 - acc: 0.9802 - val_loss: 0.0619 - val_acc: 0.9817

Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Test accuracy:0.774
current auc_score ------------------> 0.871
------------------------ current config for the test -------------------------
Layers:  [4, 4]  Growth_rate:  24  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  22  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 24, 24, 24)   3456        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 24, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 40, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 40, 24, 24)   160         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 40, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 24, 24, 24)   8640        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 64, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 64, 24, 24)   256         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 64, 24, 24)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 24, 24, 24)   13824       activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 24, 24, 24)   0           dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 88, 24, 24)   0           concatenate_2[0][0]              
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 88, 24, 24)   352         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 88, 24, 24)   0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 24, 24, 24)   19008       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 24, 24, 24)   0           dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 112, 24, 24)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 112, 24, 24)  448         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 112, 24, 24)  0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 56, 24, 24)   6272        activation_6[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 56, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 56, 12, 12)   224         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 56, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 24, 12, 12)   12096       activation_7[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 24, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 80, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 80, 12, 12)   320         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 80, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 24, 12, 12)   17280       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 24, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 104, 12, 12)  0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 104, 12, 12)  416         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 104, 12, 12)  0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 24, 12, 12)   22464       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 24, 12, 12)   0           dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 128, 12, 12)  0           concatenate_6[0][0]              
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 128, 12, 12)  512         concatenate_7[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 128, 12, 12)  0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 24, 12, 12)   27648       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 24, 12, 12)   0           dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 152, 12, 12)  0           concatenate_7[0][0]              
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 152, 12, 12)  608         concatenate_8[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 152, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 21888)        0           activation_11[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            21889       flatten_1[0][0]                  
==================================================================================================
Total params: 157,569
Trainable params: 155,857
Non-trainable params: 1,712
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/22
 - 45s - loss: 0.4517 - acc: 0.7910 - val_loss: 0.3583 - val_acc: 0.8370
Epoch 2/22
 - 43s - loss: 0.3286 - acc: 0.8616 - val_loss: 0.2756 - val_acc: 0.8850
Epoch 3/22
 - 42s - loss: 0.2754 - acc: 0.8886 - val_loss: 0.2173 - val_acc: 0.9192
Epoch 4/22
 - 42s - loss: 0.2418 - acc: 0.9072 - val_loss: 0.2177 - val_acc: 0.9152
Epoch 5/22
 - 42s - loss: 0.2139 - acc: 0.9200 - val_loss: 0.1679 - val_acc: 0.9420
Epoch 6/22
 - 42s - loss: 0.1933 - acc: 0.9298 - val_loss: 0.1545 - val_acc: 0.9479
Epoch 7/22
 - 42s - loss: 0.1747 - acc: 0.9378 - val_loss: 0.1334 - val_acc: 0.9557
Epoch 8/22
 - 42s - loss: 0.1597 - acc: 0.9446 - val_loss: 0.1216 - val_acc: 0.9621
Epoch 9/22
 - 42s - loss: 0.1474 - acc: 0.9508 - val_loss: 0.1385 - val_acc: 0.9494
Epoch 10/22
 - 42s - loss: 0.1376 - acc: 0.9534 - val_loss: 0.2125 - val_acc: 0.9194
Epoch 11/22
 - 41s - loss: 0.1280 - acc: 0.9575 - val_loss: 0.0917 - val_acc: 0.9708
Epoch 12/22
 - 42s - loss: 0.1176 - acc: 0.9622 - val_loss: 0.1194 - val_acc: 0.9556
Epoch 13/22
 - 41s - loss: 0.1103 - acc: 0.9647 - val_loss: 0.0794 - val_acc: 0.9785
Epoch 14/22
 - 42s - loss: 0.1045 - acc: 0.9675 - val_loss: 0.0880 - val_acc: 0.9705
Epoch 15/22
 - 41s - loss: 0.0985 - acc: 0.9684 - val_loss: 0.0704 - val_acc: 0.9802
Epoch 16/22
 - 41s - loss: 0.0939 - acc: 0.9715 - val_loss: 0.0735 - val_acc: 0.9769
Epoch 17/22
 - 41s - loss: 0.0884 - acc: 0.9735 - val_loss: 0.0648 - val_acc: 0.9817
Epoch 18/22
 - 42s - loss: 0.0826 - acc: 0.9749 - val_loss: 0.0864 - val_acc: 0.9713
Epoch 19/22
 - 42s - loss: 0.0783 - acc: 0.9776 - val_loss: 0.0660 - val_acc: 0.9794
Epoch 20/22
 - 41s - loss: 0.0751 - acc: 0.9785 - val_loss: 0.0527 - val_acc: 0.9871
Epoch 21/22
 - 42s - loss: 0.0721 - acc: 0.9792 - val_loss: 0.0493 - val_acc: 0.9881
Epoch 22/22
 - 42s - loss: 0.0689 - acc: 0.9811 - val_loss: 0.0509 - val_acc: 0.9866
Test accuracy:0.831
current auc_score ------------------> 0.904
------------------------ current config for the test -------------------------
Layers:  [4, 4]  Growth_rate:  24  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  22  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 24, 24, 24)   3456        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 24, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 40, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 40, 24, 24)   160         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 40, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 24, 24, 24)   8640        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 64, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 64, 24, 24)   256         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 64, 24, 24)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 24, 24, 24)   13824       activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 24, 24, 24)   0           dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 88, 24, 24)   0           concatenate_2[0][0]              
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 88, 24, 24)   352         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 88, 24, 24)   0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 24, 24, 24)   19008       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 24, 24, 24)   0           dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 112, 24, 24)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 112, 24, 24)  448         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 112, 24, 24)  0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 56, 24, 24)   6272        activation_6[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 56, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 56, 12, 12)   224         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 56, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 24, 12, 12)   12096       activation_7[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 24, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 80, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 80, 12, 12)   320         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 80, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 24, 12, 12)   17280       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 24, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 104, 12, 12)  0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 104, 12, 12)  416         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 104, 12, 12)  0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 24, 12, 12)   22464       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 24, 12, 12)   0           dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 128, 12, 12)  0           concatenate_6[0][0]              
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 128, 12, 12)  512         concatenate_7[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 128, 12, 12)  0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 24, 12, 12)   27648       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 24, 12, 12)   0           dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 152, 12, 12)  0           concatenate_7[0][0]              
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 152, 12, 12)  608         concatenate_8[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 152, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 21888)        0           activation_11[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            21889       flatten_1[0][0]                  
==================================================================================================
Total params: 157,569
Trainable params: 155,857
Non-trainable params: 1,712
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/22
 - 44s - loss: 0.4367 - acc: 0.8019 - val_loss: 0.4249 - val_acc: 0.7989
Epoch 2/22
 - 42s - loss: 0.3197 - acc: 0.8669 - val_loss: 0.2791 - val_acc: 0.8855
Epoch 3/22
 - 41s - loss: 0.2678 - acc: 0.8942 - val_loss: 0.2450 - val_acc: 0.9045
Epoch 4/22
 - 41s - loss: 0.2353 - acc: 0.9108 - val_loss: 0.2112 - val_acc: 0.9207
Epoch 5/22
 - 42s - loss: 0.2073 - acc: 0.9235 - val_loss: 0.2326 - val_acc: 0.9045
Epoch 6/22
 - 42s - loss: 0.1875 - acc: 0.9317 - val_loss: 0.1528 - val_acc: 0.9498
Epoch 7/22
 - 42s - loss: 0.1682 - acc: 0.9421 - val_loss: 0.1517 - val_acc: 0.9467
Epoch 8/22
 - 42s - loss: 0.1554 - acc: 0.9465 - val_loss: 0.1182 - val_acc: 0.9645
Epoch 9/22
 - 42s - loss: 0.1429 - acc: 0.9513 - val_loss: 0.1133 - val_acc: 0.9657
Epoch 10/22
 - 42s - loss: 0.1349 - acc: 0.9560 - val_loss: 0.1002 - val_acc: 0.9675
Epoch 11/22
 - 42s - loss: 0.1228 - acc: 0.9600 - val_loss: 0.1091 - val_acc: 0.9636
Epoch 12/22
 - 42s - loss: 0.1166 - acc: 0.9628 - val_loss: 0.0843 - val_acc: 0.9769
Epoch 13/22
 - 42s - loss: 0.1080 - acc: 0.9664 - val_loss: 0.0731 - val_acc: 0.9802
Epoch 14/22
 - 42s - loss: 0.1004 - acc: 0.9689 - val_loss: 0.0731 - val_acc: 0.9785
Epoch 15/22
 - 42s - loss: 0.0953 - acc: 0.9714 - val_loss: 0.0727 - val_acc: 0.9782
Epoch 16/22
 - 42s - loss: 0.0903 - acc: 0.9725 - val_loss: 0.0583 - val_acc: 0.9861
Epoch 17/22
 - 42s - loss: 0.0853 - acc: 0.9746 - val_loss: 0.0642 - val_acc: 0.9816
Epoch 18/22
 - 42s - loss: 0.0802 - acc: 0.9767 - val_loss: 0.0604 - val_acc: 0.9839
Epoch 19/22
 - 42s - loss: 0.0786 - acc: 0.9779 - val_loss: 0.0574 - val_acc: 0.9829
Epoch 20/22
 - 42s - loss: 0.0722 - acc: 0.9807 - val_loss: 0.0471 - val_acc: 0.9892
Epoch 21/22
 - 42s - loss: 0.0698 - acc: 0.9805 - val_loss: 0.0448 - val_acc: 0.9900
Epoch 22/22
 - 42s - loss: 0.0676 - acc: 0.9810 - val_loss: 0.0473 - val_acc: 0.9885
Test accuracy:0.830
current auc_score ------------------> 0.896
------------------------ current config for the test -------------------------
Layers:  [4, 4]  Growth_rate:  24  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  22  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 24, 24, 24)   3456        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 24, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 40, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 40, 24, 24)   160         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 40, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 24, 24, 24)   8640        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 64, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 64, 24, 24)   256         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 64, 24, 24)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 24, 24, 24)   13824       activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 24, 24, 24)   0           dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 88, 24, 24)   0           concatenate_2[0][0]              
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 88, 24, 24)   352         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 88, 24, 24)   0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 24, 24, 24)   19008       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 24, 24, 24)   0           dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 112, 24, 24)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 112, 24, 24)  448         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 112, 24, 24)  0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 56, 24, 24)   6272        activation_6[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 56, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 56, 12, 12)   224         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 56, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 24, 12, 12)   12096       activation_7[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 24, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 80, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 80, 12, 12)   320         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 80, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 24, 12, 12)   17280       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 24, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 104, 12, 12)  0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 104, 12, 12)  416         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 104, 12, 12)  0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 24, 12, 12)   22464       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 24, 12, 12)   0           dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 128, 12, 12)  0           concatenate_6[0][0]              
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 128, 12, 12)  512         concatenate_7[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 128, 12, 12)  0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 24, 12, 12)   27648       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 24, 12, 12)   0           dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 152, 12, 12)  0           concatenate_7[0][0]              
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 152, 12, 12)  608         concatenate_8[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 152, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 21888)        0           activation_11[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            21889       flatten_1[0][0]                  
==================================================================================================
Total params: 157,569
Trainable params: 155,857
Non-trainable params: 1,712
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/22
 - 44s - loss: 0.4597 - acc: 0.7880 - val_loss: 0.3532 - val_acc: 0.8453
Epoch 2/22
 - 42s - loss: 0.3285 - acc: 0.8641 - val_loss: 0.2825 - val_acc: 0.8795
Epoch 3/22
 - 42s - loss: 0.2747 - acc: 0.8889 - val_loss: 0.3111 - val_acc: 0.8607
Epoch 4/22
 - 42s - loss: 0.2372 - acc: 0.9092 - val_loss: 0.2776 - val_acc: 0.8789
Epoch 5/22
 - 42s - loss: 0.2100 - acc: 0.9225 - val_loss: 0.2642 - val_acc: 0.8862
Epoch 6/22
 - 42s - loss: 0.1872 - acc: 0.9337 - val_loss: 0.1688 - val_acc: 0.9414
Epoch 7/22
 - 42s - loss: 0.1695 - acc: 0.9403 - val_loss: 0.1337 - val_acc: 0.9549
Epoch 8/22
 - 42s - loss: 0.1553 - acc: 0.9478 - val_loss: 0.1199 - val_acc: 0.9613
Epoch 9/22
 - 42s - loss: 0.1455 - acc: 0.9511 - val_loss: 0.1162 - val_acc: 0.9645
Epoch 10/22
 - 42s - loss: 0.1326 - acc: 0.9567 - val_loss: 0.1013 - val_acc: 0.9690
Epoch 11/22
 - 42s - loss: 0.1221 - acc: 0.9618 - val_loss: 0.1064 - val_acc: 0.9669
Epoch 12/22
 - 42s - loss: 0.1155 - acc: 0.9640 - val_loss: 0.1217 - val_acc: 0.9590
Epoch 13/22
 - 42s - loss: 0.1084 - acc: 0.9678 - val_loss: 0.1019 - val_acc: 0.9665

Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 14/22
 - 43s - loss: 0.0981 - acc: 0.9715 - val_loss: 0.0762 - val_acc: 0.9799
Epoch 15/22
 - 44s - loss: 0.0959 - acc: 0.9708 - val_loss: 0.0834 - val_acc: 0.9769
Epoch 16/22
 - 43s - loss: 0.0940 - acc: 0.9719 - val_loss: 0.0691 - val_acc: 0.9834
Epoch 17/22
 - 42s - loss: 0.0900 - acc: 0.9729 - val_loss: 0.0689 - val_acc: 0.9832
Epoch 18/22
 - 42s - loss: 0.0879 - acc: 0.9757 - val_loss: 0.0643 - val_acc: 0.9852
Epoch 19/22
 - 42s - loss: 0.0862 - acc: 0.9759 - val_loss: 0.0708 - val_acc: 0.9829
Epoch 20/22
 - 42s - loss: 0.0850 - acc: 0.9752 - val_loss: 0.0628 - val_acc: 0.9852
Epoch 21/22
 - 42s - loss: 0.0843 - acc: 0.9755 - val_loss: 0.0588 - val_acc: 0.9863
Epoch 22/22
 - 42s - loss: 0.0812 - acc: 0.9767 - val_loss: 0.0673 - val_acc: 0.9838
Test accuracy:0.806
current auc_score ------------------> 0.910
------------------------ current config for the test -------------------------
Layers:  [4, 4]  Growth_rate:  24  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  22  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 24, 24, 24)   3456        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 24, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 40, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 40, 24, 24)   160         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 40, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 24, 24, 24)   8640        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 64, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 64, 24, 24)   256         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 64, 24, 24)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 24, 24, 24)   13824       activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 24, 24, 24)   0           dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 88, 24, 24)   0           concatenate_2[0][0]              
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 88, 24, 24)   352         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 88, 24, 24)   0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 24, 24, 24)   19008       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 24, 24, 24)   0           dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 112, 24, 24)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 112, 24, 24)  448         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 112, 24, 24)  0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 56, 24, 24)   6272        activation_6[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 56, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 56, 12, 12)   224         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 56, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 24, 12, 12)   12096       activation_7[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 24, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 80, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 80, 12, 12)   320         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 80, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 24, 12, 12)   17280       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 24, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 104, 12, 12)  0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 104, 12, 12)  416         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 104, 12, 12)  0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 24, 12, 12)   22464       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 24, 12, 12)   0           dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 128, 12, 12)  0           concatenate_6[0][0]              
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 128, 12, 12)  512         concatenate_7[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 128, 12, 12)  0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 24, 12, 12)   27648       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 24, 12, 12)   0           dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 152, 12, 12)  0           concatenate_7[0][0]              
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 152, 12, 12)  608         concatenate_8[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 152, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 21888)        0           activation_11[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            21889       flatten_1[0][0]                  
==================================================================================================
Total params: 157,569
Trainable params: 155,857
Non-trainable params: 1,712
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/22
 - 45s - loss: 0.4618 - acc: 0.7834 - val_loss: 0.3417 - val_acc: 0.8550
Epoch 2/22
 - 42s - loss: 0.3371 - acc: 0.8584 - val_loss: 0.3094 - val_acc: 0.8635
Epoch 3/22
 - 42s - loss: 0.2795 - acc: 0.8889 - val_loss: 0.2709 - val_acc: 0.8854
Epoch 4/22
 - 42s - loss: 0.2461 - acc: 0.9046 - val_loss: 0.2063 - val_acc: 0.9251
Epoch 5/22
 - 42s - loss: 0.2181 - acc: 0.9184 - val_loss: 0.2256 - val_acc: 0.9142
Epoch 6/22
 - 42s - loss: 0.1969 - acc: 0.9286 - val_loss: 0.1570 - val_acc: 0.9508
Epoch 7/22
 - 42s - loss: 0.1789 - acc: 0.9361 - val_loss: 0.1641 - val_acc: 0.9434
Epoch 8/22
 - 42s - loss: 0.1654 - acc: 0.9431 - val_loss: 0.1299 - val_acc: 0.9588
Epoch 9/22
 - 42s - loss: 0.1525 - acc: 0.9472 - val_loss: 0.1424 - val_acc: 0.9516
Epoch 10/22
 - 42s - loss: 0.1416 - acc: 0.9525 - val_loss: 0.1070 - val_acc: 0.9690
Epoch 11/22
 - 42s - loss: 0.1318 - acc: 0.9562 - val_loss: 0.1095 - val_acc: 0.9662
Epoch 12/22
 - 42s - loss: 0.1223 - acc: 0.9606 - val_loss: 0.1347 - val_acc: 0.9531
Epoch 13/22
 - 42s - loss: 0.1164 - acc: 0.9646 - val_loss: 0.0934 - val_acc: 0.9735
Epoch 14/22
 - 42s - loss: 0.1074 - acc: 0.9664 - val_loss: 0.0883 - val_acc: 0.9731
Epoch 15/22
 - 42s - loss: 0.1020 - acc: 0.9689 - val_loss: 0.0752 - val_acc: 0.9807
Epoch 16/22
 - 42s - loss: 0.0959 - acc: 0.9711 - val_loss: 0.0674 - val_acc: 0.9829
Epoch 17/22
 - 42s - loss: 0.0912 - acc: 0.9731 - val_loss: 0.0678 - val_acc: 0.9818
Epoch 18/22
 - 42s - loss: 0.0861 - acc: 0.9748 - val_loss: 0.0641 - val_acc: 0.9836
Epoch 19/22
 - 42s - loss: 0.0836 - acc: 0.9754 - val_loss: 0.0676 - val_acc: 0.9824
Epoch 20/22
 - 42s - loss: 0.0767 - acc: 0.9783 - val_loss: 0.0716 - val_acc: 0.9764
Epoch 21/22
 - 44s - loss: 0.0750 - acc: 0.9793 - val_loss: 0.0519 - val_acc: 0.9877
Epoch 22/22
 - 43s - loss: 0.0713 - acc: 0.9807 - val_loss: 0.0474 - val_acc: 0.9897
Test accuracy:0.811
current auc_score ------------------> 0.887
------------------------ current config for the test -------------------------
Layers:  [4, 4]  Growth_rate:  24  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  22  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 24, 24, 24)   3456        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 24, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 40, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 40, 24, 24)   160         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 40, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 24, 24, 24)   8640        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 64, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 64, 24, 24)   256         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 64, 24, 24)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 24, 24, 24)   13824       activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 24, 24, 24)   0           dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 88, 24, 24)   0           concatenate_2[0][0]              
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 88, 24, 24)   352         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 88, 24, 24)   0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 24, 24, 24)   19008       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 24, 24, 24)   0           dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 112, 24, 24)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 112, 24, 24)  448         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 112, 24, 24)  0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 56, 24, 24)   6272        activation_6[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 56, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 56, 12, 12)   224         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 56, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 24, 12, 12)   12096       activation_7[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 24, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 80, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 80, 12, 12)   320         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 80, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 24, 12, 12)   17280       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 24, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 104, 12, 12)  0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 104, 12, 12)  416         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 104, 12, 12)  0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 24, 12, 12)   22464       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 24, 12, 12)   0           dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 128, 12, 12)  0           concatenate_6[0][0]              
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 128, 12, 12)  512         concatenate_7[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 128, 12, 12)  0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 24, 12, 12)   27648       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 24, 12, 12)   0           dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 152, 12, 12)  0           concatenate_7[0][0]              
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 152, 12, 12)  608         concatenate_8[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 152, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 21888)        0           activation_11[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            21889       flatten_1[0][0]                  
==================================================================================================
Total params: 157,569
Trainable params: 155,857
Non-trainable params: 1,712
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/22
 - 47s - loss: 0.4556 - acc: 0.7902 - val_loss: 0.3558 - val_acc: 0.8419
Epoch 2/22
 - 43s - loss: 0.3277 - acc: 0.8631 - val_loss: 0.3375 - val_acc: 0.8455
Epoch 3/22
 - 43s - loss: 0.2780 - acc: 0.8873 - val_loss: 0.3279 - val_acc: 0.8535
Epoch 4/22
 - 43s - loss: 0.2384 - acc: 0.9069 - val_loss: 0.1911 - val_acc: 0.9360
Epoch 5/22
 - 43s - loss: 0.2157 - acc: 0.9193 - val_loss: 0.1985 - val_acc: 0.9252
Epoch 6/22
 - 43s - loss: 0.1934 - acc: 0.9288 - val_loss: 0.1537 - val_acc: 0.9478
Epoch 7/22
 - 43s - loss: 0.1759 - acc: 0.9364 - val_loss: 0.1506 - val_acc: 0.9494
Epoch 8/22
 - 43s - loss: 0.1614 - acc: 0.9441 - val_loss: 0.1268 - val_acc: 0.9616
Epoch 9/22
 - 43s - loss: 0.1487 - acc: 0.9503 - val_loss: 0.1290 - val_acc: 0.9581
Epoch 10/22
 - 43s - loss: 0.1369 - acc: 0.9541 - val_loss: 0.1504 - val_acc: 0.9459
Epoch 11/22
 - 43s - loss: 0.1284 - acc: 0.9586 - val_loss: 0.0975 - val_acc: 0.9725
Epoch 12/22
 - 44s - loss: 0.1197 - acc: 0.9623 - val_loss: 0.0942 - val_acc: 0.9720
Epoch 13/22
 - 45s - loss: 0.1097 - acc: 0.9666 - val_loss: 0.0881 - val_acc: 0.9745
Epoch 14/22
 - 43s - loss: 0.1036 - acc: 0.9689 - val_loss: 0.0710 - val_acc: 0.9807
Epoch 15/22
 - 43s - loss: 0.0989 - acc: 0.9701 - val_loss: 0.0659 - val_acc: 0.9848
Epoch 16/22
 - 43s - loss: 0.0929 - acc: 0.9731 - val_loss: 0.0677 - val_acc: 0.9809
Epoch 17/22
 - 43s - loss: 0.0873 - acc: 0.9747 - val_loss: 0.0599 - val_acc: 0.9849
Epoch 18/22
 - 43s - loss: 0.0827 - acc: 0.9766 - val_loss: 0.0589 - val_acc: 0.9859
Epoch 19/22
 - 43s - loss: 0.0790 - acc: 0.9779 - val_loss: 0.0602 - val_acc: 0.9828
Epoch 20/22
 - 43s - loss: 0.0745 - acc: 0.9791 - val_loss: 0.0539 - val_acc: 0.9882
Epoch 21/22
 - 43s - loss: 0.0737 - acc: 0.9792 - val_loss: 0.0444 - val_acc: 0.9922
Epoch 22/22
 - 43s - loss: 0.0688 - acc: 0.9818 - val_loss: 0.0530 - val_acc: 0.9857
Test accuracy:0.791
current auc_score ------------------> 0.892
------------------------ current config for the test -------------------------
Layers:  [4, 4]  Growth_rate:  24  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  22  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 24, 24, 24)   3456        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 24, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 40, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 40, 24, 24)   160         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 40, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 24, 24, 24)   8640        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 64, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 64, 24, 24)   256         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 64, 24, 24)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 24, 24, 24)   13824       activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 24, 24, 24)   0           dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 88, 24, 24)   0           concatenate_2[0][0]              
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 88, 24, 24)   352         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 88, 24, 24)   0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 24, 24, 24)   19008       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 24, 24, 24)   0           dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 112, 24, 24)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 112, 24, 24)  448         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 112, 24, 24)  0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 56, 24, 24)   6272        activation_6[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 56, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 56, 12, 12)   224         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 56, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 24, 12, 12)   12096       activation_7[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 24, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 80, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 80, 12, 12)   320         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 80, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 24, 12, 12)   17280       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 24, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 104, 12, 12)  0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 104, 12, 12)  416         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 104, 12, 12)  0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 24, 12, 12)   22464       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 24, 12, 12)   0           dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 128, 12, 12)  0           concatenate_6[0][0]              
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 128, 12, 12)  512         concatenate_7[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 128, 12, 12)  0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 24, 12, 12)   27648       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 24, 12, 12)   0           dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 152, 12, 12)  0           concatenate_7[0][0]              
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 152, 12, 12)  608         concatenate_8[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 152, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 21888)        0           activation_11[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            21889       flatten_1[0][0]                  
==================================================================================================
Total params: 157,569
Trainable params: 155,857
Non-trainable params: 1,712
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/22
 - 46s - loss: 0.4717 - acc: 0.7790 - val_loss: 0.3506 - val_acc: 0.8486
Epoch 2/22
 - 43s - loss: 0.3439 - acc: 0.8540 - val_loss: 0.3403 - val_acc: 0.8405
Epoch 3/22
 - 43s - loss: 0.2893 - acc: 0.8839 - val_loss: 0.3626 - val_acc: 0.8308
Epoch 4/22
 - 43s - loss: 0.2555 - acc: 0.8997 - val_loss: 0.2431 - val_acc: 0.9044
Epoch 5/22
 - 42s - loss: 0.2278 - acc: 0.9138 - val_loss: 0.2054 - val_acc: 0.9246
Epoch 6/22
 - 42s - loss: 0.2033 - acc: 0.9254 - val_loss: 0.1575 - val_acc: 0.9482
Epoch 7/22
 - 42s - loss: 0.1847 - acc: 0.9352 - val_loss: 0.1475 - val_acc: 0.9543
Epoch 8/22
 - 42s - loss: 0.1674 - acc: 0.9412 - val_loss: 0.1726 - val_acc: 0.9388
Epoch 9/22
 - 43s - loss: 0.1542 - acc: 0.9468 - val_loss: 0.1387 - val_acc: 0.9537
Epoch 10/22
 - 43s - loss: 0.1427 - acc: 0.9522 - val_loss: 0.1146 - val_acc: 0.9652
Epoch 11/22
 - 43s - loss: 0.1317 - acc: 0.9572 - val_loss: 0.1220 - val_acc: 0.9600
Epoch 12/22
 - 43s - loss: 0.1237 - acc: 0.9592 - val_loss: 0.0952 - val_acc: 0.9736
Epoch 13/22
 - 43s - loss: 0.1138 - acc: 0.9637 - val_loss: 0.1071 - val_acc: 0.9641
Epoch 14/22
 - 43s - loss: 0.1083 - acc: 0.9661 - val_loss: 0.0814 - val_acc: 0.9758
Epoch 15/22
 - 43s - loss: 0.1037 - acc: 0.9674 - val_loss: 0.0749 - val_acc: 0.9803
Epoch 16/22
 - 43s - loss: 0.0958 - acc: 0.9718 - val_loss: 0.0734 - val_acc: 0.9793
Epoch 17/22
 - 43s - loss: 0.0931 - acc: 0.9721 - val_loss: 0.0656 - val_acc: 0.9832
Epoch 18/22
 - 43s - loss: 0.0894 - acc: 0.9734 - val_loss: 0.0571 - val_acc: 0.9856
Epoch 19/22
 - 43s - loss: 0.0819 - acc: 0.9769 - val_loss: 0.0552 - val_acc: 0.9867
Epoch 20/22
 - 42s - loss: 0.0778 - acc: 0.9783 - val_loss: 0.0521 - val_acc: 0.9868
Epoch 21/22
 - 42s - loss: 0.0758 - acc: 0.9785 - val_loss: 0.0546 - val_acc: 0.9853
Epoch 22/22
 - 42s - loss: 0.0728 - acc: 0.9792 - val_loss: 0.0736 - val_acc: 0.9797
Test accuracy:0.793
current auc_score ------------------> 0.905
------------------------ current config for the test -------------------------
Layers:  [4, 4]  Growth_rate:  24  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  22  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 24, 24, 24)   3456        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 24, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 40, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 40, 24, 24)   160         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 40, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 24, 24, 24)   8640        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 64, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 64, 24, 24)   256         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 64, 24, 24)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 24, 24, 24)   13824       activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 24, 24, 24)   0           dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 88, 24, 24)   0           concatenate_2[0][0]              
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 88, 24, 24)   352         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 88, 24, 24)   0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 24, 24, 24)   19008       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 24, 24, 24)   0           dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 112, 24, 24)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 112, 24, 24)  448         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 112, 24, 24)  0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 56, 24, 24)   6272        activation_6[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 56, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 56, 12, 12)   224         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 56, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 24, 12, 12)   12096       activation_7[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 24, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 80, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 80, 12, 12)   320         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 80, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 24, 12, 12)   17280       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 24, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 104, 12, 12)  0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 104, 12, 12)  416         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 104, 12, 12)  0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 24, 12, 12)   22464       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 24, 12, 12)   0           dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 128, 12, 12)  0           concatenate_6[0][0]              
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 128, 12, 12)  512         concatenate_7[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 128, 12, 12)  0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 24, 12, 12)   27648       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 24, 12, 12)   0           dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 152, 12, 12)  0           concatenate_7[0][0]              
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 152, 12, 12)  608         concatenate_8[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 152, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 21888)        0           activation_11[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            21889       flatten_1[0][0]                  
==================================================================================================
Total params: 157,569
Trainable params: 155,857
Non-trainable params: 1,712
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/22
 - 45s - loss: 0.4598 - acc: 0.7886 - val_loss: 0.4028 - val_acc: 0.8155
Epoch 2/22
 - 42s - loss: 0.3307 - acc: 0.8649 - val_loss: 0.2809 - val_acc: 0.8869
Epoch 3/22
 - 42s - loss: 0.2767 - acc: 0.8892 - val_loss: 0.2346 - val_acc: 0.9118
Epoch 4/22
 - 42s - loss: 0.2366 - acc: 0.9096 - val_loss: 0.2653 - val_acc: 0.8876
Epoch 5/22
 - 42s - loss: 0.2089 - acc: 0.9231 - val_loss: 0.1752 - val_acc: 0.9391
Epoch 6/22
 - 42s - loss: 0.1865 - acc: 0.9346 - val_loss: 0.1606 - val_acc: 0.9454
Epoch 7/22
 - 42s - loss: 0.1696 - acc: 0.9413 - val_loss: 0.1381 - val_acc: 0.9529
Epoch 8/22
 - 42s - loss: 0.1548 - acc: 0.9473 - val_loss: 0.1505 - val_acc: 0.9475
Epoch 9/22
 - 42s - loss: 0.1431 - acc: 0.9532 - val_loss: 0.1072 - val_acc: 0.9644
Epoch 10/22
 - 42s - loss: 0.1342 - acc: 0.9559 - val_loss: 0.0941 - val_acc: 0.9733
Epoch 11/22
 - 44s - loss: 0.1229 - acc: 0.9615 - val_loss: 0.0888 - val_acc: 0.9753
Epoch 12/22
 - 43s - loss: 0.1158 - acc: 0.9644 - val_loss: 0.0819 - val_acc: 0.9773
Epoch 13/22
 - 43s - loss: 0.1085 - acc: 0.9659 - val_loss: 0.0729 - val_acc: 0.9813
Epoch 14/22
 - 43s - loss: 0.1019 - acc: 0.9693 - val_loss: 0.1043 - val_acc: 0.9652
Epoch 15/22
 - 43s - loss: 0.0964 - acc: 0.9703 - val_loss: 0.0739 - val_acc: 0.9798
Epoch 16/22
 - 43s - loss: 0.0903 - acc: 0.9733 - val_loss: 0.0786 - val_acc: 0.9779

Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 17/22
 - 43s - loss: 0.0812 - acc: 0.9771 - val_loss: 0.0550 - val_acc: 0.9892
Epoch 18/22
 - 43s - loss: 0.0790 - acc: 0.9780 - val_loss: 0.0525 - val_acc: 0.9895
Epoch 19/22
 - 43s - loss: 0.0763 - acc: 0.9797 - val_loss: 0.0569 - val_acc: 0.9872
Epoch 20/22
 - 43s - loss: 0.0764 - acc: 0.9786 - val_loss: 0.0527 - val_acc: 0.9895
Epoch 21/22
 - 43s - loss: 0.0756 - acc: 0.9787 - val_loss: 0.0496 - val_acc: 0.9900
Epoch 22/22
 - 43s - loss: 0.0740 - acc: 0.9804 - val_loss: 0.0521 - val_acc: 0.9891
Test accuracy:0.806
current auc_score ------------------> 0.903
accuracies:  [0.8655913978494624, 0.7915322580645161, 0.7743279569892473, 0.8306451612903226, 0.8297043010752688, 0.8056451612903226, 0.8106182795698925, 0.791263440860215, 0.793010752688172, 0.8055107526881721]
aucs:  [0.9367, 0.9005, 0.871, 0.9038, 0.8961, 0.9101, 0.8874, 0.8918, 0.9054, 0.9032]
mean and std AUC:  0.901+/-0.016  max:   0.9367
['4-4', '30', '2', '16', '0.2', '0.07', '20', 'adadelta', '0.5', 'FALSE', '64', 'flatten']
------------------------ current config for the test -------------------------
Layers:  [4, 4]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  20  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 30, 24, 24)   20520       activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 24, 24)   0           dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 106, 24, 24)  0           concatenate_2[0][0]              
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 106, 24, 24)  424         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 106, 24, 24)  0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 30, 24, 24)   28620       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 24, 24)   0           dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 136, 24, 24)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 136, 24, 24)  544         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 136, 24, 24)  0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 68, 24, 24)   9248        activation_6[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 68, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 68, 12, 12)   272         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 68, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_7[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 98, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 98, 12, 12)   392         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 98, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   26460       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 128, 12, 12)  0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 128, 12, 12)  512         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 128, 12, 12)  0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 30, 12, 12)   34560       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 30, 12, 12)   0           dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 158, 12, 12)  0           concatenate_6[0][0]              
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 158, 12, 12)  632         concatenate_7[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 158, 12, 12)  0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 30, 12, 12)   42660       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 30, 12, 12)   0           dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 188, 12, 12)  0           concatenate_7[0][0]              
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 188, 12, 12)  752         concatenate_8[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 188, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 27072)        0           activation_11[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            27073       flatten_1[0][0]                  
==================================================================================================
Total params: 229,953
Trainable params: 227,881
Non-trainable params: 2,072
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/20
 - 58s - loss: 0.4390 - acc: 0.7985 - val_loss: 0.3330 - val_acc: 0.8586
Epoch 2/20
 - 55s - loss: 0.3117 - acc: 0.8706 - val_loss: 0.2897 - val_acc: 0.8770
Epoch 3/20
 - 55s - loss: 0.2569 - acc: 0.8996 - val_loss: 0.2292 - val_acc: 0.9091
Epoch 4/20
 - 55s - loss: 0.2170 - acc: 0.9208 - val_loss: 0.1952 - val_acc: 0.9246
Epoch 5/20
 - 55s - loss: 0.1923 - acc: 0.9315 - val_loss: 0.1893 - val_acc: 0.9287
Epoch 6/20
 - 54s - loss: 0.1697 - acc: 0.9417 - val_loss: 0.1292 - val_acc: 0.9582
Epoch 7/20
 - 55s - loss: 0.1518 - acc: 0.9492 - val_loss: 0.1899 - val_acc: 0.9275
Epoch 8/20
 - 55s - loss: 0.1387 - acc: 0.9546 - val_loss: 0.1056 - val_acc: 0.9710
Epoch 9/20
 - 55s - loss: 0.1258 - acc: 0.9598 - val_loss: 0.0940 - val_acc: 0.9711
Epoch 10/20
 - 54s - loss: 0.1172 - acc: 0.9636 - val_loss: 0.1017 - val_acc: 0.9662
Epoch 11/20
 - 55s - loss: 0.1080 - acc: 0.9666 - val_loss: 0.0740 - val_acc: 0.9818
Epoch 12/20
 - 55s - loss: 0.0991 - acc: 0.9707 - val_loss: 0.0634 - val_acc: 0.9843
Epoch 13/20
 - 55s - loss: 0.0926 - acc: 0.9735 - val_loss: 0.0674 - val_acc: 0.9833
Epoch 14/20
 - 55s - loss: 0.0877 - acc: 0.9746 - val_loss: 0.0530 - val_acc: 0.9882
Epoch 15/20
 - 55s - loss: 0.0824 - acc: 0.9772 - val_loss: 0.0616 - val_acc: 0.9810
Epoch 16/20
 - 55s - loss: 0.0768 - acc: 0.9788 - val_loss: 0.0594 - val_acc: 0.9824
Epoch 17/20
 - 55s - loss: 0.0713 - acc: 0.9810 - val_loss: 0.0518 - val_acc: 0.9878
Epoch 18/20
 - 54s - loss: 0.0686 - acc: 0.9819 - val_loss: 0.0416 - val_acc: 0.9916
Epoch 19/20
 - 55s - loss: 0.0629 - acc: 0.9839 - val_loss: 0.0394 - val_acc: 0.9933
Epoch 20/20
 - 55s - loss: 0.0609 - acc: 0.9847 - val_loss: 0.0392 - val_acc: 0.9930
Test accuracy:0.821
current auc_score ------------------> 0.915
------------------------ current config for the test -------------------------
Layers:  [4, 4]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  20  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 30, 24, 24)   20520       activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 24, 24)   0           dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 106, 24, 24)  0           concatenate_2[0][0]              
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 106, 24, 24)  424         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 106, 24, 24)  0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 30, 24, 24)   28620       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 24, 24)   0           dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 136, 24, 24)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 136, 24, 24)  544         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 136, 24, 24)  0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 68, 24, 24)   9248        activation_6[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 68, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 68, 12, 12)   272         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 68, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_7[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 98, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 98, 12, 12)   392         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 98, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   26460       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 128, 12, 12)  0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 128, 12, 12)  512         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 128, 12, 12)  0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 30, 12, 12)   34560       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 30, 12, 12)   0           dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 158, 12, 12)  0           concatenate_6[0][0]              
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 158, 12, 12)  632         concatenate_7[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 158, 12, 12)  0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 30, 12, 12)   42660       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 30, 12, 12)   0           dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 188, 12, 12)  0           concatenate_7[0][0]              
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 188, 12, 12)  752         concatenate_8[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 188, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 27072)        0           activation_11[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            27073       flatten_1[0][0]                  
==================================================================================================
Total params: 229,953
Trainable params: 227,881
Non-trainable params: 2,072
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/20
 - 57s - loss: 0.4363 - acc: 0.8029 - val_loss: 0.4366 - val_acc: 0.7954
Epoch 2/20
 - 55s - loss: 0.3038 - acc: 0.8754 - val_loss: 0.2833 - val_acc: 0.8781
Epoch 3/20
 - 54s - loss: 0.2511 - acc: 0.9025 - val_loss: 0.2201 - val_acc: 0.9147
Epoch 4/20
 - 55s - loss: 0.2146 - acc: 0.9205 - val_loss: 0.1820 - val_acc: 0.9396
Epoch 5/20
 - 55s - loss: 0.1879 - acc: 0.9336 - val_loss: 0.1999 - val_acc: 0.9256
Epoch 6/20
 - 54s - loss: 0.1671 - acc: 0.9430 - val_loss: 0.1261 - val_acc: 0.9622
Epoch 7/20
 - 55s - loss: 0.1486 - acc: 0.9508 - val_loss: 0.1273 - val_acc: 0.9570
Epoch 8/20
 - 55s - loss: 0.1367 - acc: 0.9549 - val_loss: 0.1108 - val_acc: 0.9680
Epoch 9/20
 - 55s - loss: 0.1234 - acc: 0.9612 - val_loss: 0.0880 - val_acc: 0.9772
Epoch 10/20
 - 55s - loss: 0.1133 - acc: 0.9651 - val_loss: 0.0816 - val_acc: 0.9778
Epoch 11/20
 - 55s - loss: 0.1055 - acc: 0.9685 - val_loss: 0.0783 - val_acc: 0.9772
Epoch 12/20
 - 55s - loss: 0.0975 - acc: 0.9711 - val_loss: 0.1021 - val_acc: 0.9646
Epoch 13/20
 - 55s - loss: 0.0914 - acc: 0.9740 - val_loss: 0.0993 - val_acc: 0.9669
Epoch 14/20
 - 55s - loss: 0.0842 - acc: 0.9769 - val_loss: 0.0565 - val_acc: 0.9876
Epoch 15/20
 - 54s - loss: 0.0800 - acc: 0.9771 - val_loss: 0.0558 - val_acc: 0.9861
Epoch 16/20
 - 54s - loss: 0.0747 - acc: 0.9793 - val_loss: 0.0526 - val_acc: 0.9881
Epoch 17/20
 - 54s - loss: 0.0720 - acc: 0.9809 - val_loss: 0.0546 - val_acc: 0.9859
Epoch 18/20
 - 54s - loss: 0.0661 - acc: 0.9835 - val_loss: 0.0609 - val_acc: 0.9837
Epoch 19/20
 - 55s - loss: 0.0634 - acc: 0.9837 - val_loss: 0.0447 - val_acc: 0.9906
Epoch 20/20
 - 55s - loss: 0.0606 - acc: 0.9843 - val_loss: 0.0536 - val_acc: 0.9856
Test accuracy:0.841
current auc_score ------------------> 0.918
------------------------ current config for the test -------------------------
Layers:  [4, 4]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  20  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 30, 24, 24)   20520       activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 24, 24)   0           dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 106, 24, 24)  0           concatenate_2[0][0]              
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 106, 24, 24)  424         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 106, 24, 24)  0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 30, 24, 24)   28620       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 24, 24)   0           dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 136, 24, 24)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 136, 24, 24)  544         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 136, 24, 24)  0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 68, 24, 24)   9248        activation_6[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 68, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 68, 12, 12)   272         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 68, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_7[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 98, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 98, 12, 12)   392         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 98, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   26460       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 128, 12, 12)  0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 128, 12, 12)  512         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 128, 12, 12)  0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 30, 12, 12)   34560       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 30, 12, 12)   0           dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 158, 12, 12)  0           concatenate_6[0][0]              
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 158, 12, 12)  632         concatenate_7[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 158, 12, 12)  0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 30, 12, 12)   42660       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 30, 12, 12)   0           dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 188, 12, 12)  0           concatenate_7[0][0]              
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 188, 12, 12)  752         concatenate_8[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 188, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 27072)        0           activation_11[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            27073       flatten_1[0][0]                  
==================================================================================================
Total params: 229,953
Trainable params: 227,881
Non-trainable params: 2,072
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/20
 - 58s - loss: 0.4394 - acc: 0.7989 - val_loss: 0.3112 - val_acc: 0.8726
Epoch 2/20
 - 55s - loss: 0.3163 - acc: 0.8699 - val_loss: 0.2437 - val_acc: 0.9073
Epoch 3/20
 - 55s - loss: 0.2608 - acc: 0.8977 - val_loss: 0.2391 - val_acc: 0.9047
Epoch 4/20
 - 55s - loss: 0.2212 - acc: 0.9174 - val_loss: 0.2096 - val_acc: 0.9239
Epoch 5/20
 - 55s - loss: 0.1917 - acc: 0.9328 - val_loss: 0.1566 - val_acc: 0.9473
Epoch 6/20
 - 55s - loss: 0.1679 - acc: 0.9424 - val_loss: 0.1422 - val_acc: 0.9521
Epoch 7/20
 - 55s - loss: 0.1535 - acc: 0.9494 - val_loss: 0.1164 - val_acc: 0.9664
Epoch 8/20
 - 55s - loss: 0.1390 - acc: 0.9550 - val_loss: 0.1059 - val_acc: 0.9665
Epoch 9/20
 - 55s - loss: 0.1275 - acc: 0.9600 - val_loss: 0.0952 - val_acc: 0.9736
Epoch 10/20
 - 56s - loss: 0.1144 - acc: 0.9650 - val_loss: 0.1075 - val_acc: 0.9659
Epoch 11/20
 - 55s - loss: 0.1047 - acc: 0.9690 - val_loss: 0.0877 - val_acc: 0.9730
Epoch 12/20
 - 56s - loss: 0.0996 - acc: 0.9704 - val_loss: 0.1327 - val_acc: 0.9533
Epoch 13/20
 - 55s - loss: 0.0931 - acc: 0.9725 - val_loss: 0.0857 - val_acc: 0.9708
Epoch 00013: early stopping
Test accuracy:0.838
current auc_score ------------------> 0.912
------------------------ current config for the test -------------------------
Layers:  [4, 4]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  20  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 30, 24, 24)   20520       activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 24, 24)   0           dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 106, 24, 24)  0           concatenate_2[0][0]              
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 106, 24, 24)  424         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 106, 24, 24)  0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 30, 24, 24)   28620       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 24, 24)   0           dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 136, 24, 24)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 136, 24, 24)  544         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 136, 24, 24)  0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 68, 24, 24)   9248        activation_6[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 68, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 68, 12, 12)   272         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 68, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_7[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 98, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 98, 12, 12)   392         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 98, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   26460       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 128, 12, 12)  0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 128, 12, 12)  512         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 128, 12, 12)  0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 30, 12, 12)   34560       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 30, 12, 12)   0           dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 158, 12, 12)  0           concatenate_6[0][0]              
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 158, 12, 12)  632         concatenate_7[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 158, 12, 12)  0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 30, 12, 12)   42660       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 30, 12, 12)   0           dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 188, 12, 12)  0           concatenate_7[0][0]              
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 188, 12, 12)  752         concatenate_8[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 188, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 27072)        0           activation_11[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            27073       flatten_1[0][0]                  
==================================================================================================
Total params: 229,953
Trainable params: 227,881
Non-trainable params: 2,072
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/20
 - 58s - loss: 0.4488 - acc: 0.7945 - val_loss: 0.3490 - val_acc: 0.8459
Epoch 2/20
 - 55s - loss: 0.3199 - acc: 0.8693 - val_loss: 0.2918 - val_acc: 0.8766
Epoch 3/20
 - 56s - loss: 0.2615 - acc: 0.8988 - val_loss: 0.2287 - val_acc: 0.9104
Epoch 4/20
 - 56s - loss: 0.2203 - acc: 0.9192 - val_loss: 0.1960 - val_acc: 0.9281
Epoch 5/20
 - 56s - loss: 0.1935 - acc: 0.9314 - val_loss: 0.2400 - val_acc: 0.9012
Epoch 6/20
 - 56s - loss: 0.1747 - acc: 0.9392 - val_loss: 0.1937 - val_acc: 0.9252
Epoch 7/20
 - 54s - loss: 0.1545 - acc: 0.9487 - val_loss: 0.1239 - val_acc: 0.9596
Epoch 8/20
 - 54s - loss: 0.1402 - acc: 0.9533 - val_loss: 0.1055 - val_acc: 0.9695
Epoch 9/20
 - 55s - loss: 0.1287 - acc: 0.9592 - val_loss: 0.1218 - val_acc: 0.9595
Epoch 10/20
 - 55s - loss: 0.1170 - acc: 0.9639 - val_loss: 0.0867 - val_acc: 0.9744
Epoch 11/20
 - 55s - loss: 0.1085 - acc: 0.9672 - val_loss: 0.0864 - val_acc: 0.9754
Epoch 12/20
 - 55s - loss: 0.1006 - acc: 0.9707 - val_loss: 0.0840 - val_acc: 0.9769
Epoch 13/20
 - 55s - loss: 0.0944 - acc: 0.9731 - val_loss: 0.0639 - val_acc: 0.9851
Epoch 14/20
 - 55s - loss: 0.0874 - acc: 0.9752 - val_loss: 0.0696 - val_acc: 0.9813
Epoch 15/20
 - 55s - loss: 0.0828 - acc: 0.9778 - val_loss: 0.0648 - val_acc: 0.9851
Epoch 16/20
 - 55s - loss: 0.0765 - acc: 0.9794 - val_loss: 0.0535 - val_acc: 0.9881
Epoch 17/20
 - 56s - loss: 0.0730 - acc: 0.9806 - val_loss: 0.0446 - val_acc: 0.9915
Epoch 18/20
 - 56s - loss: 0.0677 - acc: 0.9832 - val_loss: 0.0471 - val_acc: 0.9905
Epoch 19/20
 - 55s - loss: 0.0655 - acc: 0.9831 - val_loss: 0.0489 - val_acc: 0.9901
Epoch 20/20
 - 54s - loss: 0.0613 - acc: 0.9849 - val_loss: 0.0439 - val_acc: 0.9906
Test accuracy:0.816
current auc_score ------------------> 0.929
------------------------ current config for the test -------------------------
Layers:  [4, 4]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  20  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 30, 24, 24)   20520       activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 24, 24)   0           dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 106, 24, 24)  0           concatenate_2[0][0]              
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 106, 24, 24)  424         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 106, 24, 24)  0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 30, 24, 24)   28620       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 24, 24)   0           dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 136, 24, 24)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 136, 24, 24)  544         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 136, 24, 24)  0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 68, 24, 24)   9248        activation_6[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 68, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 68, 12, 12)   272         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 68, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_7[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 98, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 98, 12, 12)   392         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 98, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   26460       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 128, 12, 12)  0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 128, 12, 12)  512         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 128, 12, 12)  0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 30, 12, 12)   34560       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 30, 12, 12)   0           dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 158, 12, 12)  0           concatenate_6[0][0]              
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 158, 12, 12)  632         concatenate_7[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 158, 12, 12)  0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 30, 12, 12)   42660       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 30, 12, 12)   0           dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 188, 12, 12)  0           concatenate_7[0][0]              
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 188, 12, 12)  752         concatenate_8[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 188, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 27072)        0           activation_11[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            27073       flatten_1[0][0]                  
==================================================================================================
Total params: 229,953
Trainable params: 227,881
Non-trainable params: 2,072
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/20
 - 57s - loss: 0.4621 - acc: 0.7836 - val_loss: 0.3490 - val_acc: 0.8555
Epoch 2/20
 - 54s - loss: 0.3244 - acc: 0.8665 - val_loss: 0.3673 - val_acc: 0.8316
Epoch 3/20
 - 55s - loss: 0.2681 - acc: 0.8961 - val_loss: 0.2145 - val_acc: 0.9206
Epoch 4/20
 - 54s - loss: 0.2270 - acc: 0.9153 - val_loss: 0.1820 - val_acc: 0.9376
Epoch 5/20
 - 55s - loss: 0.1990 - acc: 0.9287 - val_loss: 0.1524 - val_acc: 0.9498
Epoch 6/20
 - 56s - loss: 0.1749 - acc: 0.9391 - val_loss: 0.1409 - val_acc: 0.9565
Epoch 7/20
 - 55s - loss: 0.1604 - acc: 0.9455 - val_loss: 0.2383 - val_acc: 0.9037
Epoch 8/20
 - 54s - loss: 0.1414 - acc: 0.9548 - val_loss: 0.1569 - val_acc: 0.9467
Epoch 9/20
 - 54s - loss: 0.1314 - acc: 0.9572 - val_loss: 0.0991 - val_acc: 0.9665
Epoch 10/20
 - 54s - loss: 0.1189 - acc: 0.9635 - val_loss: 0.1071 - val_acc: 0.9665
Epoch 11/20
 - 54s - loss: 0.1104 - acc: 0.9677 - val_loss: 0.0877 - val_acc: 0.9755
Epoch 12/20
 - 54s - loss: 0.1024 - acc: 0.9687 - val_loss: 0.0848 - val_acc: 0.9769
Epoch 13/20
 - 54s - loss: 0.0953 - acc: 0.9723 - val_loss: 0.0628 - val_acc: 0.9839
Epoch 14/20
 - 54s - loss: 0.0896 - acc: 0.9746 - val_loss: 0.0574 - val_acc: 0.9867
Epoch 15/20
 - 54s - loss: 0.0836 - acc: 0.9758 - val_loss: 0.0625 - val_acc: 0.9858
Epoch 16/20
 - 54s - loss: 0.0778 - acc: 0.9783 - val_loss: 0.0527 - val_acc: 0.9871
Epoch 17/20
 - 53s - loss: 0.0742 - acc: 0.9798 - val_loss: 0.0520 - val_acc: 0.9910
Epoch 18/20
 - 54s - loss: 0.0695 - acc: 0.9815 - val_loss: 0.0441 - val_acc: 0.9915
Epoch 19/20
 - 54s - loss: 0.0644 - acc: 0.9838 - val_loss: 0.0449 - val_acc: 0.9915
Epoch 20/20
 - 54s - loss: 0.0634 - acc: 0.9836 - val_loss: 0.0388 - val_acc: 0.9920
Test accuracy:0.828
current auc_score ------------------> 0.899
------------------------ current config for the test -------------------------
Layers:  [4, 4]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  20  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 30, 24, 24)   20520       activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 24, 24)   0           dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 106, 24, 24)  0           concatenate_2[0][0]              
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 106, 24, 24)  424         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 106, 24, 24)  0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 30, 24, 24)   28620       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 24, 24)   0           dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 136, 24, 24)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 136, 24, 24)  544         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 136, 24, 24)  0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 68, 24, 24)   9248        activation_6[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 68, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 68, 12, 12)   272         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 68, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_7[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 98, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 98, 12, 12)   392         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 98, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   26460       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 128, 12, 12)  0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 128, 12, 12)  512         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 128, 12, 12)  0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 30, 12, 12)   34560       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 30, 12, 12)   0           dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 158, 12, 12)  0           concatenate_6[0][0]              
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 158, 12, 12)  632         concatenate_7[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 158, 12, 12)  0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 30, 12, 12)   42660       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 30, 12, 12)   0           dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 188, 12, 12)  0           concatenate_7[0][0]              
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 188, 12, 12)  752         concatenate_8[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 188, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 27072)        0           activation_11[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            27073       flatten_1[0][0]                  
==================================================================================================
Total params: 229,953
Trainable params: 227,881
Non-trainable params: 2,072
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/20
 - 57s - loss: 0.4497 - acc: 0.7951 - val_loss: 0.3701 - val_acc: 0.8328
Epoch 2/20
 - 54s - loss: 0.3196 - acc: 0.8671 - val_loss: 0.3629 - val_acc: 0.8303
Epoch 3/20
 - 54s - loss: 0.2661 - acc: 0.8966 - val_loss: 0.4335 - val_acc: 0.8066
Epoch 4/20
 - 54s - loss: 0.2322 - acc: 0.9121 - val_loss: 0.1916 - val_acc: 0.9322
Epoch 5/20
 - 54s - loss: 0.2027 - acc: 0.9268 - val_loss: 0.1595 - val_acc: 0.9483
Epoch 6/20
 - 56s - loss: 0.1782 - acc: 0.9380 - val_loss: 0.1866 - val_acc: 0.9296
Epoch 7/20
 - 55s - loss: 0.1622 - acc: 0.9455 - val_loss: 0.1265 - val_acc: 0.9593
Epoch 8/20
 - 55s - loss: 0.1463 - acc: 0.9526 - val_loss: 0.1596 - val_acc: 0.9425
Epoch 9/20
 - 55s - loss: 0.1339 - acc: 0.9568 - val_loss: 0.1083 - val_acc: 0.9682
Epoch 10/20
 - 55s - loss: 0.1228 - acc: 0.9610 - val_loss: 0.1085 - val_acc: 0.9669
Epoch 11/20
 - 55s - loss: 0.1141 - acc: 0.9651 - val_loss: 0.0868 - val_acc: 0.9743
Epoch 12/20
 - 55s - loss: 0.1054 - acc: 0.9680 - val_loss: 0.1355 - val_acc: 0.9518
Epoch 13/20
 - 55s - loss: 0.0964 - acc: 0.9721 - val_loss: 0.0766 - val_acc: 0.9774
Epoch 14/20
 - 54s - loss: 0.0918 - acc: 0.9737 - val_loss: 0.0647 - val_acc: 0.9843
Epoch 15/20
 - 55s - loss: 0.0866 - acc: 0.9753 - val_loss: 0.0845 - val_acc: 0.9735
Epoch 16/20
 - 55s - loss: 0.0799 - acc: 0.9781 - val_loss: 0.0613 - val_acc: 0.9843
Epoch 17/20
 - 55s - loss: 0.0766 - acc: 0.9790 - val_loss: 0.0515 - val_acc: 0.9874
Epoch 18/20
 - 55s - loss: 0.0715 - acc: 0.9810 - val_loss: 0.0592 - val_acc: 0.9847
Epoch 19/20
 - 55s - loss: 0.0677 - acc: 0.9823 - val_loss: 0.0478 - val_acc: 0.9902
Epoch 20/20
 - 55s - loss: 0.0638 - acc: 0.9832 - val_loss: 0.0706 - val_acc: 0.9794
Test accuracy:0.808
current auc_score ------------------> 0.901
------------------------ current config for the test -------------------------
Layers:  [4, 4]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  20  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 30, 24, 24)   20520       activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 24, 24)   0           dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 106, 24, 24)  0           concatenate_2[0][0]              
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 106, 24, 24)  424         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 106, 24, 24)  0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 30, 24, 24)   28620       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 24, 24)   0           dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 136, 24, 24)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 136, 24, 24)  544         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 136, 24, 24)  0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 68, 24, 24)   9248        activation_6[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 68, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 68, 12, 12)   272         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 68, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_7[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 98, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 98, 12, 12)   392         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 98, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   26460       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 128, 12, 12)  0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 128, 12, 12)  512         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 128, 12, 12)  0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 30, 12, 12)   34560       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 30, 12, 12)   0           dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 158, 12, 12)  0           concatenate_6[0][0]              
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 158, 12, 12)  632         concatenate_7[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 158, 12, 12)  0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 30, 12, 12)   42660       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 30, 12, 12)   0           dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 188, 12, 12)  0           concatenate_7[0][0]              
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 188, 12, 12)  752         concatenate_8[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 188, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 27072)        0           activation_11[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            27073       flatten_1[0][0]                  
==================================================================================================
Total params: 229,953
Trainable params: 227,881
Non-trainable params: 2,072
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/20
 - 58s - loss: 0.4482 - acc: 0.7931 - val_loss: 0.3646 - val_acc: 0.8385
Epoch 2/20
 - 56s - loss: 0.3147 - acc: 0.8713 - val_loss: 0.2674 - val_acc: 0.8943
Epoch 3/20
 - 55s - loss: 0.2622 - acc: 0.8985 - val_loss: 0.3002 - val_acc: 0.8739
Epoch 4/20
 - 56s - loss: 0.2254 - acc: 0.9168 - val_loss: 0.1905 - val_acc: 0.9325
Epoch 5/20
 - 55s - loss: 0.1979 - acc: 0.9286 - val_loss: 0.2525 - val_acc: 0.8956
Epoch 6/20
 - 57s - loss: 0.1764 - acc: 0.9387 - val_loss: 0.1305 - val_acc: 0.9567
Epoch 7/20
 - 56s - loss: 0.1584 - acc: 0.9475 - val_loss: 0.1166 - val_acc: 0.9659
Epoch 8/20
 - 55s - loss: 0.1448 - acc: 0.9522 - val_loss: 0.1207 - val_acc: 0.9602
Epoch 9/20
 - 55s - loss: 0.1295 - acc: 0.9598 - val_loss: 0.1123 - val_acc: 0.9652
Epoch 10/20
 - 56s - loss: 0.1216 - acc: 0.9622 - val_loss: 0.0920 - val_acc: 0.9735
Epoch 11/20
 - 55s - loss: 0.1108 - acc: 0.9657 - val_loss: 0.0876 - val_acc: 0.9767
Epoch 12/20
 - 55s - loss: 0.1015 - acc: 0.9703 - val_loss: 0.0661 - val_acc: 0.9838
Epoch 13/20
 - 57s - loss: 0.0941 - acc: 0.9719 - val_loss: 0.0670 - val_acc: 0.9821
Epoch 14/20
 - 55s - loss: 0.0901 - acc: 0.9741 - val_loss: 0.0601 - val_acc: 0.9838
Epoch 15/20
 - 54s - loss: 0.0849 - acc: 0.9767 - val_loss: 0.0611 - val_acc: 0.9864
Epoch 16/20
 - 55s - loss: 0.0799 - acc: 0.9779 - val_loss: 0.0552 - val_acc: 0.9888
Epoch 17/20
 - 55s - loss: 0.0735 - acc: 0.9800 - val_loss: 0.0672 - val_acc: 0.9837
Epoch 18/20
 - 54s - loss: 0.0711 - acc: 0.9815 - val_loss: 0.0504 - val_acc: 0.9893
Epoch 19/20
 - 55s - loss: 0.0667 - acc: 0.9824 - val_loss: 0.0439 - val_acc: 0.9910
Epoch 20/20
 - 55s - loss: 0.0623 - acc: 0.9838 - val_loss: 0.0390 - val_acc: 0.9927
Test accuracy:0.822
current auc_score ------------------> 0.907
------------------------ current config for the test -------------------------
Layers:  [4, 4]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  20  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 30, 24, 24)   20520       activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 24, 24)   0           dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 106, 24, 24)  0           concatenate_2[0][0]              
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 106, 24, 24)  424         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 106, 24, 24)  0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 30, 24, 24)   28620       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 24, 24)   0           dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 136, 24, 24)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 136, 24, 24)  544         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 136, 24, 24)  0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 68, 24, 24)   9248        activation_6[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 68, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 68, 12, 12)   272         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 68, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_7[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 98, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 98, 12, 12)   392         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 98, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   26460       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 128, 12, 12)  0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 128, 12, 12)  512         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 128, 12, 12)  0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 30, 12, 12)   34560       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 30, 12, 12)   0           dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 158, 12, 12)  0           concatenate_6[0][0]              
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 158, 12, 12)  632         concatenate_7[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 158, 12, 12)  0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 30, 12, 12)   42660       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 30, 12, 12)   0           dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 188, 12, 12)  0           concatenate_7[0][0]              
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 188, 12, 12)  752         concatenate_8[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 188, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 27072)        0           activation_11[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            27073       flatten_1[0][0]                  
==================================================================================================
Total params: 229,953
Trainable params: 227,881
Non-trainable params: 2,072
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/20
 - 58s - loss: 0.4349 - acc: 0.8037 - val_loss: 0.3279 - val_acc: 0.8568
Epoch 2/20
 - 55s - loss: 0.3099 - acc: 0.8762 - val_loss: 0.3946 - val_acc: 0.8133
Epoch 3/20
 - 56s - loss: 0.2527 - acc: 0.9025 - val_loss: 0.2755 - val_acc: 0.8837
Epoch 4/20
 - 55s - loss: 0.2134 - acc: 0.9199 - val_loss: 0.1700 - val_acc: 0.9420
Epoch 5/20
 - 55s - loss: 0.1880 - acc: 0.9331 - val_loss: 0.2199 - val_acc: 0.9154
Epoch 6/20
 - 54s - loss: 0.1687 - acc: 0.9418 - val_loss: 0.1602 - val_acc: 0.9434
Epoch 7/20
 - 55s - loss: 0.1510 - acc: 0.9494 - val_loss: 0.1179 - val_acc: 0.9649
Epoch 8/20
 - 55s - loss: 0.1371 - acc: 0.9561 - val_loss: 0.1010 - val_acc: 0.9728
Epoch 9/20
 - 55s - loss: 0.1238 - acc: 0.9614 - val_loss: 0.0882 - val_acc: 0.9765
Epoch 10/20
 - 54s - loss: 0.1150 - acc: 0.9658 - val_loss: 0.0881 - val_acc: 0.9789
Epoch 11/20
 - 55s - loss: 0.1078 - acc: 0.9678 - val_loss: 0.1174 - val_acc: 0.9635
Epoch 12/20
 - 53s - loss: 0.0979 - acc: 0.9711 - val_loss: 0.0726 - val_acc: 0.9807
Epoch 13/20
 - 55s - loss: 0.0927 - acc: 0.9734 - val_loss: 0.0642 - val_acc: 0.9842
Epoch 14/20
 - 55s - loss: 0.0860 - acc: 0.9753 - val_loss: 0.0573 - val_acc: 0.9883
Epoch 15/20
 - 53s - loss: 0.0816 - acc: 0.9776 - val_loss: 0.0616 - val_acc: 0.9854
Epoch 16/20
 - 54s - loss: 0.0773 - acc: 0.9787 - val_loss: 0.0666 - val_acc: 0.9808
Epoch 17/20
 - 53s - loss: 0.0712 - acc: 0.9809 - val_loss: 0.0510 - val_acc: 0.9872
Epoch 18/20
 - 54s - loss: 0.0705 - acc: 0.9809 - val_loss: 0.0514 - val_acc: 0.9893
Epoch 19/20
 - 54s - loss: 0.0657 - acc: 0.9829 - val_loss: 0.0433 - val_acc: 0.9908
Epoch 20/20
 - 53s - loss: 0.0621 - acc: 0.9854 - val_loss: 0.0395 - val_acc: 0.9921
Test accuracy:0.797
current auc_score ------------------> 0.898
------------------------ current config for the test -------------------------
Layers:  [4, 4]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  20  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 30, 24, 24)   20520       activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 24, 24)   0           dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 106, 24, 24)  0           concatenate_2[0][0]              
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 106, 24, 24)  424         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 106, 24, 24)  0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 30, 24, 24)   28620       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 24, 24)   0           dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 136, 24, 24)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 136, 24, 24)  544         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 136, 24, 24)  0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 68, 24, 24)   9248        activation_6[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 68, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 68, 12, 12)   272         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 68, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_7[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 98, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 98, 12, 12)   392         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 98, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   26460       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 128, 12, 12)  0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 128, 12, 12)  512         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 128, 12, 12)  0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 30, 12, 12)   34560       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 30, 12, 12)   0           dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 158, 12, 12)  0           concatenate_6[0][0]              
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 158, 12, 12)  632         concatenate_7[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 158, 12, 12)  0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 30, 12, 12)   42660       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 30, 12, 12)   0           dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 188, 12, 12)  0           concatenate_7[0][0]              
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 188, 12, 12)  752         concatenate_8[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 188, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 27072)        0           activation_11[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            27073       flatten_1[0][0]                  
==================================================================================================
Total params: 229,953
Trainable params: 227,881
Non-trainable params: 2,072
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/20
 - 57s - loss: 0.4423 - acc: 0.8005 - val_loss: 0.4094 - val_acc: 0.8071
Epoch 2/20
 - 54s - loss: 0.3044 - acc: 0.8777 - val_loss: 0.2357 - val_acc: 0.9147
Epoch 3/20
 - 54s - loss: 0.2527 - acc: 0.9022 - val_loss: 0.2280 - val_acc: 0.9125
Epoch 4/20
 - 54s - loss: 0.2154 - acc: 0.9203 - val_loss: 0.1834 - val_acc: 0.9379
Epoch 5/20
 - 54s - loss: 0.1907 - acc: 0.9321 - val_loss: 0.1713 - val_acc: 0.9404
Epoch 6/20
 - 54s - loss: 0.1693 - acc: 0.9427 - val_loss: 0.1294 - val_acc: 0.9611
Epoch 7/20
 - 54s - loss: 0.1530 - acc: 0.9487 - val_loss: 0.1178 - val_acc: 0.9637
Epoch 8/20
 - 54s - loss: 0.1389 - acc: 0.9550 - val_loss: 0.1254 - val_acc: 0.9571
Epoch 9/20
 - 54s - loss: 0.1270 - acc: 0.9596 - val_loss: 0.1056 - val_acc: 0.9665
Epoch 10/20
 - 54s - loss: 0.1183 - acc: 0.9637 - val_loss: 0.1210 - val_acc: 0.9625
Epoch 11/20
 - 54s - loss: 0.1083 - acc: 0.9673 - val_loss: 0.1251 - val_acc: 0.9559
Epoch 12/20
 - 54s - loss: 0.1025 - acc: 0.9699 - val_loss: 0.0660 - val_acc: 0.9847
Epoch 13/20
 - 54s - loss: 0.0950 - acc: 0.9718 - val_loss: 0.0898 - val_acc: 0.9730
Epoch 14/20
 - 54s - loss: 0.0870 - acc: 0.9751 - val_loss: 0.0620 - val_acc: 0.9853
Epoch 15/20
 - 54s - loss: 0.0812 - acc: 0.9781 - val_loss: 0.0571 - val_acc: 0.9886
Epoch 16/20
 - 54s - loss: 0.0776 - acc: 0.9793 - val_loss: 0.0501 - val_acc: 0.9898
Epoch 17/20
 - 54s - loss: 0.0736 - acc: 0.9800 - val_loss: 0.0506 - val_acc: 0.9900
Epoch 18/20
 - 56s - loss: 0.0703 - acc: 0.9815 - val_loss: 0.0453 - val_acc: 0.9910
Epoch 19/20
 - 55s - loss: 0.0653 - acc: 0.9836 - val_loss: 0.0446 - val_acc: 0.9901
Epoch 20/20
 - 55s - loss: 0.0609 - acc: 0.9852 - val_loss: 0.0397 - val_acc: 0.9925
Test accuracy:0.772
current auc_score ------------------> 0.887
------------------------ current config for the test -------------------------
Layers:  [4, 4]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  20  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 30, 24, 24)   20520       activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 24, 24)   0           dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 106, 24, 24)  0           concatenate_2[0][0]              
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 106, 24, 24)  424         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 106, 24, 24)  0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 30, 24, 24)   28620       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 24, 24)   0           dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 136, 24, 24)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 136, 24, 24)  544         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 136, 24, 24)  0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 68, 24, 24)   9248        activation_6[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 68, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 68, 12, 12)   272         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 68, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   18360       activation_7[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 98, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 98, 12, 12)   392         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 98, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   26460       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 128, 12, 12)  0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 128, 12, 12)  512         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 128, 12, 12)  0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 30, 12, 12)   34560       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 30, 12, 12)   0           dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 158, 12, 12)  0           concatenate_6[0][0]              
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 158, 12, 12)  632         concatenate_7[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 158, 12, 12)  0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 30, 12, 12)   42660       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 30, 12, 12)   0           dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 188, 12, 12)  0           concatenate_7[0][0]              
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 188, 12, 12)  752         concatenate_8[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 188, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 27072)        0           activation_11[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            27073       flatten_1[0][0]                  
==================================================================================================
Total params: 229,953
Trainable params: 227,881
Non-trainable params: 2,072
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/20
 - 58s - loss: 0.4465 - acc: 0.7975 - val_loss: 0.3373 - val_acc: 0.8558
Epoch 2/20
 - 55s - loss: 0.3199 - acc: 0.8694 - val_loss: 0.2961 - val_acc: 0.8736
Epoch 3/20
 - 55s - loss: 0.2605 - acc: 0.8981 - val_loss: 0.2964 - val_acc: 0.8715
Epoch 4/20
 - 55s - loss: 0.2222 - acc: 0.9174 - val_loss: 0.2119 - val_acc: 0.9196
Epoch 5/20
 - 55s - loss: 0.1919 - acc: 0.9310 - val_loss: 0.2035 - val_acc: 0.9216
Epoch 6/20
 - 55s - loss: 0.1690 - acc: 0.9421 - val_loss: 0.1522 - val_acc: 0.9502
Epoch 7/20
 - 54s - loss: 0.1514 - acc: 0.9491 - val_loss: 0.1248 - val_acc: 0.9600
Epoch 8/20
 - 55s - loss: 0.1367 - acc: 0.9549 - val_loss: 0.1193 - val_acc: 0.9640
Epoch 9/20
 - 55s - loss: 0.1269 - acc: 0.9599 - val_loss: 0.0893 - val_acc: 0.9759
Epoch 10/20
 - 55s - loss: 0.1165 - acc: 0.9636 - val_loss: 0.0821 - val_acc: 0.9768
Epoch 11/20
 - 55s - loss: 0.1047 - acc: 0.9688 - val_loss: 0.0775 - val_acc: 0.9794
Epoch 12/20
 - 55s - loss: 0.0971 - acc: 0.9719 - val_loss: 0.0739 - val_acc: 0.9797
Epoch 13/20
 - 55s - loss: 0.0923 - acc: 0.9733 - val_loss: 0.0965 - val_acc: 0.9709
Epoch 14/20
 - 54s - loss: 0.0858 - acc: 0.9759 - val_loss: 0.0603 - val_acc: 0.9858
Epoch 15/20
 - 55s - loss: 0.0822 - acc: 0.9777 - val_loss: 0.0594 - val_acc: 0.9853
Epoch 16/20
 - 54s - loss: 0.0768 - acc: 0.9789 - val_loss: 0.0484 - val_acc: 0.9900
Epoch 17/20
 - 54s - loss: 0.0721 - acc: 0.9811 - val_loss: 0.0497 - val_acc: 0.9880
Epoch 18/20
 - 54s - loss: 0.0685 - acc: 0.9823 - val_loss: 0.0440 - val_acc: 0.9913
Epoch 19/20
 - 55s - loss: 0.0630 - acc: 0.9846 - val_loss: 0.0395 - val_acc: 0.9927
Epoch 20/20
 - 55s - loss: 0.0617 - acc: 0.9843 - val_loss: 0.0374 - val_acc: 0.9936
Test accuracy:0.793
current auc_score ------------------> 0.898
accuracies:  [0.8208333333333333, 0.8413978494623656, 0.8375, 0.8155913978494623, 0.8278225806451613, 0.8079301075268818, 0.8223118279569892, 0.7969086021505376, 0.7720430107526882, 0.7928763440860215]
aucs:  [0.9154, 0.918, 0.912, 0.9295, 0.8992, 0.9009, 0.9073, 0.8984, 0.8873, 0.8981]
mean and std AUC:  0.907+/-0.012  max:   0.9295
['6-6', '12', '2', '16', '0.2', '0.07', '24', 'adadelta', '0.5', 'FALSE', '64', 'flatten']
------------------------ current config for the test -------------------------
Layers:  [6, 6]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  24  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 12, 24, 24)   1728        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 12, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 28, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 28, 24, 24)   112         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 28, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 12, 24, 24)   3024        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 12, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 40, 24, 24)   160         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 24, 24)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 12, 24, 24)   4320        activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 12, 24, 24)   0           dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 52, 24, 24)   0           concatenate_2[0][0]              
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 52, 24, 24)   208         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 52, 24, 24)   0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 12, 24, 24)   5616        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 12, 24, 24)   0           dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 64, 24, 24)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
dense_0_4_bn (BatchNormalizatio (None, 64, 24, 24)   256         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 64, 24, 24)   0           dense_0_4_bn[0][0]               
__________________________________________________________________________________________________
dense_0_4_conv2D (Conv2D)       (None, 12, 24, 24)   6912        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 12, 24, 24)   0           dense_0_4_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 76, 24, 24)   0           concatenate_4[0][0]              
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_0_5_bn (BatchNormalizatio (None, 76, 24, 24)   304         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 76, 24, 24)   0           dense_0_5_bn[0][0]               
__________________________________________________________________________________________________
dense_0_5_conv2D (Conv2D)       (None, 12, 24, 24)   8208        activation_7[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 12, 24, 24)   0           dense_0_5_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 88, 24, 24)   0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 88, 24, 24)   352         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 88, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 44, 24, 24)   3872        activation_8[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 44, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 44, 12, 12)   176         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 44, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 12, 12, 12)   4752        activation_9[0][0]               
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 12, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 56, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 56, 12, 12)   224         concatenate_7[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 56, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 12, 12, 12)   6048        activation_10[0][0]              
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 12, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 68, 12, 12)   0           concatenate_7[0][0]              
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_8[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 68, 12, 12)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 12, 12, 12)   7344        activation_11[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 12, 12, 12)   0           dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_9 (Concatenate)     (None, 80, 12, 12)   0           concatenate_8[0][0]              
                                                                 dropout_9[0][0]                  
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 80, 12, 12)   320         concatenate_9[0][0]              
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 80, 12, 12)   0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 12, 12, 12)   8640        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 12, 12, 12)   0           dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_10 (Concatenate)    (None, 92, 12, 12)   0           concatenate_9[0][0]              
                                                                 dropout_10[0][0]                 
__________________________________________________________________________________________________
dense_1_4_bn (BatchNormalizatio (None, 92, 12, 12)   368         concatenate_10[0][0]             
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 92, 12, 12)   0           dense_1_4_bn[0][0]               
__________________________________________________________________________________________________
dense_1_4_conv2D (Conv2D)       (None, 12, 12, 12)   9936        activation_13[0][0]              
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, 12, 12, 12)   0           dense_1_4_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_11 (Concatenate)    (None, 104, 12, 12)  0           concatenate_10[0][0]             
                                                                 dropout_11[0][0]                 
__________________________________________________________________________________________________
dense_1_5_bn (BatchNormalizatio (None, 104, 12, 12)  416         concatenate_11[0][0]             
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 104, 12, 12)  0           dense_1_5_bn[0][0]               
__________________________________________________________________________________________________
dense_1_5_conv2D (Conv2D)       (None, 12, 12, 12)   11232       activation_14[0][0]              
__________________________________________________________________________________________________
dropout_12 (Dropout)            (None, 12, 12, 12)   0           dense_1_5_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_12 (Concatenate)    (None, 116, 12, 12)  0           concatenate_11[0][0]             
                                                                 dropout_12[0][0]                 
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 116, 12, 12)  464         concatenate_12[0][0]             
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 116, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 16704)        0           activation_15[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            16705       flatten_1[0][0]                  
==================================================================================================
Total params: 103,665
Trainable params: 101,785
Non-trainable params: 1,880
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/24
 - 50s - loss: 0.4674 - acc: 0.7775 - val_loss: 0.4106 - val_acc: 0.8161
Epoch 2/24
 - 46s - loss: 0.3498 - acc: 0.8504 - val_loss: 0.3063 - val_acc: 0.8676
Epoch 3/24
 - 47s - loss: 0.2944 - acc: 0.8787 - val_loss: 0.2495 - val_acc: 0.9016
Epoch 4/24
 - 46s - loss: 0.2613 - acc: 0.8957 - val_loss: 0.2335 - val_acc: 0.9093
Epoch 5/24
 - 46s - loss: 0.2343 - acc: 0.9105 - val_loss: 0.2016 - val_acc: 0.9214
Epoch 6/24
 - 46s - loss: 0.2111 - acc: 0.9201 - val_loss: 0.1901 - val_acc: 0.9276
Epoch 7/24
 - 46s - loss: 0.1955 - acc: 0.9285 - val_loss: 0.1542 - val_acc: 0.9482
Epoch 8/24
 - 47s - loss: 0.1794 - acc: 0.9360 - val_loss: 0.1433 - val_acc: 0.9511
Epoch 9/24
 - 47s - loss: 0.1659 - acc: 0.9411 - val_loss: 0.1370 - val_acc: 0.9554
Epoch 10/24
 - 46s - loss: 0.1562 - acc: 0.9453 - val_loss: 0.1263 - val_acc: 0.9595
Epoch 11/24
 - 46s - loss: 0.1477 - acc: 0.9490 - val_loss: 0.1184 - val_acc: 0.9595
Epoch 12/24
 - 46s - loss: 0.1377 - acc: 0.9524 - val_loss: 0.1124 - val_acc: 0.9665
Epoch 13/24
 - 47s - loss: 0.1297 - acc: 0.9578 - val_loss: 0.1218 - val_acc: 0.9602
Epoch 14/24
 - 46s - loss: 0.1236 - acc: 0.9594 - val_loss: 0.0885 - val_acc: 0.9763
Epoch 15/24
 - 46s - loss: 0.1174 - acc: 0.9616 - val_loss: 0.0841 - val_acc: 0.9757
Epoch 16/24
 - 46s - loss: 0.1115 - acc: 0.9646 - val_loss: 0.1168 - val_acc: 0.9567
Epoch 17/24
 - 46s - loss: 0.1061 - acc: 0.9663 - val_loss: 0.0769 - val_acc: 0.9764
Epoch 18/24
 - 46s - loss: 0.1030 - acc: 0.9676 - val_loss: 0.0709 - val_acc: 0.9821
Epoch 19/24
 - 47s - loss: 0.0972 - acc: 0.9693 - val_loss: 0.0645 - val_acc: 0.9837
Epoch 20/24
 - 46s - loss: 0.0930 - acc: 0.9722 - val_loss: 0.0640 - val_acc: 0.9842
Epoch 21/24
 - 46s - loss: 0.0883 - acc: 0.9730 - val_loss: 0.0596 - val_acc: 0.9842
Epoch 22/24
 - 46s - loss: 0.0865 - acc: 0.9738 - val_loss: 0.0580 - val_acc: 0.9847
Epoch 23/24
 - 46s - loss: 0.0820 - acc: 0.9756 - val_loss: 0.0532 - val_acc: 0.9861
Epoch 24/24
 - 46s - loss: 0.0792 - acc: 0.9766 - val_loss: 0.0614 - val_acc: 0.9823
Test accuracy:0.826
current auc_score ------------------> 0.907
------------------------ current config for the test -------------------------
Layers:  [6, 6]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  24  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 12, 24, 24)   1728        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 12, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 28, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 28, 24, 24)   112         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 28, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 12, 24, 24)   3024        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 12, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 40, 24, 24)   160         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 24, 24)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 12, 24, 24)   4320        activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 12, 24, 24)   0           dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 52, 24, 24)   0           concatenate_2[0][0]              
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 52, 24, 24)   208         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 52, 24, 24)   0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 12, 24, 24)   5616        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 12, 24, 24)   0           dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 64, 24, 24)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
dense_0_4_bn (BatchNormalizatio (None, 64, 24, 24)   256         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 64, 24, 24)   0           dense_0_4_bn[0][0]               
__________________________________________________________________________________________________
dense_0_4_conv2D (Conv2D)       (None, 12, 24, 24)   6912        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 12, 24, 24)   0           dense_0_4_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 76, 24, 24)   0           concatenate_4[0][0]              
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_0_5_bn (BatchNormalizatio (None, 76, 24, 24)   304         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 76, 24, 24)   0           dense_0_5_bn[0][0]               
__________________________________________________________________________________________________
dense_0_5_conv2D (Conv2D)       (None, 12, 24, 24)   8208        activation_7[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 12, 24, 24)   0           dense_0_5_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 88, 24, 24)   0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 88, 24, 24)   352         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 88, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 44, 24, 24)   3872        activation_8[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 44, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 44, 12, 12)   176         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 44, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 12, 12, 12)   4752        activation_9[0][0]               
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 12, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 56, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 56, 12, 12)   224         concatenate_7[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 56, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 12, 12, 12)   6048        activation_10[0][0]              
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 12, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 68, 12, 12)   0           concatenate_7[0][0]              
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_8[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 68, 12, 12)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 12, 12, 12)   7344        activation_11[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 12, 12, 12)   0           dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_9 (Concatenate)     (None, 80, 12, 12)   0           concatenate_8[0][0]              
                                                                 dropout_9[0][0]                  
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 80, 12, 12)   320         concatenate_9[0][0]              
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 80, 12, 12)   0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 12, 12, 12)   8640        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 12, 12, 12)   0           dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_10 (Concatenate)    (None, 92, 12, 12)   0           concatenate_9[0][0]              
                                                                 dropout_10[0][0]                 
__________________________________________________________________________________________________
dense_1_4_bn (BatchNormalizatio (None, 92, 12, 12)   368         concatenate_10[0][0]             
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 92, 12, 12)   0           dense_1_4_bn[0][0]               
__________________________________________________________________________________________________
dense_1_4_conv2D (Conv2D)       (None, 12, 12, 12)   9936        activation_13[0][0]              
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, 12, 12, 12)   0           dense_1_4_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_11 (Concatenate)    (None, 104, 12, 12)  0           concatenate_10[0][0]             
                                                                 dropout_11[0][0]                 
__________________________________________________________________________________________________
dense_1_5_bn (BatchNormalizatio (None, 104, 12, 12)  416         concatenate_11[0][0]             
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 104, 12, 12)  0           dense_1_5_bn[0][0]               
__________________________________________________________________________________________________
dense_1_5_conv2D (Conv2D)       (None, 12, 12, 12)   11232       activation_14[0][0]              
__________________________________________________________________________________________________
dropout_12 (Dropout)            (None, 12, 12, 12)   0           dense_1_5_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_12 (Concatenate)    (None, 116, 12, 12)  0           concatenate_11[0][0]             
                                                                 dropout_12[0][0]                 
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 116, 12, 12)  464         concatenate_12[0][0]             
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 116, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 16704)        0           activation_15[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            16705       flatten_1[0][0]                  
==================================================================================================
Total params: 103,665
Trainable params: 101,785
Non-trainable params: 1,880
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/24
 - 51s - loss: 0.4710 - acc: 0.7794 - val_loss: 0.3990 - val_acc: 0.8249
Epoch 2/24
 - 47s - loss: 0.3542 - acc: 0.8524 - val_loss: 0.2915 - val_acc: 0.8830
Epoch 3/24
 - 47s - loss: 0.3009 - acc: 0.8754 - val_loss: 0.2587 - val_acc: 0.8962
Epoch 4/24
 - 47s - loss: 0.2631 - acc: 0.8960 - val_loss: 0.2227 - val_acc: 0.9178
Epoch 5/24
 - 46s - loss: 0.2349 - acc: 0.9093 - val_loss: 0.2221 - val_acc: 0.9138
Epoch 6/24
 - 47s - loss: 0.2178 - acc: 0.9187 - val_loss: 0.2352 - val_acc: 0.9060
Epoch 7/24
 - 46s - loss: 0.1993 - acc: 0.9266 - val_loss: 0.1600 - val_acc: 0.9454
Epoch 8/24
 - 46s - loss: 0.1832 - acc: 0.9338 - val_loss: 0.1645 - val_acc: 0.9419
Epoch 9/24
 - 46s - loss: 0.1705 - acc: 0.9388 - val_loss: 0.1347 - val_acc: 0.9547
Epoch 10/24
 - 46s - loss: 0.1586 - acc: 0.9435 - val_loss: 0.1300 - val_acc: 0.9566
Epoch 11/24
 - 47s - loss: 0.1506 - acc: 0.9485 - val_loss: 0.1157 - val_acc: 0.9612
Epoch 12/24
 - 47s - loss: 0.1415 - acc: 0.9511 - val_loss: 0.1309 - val_acc: 0.9516
Epoch 13/24
 - 47s - loss: 0.1327 - acc: 0.9549 - val_loss: 0.1262 - val_acc: 0.9570
Epoch 14/24
 - 47s - loss: 0.1261 - acc: 0.9584 - val_loss: 0.1158 - val_acc: 0.9586

Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 15/24
 - 47s - loss: 0.1152 - acc: 0.9631 - val_loss: 0.0902 - val_acc: 0.9724
Epoch 16/24
 - 47s - loss: 0.1114 - acc: 0.9651 - val_loss: 0.0855 - val_acc: 0.9741
Epoch 17/24
 - 47s - loss: 0.1100 - acc: 0.9640 - val_loss: 0.0853 - val_acc: 0.9735
Epoch 18/24
 - 46s - loss: 0.1090 - acc: 0.9659 - val_loss: 0.0886 - val_acc: 0.9714
Epoch 19/24
 - 46s - loss: 0.1078 - acc: 0.9652 - val_loss: 0.0790 - val_acc: 0.9760
Epoch 20/24
 - 47s - loss: 0.1050 - acc: 0.9667 - val_loss: 0.0768 - val_acc: 0.9774
Epoch 21/24
 - 46s - loss: 0.1035 - acc: 0.9673 - val_loss: 0.0847 - val_acc: 0.9730
Epoch 22/24
 - 47s - loss: 0.1011 - acc: 0.9698 - val_loss: 0.0756 - val_acc: 0.9778
Epoch 23/24
 - 47s - loss: 0.1012 - acc: 0.9686 - val_loss: 0.0731 - val_acc: 0.9777
Epoch 24/24
 - 47s - loss: 0.0994 - acc: 0.9688 - val_loss: 0.0732 - val_acc: 0.9783
Test accuracy:0.800
current auc_score ------------------> 0.905
------------------------ current config for the test -------------------------
Layers:  [6, 6]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  24  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 12, 24, 24)   1728        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 12, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 28, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 28, 24, 24)   112         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 28, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 12, 24, 24)   3024        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 12, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 40, 24, 24)   160         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 24, 24)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 12, 24, 24)   4320        activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 12, 24, 24)   0           dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 52, 24, 24)   0           concatenate_2[0][0]              
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 52, 24, 24)   208         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 52, 24, 24)   0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 12, 24, 24)   5616        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 12, 24, 24)   0           dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 64, 24, 24)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
dense_0_4_bn (BatchNormalizatio (None, 64, 24, 24)   256         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 64, 24, 24)   0           dense_0_4_bn[0][0]               
__________________________________________________________________________________________________
dense_0_4_conv2D (Conv2D)       (None, 12, 24, 24)   6912        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 12, 24, 24)   0           dense_0_4_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 76, 24, 24)   0           concatenate_4[0][0]              
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_0_5_bn (BatchNormalizatio (None, 76, 24, 24)   304         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 76, 24, 24)   0           dense_0_5_bn[0][0]               
__________________________________________________________________________________________________
dense_0_5_conv2D (Conv2D)       (None, 12, 24, 24)   8208        activation_7[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 12, 24, 24)   0           dense_0_5_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 88, 24, 24)   0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 88, 24, 24)   352         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 88, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 44, 24, 24)   3872        activation_8[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 44, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 44, 12, 12)   176         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 44, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 12, 12, 12)   4752        activation_9[0][0]               
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 12, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 56, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 56, 12, 12)   224         concatenate_7[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 56, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 12, 12, 12)   6048        activation_10[0][0]              
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 12, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 68, 12, 12)   0           concatenate_7[0][0]              
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_8[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 68, 12, 12)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 12, 12, 12)   7344        activation_11[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 12, 12, 12)   0           dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_9 (Concatenate)     (None, 80, 12, 12)   0           concatenate_8[0][0]              
                                                                 dropout_9[0][0]                  
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 80, 12, 12)   320         concatenate_9[0][0]              
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 80, 12, 12)   0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 12, 12, 12)   8640        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 12, 12, 12)   0           dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_10 (Concatenate)    (None, 92, 12, 12)   0           concatenate_9[0][0]              
                                                                 dropout_10[0][0]                 
__________________________________________________________________________________________________
dense_1_4_bn (BatchNormalizatio (None, 92, 12, 12)   368         concatenate_10[0][0]             
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 92, 12, 12)   0           dense_1_4_bn[0][0]               
__________________________________________________________________________________________________
dense_1_4_conv2D (Conv2D)       (None, 12, 12, 12)   9936        activation_13[0][0]              
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, 12, 12, 12)   0           dense_1_4_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_11 (Concatenate)    (None, 104, 12, 12)  0           concatenate_10[0][0]             
                                                                 dropout_11[0][0]                 
__________________________________________________________________________________________________
dense_1_5_bn (BatchNormalizatio (None, 104, 12, 12)  416         concatenate_11[0][0]             
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 104, 12, 12)  0           dense_1_5_bn[0][0]               
__________________________________________________________________________________________________
dense_1_5_conv2D (Conv2D)       (None, 12, 12, 12)   11232       activation_14[0][0]              
__________________________________________________________________________________________________
dropout_12 (Dropout)            (None, 12, 12, 12)   0           dense_1_5_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_12 (Concatenate)    (None, 116, 12, 12)  0           concatenate_11[0][0]             
                                                                 dropout_12[0][0]                 
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 116, 12, 12)  464         concatenate_12[0][0]             
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 116, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 16704)        0           activation_15[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            16705       flatten_1[0][0]                  
==================================================================================================
Total params: 103,665
Trainable params: 101,785
Non-trainable params: 1,880
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/24
 - 50s - loss: 0.4595 - acc: 0.7873 - val_loss: 0.3731 - val_acc: 0.8421
Epoch 2/24
 - 46s - loss: 0.3458 - acc: 0.8526 - val_loss: 0.2941 - val_acc: 0.8764
Epoch 3/24
 - 46s - loss: 0.2985 - acc: 0.8761 - val_loss: 0.2534 - val_acc: 0.9010
Epoch 4/24
 - 46s - loss: 0.2647 - acc: 0.8940 - val_loss: 0.2241 - val_acc: 0.9142
Epoch 5/24
 - 46s - loss: 0.2387 - acc: 0.9057 - val_loss: 0.2339 - val_acc: 0.9095
Epoch 6/24
 - 46s - loss: 0.2164 - acc: 0.9181 - val_loss: 0.1828 - val_acc: 0.9351
Epoch 7/24
 - 46s - loss: 0.1975 - acc: 0.9260 - val_loss: 0.1553 - val_acc: 0.9480
Epoch 8/24
 - 46s - loss: 0.1827 - acc: 0.9355 - val_loss: 0.1444 - val_acc: 0.9488
Epoch 9/24
 - 46s - loss: 0.1696 - acc: 0.9398 - val_loss: 0.1766 - val_acc: 0.9317
Epoch 10/24
 - 47s - loss: 0.1616 - acc: 0.9409 - val_loss: 0.1292 - val_acc: 0.9558
Epoch 11/24
 - 46s - loss: 0.1503 - acc: 0.9472 - val_loss: 0.1179 - val_acc: 0.9630
Epoch 12/24
 - 46s - loss: 0.1420 - acc: 0.9506 - val_loss: 0.1236 - val_acc: 0.9561
Epoch 13/24
 - 47s - loss: 0.1327 - acc: 0.9548 - val_loss: 0.0960 - val_acc: 0.9706
Epoch 14/24
 - 47s - loss: 0.1239 - acc: 0.9595 - val_loss: 0.0936 - val_acc: 0.9688
Epoch 15/24
 - 47s - loss: 0.1199 - acc: 0.9598 - val_loss: 0.0864 - val_acc: 0.9740
Epoch 16/24
 - 46s - loss: 0.1131 - acc: 0.9632 - val_loss: 0.1049 - val_acc: 0.9641
Epoch 17/24
 - 46s - loss: 0.1081 - acc: 0.9649 - val_loss: 0.0817 - val_acc: 0.9757
Epoch 18/24
 - 46s - loss: 0.1015 - acc: 0.9672 - val_loss: 0.0732 - val_acc: 0.9788
Epoch 19/24
 - 46s - loss: 0.0971 - acc: 0.9692 - val_loss: 0.0667 - val_acc: 0.9816
Epoch 20/24
 - 46s - loss: 0.0940 - acc: 0.9703 - val_loss: 0.0636 - val_acc: 0.9826
Epoch 21/24
 - 47s - loss: 0.0887 - acc: 0.9718 - val_loss: 0.0574 - val_acc: 0.9848
Epoch 22/24
 - 47s - loss: 0.0874 - acc: 0.9732 - val_loss: 0.0564 - val_acc: 0.9846
Epoch 23/24
 - 46s - loss: 0.0827 - acc: 0.9745 - val_loss: 0.0543 - val_acc: 0.9844
Epoch 24/24
 - 47s - loss: 0.0797 - acc: 0.9759 - val_loss: 0.0547 - val_acc: 0.9851
Test accuracy:0.764
current auc_score ------------------> 0.899
------------------------ current config for the test -------------------------
Layers:  [6, 6]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  24  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 12, 24, 24)   1728        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 12, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 28, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 28, 24, 24)   112         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 28, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 12, 24, 24)   3024        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 12, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 40, 24, 24)   160         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 24, 24)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 12, 24, 24)   4320        activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 12, 24, 24)   0           dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 52, 24, 24)   0           concatenate_2[0][0]              
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 52, 24, 24)   208         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 52, 24, 24)   0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 12, 24, 24)   5616        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 12, 24, 24)   0           dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 64, 24, 24)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
dense_0_4_bn (BatchNormalizatio (None, 64, 24, 24)   256         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 64, 24, 24)   0           dense_0_4_bn[0][0]               
__________________________________________________________________________________________________
dense_0_4_conv2D (Conv2D)       (None, 12, 24, 24)   6912        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 12, 24, 24)   0           dense_0_4_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 76, 24, 24)   0           concatenate_4[0][0]              
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_0_5_bn (BatchNormalizatio (None, 76, 24, 24)   304         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 76, 24, 24)   0           dense_0_5_bn[0][0]               
__________________________________________________________________________________________________
dense_0_5_conv2D (Conv2D)       (None, 12, 24, 24)   8208        activation_7[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 12, 24, 24)   0           dense_0_5_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 88, 24, 24)   0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 88, 24, 24)   352         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 88, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 44, 24, 24)   3872        activation_8[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 44, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 44, 12, 12)   176         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 44, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 12, 12, 12)   4752        activation_9[0][0]               
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 12, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 56, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 56, 12, 12)   224         concatenate_7[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 56, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 12, 12, 12)   6048        activation_10[0][0]              
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 12, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 68, 12, 12)   0           concatenate_7[0][0]              
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_8[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 68, 12, 12)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 12, 12, 12)   7344        activation_11[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 12, 12, 12)   0           dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_9 (Concatenate)     (None, 80, 12, 12)   0           concatenate_8[0][0]              
                                                                 dropout_9[0][0]                  
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 80, 12, 12)   320         concatenate_9[0][0]              
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 80, 12, 12)   0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 12, 12, 12)   8640        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 12, 12, 12)   0           dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_10 (Concatenate)    (None, 92, 12, 12)   0           concatenate_9[0][0]              
                                                                 dropout_10[0][0]                 
__________________________________________________________________________________________________
dense_1_4_bn (BatchNormalizatio (None, 92, 12, 12)   368         concatenate_10[0][0]             
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 92, 12, 12)   0           dense_1_4_bn[0][0]               
__________________________________________________________________________________________________
dense_1_4_conv2D (Conv2D)       (None, 12, 12, 12)   9936        activation_13[0][0]              
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, 12, 12, 12)   0           dense_1_4_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_11 (Concatenate)    (None, 104, 12, 12)  0           concatenate_10[0][0]             
                                                                 dropout_11[0][0]                 
__________________________________________________________________________________________________
dense_1_5_bn (BatchNormalizatio (None, 104, 12, 12)  416         concatenate_11[0][0]             
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 104, 12, 12)  0           dense_1_5_bn[0][0]               
__________________________________________________________________________________________________
dense_1_5_conv2D (Conv2D)       (None, 12, 12, 12)   11232       activation_14[0][0]              
__________________________________________________________________________________________________
dropout_12 (Dropout)            (None, 12, 12, 12)   0           dense_1_5_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_12 (Concatenate)    (None, 116, 12, 12)  0           concatenate_11[0][0]             
                                                                 dropout_12[0][0]                 
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 116, 12, 12)  464         concatenate_12[0][0]             
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 116, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 16704)        0           activation_15[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            16705       flatten_1[0][0]                  
==================================================================================================
Total params: 103,665
Trainable params: 101,785
Non-trainable params: 1,880
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/24
 - 50s - loss: 0.4653 - acc: 0.7804 - val_loss: 0.3663 - val_acc: 0.8405
Epoch 2/24
 - 46s - loss: 0.3479 - acc: 0.8506 - val_loss: 0.3159 - val_acc: 0.8607
Epoch 3/24
 - 46s - loss: 0.2957 - acc: 0.8785 - val_loss: 0.2580 - val_acc: 0.8985
Epoch 4/24
 - 46s - loss: 0.2594 - acc: 0.8969 - val_loss: 0.2243 - val_acc: 0.9143
Epoch 5/24
 - 46s - loss: 0.2329 - acc: 0.9112 - val_loss: 0.1917 - val_acc: 0.9296
Epoch 6/24
 - 46s - loss: 0.2122 - acc: 0.9194 - val_loss: 0.1749 - val_acc: 0.9376
Epoch 7/24
 - 47s - loss: 0.1928 - acc: 0.9300 - val_loss: 0.1589 - val_acc: 0.9413
Epoch 8/24
 - 46s - loss: 0.1795 - acc: 0.9336 - val_loss: 0.1474 - val_acc: 0.9478
Epoch 9/24
 - 46s - loss: 0.1666 - acc: 0.9417 - val_loss: 0.1338 - val_acc: 0.9541
Epoch 10/24
 - 46s - loss: 0.1575 - acc: 0.9435 - val_loss: 0.1255 - val_acc: 0.9563
Epoch 11/24
 - 46s - loss: 0.1461 - acc: 0.9513 - val_loss: 0.1226 - val_acc: 0.9581
Epoch 12/24
 - 46s - loss: 0.1382 - acc: 0.9529 - val_loss: 0.1125 - val_acc: 0.9631
Epoch 13/24
 - 46s - loss: 0.1298 - acc: 0.9570 - val_loss: 0.1037 - val_acc: 0.9686
Epoch 14/24
 - 46s - loss: 0.1224 - acc: 0.9606 - val_loss: 0.0915 - val_acc: 0.9716
Epoch 15/24
 - 46s - loss: 0.1171 - acc: 0.9618 - val_loss: 0.1089 - val_acc: 0.9616
Epoch 16/24
 - 46s - loss: 0.1133 - acc: 0.9633 - val_loss: 0.0846 - val_acc: 0.9743
Epoch 17/24
 - 46s - loss: 0.1060 - acc: 0.9653 - val_loss: 0.0794 - val_acc: 0.9741
Epoch 18/24
 - 46s - loss: 0.1013 - acc: 0.9675 - val_loss: 0.0847 - val_acc: 0.9716
Epoch 19/24
 - 46s - loss: 0.0975 - acc: 0.9694 - val_loss: 0.0750 - val_acc: 0.9752
Epoch 20/24
 - 46s - loss: 0.0918 - acc: 0.9722 - val_loss: 0.0767 - val_acc: 0.9740
Epoch 21/24
 - 46s - loss: 0.0888 - acc: 0.9723 - val_loss: 0.0840 - val_acc: 0.9709
Epoch 22/24
 - 46s - loss: 0.0860 - acc: 0.9737 - val_loss: 0.0774 - val_acc: 0.9740

Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 23/24
 - 46s - loss: 0.0780 - acc: 0.9779 - val_loss: 0.0575 - val_acc: 0.9854
Epoch 24/24
 - 46s - loss: 0.0775 - acc: 0.9763 - val_loss: 0.0631 - val_acc: 0.9814
Test accuracy:0.839
current auc_score ------------------> 0.919
------------------------ current config for the test -------------------------
Layers:  [6, 6]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  24  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 12, 24, 24)   1728        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 12, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 28, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 28, 24, 24)   112         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 28, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 12, 24, 24)   3024        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 12, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 40, 24, 24)   160         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 24, 24)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 12, 24, 24)   4320        activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 12, 24, 24)   0           dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 52, 24, 24)   0           concatenate_2[0][0]              
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 52, 24, 24)   208         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 52, 24, 24)   0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 12, 24, 24)   5616        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 12, 24, 24)   0           dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 64, 24, 24)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
dense_0_4_bn (BatchNormalizatio (None, 64, 24, 24)   256         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 64, 24, 24)   0           dense_0_4_bn[0][0]               
__________________________________________________________________________________________________
dense_0_4_conv2D (Conv2D)       (None, 12, 24, 24)   6912        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 12, 24, 24)   0           dense_0_4_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 76, 24, 24)   0           concatenate_4[0][0]              
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_0_5_bn (BatchNormalizatio (None, 76, 24, 24)   304         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 76, 24, 24)   0           dense_0_5_bn[0][0]               
__________________________________________________________________________________________________
dense_0_5_conv2D (Conv2D)       (None, 12, 24, 24)   8208        activation_7[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 12, 24, 24)   0           dense_0_5_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 88, 24, 24)   0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 88, 24, 24)   352         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 88, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 44, 24, 24)   3872        activation_8[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 44, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 44, 12, 12)   176         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 44, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 12, 12, 12)   4752        activation_9[0][0]               
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 12, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 56, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 56, 12, 12)   224         concatenate_7[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 56, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 12, 12, 12)   6048        activation_10[0][0]              
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 12, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 68, 12, 12)   0           concatenate_7[0][0]              
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_8[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 68, 12, 12)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 12, 12, 12)   7344        activation_11[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 12, 12, 12)   0           dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_9 (Concatenate)     (None, 80, 12, 12)   0           concatenate_8[0][0]              
                                                                 dropout_9[0][0]                  
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 80, 12, 12)   320         concatenate_9[0][0]              
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 80, 12, 12)   0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 12, 12, 12)   8640        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 12, 12, 12)   0           dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_10 (Concatenate)    (None, 92, 12, 12)   0           concatenate_9[0][0]              
                                                                 dropout_10[0][0]                 
__________________________________________________________________________________________________
dense_1_4_bn (BatchNormalizatio (None, 92, 12, 12)   368         concatenate_10[0][0]             
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 92, 12, 12)   0           dense_1_4_bn[0][0]               
__________________________________________________________________________________________________
dense_1_4_conv2D (Conv2D)       (None, 12, 12, 12)   9936        activation_13[0][0]              
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, 12, 12, 12)   0           dense_1_4_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_11 (Concatenate)    (None, 104, 12, 12)  0           concatenate_10[0][0]             
                                                                 dropout_11[0][0]                 
__________________________________________________________________________________________________
dense_1_5_bn (BatchNormalizatio (None, 104, 12, 12)  416         concatenate_11[0][0]             
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 104, 12, 12)  0           dense_1_5_bn[0][0]               
__________________________________________________________________________________________________
dense_1_5_conv2D (Conv2D)       (None, 12, 12, 12)   11232       activation_14[0][0]              
__________________________________________________________________________________________________
dropout_12 (Dropout)            (None, 12, 12, 12)   0           dense_1_5_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_12 (Concatenate)    (None, 116, 12, 12)  0           concatenate_11[0][0]             
                                                                 dropout_12[0][0]                 
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 116, 12, 12)  464         concatenate_12[0][0]             
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 116, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 16704)        0           activation_15[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            16705       flatten_1[0][0]                  
==================================================================================================
Total params: 103,665
Trainable params: 101,785
Non-trainable params: 1,880
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/24
 - 50s - loss: 0.4611 - acc: 0.7849 - val_loss: 0.3579 - val_acc: 0.8370
Epoch 2/24
 - 46s - loss: 0.3400 - acc: 0.8569 - val_loss: 0.2884 - val_acc: 0.8803
Epoch 3/24
 - 46s - loss: 0.2892 - acc: 0.8838 - val_loss: 0.2657 - val_acc: 0.8947
Epoch 4/24
 - 46s - loss: 0.2543 - acc: 0.9000 - val_loss: 0.2020 - val_acc: 0.9252
Epoch 5/24
 - 46s - loss: 0.2283 - acc: 0.9120 - val_loss: 0.2201 - val_acc: 0.9086
Epoch 6/24
 - 46s - loss: 0.2073 - acc: 0.9217 - val_loss: 0.1652 - val_acc: 0.9419
Epoch 7/24
 - 46s - loss: 0.1931 - acc: 0.9295 - val_loss: 0.1681 - val_acc: 0.9356
Epoch 8/24
 - 46s - loss: 0.1775 - acc: 0.9351 - val_loss: 0.1926 - val_acc: 0.9251
Epoch 9/24
 - 46s - loss: 0.1675 - acc: 0.9397 - val_loss: 0.1323 - val_acc: 0.9549
Epoch 10/24
 - 46s - loss: 0.1553 - acc: 0.9469 - val_loss: 0.1158 - val_acc: 0.9629
Epoch 11/24
 - 46s - loss: 0.1463 - acc: 0.9493 - val_loss: 0.1144 - val_acc: 0.9610
Epoch 12/24
 - 46s - loss: 0.1383 - acc: 0.9529 - val_loss: 0.1022 - val_acc: 0.9676
Epoch 13/24
 - 46s - loss: 0.1304 - acc: 0.9561 - val_loss: 0.1105 - val_acc: 0.9644
Epoch 14/24
 - 46s - loss: 0.1256 - acc: 0.9581 - val_loss: 0.0985 - val_acc: 0.9700
Epoch 15/24
 - 46s - loss: 0.1200 - acc: 0.9610 - val_loss: 0.0884 - val_acc: 0.9738
Epoch 16/24
 - 46s - loss: 0.1129 - acc: 0.9638 - val_loss: 0.0924 - val_acc: 0.9701
Epoch 17/24
 - 46s - loss: 0.1080 - acc: 0.9651 - val_loss: 0.0730 - val_acc: 0.9788
Epoch 18/24
 - 46s - loss: 0.1037 - acc: 0.9671 - val_loss: 0.0821 - val_acc: 0.9744
Epoch 19/24
 - 46s - loss: 0.0979 - acc: 0.9699 - val_loss: 0.0776 - val_acc: 0.9777
Epoch 20/24
 - 46s - loss: 0.0939 - acc: 0.9709 - val_loss: 0.0640 - val_acc: 0.9819
Epoch 21/24
 - 46s - loss: 0.0909 - acc: 0.9719 - val_loss: 0.0673 - val_acc: 0.9816
Epoch 22/24
 - 46s - loss: 0.0872 - acc: 0.9739 - val_loss: 0.0705 - val_acc: 0.9780
Epoch 23/24
 - 46s - loss: 0.0841 - acc: 0.9742 - val_loss: 0.0862 - val_acc: 0.9718

Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 24/24
 - 46s - loss: 0.0763 - acc: 0.9787 - val_loss: 0.0591 - val_acc: 0.9833
Test accuracy:0.861
current auc_score ------------------> 0.917
------------------------ current config for the test -------------------------
Layers:  [6, 6]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  24  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 12, 24, 24)   1728        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 12, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 28, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 28, 24, 24)   112         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 28, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 12, 24, 24)   3024        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 12, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 40, 24, 24)   160         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 24, 24)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 12, 24, 24)   4320        activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 12, 24, 24)   0           dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 52, 24, 24)   0           concatenate_2[0][0]              
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 52, 24, 24)   208         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 52, 24, 24)   0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 12, 24, 24)   5616        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 12, 24, 24)   0           dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 64, 24, 24)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
dense_0_4_bn (BatchNormalizatio (None, 64, 24, 24)   256         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 64, 24, 24)   0           dense_0_4_bn[0][0]               
__________________________________________________________________________________________________
dense_0_4_conv2D (Conv2D)       (None, 12, 24, 24)   6912        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 12, 24, 24)   0           dense_0_4_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 76, 24, 24)   0           concatenate_4[0][0]              
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_0_5_bn (BatchNormalizatio (None, 76, 24, 24)   304         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 76, 24, 24)   0           dense_0_5_bn[0][0]               
__________________________________________________________________________________________________
dense_0_5_conv2D (Conv2D)       (None, 12, 24, 24)   8208        activation_7[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 12, 24, 24)   0           dense_0_5_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 88, 24, 24)   0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 88, 24, 24)   352         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 88, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 44, 24, 24)   3872        activation_8[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 44, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 44, 12, 12)   176         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 44, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 12, 12, 12)   4752        activation_9[0][0]               
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 12, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 56, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 56, 12, 12)   224         concatenate_7[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 56, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 12, 12, 12)   6048        activation_10[0][0]              
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 12, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 68, 12, 12)   0           concatenate_7[0][0]              
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_8[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 68, 12, 12)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 12, 12, 12)   7344        activation_11[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 12, 12, 12)   0           dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_9 (Concatenate)     (None, 80, 12, 12)   0           concatenate_8[0][0]              
                                                                 dropout_9[0][0]                  
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 80, 12, 12)   320         concatenate_9[0][0]              
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 80, 12, 12)   0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 12, 12, 12)   8640        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 12, 12, 12)   0           dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_10 (Concatenate)    (None, 92, 12, 12)   0           concatenate_9[0][0]              
                                                                 dropout_10[0][0]                 
__________________________________________________________________________________________________
dense_1_4_bn (BatchNormalizatio (None, 92, 12, 12)   368         concatenate_10[0][0]             
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 92, 12, 12)   0           dense_1_4_bn[0][0]               
__________________________________________________________________________________________________
dense_1_4_conv2D (Conv2D)       (None, 12, 12, 12)   9936        activation_13[0][0]              
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, 12, 12, 12)   0           dense_1_4_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_11 (Concatenate)    (None, 104, 12, 12)  0           concatenate_10[0][0]             
                                                                 dropout_11[0][0]                 
__________________________________________________________________________________________________
dense_1_5_bn (BatchNormalizatio (None, 104, 12, 12)  416         concatenate_11[0][0]             
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 104, 12, 12)  0           dense_1_5_bn[0][0]               
__________________________________________________________________________________________________
dense_1_5_conv2D (Conv2D)       (None, 12, 12, 12)   11232       activation_14[0][0]              
__________________________________________________________________________________________________
dropout_12 (Dropout)            (None, 12, 12, 12)   0           dense_1_5_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_12 (Concatenate)    (None, 116, 12, 12)  0           concatenate_11[0][0]             
                                                                 dropout_12[0][0]                 
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 116, 12, 12)  464         concatenate_12[0][0]             
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 116, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 16704)        0           activation_15[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            16705       flatten_1[0][0]                  
==================================================================================================
Total params: 103,665
Trainable params: 101,785
Non-trainable params: 1,880
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/24
 - 50s - loss: 0.4631 - acc: 0.7834 - val_loss: 0.4227 - val_acc: 0.7986
Epoch 2/24
 - 47s - loss: 0.3419 - acc: 0.8557 - val_loss: 0.3607 - val_acc: 0.8347
Epoch 3/24
 - 47s - loss: 0.2940 - acc: 0.8799 - val_loss: 0.2584 - val_acc: 0.9004
Epoch 4/24
 - 46s - loss: 0.2592 - acc: 0.8988 - val_loss: 0.2263 - val_acc: 0.9130
Epoch 5/24
 - 46s - loss: 0.2348 - acc: 0.9093 - val_loss: 0.1986 - val_acc: 0.9262
Epoch 6/24
 - 46s - loss: 0.2151 - acc: 0.9191 - val_loss: 0.1996 - val_acc: 0.9223
Epoch 7/24
 - 46s - loss: 0.1960 - acc: 0.9289 - val_loss: 0.2128 - val_acc: 0.9150
Epoch 8/24
 - 46s - loss: 0.1825 - acc: 0.9331 - val_loss: 0.2063 - val_acc: 0.9154

Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 9/24
 - 47s - loss: 0.1663 - acc: 0.9404 - val_loss: 0.1589 - val_acc: 0.9444
Epoch 10/24
 - 46s - loss: 0.1617 - acc: 0.9431 - val_loss: 0.1606 - val_acc: 0.9416
Epoch 11/24
 - 47s - loss: 0.1567 - acc: 0.9462 - val_loss: 0.1559 - val_acc: 0.9459
Epoch 12/24
 - 46s - loss: 0.1537 - acc: 0.9489 - val_loss: 0.1478 - val_acc: 0.9475
Epoch 13/24
 - 47s - loss: 0.1494 - acc: 0.9484 - val_loss: 0.1351 - val_acc: 0.9548
Epoch 14/24
 - 47s - loss: 0.1450 - acc: 0.9501 - val_loss: 0.1346 - val_acc: 0.9562
Epoch 15/24
 - 46s - loss: 0.1424 - acc: 0.9520 - val_loss: 0.1691 - val_acc: 0.9370
Epoch 16/24
 - 47s - loss: 0.1409 - acc: 0.9516 - val_loss: 0.1360 - val_acc: 0.9554
Epoch 17/24
 - 47s - loss: 0.1360 - acc: 0.9548 - val_loss: 0.1152 - val_acc: 0.9636
Epoch 18/24
 - 47s - loss: 0.1325 - acc: 0.9564 - val_loss: 0.1297 - val_acc: 0.9580
Epoch 19/24
 - 47s - loss: 0.1313 - acc: 0.9567 - val_loss: 0.1232 - val_acc: 0.9605
Epoch 20/24
 - 47s - loss: 0.1280 - acc: 0.9579 - val_loss: 0.1135 - val_acc: 0.9645
Epoch 21/24
 - 47s - loss: 0.1263 - acc: 0.9586 - val_loss: 0.1100 - val_acc: 0.9662
Epoch 22/24
 - 46s - loss: 0.1234 - acc: 0.9600 - val_loss: 0.1140 - val_acc: 0.9635
Epoch 23/24
 - 47s - loss: 0.1203 - acc: 0.9620 - val_loss: 0.1089 - val_acc: 0.9664
Epoch 24/24
 - 46s - loss: 0.1179 - acc: 0.9619 - val_loss: 0.0976 - val_acc: 0.9705
Test accuracy:0.830
current auc_score ------------------> 0.913
------------------------ current config for the test -------------------------
Layers:  [6, 6]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  24  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 12, 24, 24)   1728        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 12, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 28, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 28, 24, 24)   112         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 28, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 12, 24, 24)   3024        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 12, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 40, 24, 24)   160         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 24, 24)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 12, 24, 24)   4320        activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 12, 24, 24)   0           dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 52, 24, 24)   0           concatenate_2[0][0]              
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 52, 24, 24)   208         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 52, 24, 24)   0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 12, 24, 24)   5616        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 12, 24, 24)   0           dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 64, 24, 24)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
dense_0_4_bn (BatchNormalizatio (None, 64, 24, 24)   256         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 64, 24, 24)   0           dense_0_4_bn[0][0]               
__________________________________________________________________________________________________
dense_0_4_conv2D (Conv2D)       (None, 12, 24, 24)   6912        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 12, 24, 24)   0           dense_0_4_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 76, 24, 24)   0           concatenate_4[0][0]              
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_0_5_bn (BatchNormalizatio (None, 76, 24, 24)   304         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 76, 24, 24)   0           dense_0_5_bn[0][0]               
__________________________________________________________________________________________________
dense_0_5_conv2D (Conv2D)       (None, 12, 24, 24)   8208        activation_7[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 12, 24, 24)   0           dense_0_5_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 88, 24, 24)   0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 88, 24, 24)   352         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 88, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 44, 24, 24)   3872        activation_8[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 44, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 44, 12, 12)   176         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 44, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 12, 12, 12)   4752        activation_9[0][0]               
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 12, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 56, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 56, 12, 12)   224         concatenate_7[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 56, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 12, 12, 12)   6048        activation_10[0][0]              
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 12, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 68, 12, 12)   0           concatenate_7[0][0]              
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_8[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 68, 12, 12)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 12, 12, 12)   7344        activation_11[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 12, 12, 12)   0           dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_9 (Concatenate)     (None, 80, 12, 12)   0           concatenate_8[0][0]              
                                                                 dropout_9[0][0]                  
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 80, 12, 12)   320         concatenate_9[0][0]              
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 80, 12, 12)   0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 12, 12, 12)   8640        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 12, 12, 12)   0           dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_10 (Concatenate)    (None, 92, 12, 12)   0           concatenate_9[0][0]              
                                                                 dropout_10[0][0]                 
__________________________________________________________________________________________________
dense_1_4_bn (BatchNormalizatio (None, 92, 12, 12)   368         concatenate_10[0][0]             
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 92, 12, 12)   0           dense_1_4_bn[0][0]               
__________________________________________________________________________________________________
dense_1_4_conv2D (Conv2D)       (None, 12, 12, 12)   9936        activation_13[0][0]              
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, 12, 12, 12)   0           dense_1_4_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_11 (Concatenate)    (None, 104, 12, 12)  0           concatenate_10[0][0]             
                                                                 dropout_11[0][0]                 
__________________________________________________________________________________________________
dense_1_5_bn (BatchNormalizatio (None, 104, 12, 12)  416         concatenate_11[0][0]             
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 104, 12, 12)  0           dense_1_5_bn[0][0]               
__________________________________________________________________________________________________
dense_1_5_conv2D (Conv2D)       (None, 12, 12, 12)   11232       activation_14[0][0]              
__________________________________________________________________________________________________
dropout_12 (Dropout)            (None, 12, 12, 12)   0           dense_1_5_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_12 (Concatenate)    (None, 116, 12, 12)  0           concatenate_11[0][0]             
                                                                 dropout_12[0][0]                 
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 116, 12, 12)  464         concatenate_12[0][0]             
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 116, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 16704)        0           activation_15[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            16705       flatten_1[0][0]                  
==================================================================================================
Total params: 103,665
Trainable params: 101,785
Non-trainable params: 1,880
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/24
 - 49s - loss: 0.4616 - acc: 0.7863 - val_loss: 0.3928 - val_acc: 0.8217
Epoch 2/24
 - 45s - loss: 0.3496 - acc: 0.8513 - val_loss: 0.2973 - val_acc: 0.8814
Epoch 3/24
 - 45s - loss: 0.2956 - acc: 0.8800 - val_loss: 0.2630 - val_acc: 0.8903
Epoch 4/24
 - 45s - loss: 0.2574 - acc: 0.8991 - val_loss: 0.2247 - val_acc: 0.9133
Epoch 5/24
 - 46s - loss: 0.2306 - acc: 0.9123 - val_loss: 0.2428 - val_acc: 0.8957
Epoch 6/24
 - 45s - loss: 0.2086 - acc: 0.9215 - val_loss: 0.1704 - val_acc: 0.9378
Epoch 7/24
 - 44s - loss: 0.1901 - acc: 0.9295 - val_loss: 0.1654 - val_acc: 0.9390
Epoch 8/24
 - 45s - loss: 0.1742 - acc: 0.9387 - val_loss: 0.1478 - val_acc: 0.9488
Epoch 9/24
 - 45s - loss: 0.1633 - acc: 0.9435 - val_loss: 0.1574 - val_acc: 0.9416
Epoch 10/24
 - 45s - loss: 0.1514 - acc: 0.9461 - val_loss: 0.1217 - val_acc: 0.9588
Epoch 11/24
 - 47s - loss: 0.1434 - acc: 0.9513 - val_loss: 0.1161 - val_acc: 0.9617
Epoch 12/24
 - 45s - loss: 0.1335 - acc: 0.9567 - val_loss: 0.1188 - val_acc: 0.9616
Epoch 13/24
 - 45s - loss: 0.1277 - acc: 0.9575 - val_loss: 0.1038 - val_acc: 0.9665
Epoch 14/24
 - 46s - loss: 0.1210 - acc: 0.9607 - val_loss: 0.0914 - val_acc: 0.9730
Epoch 15/24
 - 46s - loss: 0.1159 - acc: 0.9633 - val_loss: 0.0848 - val_acc: 0.9752
Epoch 16/24
 - 45s - loss: 0.1089 - acc: 0.9655 - val_loss: 0.0852 - val_acc: 0.9753
Epoch 17/24
 - 45s - loss: 0.1041 - acc: 0.9669 - val_loss: 0.1022 - val_acc: 0.9662
Epoch 18/24
 - 45s - loss: 0.0991 - acc: 0.9686 - val_loss: 0.0820 - val_acc: 0.9773
Epoch 19/24
 - 45s - loss: 0.0958 - acc: 0.9701 - val_loss: 0.0649 - val_acc: 0.9823
Epoch 20/24
 - 45s - loss: 0.0916 - acc: 0.9718 - val_loss: 0.0646 - val_acc: 0.9816
Epoch 21/24
 - 45s - loss: 0.0889 - acc: 0.9725 - val_loss: 0.0618 - val_acc: 0.9843
Epoch 22/24
 - 46s - loss: 0.0845 - acc: 0.9747 - val_loss: 0.0611 - val_acc: 0.9841
Epoch 23/24
 - 46s - loss: 0.0815 - acc: 0.9756 - val_loss: 0.0597 - val_acc: 0.9823
Epoch 24/24
 - 46s - loss: 0.0782 - acc: 0.9770 - val_loss: 0.0538 - val_acc: 0.9866
Test accuracy:0.776
current auc_score ------------------> 0.916
------------------------ current config for the test -------------------------
Layers:  [6, 6]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  24  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 12, 24, 24)   1728        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 12, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 28, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 28, 24, 24)   112         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 28, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 12, 24, 24)   3024        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 12, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 40, 24, 24)   160         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 24, 24)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 12, 24, 24)   4320        activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 12, 24, 24)   0           dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 52, 24, 24)   0           concatenate_2[0][0]              
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 52, 24, 24)   208         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 52, 24, 24)   0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 12, 24, 24)   5616        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 12, 24, 24)   0           dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 64, 24, 24)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
dense_0_4_bn (BatchNormalizatio (None, 64, 24, 24)   256         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 64, 24, 24)   0           dense_0_4_bn[0][0]               
__________________________________________________________________________________________________
dense_0_4_conv2D (Conv2D)       (None, 12, 24, 24)   6912        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 12, 24, 24)   0           dense_0_4_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 76, 24, 24)   0           concatenate_4[0][0]              
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_0_5_bn (BatchNormalizatio (None, 76, 24, 24)   304         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 76, 24, 24)   0           dense_0_5_bn[0][0]               
__________________________________________________________________________________________________
dense_0_5_conv2D (Conv2D)       (None, 12, 24, 24)   8208        activation_7[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 12, 24, 24)   0           dense_0_5_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 88, 24, 24)   0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 88, 24, 24)   352         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 88, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 44, 24, 24)   3872        activation_8[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 44, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 44, 12, 12)   176         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 44, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 12, 12, 12)   4752        activation_9[0][0]               
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 12, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 56, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 56, 12, 12)   224         concatenate_7[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 56, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 12, 12, 12)   6048        activation_10[0][0]              
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 12, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 68, 12, 12)   0           concatenate_7[0][0]              
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_8[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 68, 12, 12)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 12, 12, 12)   7344        activation_11[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 12, 12, 12)   0           dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_9 (Concatenate)     (None, 80, 12, 12)   0           concatenate_8[0][0]              
                                                                 dropout_9[0][0]                  
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 80, 12, 12)   320         concatenate_9[0][0]              
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 80, 12, 12)   0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 12, 12, 12)   8640        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 12, 12, 12)   0           dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_10 (Concatenate)    (None, 92, 12, 12)   0           concatenate_9[0][0]              
                                                                 dropout_10[0][0]                 
__________________________________________________________________________________________________
dense_1_4_bn (BatchNormalizatio (None, 92, 12, 12)   368         concatenate_10[0][0]             
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 92, 12, 12)   0           dense_1_4_bn[0][0]               
__________________________________________________________________________________________________
dense_1_4_conv2D (Conv2D)       (None, 12, 12, 12)   9936        activation_13[0][0]              
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, 12, 12, 12)   0           dense_1_4_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_11 (Concatenate)    (None, 104, 12, 12)  0           concatenate_10[0][0]             
                                                                 dropout_11[0][0]                 
__________________________________________________________________________________________________
dense_1_5_bn (BatchNormalizatio (None, 104, 12, 12)  416         concatenate_11[0][0]             
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 104, 12, 12)  0           dense_1_5_bn[0][0]               
__________________________________________________________________________________________________
dense_1_5_conv2D (Conv2D)       (None, 12, 12, 12)   11232       activation_14[0][0]              
__________________________________________________________________________________________________
dropout_12 (Dropout)            (None, 12, 12, 12)   0           dense_1_5_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_12 (Concatenate)    (None, 116, 12, 12)  0           concatenate_11[0][0]             
                                                                 dropout_12[0][0]                 
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 116, 12, 12)  464         concatenate_12[0][0]             
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 116, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 16704)        0           activation_15[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            16705       flatten_1[0][0]                  
==================================================================================================
Total params: 103,665
Trainable params: 101,785
Non-trainable params: 1,880
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/24
 - 50s - loss: 0.4645 - acc: 0.7851 - val_loss: 0.3536 - val_acc: 0.8454
Epoch 2/24
 - 46s - loss: 0.3439 - acc: 0.8528 - val_loss: 0.3759 - val_acc: 0.8207
Epoch 3/24
 - 47s - loss: 0.2948 - acc: 0.8777 - val_loss: 0.2884 - val_acc: 0.8780
Epoch 4/24
 - 47s - loss: 0.2576 - acc: 0.8976 - val_loss: 0.2254 - val_acc: 0.9109
Epoch 5/24
 - 46s - loss: 0.2330 - acc: 0.9092 - val_loss: 0.2015 - val_acc: 0.9233
Epoch 6/24
 - 46s - loss: 0.2097 - acc: 0.9211 - val_loss: 0.2129 - val_acc: 0.9153
Epoch 7/24
 - 46s - loss: 0.1939 - acc: 0.9287 - val_loss: 0.1684 - val_acc: 0.9367
Epoch 8/24
 - 45s - loss: 0.1816 - acc: 0.9354 - val_loss: 0.1823 - val_acc: 0.9293
Epoch 9/24
 - 46s - loss: 0.1670 - acc: 0.9400 - val_loss: 0.1393 - val_acc: 0.9523
Epoch 10/24
 - 46s - loss: 0.1562 - acc: 0.9453 - val_loss: 0.1349 - val_acc: 0.9526
Epoch 11/24
 - 45s - loss: 0.1480 - acc: 0.9485 - val_loss: 0.1320 - val_acc: 0.9516
Epoch 12/24
 - 45s - loss: 0.1402 - acc: 0.9523 - val_loss: 0.1244 - val_acc: 0.9558
Epoch 13/24
 - 46s - loss: 0.1330 - acc: 0.9554 - val_loss: 0.1042 - val_acc: 0.9656
Epoch 14/24
 - 45s - loss: 0.1242 - acc: 0.9586 - val_loss: 0.0945 - val_acc: 0.9706
Epoch 15/24
 - 46s - loss: 0.1182 - acc: 0.9610 - val_loss: 0.0875 - val_acc: 0.9724
Epoch 16/24
 - 46s - loss: 0.1131 - acc: 0.9633 - val_loss: 0.0911 - val_acc: 0.9700
Epoch 17/24
 - 45s - loss: 0.1086 - acc: 0.9654 - val_loss: 0.1167 - val_acc: 0.9580
Epoch 18/24
 - 45s - loss: 0.1025 - acc: 0.9688 - val_loss: 0.0757 - val_acc: 0.9787
Epoch 19/24
 - 45s - loss: 0.1016 - acc: 0.9672 - val_loss: 0.0829 - val_acc: 0.9733
Epoch 20/24
 - 46s - loss: 0.0959 - acc: 0.9704 - val_loss: 0.0746 - val_acc: 0.9759
Epoch 21/24
 - 45s - loss: 0.0926 - acc: 0.9704 - val_loss: 0.0735 - val_acc: 0.9764
Epoch 22/24
 - 45s - loss: 0.0878 - acc: 0.9742 - val_loss: 0.0680 - val_acc: 0.9784
Epoch 00022: early stopping
Test accuracy:0.825
current auc_score ------------------> 0.901
------------------------ current config for the test -------------------------
Layers:  [6, 6]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  24  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 12, 24, 24)   1728        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 12, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 28, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 28, 24, 24)   112         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 28, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 12, 24, 24)   3024        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 12, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 40, 24, 24)   160         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 24, 24)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 12, 24, 24)   4320        activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 12, 24, 24)   0           dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 52, 24, 24)   0           concatenate_2[0][0]              
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 52, 24, 24)   208         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 52, 24, 24)   0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 12, 24, 24)   5616        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 12, 24, 24)   0           dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 64, 24, 24)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
dense_0_4_bn (BatchNormalizatio (None, 64, 24, 24)   256         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 64, 24, 24)   0           dense_0_4_bn[0][0]               
__________________________________________________________________________________________________
dense_0_4_conv2D (Conv2D)       (None, 12, 24, 24)   6912        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 12, 24, 24)   0           dense_0_4_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 76, 24, 24)   0           concatenate_4[0][0]              
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_0_5_bn (BatchNormalizatio (None, 76, 24, 24)   304         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 76, 24, 24)   0           dense_0_5_bn[0][0]               
__________________________________________________________________________________________________
dense_0_5_conv2D (Conv2D)       (None, 12, 24, 24)   8208        activation_7[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 12, 24, 24)   0           dense_0_5_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 88, 24, 24)   0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 88, 24, 24)   352         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 88, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 44, 24, 24)   3872        activation_8[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 44, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 44, 12, 12)   176         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 44, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 12, 12, 12)   4752        activation_9[0][0]               
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 12, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 56, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 56, 12, 12)   224         concatenate_7[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 56, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 12, 12, 12)   6048        activation_10[0][0]              
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 12, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 68, 12, 12)   0           concatenate_7[0][0]              
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_8[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 68, 12, 12)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 12, 12, 12)   7344        activation_11[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 12, 12, 12)   0           dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_9 (Concatenate)     (None, 80, 12, 12)   0           concatenate_8[0][0]              
                                                                 dropout_9[0][0]                  
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 80, 12, 12)   320         concatenate_9[0][0]              
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 80, 12, 12)   0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 12, 12, 12)   8640        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 12, 12, 12)   0           dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_10 (Concatenate)    (None, 92, 12, 12)   0           concatenate_9[0][0]              
                                                                 dropout_10[0][0]                 
__________________________________________________________________________________________________
dense_1_4_bn (BatchNormalizatio (None, 92, 12, 12)   368         concatenate_10[0][0]             
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 92, 12, 12)   0           dense_1_4_bn[0][0]               
__________________________________________________________________________________________________
dense_1_4_conv2D (Conv2D)       (None, 12, 12, 12)   9936        activation_13[0][0]              
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, 12, 12, 12)   0           dense_1_4_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_11 (Concatenate)    (None, 104, 12, 12)  0           concatenate_10[0][0]             
                                                                 dropout_11[0][0]                 
__________________________________________________________________________________________________
dense_1_5_bn (BatchNormalizatio (None, 104, 12, 12)  416         concatenate_11[0][0]             
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 104, 12, 12)  0           dense_1_5_bn[0][0]               
__________________________________________________________________________________________________
dense_1_5_conv2D (Conv2D)       (None, 12, 12, 12)   11232       activation_14[0][0]              
__________________________________________________________________________________________________
dropout_12 (Dropout)            (None, 12, 12, 12)   0           dense_1_5_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_12 (Concatenate)    (None, 116, 12, 12)  0           concatenate_11[0][0]             
                                                                 dropout_12[0][0]                 
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 116, 12, 12)  464         concatenate_12[0][0]             
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 116, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 16704)        0           activation_15[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            16705       flatten_1[0][0]                  
==================================================================================================
Total params: 103,665
Trainable params: 101,785
Non-trainable params: 1,880
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/24
 - 49s - loss: 0.4664 - acc: 0.7778 - val_loss: 0.4085 - val_acc: 0.8194
Epoch 2/24
 - 46s - loss: 0.3396 - acc: 0.8549 - val_loss: 0.3082 - val_acc: 0.8647
Epoch 3/24
 - 45s - loss: 0.2926 - acc: 0.8801 - val_loss: 0.2609 - val_acc: 0.8955
Epoch 4/24
 - 45s - loss: 0.2605 - acc: 0.8968 - val_loss: 0.2214 - val_acc: 0.9155
Epoch 5/24
 - 45s - loss: 0.2339 - acc: 0.9094 - val_loss: 0.2190 - val_acc: 0.9138
Epoch 6/24
 - 46s - loss: 0.2148 - acc: 0.9178 - val_loss: 0.1850 - val_acc: 0.9316
Epoch 7/24
 - 45s - loss: 0.1979 - acc: 0.9259 - val_loss: 0.1660 - val_acc: 0.9406
Epoch 8/24
 - 45s - loss: 0.1858 - acc: 0.9332 - val_loss: 0.1645 - val_acc: 0.9388
Epoch 9/24
 - 47s - loss: 0.1706 - acc: 0.9384 - val_loss: 0.1416 - val_acc: 0.9493
Epoch 10/24
 - 46s - loss: 0.1618 - acc: 0.9431 - val_loss: 0.1305 - val_acc: 0.9544
Epoch 11/24
 - 46s - loss: 0.1520 - acc: 0.9473 - val_loss: 0.1244 - val_acc: 0.9608
Epoch 12/24
 - 46s - loss: 0.1437 - acc: 0.9498 - val_loss: 0.1141 - val_acc: 0.9621
Epoch 13/24
 - 46s - loss: 0.1367 - acc: 0.9536 - val_loss: 0.1190 - val_acc: 0.9573
Epoch 14/24
 - 46s - loss: 0.1282 - acc: 0.9571 - val_loss: 0.1108 - val_acc: 0.9603
Epoch 15/24
 - 46s - loss: 0.1234 - acc: 0.9589 - val_loss: 0.0912 - val_acc: 0.9711
Epoch 16/24
 - 46s - loss: 0.1169 - acc: 0.9620 - val_loss: 0.0878 - val_acc: 0.9726
Epoch 17/24
 - 46s - loss: 0.1128 - acc: 0.9640 - val_loss: 0.1211 - val_acc: 0.9591
Epoch 18/24
 - 46s - loss: 0.1085 - acc: 0.9649 - val_loss: 0.0772 - val_acc: 0.9773
Epoch 19/24
 - 46s - loss: 0.1031 - acc: 0.9677 - val_loss: 0.0727 - val_acc: 0.9794
Epoch 20/24
 - 46s - loss: 0.0980 - acc: 0.9685 - val_loss: 0.0790 - val_acc: 0.9749
Epoch 21/24
 - 46s - loss: 0.0924 - acc: 0.9704 - val_loss: 0.0715 - val_acc: 0.9799
Epoch 22/24
 - 46s - loss: 0.0903 - acc: 0.9720 - val_loss: 0.0672 - val_acc: 0.9812
Epoch 23/24
 - 46s - loss: 0.0887 - acc: 0.9722 - val_loss: 0.0710 - val_acc: 0.9802
Epoch 24/24
 - 46s - loss: 0.0847 - acc: 0.9749 - val_loss: 0.0599 - val_acc: 0.9838
Test accuracy:0.825
current auc_score ------------------> 0.911
------------------------ current config for the test -------------------------
Layers:  [6, 6]  Growth_rate:  12  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  24  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 12, 24, 24)   1728        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 12, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 28, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 28, 24, 24)   112         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 28, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 12, 24, 24)   3024        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 12, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 40, 24, 24)   160         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 24, 24)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 12, 24, 24)   4320        activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 12, 24, 24)   0           dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 52, 24, 24)   0           concatenate_2[0][0]              
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 52, 24, 24)   208         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 52, 24, 24)   0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 12, 24, 24)   5616        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 12, 24, 24)   0           dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 64, 24, 24)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
dense_0_4_bn (BatchNormalizatio (None, 64, 24, 24)   256         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 64, 24, 24)   0           dense_0_4_bn[0][0]               
__________________________________________________________________________________________________
dense_0_4_conv2D (Conv2D)       (None, 12, 24, 24)   6912        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 12, 24, 24)   0           dense_0_4_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 76, 24, 24)   0           concatenate_4[0][0]              
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_0_5_bn (BatchNormalizatio (None, 76, 24, 24)   304         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 76, 24, 24)   0           dense_0_5_bn[0][0]               
__________________________________________________________________________________________________
dense_0_5_conv2D (Conv2D)       (None, 12, 24, 24)   8208        activation_7[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 12, 24, 24)   0           dense_0_5_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 88, 24, 24)   0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 88, 24, 24)   352         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 88, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 44, 24, 24)   3872        activation_8[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 44, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 44, 12, 12)   176         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 44, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 12, 12, 12)   4752        activation_9[0][0]               
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 12, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 56, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 56, 12, 12)   224         concatenate_7[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 56, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 12, 12, 12)   6048        activation_10[0][0]              
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 12, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 68, 12, 12)   0           concatenate_7[0][0]              
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_8[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 68, 12, 12)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 12, 12, 12)   7344        activation_11[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 12, 12, 12)   0           dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_9 (Concatenate)     (None, 80, 12, 12)   0           concatenate_8[0][0]              
                                                                 dropout_9[0][0]                  
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 80, 12, 12)   320         concatenate_9[0][0]              
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 80, 12, 12)   0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 12, 12, 12)   8640        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 12, 12, 12)   0           dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_10 (Concatenate)    (None, 92, 12, 12)   0           concatenate_9[0][0]              
                                                                 dropout_10[0][0]                 
__________________________________________________________________________________________________
dense_1_4_bn (BatchNormalizatio (None, 92, 12, 12)   368         concatenate_10[0][0]             
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 92, 12, 12)   0           dense_1_4_bn[0][0]               
__________________________________________________________________________________________________
dense_1_4_conv2D (Conv2D)       (None, 12, 12, 12)   9936        activation_13[0][0]              
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, 12, 12, 12)   0           dense_1_4_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_11 (Concatenate)    (None, 104, 12, 12)  0           concatenate_10[0][0]             
                                                                 dropout_11[0][0]                 
__________________________________________________________________________________________________
dense_1_5_bn (BatchNormalizatio (None, 104, 12, 12)  416         concatenate_11[0][0]             
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 104, 12, 12)  0           dense_1_5_bn[0][0]               
__________________________________________________________________________________________________
dense_1_5_conv2D (Conv2D)       (None, 12, 12, 12)   11232       activation_14[0][0]              
__________________________________________________________________________________________________
dropout_12 (Dropout)            (None, 12, 12, 12)   0           dense_1_5_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_12 (Concatenate)    (None, 116, 12, 12)  0           concatenate_11[0][0]             
                                                                 dropout_12[0][0]                 
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 116, 12, 12)  464         concatenate_12[0][0]             
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 116, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 16704)        0           activation_15[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            16705       flatten_1[0][0]                  
==================================================================================================
Total params: 103,665
Trainable params: 101,785
Non-trainable params: 1,880
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/24
 - 50s - loss: 0.4656 - acc: 0.7826 - val_loss: 0.3884 - val_acc: 0.8222
Epoch 2/24
 - 46s - loss: 0.3419 - acc: 0.8570 - val_loss: 0.3542 - val_acc: 0.8402
Epoch 3/24
 - 46s - loss: 0.2937 - acc: 0.8791 - val_loss: 0.2845 - val_acc: 0.8775
Epoch 4/24
 - 46s - loss: 0.2581 - acc: 0.8982 - val_loss: 0.2263 - val_acc: 0.9153
Epoch 5/24
 - 46s - loss: 0.2306 - acc: 0.9116 - val_loss: 0.2399 - val_acc: 0.9046
Epoch 6/24
 - 46s - loss: 0.2078 - acc: 0.9229 - val_loss: 0.1732 - val_acc: 0.9415
Epoch 7/24
 - 46s - loss: 0.1895 - acc: 0.9319 - val_loss: 0.1591 - val_acc: 0.9414
Epoch 8/24
 - 46s - loss: 0.1766 - acc: 0.9370 - val_loss: 0.1433 - val_acc: 0.9513
Epoch 9/24
 - 46s - loss: 0.1619 - acc: 0.9434 - val_loss: 0.1554 - val_acc: 0.9415
Epoch 10/24
 - 46s - loss: 0.1500 - acc: 0.9490 - val_loss: 0.1244 - val_acc: 0.9597
Epoch 11/24
 - 46s - loss: 0.1420 - acc: 0.9513 - val_loss: 0.1065 - val_acc: 0.9674
Epoch 12/24
 - 46s - loss: 0.1319 - acc: 0.9570 - val_loss: 0.1154 - val_acc: 0.9602
Epoch 13/24
 - 46s - loss: 0.1256 - acc: 0.9595 - val_loss: 0.1401 - val_acc: 0.9495
Epoch 14/24
 - 46s - loss: 0.1186 - acc: 0.9617 - val_loss: 0.1038 - val_acc: 0.9669
Epoch 15/24
 - 46s - loss: 0.1134 - acc: 0.9636 - val_loss: 0.1005 - val_acc: 0.9676
Epoch 16/24
 - 47s - loss: 0.1070 - acc: 0.9656 - val_loss: 0.1190 - val_acc: 0.9592
Epoch 17/24
 - 46s - loss: 0.1017 - acc: 0.9684 - val_loss: 0.0855 - val_acc: 0.9721
Epoch 18/24
 - 47s - loss: 0.0976 - acc: 0.9700 - val_loss: 0.0811 - val_acc: 0.9745
Epoch 19/24
 - 46s - loss: 0.0931 - acc: 0.9717 - val_loss: 0.0688 - val_acc: 0.9808
Epoch 20/24
 - 46s - loss: 0.0886 - acc: 0.9726 - val_loss: 0.0673 - val_acc: 0.9799
Epoch 21/24
 - 46s - loss: 0.0862 - acc: 0.9740 - val_loss: 0.0726 - val_acc: 0.9778
Epoch 22/24
 - 46s - loss: 0.0829 - acc: 0.9755 - val_loss: 0.0678 - val_acc: 0.9794
Epoch 23/24
 - 46s - loss: 0.0777 - acc: 0.9771 - val_loss: 0.0633 - val_acc: 0.9805
Epoch 00023: early stopping
Test accuracy:0.826
current auc_score ------------------> 0.904
accuracies:  [0.8256720430107527, 0.8002688172043011, 0.7638440860215053, 0.8387096774193549, 0.860752688172043, 0.8302419354838709, 0.7758064516129032, 0.8248655913978494, 0.8254032258064516, 0.8258064516129032]
aucs:  [0.9071, 0.9055, 0.8994, 0.9192, 0.9169, 0.9133, 0.916, 0.901, 0.9106, 0.9045]
mean and std AUC:  0.909+/-0.007  max:   0.9192
['6-6', '18', '2', '16', '0.2', '0.07', '21', 'adadelta', '0.5', 'FALSE', '64', 'flatten']
------------------------ current config for the test -------------------------
Layers:  [6, 6]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   2592        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 34, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 34, 24, 24)   136         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 34, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   5508        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 52, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 52, 24, 24)   208         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 52, 24, 24)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 18, 24, 24)   8424        activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 24, 24)   0           dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 70, 24, 24)   0           concatenate_2[0][0]              
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 70, 24, 24)   280         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 70, 24, 24)   0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 18, 24, 24)   11340       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 24, 24)   0           dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 88, 24, 24)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
dense_0_4_bn (BatchNormalizatio (None, 88, 24, 24)   352         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 88, 24, 24)   0           dense_0_4_bn[0][0]               
__________________________________________________________________________________________________
dense_0_4_conv2D (Conv2D)       (None, 18, 24, 24)   14256       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 18, 24, 24)   0           dense_0_4_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 106, 24, 24)  0           concatenate_4[0][0]              
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_0_5_bn (BatchNormalizatio (None, 106, 24, 24)  424         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 106, 24, 24)  0           dense_0_5_bn[0][0]               
__________________________________________________________________________________________________
dense_0_5_conv2D (Conv2D)       (None, 18, 24, 24)   17172       activation_7[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 18, 24, 24)   0           dense_0_5_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 124, 24, 24)  0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 124, 24, 24)  496         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 124, 24, 24)  0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 62, 24, 24)   7688        activation_8[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 62, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 62, 12, 12)   248         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 62, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   10044       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 80, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 80, 12, 12)   320         concatenate_7[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 80, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   12960       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 98, 12, 12)   0           concatenate_7[0][0]              
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 98, 12, 12)   392         concatenate_8[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 18, 12, 12)   15876       activation_11[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 18, 12, 12)   0           dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_9 (Concatenate)     (None, 116, 12, 12)  0           concatenate_8[0][0]              
                                                                 dropout_9[0][0]                  
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 116, 12, 12)  464         concatenate_9[0][0]              
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 116, 12, 12)  0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 18, 12, 12)   18792       activation_12[0][0]              
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 18, 12, 12)   0           dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_10 (Concatenate)    (None, 134, 12, 12)  0           concatenate_9[0][0]              
                                                                 dropout_10[0][0]                 
__________________________________________________________________________________________________
dense_1_4_bn (BatchNormalizatio (None, 134, 12, 12)  536         concatenate_10[0][0]             
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 134, 12, 12)  0           dense_1_4_bn[0][0]               
__________________________________________________________________________________________________
dense_1_4_conv2D (Conv2D)       (None, 18, 12, 12)   21708       activation_13[0][0]              
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, 18, 12, 12)   0           dense_1_4_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_11 (Concatenate)    (None, 152, 12, 12)  0           concatenate_10[0][0]             
                                                                 dropout_11[0][0]                 
__________________________________________________________________________________________________
dense_1_5_bn (BatchNormalizatio (None, 152, 12, 12)  608         concatenate_11[0][0]             
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 152, 12, 12)  0           dense_1_5_bn[0][0]               
__________________________________________________________________________________________________
dense_1_5_conv2D (Conv2D)       (None, 18, 12, 12)   24624       activation_14[0][0]              
__________________________________________________________________________________________________
dropout_12 (Dropout)            (None, 18, 12, 12)   0           dense_1_5_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_12 (Concatenate)    (None, 170, 12, 12)  0           concatenate_11[0][0]             
                                                                 dropout_12[0][0]                 
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 170, 12, 12)  680         concatenate_12[0][0]             
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 170, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 24480)        0           activation_15[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            24481       flatten_1[0][0]                  
==================================================================================================
Total params: 202,305
Trainable params: 199,669
Non-trainable params: 2,636
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 63s - loss: 0.4499 - acc: 0.7925 - val_loss: 0.3547 - val_acc: 0.8436
Epoch 2/21
 - 59s - loss: 0.3300 - acc: 0.8615 - val_loss: 0.2747 - val_acc: 0.8927
Epoch 3/21
 - 59s - loss: 0.2678 - acc: 0.8942 - val_loss: 0.2197 - val_acc: 0.9180
Epoch 4/21
 - 59s - loss: 0.2301 - acc: 0.9137 - val_loss: 0.1979 - val_acc: 0.9270
Epoch 5/21
 - 59s - loss: 0.1990 - acc: 0.9277 - val_loss: 0.1760 - val_acc: 0.9326
Epoch 6/21
 - 59s - loss: 0.1775 - acc: 0.9380 - val_loss: 0.1677 - val_acc: 0.9390
Epoch 7/21
 - 59s - loss: 0.1601 - acc: 0.9457 - val_loss: 0.1137 - val_acc: 0.9660
Epoch 8/21
 - 59s - loss: 0.1467 - acc: 0.9517 - val_loss: 0.1570 - val_acc: 0.9421
Epoch 9/21
 - 59s - loss: 0.1339 - acc: 0.9558 - val_loss: 0.1004 - val_acc: 0.9695
Epoch 10/21
 - 59s - loss: 0.1235 - acc: 0.9606 - val_loss: 0.1014 - val_acc: 0.9672
Epoch 11/21
 - 59s - loss: 0.1115 - acc: 0.9652 - val_loss: 0.0767 - val_acc: 0.9799
Epoch 12/21
 - 59s - loss: 0.1067 - acc: 0.9669 - val_loss: 0.0806 - val_acc: 0.9768
Epoch 13/21
 - 59s - loss: 0.0985 - acc: 0.9699 - val_loss: 0.0745 - val_acc: 0.9800
Epoch 14/21
 - 59s - loss: 0.0943 - acc: 0.9720 - val_loss: 0.0724 - val_acc: 0.9790
Epoch 15/21
 - 59s - loss: 0.0874 - acc: 0.9744 - val_loss: 0.0660 - val_acc: 0.9810
Epoch 16/21
 - 59s - loss: 0.0835 - acc: 0.9756 - val_loss: 0.0631 - val_acc: 0.9836
Epoch 17/21
 - 59s - loss: 0.0790 - acc: 0.9778 - val_loss: 0.0656 - val_acc: 0.9822
Epoch 18/21
 - 62s - loss: 0.0751 - acc: 0.9789 - val_loss: 0.0556 - val_acc: 0.9874
Epoch 19/21
 - 59s - loss: 0.0707 - acc: 0.9809 - val_loss: 0.0612 - val_acc: 0.9832
Epoch 20/21
 - 60s - loss: 0.0670 - acc: 0.9824 - val_loss: 0.0594 - val_acc: 0.9824
Epoch 21/21
 - 59s - loss: 0.0645 - acc: 0.9835 - val_loss: 0.0498 - val_acc: 0.9877
Test accuracy:0.830
current auc_score ------------------> 0.920
------------------------ current config for the test -------------------------
Layers:  [6, 6]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   2592        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 34, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 34, 24, 24)   136         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 34, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   5508        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 52, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 52, 24, 24)   208         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 52, 24, 24)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 18, 24, 24)   8424        activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 24, 24)   0           dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 70, 24, 24)   0           concatenate_2[0][0]              
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 70, 24, 24)   280         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 70, 24, 24)   0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 18, 24, 24)   11340       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 24, 24)   0           dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 88, 24, 24)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
dense_0_4_bn (BatchNormalizatio (None, 88, 24, 24)   352         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 88, 24, 24)   0           dense_0_4_bn[0][0]               
__________________________________________________________________________________________________
dense_0_4_conv2D (Conv2D)       (None, 18, 24, 24)   14256       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 18, 24, 24)   0           dense_0_4_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 106, 24, 24)  0           concatenate_4[0][0]              
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_0_5_bn (BatchNormalizatio (None, 106, 24, 24)  424         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 106, 24, 24)  0           dense_0_5_bn[0][0]               
__________________________________________________________________________________________________
dense_0_5_conv2D (Conv2D)       (None, 18, 24, 24)   17172       activation_7[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 18, 24, 24)   0           dense_0_5_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 124, 24, 24)  0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 124, 24, 24)  496         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 124, 24, 24)  0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 62, 24, 24)   7688        activation_8[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 62, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 62, 12, 12)   248         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 62, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   10044       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 80, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 80, 12, 12)   320         concatenate_7[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 80, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   12960       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 98, 12, 12)   0           concatenate_7[0][0]              
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 98, 12, 12)   392         concatenate_8[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 18, 12, 12)   15876       activation_11[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 18, 12, 12)   0           dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_9 (Concatenate)     (None, 116, 12, 12)  0           concatenate_8[0][0]              
                                                                 dropout_9[0][0]                  
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 116, 12, 12)  464         concatenate_9[0][0]              
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 116, 12, 12)  0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 18, 12, 12)   18792       activation_12[0][0]              
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 18, 12, 12)   0           dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_10 (Concatenate)    (None, 134, 12, 12)  0           concatenate_9[0][0]              
                                                                 dropout_10[0][0]                 
__________________________________________________________________________________________________
dense_1_4_bn (BatchNormalizatio (None, 134, 12, 12)  536         concatenate_10[0][0]             
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 134, 12, 12)  0           dense_1_4_bn[0][0]               
__________________________________________________________________________________________________
dense_1_4_conv2D (Conv2D)       (None, 18, 12, 12)   21708       activation_13[0][0]              
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, 18, 12, 12)   0           dense_1_4_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_11 (Concatenate)    (None, 152, 12, 12)  0           concatenate_10[0][0]             
                                                                 dropout_11[0][0]                 
__________________________________________________________________________________________________
dense_1_5_bn (BatchNormalizatio (None, 152, 12, 12)  608         concatenate_11[0][0]             
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 152, 12, 12)  0           dense_1_5_bn[0][0]               
__________________________________________________________________________________________________
dense_1_5_conv2D (Conv2D)       (None, 18, 12, 12)   24624       activation_14[0][0]              
__________________________________________________________________________________________________
dropout_12 (Dropout)            (None, 18, 12, 12)   0           dense_1_5_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_12 (Concatenate)    (None, 170, 12, 12)  0           concatenate_11[0][0]             
                                                                 dropout_12[0][0]                 
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 170, 12, 12)  680         concatenate_12[0][0]             
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 170, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 24480)        0           activation_15[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            24481       flatten_1[0][0]                  
==================================================================================================
Total params: 202,305
Trainable params: 199,669
Non-trainable params: 2,636
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 63s - loss: 0.4487 - acc: 0.7927 - val_loss: 0.3451 - val_acc: 0.8451
Epoch 2/21
 - 59s - loss: 0.3147 - acc: 0.8690 - val_loss: 0.3151 - val_acc: 0.8624
Epoch 3/21
 - 59s - loss: 0.2611 - acc: 0.9001 - val_loss: 0.2232 - val_acc: 0.9137
Epoch 4/21
 - 59s - loss: 0.2247 - acc: 0.9146 - val_loss: 0.2030 - val_acc: 0.9257
Epoch 5/21
 - 59s - loss: 0.1947 - acc: 0.9306 - val_loss: 0.1633 - val_acc: 0.9421
Epoch 6/21
 - 59s - loss: 0.1769 - acc: 0.9386 - val_loss: 0.1335 - val_acc: 0.9552
Epoch 7/21
 - 60s - loss: 0.1576 - acc: 0.9467 - val_loss: 0.1289 - val_acc: 0.9562
Epoch 8/21
 - 60s - loss: 0.1435 - acc: 0.9524 - val_loss: 0.1187 - val_acc: 0.9583
Epoch 9/21
 - 60s - loss: 0.1311 - acc: 0.9578 - val_loss: 0.1190 - val_acc: 0.9585
Epoch 10/21
 - 60s - loss: 0.1196 - acc: 0.9622 - val_loss: 0.1032 - val_acc: 0.9688
Epoch 11/21
 - 60s - loss: 0.1092 - acc: 0.9674 - val_loss: 0.0789 - val_acc: 0.9790
Epoch 12/21
 - 60s - loss: 0.1035 - acc: 0.9683 - val_loss: 0.1308 - val_acc: 0.9514
Epoch 13/21
 - 60s - loss: 0.0947 - acc: 0.9719 - val_loss: 0.0698 - val_acc: 0.9821
Epoch 14/21
 - 59s - loss: 0.0900 - acc: 0.9743 - val_loss: 0.0591 - val_acc: 0.9868
Epoch 15/21
 - 60s - loss: 0.0829 - acc: 0.9759 - val_loss: 0.0721 - val_acc: 0.9788
Epoch 16/21
 - 60s - loss: 0.0796 - acc: 0.9772 - val_loss: 0.0631 - val_acc: 0.9805
Epoch 17/21
 - 60s - loss: 0.0747 - acc: 0.9791 - val_loss: 0.0729 - val_acc: 0.9770

Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 18/21
 - 59s - loss: 0.0661 - acc: 0.9834 - val_loss: 0.0468 - val_acc: 0.9895
Epoch 19/21
 - 60s - loss: 0.0629 - acc: 0.9841 - val_loss: 0.0478 - val_acc: 0.9885
Epoch 20/21
 - 60s - loss: 0.0624 - acc: 0.9846 - val_loss: 0.0500 - val_acc: 0.9868
Epoch 21/21
 - 60s - loss: 0.0613 - acc: 0.9850 - val_loss: 0.0463 - val_acc: 0.9890
Test accuracy:0.859
current auc_score ------------------> 0.926
------------------------ current config for the test -------------------------
Layers:  [6, 6]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   2592        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 34, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 34, 24, 24)   136         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 34, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   5508        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 52, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 52, 24, 24)   208         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 52, 24, 24)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 18, 24, 24)   8424        activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 24, 24)   0           dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 70, 24, 24)   0           concatenate_2[0][0]              
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 70, 24, 24)   280         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 70, 24, 24)   0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 18, 24, 24)   11340       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 24, 24)   0           dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 88, 24, 24)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
dense_0_4_bn (BatchNormalizatio (None, 88, 24, 24)   352         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 88, 24, 24)   0           dense_0_4_bn[0][0]               
__________________________________________________________________________________________________
dense_0_4_conv2D (Conv2D)       (None, 18, 24, 24)   14256       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 18, 24, 24)   0           dense_0_4_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 106, 24, 24)  0           concatenate_4[0][0]              
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_0_5_bn (BatchNormalizatio (None, 106, 24, 24)  424         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 106, 24, 24)  0           dense_0_5_bn[0][0]               
__________________________________________________________________________________________________
dense_0_5_conv2D (Conv2D)       (None, 18, 24, 24)   17172       activation_7[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 18, 24, 24)   0           dense_0_5_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 124, 24, 24)  0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 124, 24, 24)  496         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 124, 24, 24)  0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 62, 24, 24)   7688        activation_8[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 62, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 62, 12, 12)   248         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 62, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   10044       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 80, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 80, 12, 12)   320         concatenate_7[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 80, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   12960       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 98, 12, 12)   0           concatenate_7[0][0]              
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 98, 12, 12)   392         concatenate_8[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 18, 12, 12)   15876       activation_11[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 18, 12, 12)   0           dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_9 (Concatenate)     (None, 116, 12, 12)  0           concatenate_8[0][0]              
                                                                 dropout_9[0][0]                  
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 116, 12, 12)  464         concatenate_9[0][0]              
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 116, 12, 12)  0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 18, 12, 12)   18792       activation_12[0][0]              
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 18, 12, 12)   0           dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_10 (Concatenate)    (None, 134, 12, 12)  0           concatenate_9[0][0]              
                                                                 dropout_10[0][0]                 
__________________________________________________________________________________________________
dense_1_4_bn (BatchNormalizatio (None, 134, 12, 12)  536         concatenate_10[0][0]             
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 134, 12, 12)  0           dense_1_4_bn[0][0]               
__________________________________________________________________________________________________
dense_1_4_conv2D (Conv2D)       (None, 18, 12, 12)   21708       activation_13[0][0]              
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, 18, 12, 12)   0           dense_1_4_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_11 (Concatenate)    (None, 152, 12, 12)  0           concatenate_10[0][0]             
                                                                 dropout_11[0][0]                 
__________________________________________________________________________________________________
dense_1_5_bn (BatchNormalizatio (None, 152, 12, 12)  608         concatenate_11[0][0]             
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 152, 12, 12)  0           dense_1_5_bn[0][0]               
__________________________________________________________________________________________________
dense_1_5_conv2D (Conv2D)       (None, 18, 12, 12)   24624       activation_14[0][0]              
__________________________________________________________________________________________________
dropout_12 (Dropout)            (None, 18, 12, 12)   0           dense_1_5_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_12 (Concatenate)    (None, 170, 12, 12)  0           concatenate_11[0][0]             
                                                                 dropout_12[0][0]                 
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 170, 12, 12)  680         concatenate_12[0][0]             
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 170, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 24480)        0           activation_15[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            24481       flatten_1[0][0]                  
==================================================================================================
Total params: 202,305
Trainable params: 199,669
Non-trainable params: 2,636
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 63s - loss: 0.4625 - acc: 0.7860 - val_loss: 0.3398 - val_acc: 0.8540
Epoch 2/21
 - 60s - loss: 0.3357 - acc: 0.8595 - val_loss: 0.2781 - val_acc: 0.8874
Epoch 3/21
 - 59s - loss: 0.2821 - acc: 0.8851 - val_loss: 0.3982 - val_acc: 0.8168
Epoch 4/21
 - 59s - loss: 0.2459 - acc: 0.9050 - val_loss: 0.1941 - val_acc: 0.9288
Epoch 5/21
 - 59s - loss: 0.2162 - acc: 0.9176 - val_loss: 0.3093 - val_acc: 0.8650
Epoch 6/21
 - 59s - loss: 0.1924 - acc: 0.9322 - val_loss: 0.1974 - val_acc: 0.9227
Epoch 7/21
 - 59s - loss: 0.1726 - acc: 0.9385 - val_loss: 0.1442 - val_acc: 0.9501
Epoch 8/21
 - 59s - loss: 0.1550 - acc: 0.9473 - val_loss: 0.1231 - val_acc: 0.9621
Epoch 9/21
 - 59s - loss: 0.1401 - acc: 0.9538 - val_loss: 0.1335 - val_acc: 0.9537
Epoch 10/21
 - 59s - loss: 0.1311 - acc: 0.9569 - val_loss: 0.1169 - val_acc: 0.9602
Epoch 11/21
 - 59s - loss: 0.1180 - acc: 0.9625 - val_loss: 0.0980 - val_acc: 0.9715
Epoch 12/21
 - 60s - loss: 0.1125 - acc: 0.9652 - val_loss: 0.0800 - val_acc: 0.9784
Epoch 13/21
 - 59s - loss: 0.1037 - acc: 0.9690 - val_loss: 0.0764 - val_acc: 0.9794
Epoch 14/21
 - 59s - loss: 0.1000 - acc: 0.9698 - val_loss: 0.0766 - val_acc: 0.9785
Epoch 15/21
 - 59s - loss: 0.0909 - acc: 0.9728 - val_loss: 0.0620 - val_acc: 0.9849
Epoch 16/21
 - 59s - loss: 0.0883 - acc: 0.9738 - val_loss: 0.0606 - val_acc: 0.9846
Epoch 17/21
 - 60s - loss: 0.0823 - acc: 0.9764 - val_loss: 0.0556 - val_acc: 0.9858
Epoch 18/21
 - 59s - loss: 0.0775 - acc: 0.9777 - val_loss: 0.0541 - val_acc: 0.9859
Epoch 19/21
 - 59s - loss: 0.0744 - acc: 0.9796 - val_loss: 0.0592 - val_acc: 0.9834
Epoch 20/21
 - 59s - loss: 0.0709 - acc: 0.9807 - val_loss: 0.0545 - val_acc: 0.9849
Epoch 21/21
 - 58s - loss: 0.0680 - acc: 0.9813 - val_loss: 0.0395 - val_acc: 0.9918
Test accuracy:0.842
current auc_score ------------------> 0.930
------------------------ current config for the test -------------------------
Layers:  [6, 6]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   2592        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 34, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 34, 24, 24)   136         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 34, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   5508        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 52, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 52, 24, 24)   208         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 52, 24, 24)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 18, 24, 24)   8424        activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 24, 24)   0           dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 70, 24, 24)   0           concatenate_2[0][0]              
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 70, 24, 24)   280         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 70, 24, 24)   0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 18, 24, 24)   11340       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 24, 24)   0           dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 88, 24, 24)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
dense_0_4_bn (BatchNormalizatio (None, 88, 24, 24)   352         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 88, 24, 24)   0           dense_0_4_bn[0][0]               
__________________________________________________________________________________________________
dense_0_4_conv2D (Conv2D)       (None, 18, 24, 24)   14256       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 18, 24, 24)   0           dense_0_4_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 106, 24, 24)  0           concatenate_4[0][0]              
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_0_5_bn (BatchNormalizatio (None, 106, 24, 24)  424         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 106, 24, 24)  0           dense_0_5_bn[0][0]               
__________________________________________________________________________________________________
dense_0_5_conv2D (Conv2D)       (None, 18, 24, 24)   17172       activation_7[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 18, 24, 24)   0           dense_0_5_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 124, 24, 24)  0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 124, 24, 24)  496         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 124, 24, 24)  0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 62, 24, 24)   7688        activation_8[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 62, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 62, 12, 12)   248         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 62, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   10044       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 80, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 80, 12, 12)   320         concatenate_7[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 80, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   12960       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 98, 12, 12)   0           concatenate_7[0][0]              
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 98, 12, 12)   392         concatenate_8[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 18, 12, 12)   15876       activation_11[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 18, 12, 12)   0           dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_9 (Concatenate)     (None, 116, 12, 12)  0           concatenate_8[0][0]              
                                                                 dropout_9[0][0]                  
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 116, 12, 12)  464         concatenate_9[0][0]              
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 116, 12, 12)  0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 18, 12, 12)   18792       activation_12[0][0]              
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 18, 12, 12)   0           dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_10 (Concatenate)    (None, 134, 12, 12)  0           concatenate_9[0][0]              
                                                                 dropout_10[0][0]                 
__________________________________________________________________________________________________
dense_1_4_bn (BatchNormalizatio (None, 134, 12, 12)  536         concatenate_10[0][0]             
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 134, 12, 12)  0           dense_1_4_bn[0][0]               
__________________________________________________________________________________________________
dense_1_4_conv2D (Conv2D)       (None, 18, 12, 12)   21708       activation_13[0][0]              
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, 18, 12, 12)   0           dense_1_4_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_11 (Concatenate)    (None, 152, 12, 12)  0           concatenate_10[0][0]             
                                                                 dropout_11[0][0]                 
__________________________________________________________________________________________________
dense_1_5_bn (BatchNormalizatio (None, 152, 12, 12)  608         concatenate_11[0][0]             
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 152, 12, 12)  0           dense_1_5_bn[0][0]               
__________________________________________________________________________________________________
dense_1_5_conv2D (Conv2D)       (None, 18, 12, 12)   24624       activation_14[0][0]              
__________________________________________________________________________________________________
dropout_12 (Dropout)            (None, 18, 12, 12)   0           dense_1_5_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_12 (Concatenate)    (None, 170, 12, 12)  0           concatenate_11[0][0]             
                                                                 dropout_12[0][0]                 
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 170, 12, 12)  680         concatenate_12[0][0]             
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 170, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 24480)        0           activation_15[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            24481       flatten_1[0][0]                  
==================================================================================================
Total params: 202,305
Trainable params: 199,669
Non-trainable params: 2,636
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 62s - loss: 0.4487 - acc: 0.7935 - val_loss: 0.3471 - val_acc: 0.8473
Epoch 2/21
 - 58s - loss: 0.3295 - acc: 0.8598 - val_loss: 0.2848 - val_acc: 0.8814
Epoch 3/21
 - 58s - loss: 0.2738 - acc: 0.8909 - val_loss: 0.3609 - val_acc: 0.8400
Epoch 4/21
 - 59s - loss: 0.2344 - acc: 0.9118 - val_loss: 0.3382 - val_acc: 0.8438
Epoch 5/21
 - 59s - loss: 0.2068 - acc: 0.9226 - val_loss: 0.2430 - val_acc: 0.9040
Epoch 6/21
 - 58s - loss: 0.1875 - acc: 0.9330 - val_loss: 0.2039 - val_acc: 0.9217
Epoch 7/21
 - 58s - loss: 0.1685 - acc: 0.9412 - val_loss: 0.1408 - val_acc: 0.9529
Epoch 8/21
 - 58s - loss: 0.1519 - acc: 0.9488 - val_loss: 0.1225 - val_acc: 0.9615
Epoch 9/21
 - 58s - loss: 0.1373 - acc: 0.9544 - val_loss: 0.1253 - val_acc: 0.9582
Epoch 10/21
 - 58s - loss: 0.1269 - acc: 0.9595 - val_loss: 0.1125 - val_acc: 0.9623
Epoch 11/21
 - 58s - loss: 0.1182 - acc: 0.9629 - val_loss: 0.0823 - val_acc: 0.9785
Epoch 12/21
 - 58s - loss: 0.1085 - acc: 0.9664 - val_loss: 0.0814 - val_acc: 0.9779
Epoch 13/21
 - 59s - loss: 0.1017 - acc: 0.9693 - val_loss: 0.0819 - val_acc: 0.9746
Epoch 14/21
 - 58s - loss: 0.0941 - acc: 0.9718 - val_loss: 0.0728 - val_acc: 0.9788
Epoch 15/21
 - 59s - loss: 0.0898 - acc: 0.9738 - val_loss: 0.0631 - val_acc: 0.9837
Epoch 16/21
 - 58s - loss: 0.0849 - acc: 0.9755 - val_loss: 0.0649 - val_acc: 0.9827
Epoch 17/21
 - 58s - loss: 0.0793 - acc: 0.9774 - val_loss: 0.0782 - val_acc: 0.9748
Epoch 18/21
 - 58s - loss: 0.0761 - acc: 0.9794 - val_loss: 0.0672 - val_acc: 0.9789

Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 19/21
 - 58s - loss: 0.0666 - acc: 0.9833 - val_loss: 0.0507 - val_acc: 0.9871
Epoch 20/21
 - 58s - loss: 0.0638 - acc: 0.9841 - val_loss: 0.0554 - val_acc: 0.9847
Epoch 21/21
 - 58s - loss: 0.0626 - acc: 0.9841 - val_loss: 0.0480 - val_acc: 0.9881
Test accuracy:0.829
current auc_score ------------------> 0.914
------------------------ current config for the test -------------------------
Layers:  [6, 6]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   2592        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 34, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 34, 24, 24)   136         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 34, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   5508        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 52, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 52, 24, 24)   208         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 52, 24, 24)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 18, 24, 24)   8424        activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 24, 24)   0           dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 70, 24, 24)   0           concatenate_2[0][0]              
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 70, 24, 24)   280         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 70, 24, 24)   0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 18, 24, 24)   11340       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 24, 24)   0           dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 88, 24, 24)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
dense_0_4_bn (BatchNormalizatio (None, 88, 24, 24)   352         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 88, 24, 24)   0           dense_0_4_bn[0][0]               
__________________________________________________________________________________________________
dense_0_4_conv2D (Conv2D)       (None, 18, 24, 24)   14256       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 18, 24, 24)   0           dense_0_4_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 106, 24, 24)  0           concatenate_4[0][0]              
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_0_5_bn (BatchNormalizatio (None, 106, 24, 24)  424         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 106, 24, 24)  0           dense_0_5_bn[0][0]               
__________________________________________________________________________________________________
dense_0_5_conv2D (Conv2D)       (None, 18, 24, 24)   17172       activation_7[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 18, 24, 24)   0           dense_0_5_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 124, 24, 24)  0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 124, 24, 24)  496         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 124, 24, 24)  0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 62, 24, 24)   7688        activation_8[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 62, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 62, 12, 12)   248         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 62, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   10044       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 80, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 80, 12, 12)   320         concatenate_7[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 80, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   12960       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 98, 12, 12)   0           concatenate_7[0][0]              
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 98, 12, 12)   392         concatenate_8[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 18, 12, 12)   15876       activation_11[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 18, 12, 12)   0           dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_9 (Concatenate)     (None, 116, 12, 12)  0           concatenate_8[0][0]              
                                                                 dropout_9[0][0]                  
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 116, 12, 12)  464         concatenate_9[0][0]              
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 116, 12, 12)  0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 18, 12, 12)   18792       activation_12[0][0]              
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 18, 12, 12)   0           dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_10 (Concatenate)    (None, 134, 12, 12)  0           concatenate_9[0][0]              
                                                                 dropout_10[0][0]                 
__________________________________________________________________________________________________
dense_1_4_bn (BatchNormalizatio (None, 134, 12, 12)  536         concatenate_10[0][0]             
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 134, 12, 12)  0           dense_1_4_bn[0][0]               
__________________________________________________________________________________________________
dense_1_4_conv2D (Conv2D)       (None, 18, 12, 12)   21708       activation_13[0][0]              
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, 18, 12, 12)   0           dense_1_4_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_11 (Concatenate)    (None, 152, 12, 12)  0           concatenate_10[0][0]             
                                                                 dropout_11[0][0]                 
__________________________________________________________________________________________________
dense_1_5_bn (BatchNormalizatio (None, 152, 12, 12)  608         concatenate_11[0][0]             
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 152, 12, 12)  0           dense_1_5_bn[0][0]               
__________________________________________________________________________________________________
dense_1_5_conv2D (Conv2D)       (None, 18, 12, 12)   24624       activation_14[0][0]              
__________________________________________________________________________________________________
dropout_12 (Dropout)            (None, 18, 12, 12)   0           dense_1_5_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_12 (Concatenate)    (None, 170, 12, 12)  0           concatenate_11[0][0]             
                                                                 dropout_12[0][0]                 
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 170, 12, 12)  680         concatenate_12[0][0]             
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 170, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 24480)        0           activation_15[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            24481       flatten_1[0][0]                  
==================================================================================================
Total params: 202,305
Trainable params: 199,669
Non-trainable params: 2,636
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 62s - loss: 0.4529 - acc: 0.7899 - val_loss: 0.3331 - val_acc: 0.8655
Epoch 2/21
 - 58s - loss: 0.3291 - acc: 0.8637 - val_loss: 0.2940 - val_acc: 0.8755
Epoch 3/21
 - 59s - loss: 0.2731 - acc: 0.8918 - val_loss: 0.2732 - val_acc: 0.8847
Epoch 4/21
 - 58s - loss: 0.2360 - acc: 0.9090 - val_loss: 0.1859 - val_acc: 0.9332
Epoch 5/21
 - 59s - loss: 0.2053 - acc: 0.9253 - val_loss: 0.2508 - val_acc: 0.8942
Epoch 6/21
 - 59s - loss: 0.1824 - acc: 0.9359 - val_loss: 0.2019 - val_acc: 0.9234
Epoch 7/21
 - 59s - loss: 0.1659 - acc: 0.9425 - val_loss: 0.1494 - val_acc: 0.9521
Epoch 8/21
 - 58s - loss: 0.1501 - acc: 0.9482 - val_loss: 0.1188 - val_acc: 0.9605
Epoch 9/21
 - 59s - loss: 0.1368 - acc: 0.9547 - val_loss: 0.1281 - val_acc: 0.9578
Epoch 10/21
 - 59s - loss: 0.1271 - acc: 0.9594 - val_loss: 0.1140 - val_acc: 0.9642
Epoch 11/21
 - 59s - loss: 0.1171 - acc: 0.9626 - val_loss: 0.1006 - val_acc: 0.9694
Epoch 12/21
 - 58s - loss: 0.1078 - acc: 0.9659 - val_loss: 0.0825 - val_acc: 0.9770
Epoch 13/21
 - 59s - loss: 0.1030 - acc: 0.9679 - val_loss: 0.0931 - val_acc: 0.9721
Epoch 14/21
 - 59s - loss: 0.0966 - acc: 0.9711 - val_loss: 0.0648 - val_acc: 0.9821
Epoch 15/21
 - 58s - loss: 0.0883 - acc: 0.9743 - val_loss: 0.0637 - val_acc: 0.9832
Epoch 16/21
 - 58s - loss: 0.0840 - acc: 0.9763 - val_loss: 0.0526 - val_acc: 0.9885
Epoch 17/21
 - 58s - loss: 0.0782 - acc: 0.9777 - val_loss: 0.0637 - val_acc: 0.9829
Epoch 18/21
 - 59s - loss: 0.0744 - acc: 0.9790 - val_loss: 0.0475 - val_acc: 0.9877
Epoch 19/21
 - 59s - loss: 0.0700 - acc: 0.9813 - val_loss: 0.0415 - val_acc: 0.9918
Epoch 20/21
 - 59s - loss: 0.0670 - acc: 0.9816 - val_loss: 0.0469 - val_acc: 0.9900
Epoch 21/21
 - 59s - loss: 0.0640 - acc: 0.9831 - val_loss: 0.0389 - val_acc: 0.9925
Test accuracy:0.806
current auc_score ------------------> 0.898
------------------------ current config for the test -------------------------
Layers:  [6, 6]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   2592        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 34, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 34, 24, 24)   136         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 34, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   5508        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 52, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 52, 24, 24)   208         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 52, 24, 24)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 18, 24, 24)   8424        activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 24, 24)   0           dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 70, 24, 24)   0           concatenate_2[0][0]              
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 70, 24, 24)   280         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 70, 24, 24)   0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 18, 24, 24)   11340       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 24, 24)   0           dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 88, 24, 24)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
dense_0_4_bn (BatchNormalizatio (None, 88, 24, 24)   352         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 88, 24, 24)   0           dense_0_4_bn[0][0]               
__________________________________________________________________________________________________
dense_0_4_conv2D (Conv2D)       (None, 18, 24, 24)   14256       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 18, 24, 24)   0           dense_0_4_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 106, 24, 24)  0           concatenate_4[0][0]              
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_0_5_bn (BatchNormalizatio (None, 106, 24, 24)  424         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 106, 24, 24)  0           dense_0_5_bn[0][0]               
__________________________________________________________________________________________________
dense_0_5_conv2D (Conv2D)       (None, 18, 24, 24)   17172       activation_7[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 18, 24, 24)   0           dense_0_5_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 124, 24, 24)  0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 124, 24, 24)  496         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 124, 24, 24)  0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 62, 24, 24)   7688        activation_8[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 62, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 62, 12, 12)   248         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 62, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   10044       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 80, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 80, 12, 12)   320         concatenate_7[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 80, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   12960       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 98, 12, 12)   0           concatenate_7[0][0]              
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 98, 12, 12)   392         concatenate_8[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 18, 12, 12)   15876       activation_11[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 18, 12, 12)   0           dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_9 (Concatenate)     (None, 116, 12, 12)  0           concatenate_8[0][0]              
                                                                 dropout_9[0][0]                  
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 116, 12, 12)  464         concatenate_9[0][0]              
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 116, 12, 12)  0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 18, 12, 12)   18792       activation_12[0][0]              
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 18, 12, 12)   0           dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_10 (Concatenate)    (None, 134, 12, 12)  0           concatenate_9[0][0]              
                                                                 dropout_10[0][0]                 
__________________________________________________________________________________________________
dense_1_4_bn (BatchNormalizatio (None, 134, 12, 12)  536         concatenate_10[0][0]             
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 134, 12, 12)  0           dense_1_4_bn[0][0]               
__________________________________________________________________________________________________
dense_1_4_conv2D (Conv2D)       (None, 18, 12, 12)   21708       activation_13[0][0]              
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, 18, 12, 12)   0           dense_1_4_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_11 (Concatenate)    (None, 152, 12, 12)  0           concatenate_10[0][0]             
                                                                 dropout_11[0][0]                 
__________________________________________________________________________________________________
dense_1_5_bn (BatchNormalizatio (None, 152, 12, 12)  608         concatenate_11[0][0]             
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 152, 12, 12)  0           dense_1_5_bn[0][0]               
__________________________________________________________________________________________________
dense_1_5_conv2D (Conv2D)       (None, 18, 12, 12)   24624       activation_14[0][0]              
__________________________________________________________________________________________________
dropout_12 (Dropout)            (None, 18, 12, 12)   0           dense_1_5_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_12 (Concatenate)    (None, 170, 12, 12)  0           concatenate_11[0][0]             
                                                                 dropout_12[0][0]                 
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 170, 12, 12)  680         concatenate_12[0][0]             
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 170, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 24480)        0           activation_15[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            24481       flatten_1[0][0]                  
==================================================================================================
Total params: 202,305
Trainable params: 199,669
Non-trainable params: 2,636
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 62s - loss: 0.4520 - acc: 0.7923 - val_loss: 0.3386 - val_acc: 0.8594
Epoch 2/21
 - 59s - loss: 0.3260 - acc: 0.8656 - val_loss: 0.3462 - val_acc: 0.8458
Epoch 3/21
 - 59s - loss: 0.2723 - acc: 0.8923 - val_loss: 0.2327 - val_acc: 0.9116
Epoch 4/21
 - 59s - loss: 0.2358 - acc: 0.9115 - val_loss: 0.4074 - val_acc: 0.8163
Epoch 5/21
 - 58s - loss: 0.2072 - acc: 0.9238 - val_loss: 0.2795 - val_acc: 0.8785
Epoch 6/21
 - 59s - loss: 0.1836 - acc: 0.9336 - val_loss: 0.1508 - val_acc: 0.9513
Epoch 7/21
 - 58s - loss: 0.1656 - acc: 0.9422 - val_loss: 0.1362 - val_acc: 0.9553
Epoch 8/21
 - 58s - loss: 0.1515 - acc: 0.9481 - val_loss: 0.1949 - val_acc: 0.9203
Epoch 9/21
 - 58s - loss: 0.1386 - acc: 0.9535 - val_loss: 0.1035 - val_acc: 0.9709
Epoch 10/21
 - 58s - loss: 0.1276 - acc: 0.9578 - val_loss: 0.0964 - val_acc: 0.9713
Epoch 11/21
 - 58s - loss: 0.1173 - acc: 0.9622 - val_loss: 0.0900 - val_acc: 0.9729
Epoch 12/21
 - 58s - loss: 0.1076 - acc: 0.9665 - val_loss: 0.0855 - val_acc: 0.9749
Epoch 13/21
 - 59s - loss: 0.1023 - acc: 0.9695 - val_loss: 0.0760 - val_acc: 0.9798
Epoch 14/21
 - 58s - loss: 0.0940 - acc: 0.9715 - val_loss: 0.0716 - val_acc: 0.9804
Epoch 15/21
 - 58s - loss: 0.0891 - acc: 0.9743 - val_loss: 0.0871 - val_acc: 0.9700
Epoch 16/21
 - 58s - loss: 0.0839 - acc: 0.9760 - val_loss: 0.0573 - val_acc: 0.9861
Epoch 17/21
 - 58s - loss: 0.0774 - acc: 0.9782 - val_loss: 0.1022 - val_acc: 0.9654
Epoch 18/21
 - 58s - loss: 0.0745 - acc: 0.9793 - val_loss: 0.0584 - val_acc: 0.9842
Epoch 19/21
 - 58s - loss: 0.0711 - acc: 0.9809 - val_loss: 0.0496 - val_acc: 0.9893
Epoch 20/21
 - 58s - loss: 0.0679 - acc: 0.9814 - val_loss: 0.0424 - val_acc: 0.9907
Epoch 21/21
 - 58s - loss: 0.0633 - acc: 0.9830 - val_loss: 0.0425 - val_acc: 0.9912
Test accuracy:0.828
current auc_score ------------------> 0.910
------------------------ current config for the test -------------------------
Layers:  [6, 6]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   2592        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 34, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 34, 24, 24)   136         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 34, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   5508        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 52, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 52, 24, 24)   208         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 52, 24, 24)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 18, 24, 24)   8424        activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 24, 24)   0           dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 70, 24, 24)   0           concatenate_2[0][0]              
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 70, 24, 24)   280         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 70, 24, 24)   0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 18, 24, 24)   11340       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 24, 24)   0           dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 88, 24, 24)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
dense_0_4_bn (BatchNormalizatio (None, 88, 24, 24)   352         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 88, 24, 24)   0           dense_0_4_bn[0][0]               
__________________________________________________________________________________________________
dense_0_4_conv2D (Conv2D)       (None, 18, 24, 24)   14256       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 18, 24, 24)   0           dense_0_4_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 106, 24, 24)  0           concatenate_4[0][0]              
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_0_5_bn (BatchNormalizatio (None, 106, 24, 24)  424         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 106, 24, 24)  0           dense_0_5_bn[0][0]               
__________________________________________________________________________________________________
dense_0_5_conv2D (Conv2D)       (None, 18, 24, 24)   17172       activation_7[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 18, 24, 24)   0           dense_0_5_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 124, 24, 24)  0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 124, 24, 24)  496         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 124, 24, 24)  0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 62, 24, 24)   7688        activation_8[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 62, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 62, 12, 12)   248         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 62, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   10044       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 80, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 80, 12, 12)   320         concatenate_7[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 80, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   12960       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 98, 12, 12)   0           concatenate_7[0][0]              
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 98, 12, 12)   392         concatenate_8[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 18, 12, 12)   15876       activation_11[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 18, 12, 12)   0           dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_9 (Concatenate)     (None, 116, 12, 12)  0           concatenate_8[0][0]              
                                                                 dropout_9[0][0]                  
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 116, 12, 12)  464         concatenate_9[0][0]              
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 116, 12, 12)  0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 18, 12, 12)   18792       activation_12[0][0]              
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 18, 12, 12)   0           dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_10 (Concatenate)    (None, 134, 12, 12)  0           concatenate_9[0][0]              
                                                                 dropout_10[0][0]                 
__________________________________________________________________________________________________
dense_1_4_bn (BatchNormalizatio (None, 134, 12, 12)  536         concatenate_10[0][0]             
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 134, 12, 12)  0           dense_1_4_bn[0][0]               
__________________________________________________________________________________________________
dense_1_4_conv2D (Conv2D)       (None, 18, 12, 12)   21708       activation_13[0][0]              
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, 18, 12, 12)   0           dense_1_4_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_11 (Concatenate)    (None, 152, 12, 12)  0           concatenate_10[0][0]             
                                                                 dropout_11[0][0]                 
__________________________________________________________________________________________________
dense_1_5_bn (BatchNormalizatio (None, 152, 12, 12)  608         concatenate_11[0][0]             
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 152, 12, 12)  0           dense_1_5_bn[0][0]               
__________________________________________________________________________________________________
dense_1_5_conv2D (Conv2D)       (None, 18, 12, 12)   24624       activation_14[0][0]              
__________________________________________________________________________________________________
dropout_12 (Dropout)            (None, 18, 12, 12)   0           dense_1_5_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_12 (Concatenate)    (None, 170, 12, 12)  0           concatenate_11[0][0]             
                                                                 dropout_12[0][0]                 
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 170, 12, 12)  680         concatenate_12[0][0]             
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 170, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 24480)        0           activation_15[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            24481       flatten_1[0][0]                  
==================================================================================================
Total params: 202,305
Trainable params: 199,669
Non-trainable params: 2,636
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 62s - loss: 0.4433 - acc: 0.7969 - val_loss: 0.3251 - val_acc: 0.8642
Epoch 2/21
 - 59s - loss: 0.3168 - acc: 0.8710 - val_loss: 0.2489 - val_acc: 0.9041
Epoch 3/21
 - 59s - loss: 0.2606 - acc: 0.8976 - val_loss: 0.2318 - val_acc: 0.9081
Epoch 4/21
 - 59s - loss: 0.2264 - acc: 0.9155 - val_loss: 0.1847 - val_acc: 0.9351
Epoch 5/21
 - 59s - loss: 0.1995 - acc: 0.9292 - val_loss: 0.1600 - val_acc: 0.9468
Epoch 6/21
 - 59s - loss: 0.1776 - acc: 0.9385 - val_loss: 0.1637 - val_acc: 0.9403
Epoch 7/21
 - 59s - loss: 0.1603 - acc: 0.9454 - val_loss: 0.1365 - val_acc: 0.9566
Epoch 8/21
 - 59s - loss: 0.1481 - acc: 0.9498 - val_loss: 0.1161 - val_acc: 0.9602
Epoch 9/21
 - 58s - loss: 0.1344 - acc: 0.9555 - val_loss: 0.0995 - val_acc: 0.9701
Epoch 10/21
 - 58s - loss: 0.1243 - acc: 0.9608 - val_loss: 0.0982 - val_acc: 0.9674
Epoch 11/21
 - 59s - loss: 0.1150 - acc: 0.9638 - val_loss: 0.1055 - val_acc: 0.9644
Epoch 12/21
 - 59s - loss: 0.1068 - acc: 0.9663 - val_loss: 0.0884 - val_acc: 0.9757
Epoch 13/21
 - 59s - loss: 0.1002 - acc: 0.9698 - val_loss: 0.0630 - val_acc: 0.9856
Epoch 14/21
 - 58s - loss: 0.0919 - acc: 0.9726 - val_loss: 0.0842 - val_acc: 0.9709
Epoch 15/21
 - 59s - loss: 0.0884 - acc: 0.9743 - val_loss: 0.0548 - val_acc: 0.9882
Epoch 16/21
 - 59s - loss: 0.0819 - acc: 0.9771 - val_loss: 0.0508 - val_acc: 0.9881
Epoch 17/21
 - 59s - loss: 0.0772 - acc: 0.9775 - val_loss: 0.0606 - val_acc: 0.9841
Epoch 18/21
 - 59s - loss: 0.0736 - acc: 0.9797 - val_loss: 0.0446 - val_acc: 0.9900
Epoch 19/21
 - 59s - loss: 0.0696 - acc: 0.9804 - val_loss: 0.0548 - val_acc: 0.9854
Epoch 20/21
 - 59s - loss: 0.0656 - acc: 0.9823 - val_loss: 0.0369 - val_acc: 0.9936
Epoch 21/21
 - 59s - loss: 0.0639 - acc: 0.9828 - val_loss: 0.0381 - val_acc: 0.9926
Test accuracy:0.802
current auc_score ------------------> 0.904
------------------------ current config for the test -------------------------
Layers:  [6, 6]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   2592        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 34, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 34, 24, 24)   136         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 34, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   5508        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 52, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 52, 24, 24)   208         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 52, 24, 24)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 18, 24, 24)   8424        activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 24, 24)   0           dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 70, 24, 24)   0           concatenate_2[0][0]              
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 70, 24, 24)   280         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 70, 24, 24)   0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 18, 24, 24)   11340       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 24, 24)   0           dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 88, 24, 24)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
dense_0_4_bn (BatchNormalizatio (None, 88, 24, 24)   352         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 88, 24, 24)   0           dense_0_4_bn[0][0]               
__________________________________________________________________________________________________
dense_0_4_conv2D (Conv2D)       (None, 18, 24, 24)   14256       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 18, 24, 24)   0           dense_0_4_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 106, 24, 24)  0           concatenate_4[0][0]              
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_0_5_bn (BatchNormalizatio (None, 106, 24, 24)  424         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 106, 24, 24)  0           dense_0_5_bn[0][0]               
__________________________________________________________________________________________________
dense_0_5_conv2D (Conv2D)       (None, 18, 24, 24)   17172       activation_7[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 18, 24, 24)   0           dense_0_5_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 124, 24, 24)  0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 124, 24, 24)  496         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 124, 24, 24)  0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 62, 24, 24)   7688        activation_8[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 62, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 62, 12, 12)   248         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 62, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   10044       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 80, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 80, 12, 12)   320         concatenate_7[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 80, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   12960       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 98, 12, 12)   0           concatenate_7[0][0]              
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 98, 12, 12)   392         concatenate_8[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 18, 12, 12)   15876       activation_11[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 18, 12, 12)   0           dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_9 (Concatenate)     (None, 116, 12, 12)  0           concatenate_8[0][0]              
                                                                 dropout_9[0][0]                  
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 116, 12, 12)  464         concatenate_9[0][0]              
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 116, 12, 12)  0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 18, 12, 12)   18792       activation_12[0][0]              
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 18, 12, 12)   0           dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_10 (Concatenate)    (None, 134, 12, 12)  0           concatenate_9[0][0]              
                                                                 dropout_10[0][0]                 
__________________________________________________________________________________________________
dense_1_4_bn (BatchNormalizatio (None, 134, 12, 12)  536         concatenate_10[0][0]             
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 134, 12, 12)  0           dense_1_4_bn[0][0]               
__________________________________________________________________________________________________
dense_1_4_conv2D (Conv2D)       (None, 18, 12, 12)   21708       activation_13[0][0]              
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, 18, 12, 12)   0           dense_1_4_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_11 (Concatenate)    (None, 152, 12, 12)  0           concatenate_10[0][0]             
                                                                 dropout_11[0][0]                 
__________________________________________________________________________________________________
dense_1_5_bn (BatchNormalizatio (None, 152, 12, 12)  608         concatenate_11[0][0]             
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 152, 12, 12)  0           dense_1_5_bn[0][0]               
__________________________________________________________________________________________________
dense_1_5_conv2D (Conv2D)       (None, 18, 12, 12)   24624       activation_14[0][0]              
__________________________________________________________________________________________________
dropout_12 (Dropout)            (None, 18, 12, 12)   0           dense_1_5_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_12 (Concatenate)    (None, 170, 12, 12)  0           concatenate_11[0][0]             
                                                                 dropout_12[0][0]                 
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 170, 12, 12)  680         concatenate_12[0][0]             
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 170, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 24480)        0           activation_15[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            24481       flatten_1[0][0]                  
==================================================================================================
Total params: 202,305
Trainable params: 199,669
Non-trainable params: 2,636
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 62s - loss: 0.4491 - acc: 0.7963 - val_loss: 0.3325 - val_acc: 0.8571
Epoch 2/21
 - 58s - loss: 0.3222 - acc: 0.8660 - val_loss: 0.4333 - val_acc: 0.7982
Epoch 3/21
 - 58s - loss: 0.2649 - acc: 0.8969 - val_loss: 0.2268 - val_acc: 0.9162
Epoch 4/21
 - 59s - loss: 0.2255 - acc: 0.9160 - val_loss: 0.2794 - val_acc: 0.8820
Epoch 5/21
 - 59s - loss: 0.1961 - acc: 0.9298 - val_loss: 0.2161 - val_acc: 0.9164
Epoch 6/21
 - 59s - loss: 0.1731 - acc: 0.9394 - val_loss: 0.2292 - val_acc: 0.9099
Epoch 7/21
 - 59s - loss: 0.1582 - acc: 0.9473 - val_loss: 0.1179 - val_acc: 0.9626
Epoch 8/21
 - 58s - loss: 0.1434 - acc: 0.9530 - val_loss: 0.1590 - val_acc: 0.9434
Epoch 9/21
 - 58s - loss: 0.1301 - acc: 0.9579 - val_loss: 0.0932 - val_acc: 0.9726
Epoch 10/21
 - 58s - loss: 0.1196 - acc: 0.9626 - val_loss: 0.0948 - val_acc: 0.9715
Epoch 11/21
 - 60s - loss: 0.1089 - acc: 0.9664 - val_loss: 0.0843 - val_acc: 0.9745
Epoch 12/21
 - 60s - loss: 0.1041 - acc: 0.9682 - val_loss: 0.1075 - val_acc: 0.9655
Epoch 13/21
 - 59s - loss: 0.0973 - acc: 0.9708 - val_loss: 0.0613 - val_acc: 0.9861
Epoch 14/21
 - 59s - loss: 0.0907 - acc: 0.9737 - val_loss: 0.0939 - val_acc: 0.9701
Epoch 15/21
 - 60s - loss: 0.0821 - acc: 0.9768 - val_loss: 0.0811 - val_acc: 0.9752
Epoch 16/21
 - 60s - loss: 0.0812 - acc: 0.9767 - val_loss: 0.0547 - val_acc: 0.9873
Epoch 17/21
 - 59s - loss: 0.0747 - acc: 0.9802 - val_loss: 0.0604 - val_acc: 0.9832
Epoch 18/21
 - 60s - loss: 0.0700 - acc: 0.9812 - val_loss: 0.0466 - val_acc: 0.9897
Epoch 19/21
 - 60s - loss: 0.0681 - acc: 0.9819 - val_loss: 0.0410 - val_acc: 0.9930
Epoch 20/21
 - 59s - loss: 0.0659 - acc: 0.9822 - val_loss: 0.0376 - val_acc: 0.9937
Epoch 21/21
 - 59s - loss: 0.0597 - acc: 0.9851 - val_loss: 0.0374 - val_acc: 0.9931
Test accuracy:0.800
current auc_score ------------------> 0.911
------------------------ current config for the test -------------------------
Layers:  [6, 6]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   2592        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 34, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 34, 24, 24)   136         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 34, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   5508        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 52, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 52, 24, 24)   208         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 52, 24, 24)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 18, 24, 24)   8424        activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 24, 24)   0           dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 70, 24, 24)   0           concatenate_2[0][0]              
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 70, 24, 24)   280         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 70, 24, 24)   0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 18, 24, 24)   11340       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 24, 24)   0           dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 88, 24, 24)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
dense_0_4_bn (BatchNormalizatio (None, 88, 24, 24)   352         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 88, 24, 24)   0           dense_0_4_bn[0][0]               
__________________________________________________________________________________________________
dense_0_4_conv2D (Conv2D)       (None, 18, 24, 24)   14256       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 18, 24, 24)   0           dense_0_4_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 106, 24, 24)  0           concatenate_4[0][0]              
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_0_5_bn (BatchNormalizatio (None, 106, 24, 24)  424         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 106, 24, 24)  0           dense_0_5_bn[0][0]               
__________________________________________________________________________________________________
dense_0_5_conv2D (Conv2D)       (None, 18, 24, 24)   17172       activation_7[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 18, 24, 24)   0           dense_0_5_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 124, 24, 24)  0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 124, 24, 24)  496         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 124, 24, 24)  0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 62, 24, 24)   7688        activation_8[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 62, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 62, 12, 12)   248         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 62, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   10044       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 80, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 80, 12, 12)   320         concatenate_7[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 80, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   12960       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 98, 12, 12)   0           concatenate_7[0][0]              
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 98, 12, 12)   392         concatenate_8[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 18, 12, 12)   15876       activation_11[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 18, 12, 12)   0           dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_9 (Concatenate)     (None, 116, 12, 12)  0           concatenate_8[0][0]              
                                                                 dropout_9[0][0]                  
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 116, 12, 12)  464         concatenate_9[0][0]              
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 116, 12, 12)  0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 18, 12, 12)   18792       activation_12[0][0]              
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 18, 12, 12)   0           dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_10 (Concatenate)    (None, 134, 12, 12)  0           concatenate_9[0][0]              
                                                                 dropout_10[0][0]                 
__________________________________________________________________________________________________
dense_1_4_bn (BatchNormalizatio (None, 134, 12, 12)  536         concatenate_10[0][0]             
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 134, 12, 12)  0           dense_1_4_bn[0][0]               
__________________________________________________________________________________________________
dense_1_4_conv2D (Conv2D)       (None, 18, 12, 12)   21708       activation_13[0][0]              
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, 18, 12, 12)   0           dense_1_4_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_11 (Concatenate)    (None, 152, 12, 12)  0           concatenate_10[0][0]             
                                                                 dropout_11[0][0]                 
__________________________________________________________________________________________________
dense_1_5_bn (BatchNormalizatio (None, 152, 12, 12)  608         concatenate_11[0][0]             
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 152, 12, 12)  0           dense_1_5_bn[0][0]               
__________________________________________________________________________________________________
dense_1_5_conv2D (Conv2D)       (None, 18, 12, 12)   24624       activation_14[0][0]              
__________________________________________________________________________________________________
dropout_12 (Dropout)            (None, 18, 12, 12)   0           dense_1_5_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_12 (Concatenate)    (None, 170, 12, 12)  0           concatenate_11[0][0]             
                                                                 dropout_12[0][0]                 
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 170, 12, 12)  680         concatenate_12[0][0]             
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 170, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 24480)        0           activation_15[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            24481       flatten_1[0][0]                  
==================================================================================================
Total params: 202,305
Trainable params: 199,669
Non-trainable params: 2,636
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 63s - loss: 0.4577 - acc: 0.7889 - val_loss: 0.3505 - val_acc: 0.8485
Epoch 2/21
 - 59s - loss: 0.3278 - acc: 0.8635 - val_loss: 0.2731 - val_acc: 0.8888
Epoch 3/21
 - 59s - loss: 0.2736 - acc: 0.8917 - val_loss: 0.2406 - val_acc: 0.9064
Epoch 4/21
 - 59s - loss: 0.2338 - acc: 0.9111 - val_loss: 0.1878 - val_acc: 0.9327
Epoch 5/21
 - 59s - loss: 0.2059 - acc: 0.9247 - val_loss: 0.1660 - val_acc: 0.9425
Epoch 6/21
 - 60s - loss: 0.1844 - acc: 0.9347 - val_loss: 0.1493 - val_acc: 0.9537
Epoch 7/21
 - 59s - loss: 0.1645 - acc: 0.9441 - val_loss: 0.1391 - val_acc: 0.9482
Epoch 8/21
 - 59s - loss: 0.1505 - acc: 0.9500 - val_loss: 0.1245 - val_acc: 0.9566
Epoch 9/21
 - 60s - loss: 0.1381 - acc: 0.9536 - val_loss: 0.1224 - val_acc: 0.9558
Epoch 10/21
 - 60s - loss: 0.1260 - acc: 0.9598 - val_loss: 0.1013 - val_acc: 0.9689
Epoch 11/21
 - 59s - loss: 0.1154 - acc: 0.9633 - val_loss: 0.0898 - val_acc: 0.9714
Epoch 12/21
 - 60s - loss: 0.1106 - acc: 0.9654 - val_loss: 0.0744 - val_acc: 0.9794
Epoch 13/21
 - 60s - loss: 0.1006 - acc: 0.9701 - val_loss: 0.0725 - val_acc: 0.9808
Epoch 14/21
 - 59s - loss: 0.0957 - acc: 0.9716 - val_loss: 0.0642 - val_acc: 0.9833
Epoch 15/21
 - 59s - loss: 0.0889 - acc: 0.9737 - val_loss: 0.0639 - val_acc: 0.9819
Epoch 16/21
 - 60s - loss: 0.0851 - acc: 0.9748 - val_loss: 0.0625 - val_acc: 0.9833
Epoch 17/21
 - 59s - loss: 0.0809 - acc: 0.9774 - val_loss: 0.0606 - val_acc: 0.9831
Epoch 18/21
 - 59s - loss: 0.0771 - acc: 0.9786 - val_loss: 0.0532 - val_acc: 0.9872
Epoch 19/21
 - 59s - loss: 0.0727 - acc: 0.9793 - val_loss: 0.0437 - val_acc: 0.9917
Epoch 20/21
 - 60s - loss: 0.0694 - acc: 0.9807 - val_loss: 0.0507 - val_acc: 0.9877
Epoch 21/21
 - 59s - loss: 0.0662 - acc: 0.9825 - val_loss: 0.0433 - val_acc: 0.9925
Test accuracy:0.788
current auc_score ------------------> 0.914
------------------------ current config for the test -------------------------
Layers:  [6, 6]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  21  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   2592        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 34, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 34, 24, 24)   136         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 34, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   5508        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 52, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 52, 24, 24)   208         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 52, 24, 24)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 18, 24, 24)   8424        activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 24, 24)   0           dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 70, 24, 24)   0           concatenate_2[0][0]              
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 70, 24, 24)   280         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 70, 24, 24)   0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 18, 24, 24)   11340       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 24, 24)   0           dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 88, 24, 24)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
dense_0_4_bn (BatchNormalizatio (None, 88, 24, 24)   352         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 88, 24, 24)   0           dense_0_4_bn[0][0]               
__________________________________________________________________________________________________
dense_0_4_conv2D (Conv2D)       (None, 18, 24, 24)   14256       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 18, 24, 24)   0           dense_0_4_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 106, 24, 24)  0           concatenate_4[0][0]              
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_0_5_bn (BatchNormalizatio (None, 106, 24, 24)  424         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 106, 24, 24)  0           dense_0_5_bn[0][0]               
__________________________________________________________________________________________________
dense_0_5_conv2D (Conv2D)       (None, 18, 24, 24)   17172       activation_7[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 18, 24, 24)   0           dense_0_5_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 124, 24, 24)  0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 124, 24, 24)  496         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 124, 24, 24)  0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 62, 24, 24)   7688        activation_8[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 62, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 62, 12, 12)   248         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 62, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   10044       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 80, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 80, 12, 12)   320         concatenate_7[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 80, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   12960       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 98, 12, 12)   0           concatenate_7[0][0]              
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 98, 12, 12)   392         concatenate_8[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 18, 12, 12)   15876       activation_11[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 18, 12, 12)   0           dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_9 (Concatenate)     (None, 116, 12, 12)  0           concatenate_8[0][0]              
                                                                 dropout_9[0][0]                  
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 116, 12, 12)  464         concatenate_9[0][0]              
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 116, 12, 12)  0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 18, 12, 12)   18792       activation_12[0][0]              
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 18, 12, 12)   0           dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_10 (Concatenate)    (None, 134, 12, 12)  0           concatenate_9[0][0]              
                                                                 dropout_10[0][0]                 
__________________________________________________________________________________________________
dense_1_4_bn (BatchNormalizatio (None, 134, 12, 12)  536         concatenate_10[0][0]             
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 134, 12, 12)  0           dense_1_4_bn[0][0]               
__________________________________________________________________________________________________
dense_1_4_conv2D (Conv2D)       (None, 18, 12, 12)   21708       activation_13[0][0]              
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, 18, 12, 12)   0           dense_1_4_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_11 (Concatenate)    (None, 152, 12, 12)  0           concatenate_10[0][0]             
                                                                 dropout_11[0][0]                 
__________________________________________________________________________________________________
dense_1_5_bn (BatchNormalizatio (None, 152, 12, 12)  608         concatenate_11[0][0]             
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 152, 12, 12)  0           dense_1_5_bn[0][0]               
__________________________________________________________________________________________________
dense_1_5_conv2D (Conv2D)       (None, 18, 12, 12)   24624       activation_14[0][0]              
__________________________________________________________________________________________________
dropout_12 (Dropout)            (None, 18, 12, 12)   0           dense_1_5_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_12 (Concatenate)    (None, 170, 12, 12)  0           concatenate_11[0][0]             
                                                                 dropout_12[0][0]                 
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 170, 12, 12)  680         concatenate_12[0][0]             
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 170, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 24480)        0           activation_15[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            24481       flatten_1[0][0]                  
==================================================================================================
Total params: 202,305
Trainable params: 199,669
Non-trainable params: 2,636
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 63s - loss: 0.4473 - acc: 0.7910 - val_loss: 0.3485 - val_acc: 0.8522
Epoch 2/21
 - 59s - loss: 0.3281 - acc: 0.8638 - val_loss: 0.3542 - val_acc: 0.8345
Epoch 3/21
 - 59s - loss: 0.2735 - acc: 0.8891 - val_loss: 0.2361 - val_acc: 0.9123
Epoch 4/21
 - 59s - loss: 0.2389 - acc: 0.9090 - val_loss: 0.1979 - val_acc: 0.9282
Epoch 5/21
 - 59s - loss: 0.2089 - acc: 0.9231 - val_loss: 0.2053 - val_acc: 0.9206
Epoch 6/21
 - 59s - loss: 0.1882 - acc: 0.9325 - val_loss: 0.1662 - val_acc: 0.9430
Epoch 7/21
 - 59s - loss: 0.1681 - acc: 0.9401 - val_loss: 0.1339 - val_acc: 0.9562
Epoch 8/21
 - 59s - loss: 0.1530 - acc: 0.9479 - val_loss: 0.1566 - val_acc: 0.9425
Epoch 9/21
 - 59s - loss: 0.1391 - acc: 0.9543 - val_loss: 0.1343 - val_acc: 0.9558
Epoch 10/21
 - 59s - loss: 0.1308 - acc: 0.9577 - val_loss: 0.0987 - val_acc: 0.9693
Epoch 11/21
 - 60s - loss: 0.1209 - acc: 0.9611 - val_loss: 0.0881 - val_acc: 0.9733
Epoch 12/21
 - 60s - loss: 0.1114 - acc: 0.9658 - val_loss: 0.0959 - val_acc: 0.9690
Epoch 13/21
 - 59s - loss: 0.1044 - acc: 0.9683 - val_loss: 0.0920 - val_acc: 0.9710
Epoch 14/21
 - 59s - loss: 0.0962 - acc: 0.9706 - val_loss: 0.0686 - val_acc: 0.9809
Epoch 15/21
 - 59s - loss: 0.0925 - acc: 0.9727 - val_loss: 0.0648 - val_acc: 0.9813
Epoch 16/21
 - 59s - loss: 0.0862 - acc: 0.9747 - val_loss: 0.0907 - val_acc: 0.9696
Epoch 17/21
 - 59s - loss: 0.0809 - acc: 0.9770 - val_loss: 0.0522 - val_acc: 0.9883
Epoch 18/21
 - 59s - loss: 0.0781 - acc: 0.9778 - val_loss: 0.0582 - val_acc: 0.9839
Epoch 19/21
 - 59s - loss: 0.0737 - acc: 0.9797 - val_loss: 0.0502 - val_acc: 0.9873
Epoch 20/21
 - 59s - loss: 0.0694 - acc: 0.9816 - val_loss: 0.0473 - val_acc: 0.9902
Epoch 21/21
 - 59s - loss: 0.0662 - acc: 0.9825 - val_loss: 0.0768 - val_acc: 0.9743
Test accuracy:0.845
current auc_score ------------------> 0.924
accuracies:  [0.8297043010752688, 0.8588709677419355, 0.8418010752688172, 0.8294354838709678, 0.8061827956989247, 0.8275537634408602, 0.802016129032258, 0.7997311827956989, 0.7879032258064517, 0.8450268817204301]
aucs:  [0.9203, 0.9261, 0.9297, 0.9142, 0.8977, 0.9105, 0.9044, 0.9113, 0.9145, 0.9239]
mean and std AUC:  0.915+/-0.009  max:   0.9297
['6-6', '24', '2', '16', '0.2', '0.07', '19', 'adadelta', '0.5', 'FALSE', '64', 'flatten']
------------------------ current config for the test -------------------------
Layers:  [6, 6]  Growth_rate:  24  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  19  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 24, 24, 24)   3456        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 24, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 40, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 40, 24, 24)   160         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 40, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 24, 24, 24)   8640        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 64, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 64, 24, 24)   256         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 64, 24, 24)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 24, 24, 24)   13824       activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 24, 24, 24)   0           dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 88, 24, 24)   0           concatenate_2[0][0]              
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 88, 24, 24)   352         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 88, 24, 24)   0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 24, 24, 24)   19008       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 24, 24, 24)   0           dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 112, 24, 24)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
dense_0_4_bn (BatchNormalizatio (None, 112, 24, 24)  448         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 112, 24, 24)  0           dense_0_4_bn[0][0]               
__________________________________________________________________________________________________
dense_0_4_conv2D (Conv2D)       (None, 24, 24, 24)   24192       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 24, 24, 24)   0           dense_0_4_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 136, 24, 24)  0           concatenate_4[0][0]              
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_0_5_bn (BatchNormalizatio (None, 136, 24, 24)  544         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 136, 24, 24)  0           dense_0_5_bn[0][0]               
__________________________________________________________________________________________________
dense_0_5_conv2D (Conv2D)       (None, 24, 24, 24)   29376       activation_7[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 24, 24, 24)   0           dense_0_5_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 160, 24, 24)  0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 160, 24, 24)  640         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 160, 24, 24)  0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 80, 24, 24)   12800       activation_8[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 80, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 80, 12, 12)   320         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 80, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 24, 12, 12)   17280       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 24, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 104, 12, 12)  0           average_pooling2d_1[0][0]        
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 104, 12, 12)  416         concatenate_7[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 104, 12, 12)  0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 24, 12, 12)   22464       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 24, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 128, 12, 12)  0           concatenate_7[0][0]              
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 128, 12, 12)  512         concatenate_8[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 128, 12, 12)  0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 24, 12, 12)   27648       activation_11[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 24, 12, 12)   0           dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_9 (Concatenate)     (None, 152, 12, 12)  0           concatenate_8[0][0]              
                                                                 dropout_9[0][0]                  
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 152, 12, 12)  608         concatenate_9[0][0]              
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 152, 12, 12)  0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 24, 12, 12)   32832       activation_12[0][0]              
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 24, 12, 12)   0           dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_10 (Concatenate)    (None, 176, 12, 12)  0           concatenate_9[0][0]              
                                                                 dropout_10[0][0]                 
__________________________________________________________________________________________________
dense_1_4_bn (BatchNormalizatio (None, 176, 12, 12)  704         concatenate_10[0][0]             
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 176, 12, 12)  0           dense_1_4_bn[0][0]               
__________________________________________________________________________________________________
dense_1_4_conv2D (Conv2D)       (None, 24, 12, 12)   38016       activation_13[0][0]              
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, 24, 12, 12)   0           dense_1_4_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_11 (Concatenate)    (None, 200, 12, 12)  0           concatenate_10[0][0]             
                                                                 dropout_11[0][0]                 
__________________________________________________________________________________________________
dense_1_5_bn (BatchNormalizatio (None, 200, 12, 12)  800         concatenate_11[0][0]             
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 200, 12, 12)  0           dense_1_5_bn[0][0]               
__________________________________________________________________________________________________
dense_1_5_conv2D (Conv2D)       (None, 24, 12, 12)   43200       activation_14[0][0]              
__________________________________________________________________________________________________
dropout_12 (Dropout)            (None, 24, 12, 12)   0           dense_1_5_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_12 (Concatenate)    (None, 224, 12, 12)  0           concatenate_11[0][0]             
                                                                 dropout_12[0][0]                 
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 224, 12, 12)  896         concatenate_12[0][0]             
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 224, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 32256)        0           activation_15[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            32257       flatten_1[0][0]                  
==================================================================================================
Total params: 333,345
Trainable params: 329,953
Non-trainable params: 3,392
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/19
 - 73s - loss: 0.4441 - acc: 0.8031 - val_loss: 0.3169 - val_acc: 0.8763
Epoch 2/19
 - 70s - loss: 0.3048 - acc: 0.8784 - val_loss: 0.2300 - val_acc: 0.9143
Epoch 3/19
 - 70s - loss: 0.2463 - acc: 0.9079 - val_loss: 0.1940 - val_acc: 0.9302
Epoch 4/19
 - 70s - loss: 0.2041 - acc: 0.9280 - val_loss: 0.1628 - val_acc: 0.9448
Epoch 5/19
 - 69s - loss: 0.1782 - acc: 0.9392 - val_loss: 0.1515 - val_acc: 0.9483
Epoch 6/19
 - 70s - loss: 0.1565 - acc: 0.9479 - val_loss: 0.1788 - val_acc: 0.9352
Epoch 7/19
 - 69s - loss: 0.1367 - acc: 0.9564 - val_loss: 0.1086 - val_acc: 0.9652
Epoch 8/19
 - 69s - loss: 0.1234 - acc: 0.9620 - val_loss: 0.0965 - val_acc: 0.9724
Epoch 9/19
 - 69s - loss: 0.1118 - acc: 0.9665 - val_loss: 0.0813 - val_acc: 0.9765
Epoch 10/19
 - 69s - loss: 0.1017 - acc: 0.9713 - val_loss: 0.0893 - val_acc: 0.9711
Epoch 11/19
 - 69s - loss: 0.0935 - acc: 0.9735 - val_loss: 0.0768 - val_acc: 0.9790
Epoch 12/19
 - 70s - loss: 0.0865 - acc: 0.9757 - val_loss: 0.0893 - val_acc: 0.9701
Epoch 13/19
 - 70s - loss: 0.0785 - acc: 0.9796 - val_loss: 0.0554 - val_acc: 0.9857
Epoch 14/19
 - 70s - loss: 0.0738 - acc: 0.9803 - val_loss: 0.0622 - val_acc: 0.9823
Epoch 15/19
 - 70s - loss: 0.0677 - acc: 0.9832 - val_loss: 0.0560 - val_acc: 0.9876
Epoch 16/19
 - 70s - loss: 0.0651 - acc: 0.9834 - val_loss: 0.0423 - val_acc: 0.9912
Epoch 17/19
 - 70s - loss: 0.0600 - acc: 0.9860 - val_loss: 0.0388 - val_acc: 0.9915
Epoch 18/19
 - 69s - loss: 0.0571 - acc: 0.9869 - val_loss: 0.0396 - val_acc: 0.9936
Epoch 19/19
 - 70s - loss: 0.0543 - acc: 0.9877 - val_loss: 0.0369 - val_acc: 0.9935
Test accuracy:0.846
current auc_score ------------------> 0.916
------------------------ current config for the test -------------------------
Layers:  [6, 6]  Growth_rate:  24  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  19  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 24, 24, 24)   3456        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 24, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 40, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 40, 24, 24)   160         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 40, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 24, 24, 24)   8640        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 64, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 64, 24, 24)   256         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 64, 24, 24)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 24, 24, 24)   13824       activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 24, 24, 24)   0           dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 88, 24, 24)   0           concatenate_2[0][0]              
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 88, 24, 24)   352         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 88, 24, 24)   0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 24, 24, 24)   19008       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 24, 24, 24)   0           dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 112, 24, 24)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
dense_0_4_bn (BatchNormalizatio (None, 112, 24, 24)  448         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 112, 24, 24)  0           dense_0_4_bn[0][0]               
__________________________________________________________________________________________________
dense_0_4_conv2D (Conv2D)       (None, 24, 24, 24)   24192       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 24, 24, 24)   0           dense_0_4_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 136, 24, 24)  0           concatenate_4[0][0]              
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_0_5_bn (BatchNormalizatio (None, 136, 24, 24)  544         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 136, 24, 24)  0           dense_0_5_bn[0][0]               
__________________________________________________________________________________________________
dense_0_5_conv2D (Conv2D)       (None, 24, 24, 24)   29376       activation_7[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 24, 24, 24)   0           dense_0_5_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 160, 24, 24)  0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 160, 24, 24)  640         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 160, 24, 24)  0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 80, 24, 24)   12800       activation_8[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 80, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 80, 12, 12)   320         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 80, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 24, 12, 12)   17280       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 24, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 104, 12, 12)  0           average_pooling2d_1[0][0]        
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 104, 12, 12)  416         concatenate_7[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 104, 12, 12)  0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 24, 12, 12)   22464       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 24, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 128, 12, 12)  0           concatenate_7[0][0]              
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 128, 12, 12)  512         concatenate_8[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 128, 12, 12)  0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 24, 12, 12)   27648       activation_11[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 24, 12, 12)   0           dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_9 (Concatenate)     (None, 152, 12, 12)  0           concatenate_8[0][0]              
                                                                 dropout_9[0][0]                  
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 152, 12, 12)  608         concatenate_9[0][0]              
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 152, 12, 12)  0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 24, 12, 12)   32832       activation_12[0][0]              
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 24, 12, 12)   0           dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_10 (Concatenate)    (None, 176, 12, 12)  0           concatenate_9[0][0]              
                                                                 dropout_10[0][0]                 
__________________________________________________________________________________________________
dense_1_4_bn (BatchNormalizatio (None, 176, 12, 12)  704         concatenate_10[0][0]             
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 176, 12, 12)  0           dense_1_4_bn[0][0]               
__________________________________________________________________________________________________
dense_1_4_conv2D (Conv2D)       (None, 24, 12, 12)   38016       activation_13[0][0]              
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, 24, 12, 12)   0           dense_1_4_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_11 (Concatenate)    (None, 200, 12, 12)  0           concatenate_10[0][0]             
                                                                 dropout_11[0][0]                 
__________________________________________________________________________________________________
dense_1_5_bn (BatchNormalizatio (None, 200, 12, 12)  800         concatenate_11[0][0]             
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 200, 12, 12)  0           dense_1_5_bn[0][0]               
__________________________________________________________________________________________________
dense_1_5_conv2D (Conv2D)       (None, 24, 12, 12)   43200       activation_14[0][0]              
__________________________________________________________________________________________________
dropout_12 (Dropout)            (None, 24, 12, 12)   0           dense_1_5_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_12 (Concatenate)    (None, 224, 12, 12)  0           concatenate_11[0][0]             
                                                                 dropout_12[0][0]                 
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 224, 12, 12)  896         concatenate_12[0][0]             
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 224, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 32256)        0           activation_15[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            32257       flatten_1[0][0]                  
==================================================================================================
Total params: 333,345
Trainable params: 329,953
Non-trainable params: 3,392
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/19
 - 72s - loss: 0.4419 - acc: 0.8014 - val_loss: 0.4393 - val_acc: 0.7981
Epoch 2/19
 - 68s - loss: 0.3112 - acc: 0.8751 - val_loss: 0.2428 - val_acc: 0.9100
Epoch 3/19
 - 69s - loss: 0.2557 - acc: 0.9034 - val_loss: 0.5389 - val_acc: 0.7525
Epoch 4/19
 - 68s - loss: 0.2175 - acc: 0.9196 - val_loss: 0.1880 - val_acc: 0.9336
Epoch 5/19
 - 69s - loss: 0.1873 - acc: 0.9344 - val_loss: 0.1623 - val_acc: 0.9421
Epoch 6/19
 - 69s - loss: 0.1665 - acc: 0.9441 - val_loss: 0.1305 - val_acc: 0.9577
Epoch 7/19
 - 69s - loss: 0.1476 - acc: 0.9520 - val_loss: 0.1471 - val_acc: 0.9489
Epoch 8/19
 - 69s - loss: 0.1330 - acc: 0.9578 - val_loss: 0.1110 - val_acc: 0.9664
Epoch 9/19
 - 69s - loss: 0.1186 - acc: 0.9645 - val_loss: 0.0845 - val_acc: 0.9768
Epoch 10/19
 - 69s - loss: 0.1092 - acc: 0.9676 - val_loss: 0.0913 - val_acc: 0.9735
Epoch 11/19
 - 69s - loss: 0.1011 - acc: 0.9716 - val_loss: 0.0734 - val_acc: 0.9802
Epoch 12/19
 - 69s - loss: 0.0917 - acc: 0.9732 - val_loss: 0.0804 - val_acc: 0.9773
Epoch 13/19
 - 69s - loss: 0.0865 - acc: 0.9757 - val_loss: 0.0650 - val_acc: 0.9827
Epoch 14/19
 - 69s - loss: 0.0803 - acc: 0.9789 - val_loss: 0.0610 - val_acc: 0.9842
Epoch 15/19
 - 69s - loss: 0.0741 - acc: 0.9804 - val_loss: 0.0557 - val_acc: 0.9864
Epoch 16/19
 - 69s - loss: 0.0692 - acc: 0.9832 - val_loss: 0.0490 - val_acc: 0.9887
Epoch 17/19
 - 69s - loss: 0.0667 - acc: 0.9837 - val_loss: 0.0501 - val_acc: 0.9901
Epoch 18/19
 - 69s - loss: 0.0620 - acc: 0.9855 - val_loss: 0.0778 - val_acc: 0.9775
Epoch 19/19
 - 69s - loss: 0.0585 - acc: 0.9861 - val_loss: 0.0426 - val_acc: 0.9913
Test accuracy:0.816
current auc_score ------------------> 0.905
------------------------ current config for the test -------------------------
Layers:  [6, 6]  Growth_rate:  24  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  19  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 24, 24, 24)   3456        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 24, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 40, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 40, 24, 24)   160         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 40, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 24, 24, 24)   8640        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 64, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 64, 24, 24)   256         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 64, 24, 24)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 24, 24, 24)   13824       activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 24, 24, 24)   0           dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 88, 24, 24)   0           concatenate_2[0][0]              
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 88, 24, 24)   352         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 88, 24, 24)   0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 24, 24, 24)   19008       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 24, 24, 24)   0           dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 112, 24, 24)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
dense_0_4_bn (BatchNormalizatio (None, 112, 24, 24)  448         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 112, 24, 24)  0           dense_0_4_bn[0][0]               
__________________________________________________________________________________________________
dense_0_4_conv2D (Conv2D)       (None, 24, 24, 24)   24192       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 24, 24, 24)   0           dense_0_4_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 136, 24, 24)  0           concatenate_4[0][0]              
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_0_5_bn (BatchNormalizatio (None, 136, 24, 24)  544         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 136, 24, 24)  0           dense_0_5_bn[0][0]               
__________________________________________________________________________________________________
dense_0_5_conv2D (Conv2D)       (None, 24, 24, 24)   29376       activation_7[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 24, 24, 24)   0           dense_0_5_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 160, 24, 24)  0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 160, 24, 24)  640         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 160, 24, 24)  0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 80, 24, 24)   12800       activation_8[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 80, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 80, 12, 12)   320         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 80, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 24, 12, 12)   17280       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 24, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 104, 12, 12)  0           average_pooling2d_1[0][0]        
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 104, 12, 12)  416         concatenate_7[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 104, 12, 12)  0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 24, 12, 12)   22464       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 24, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 128, 12, 12)  0           concatenate_7[0][0]              
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 128, 12, 12)  512         concatenate_8[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 128, 12, 12)  0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 24, 12, 12)   27648       activation_11[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 24, 12, 12)   0           dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_9 (Concatenate)     (None, 152, 12, 12)  0           concatenate_8[0][0]              
                                                                 dropout_9[0][0]                  
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 152, 12, 12)  608         concatenate_9[0][0]              
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 152, 12, 12)  0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 24, 12, 12)   32832       activation_12[0][0]              
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 24, 12, 12)   0           dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_10 (Concatenate)    (None, 176, 12, 12)  0           concatenate_9[0][0]              
                                                                 dropout_10[0][0]                 
__________________________________________________________________________________________________
dense_1_4_bn (BatchNormalizatio (None, 176, 12, 12)  704         concatenate_10[0][0]             
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 176, 12, 12)  0           dense_1_4_bn[0][0]               
__________________________________________________________________________________________________
dense_1_4_conv2D (Conv2D)       (None, 24, 12, 12)   38016       activation_13[0][0]              
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, 24, 12, 12)   0           dense_1_4_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_11 (Concatenate)    (None, 200, 12, 12)  0           concatenate_10[0][0]             
                                                                 dropout_11[0][0]                 
__________________________________________________________________________________________________
dense_1_5_bn (BatchNormalizatio (None, 200, 12, 12)  800         concatenate_11[0][0]             
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 200, 12, 12)  0           dense_1_5_bn[0][0]               
__________________________________________________________________________________________________
dense_1_5_conv2D (Conv2D)       (None, 24, 12, 12)   43200       activation_14[0][0]              
__________________________________________________________________________________________________
dropout_12 (Dropout)            (None, 24, 12, 12)   0           dense_1_5_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_12 (Concatenate)    (None, 224, 12, 12)  0           concatenate_11[0][0]             
                                                                 dropout_12[0][0]                 
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 224, 12, 12)  896         concatenate_12[0][0]             
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 224, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 32256)        0           activation_15[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            32257       flatten_1[0][0]                  
==================================================================================================
Total params: 333,345
Trainable params: 329,953
Non-trainable params: 3,392
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/19
 - 75s - loss: 0.4363 - acc: 0.8066 - val_loss: 0.4086 - val_acc: 0.8107
Epoch 2/19
 - 69s - loss: 0.3059 - acc: 0.8772 - val_loss: 0.4267 - val_acc: 0.8041
Epoch 3/19
 - 69s - loss: 0.2498 - acc: 0.9048 - val_loss: 0.2180 - val_acc: 0.9179
Epoch 4/19
 - 69s - loss: 0.2092 - acc: 0.9253 - val_loss: 0.1636 - val_acc: 0.9431
Epoch 5/19
 - 69s - loss: 0.1810 - acc: 0.9375 - val_loss: 0.1522 - val_acc: 0.9440
Epoch 6/19
 - 69s - loss: 0.1610 - acc: 0.9457 - val_loss: 0.1428 - val_acc: 0.9519
Epoch 7/19
 - 69s - loss: 0.1414 - acc: 0.9545 - val_loss: 0.1088 - val_acc: 0.9672
Epoch 8/19
 - 69s - loss: 0.1263 - acc: 0.9614 - val_loss: 0.0981 - val_acc: 0.9689
Epoch 9/19
 - 69s - loss: 0.1146 - acc: 0.9650 - val_loss: 0.0828 - val_acc: 0.9759
Epoch 10/19
 - 69s - loss: 0.1041 - acc: 0.9697 - val_loss: 0.0686 - val_acc: 0.9831
Epoch 11/19
 - 69s - loss: 0.0973 - acc: 0.9712 - val_loss: 0.0612 - val_acc: 0.9863
Epoch 12/19
 - 69s - loss: 0.0858 - acc: 0.9766 - val_loss: 0.0583 - val_acc: 0.9872
Epoch 13/19
 - 69s - loss: 0.0809 - acc: 0.9779 - val_loss: 0.0604 - val_acc: 0.9846
Epoch 14/19
 - 69s - loss: 0.0758 - acc: 0.9796 - val_loss: 0.0504 - val_acc: 0.9906
Epoch 15/19
 - 69s - loss: 0.0708 - acc: 0.9815 - val_loss: 0.0639 - val_acc: 0.9838
Epoch 16/19
 - 69s - loss: 0.0680 - acc: 0.9831 - val_loss: 0.0543 - val_acc: 0.9883
Epoch 17/19
 - 69s - loss: 0.0630 - acc: 0.9842 - val_loss: 0.0424 - val_acc: 0.9908
Epoch 18/19
 - 69s - loss: 0.0602 - acc: 0.9859 - val_loss: 0.0465 - val_acc: 0.9911
Epoch 19/19
 - 69s - loss: 0.0568 - acc: 0.9865 - val_loss: 0.0360 - val_acc: 0.9941
Test accuracy:0.823
current auc_score ------------------> 0.899
------------------------ current config for the test -------------------------
Layers:  [6, 6]  Growth_rate:  24  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  19  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 24, 24, 24)   3456        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 24, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 40, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 40, 24, 24)   160         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 40, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 24, 24, 24)   8640        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 64, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 64, 24, 24)   256         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 64, 24, 24)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 24, 24, 24)   13824       activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 24, 24, 24)   0           dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 88, 24, 24)   0           concatenate_2[0][0]              
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 88, 24, 24)   352         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 88, 24, 24)   0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 24, 24, 24)   19008       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 24, 24, 24)   0           dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 112, 24, 24)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
dense_0_4_bn (BatchNormalizatio (None, 112, 24, 24)  448         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 112, 24, 24)  0           dense_0_4_bn[0][0]               
__________________________________________________________________________________________________
dense_0_4_conv2D (Conv2D)       (None, 24, 24, 24)   24192       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 24, 24, 24)   0           dense_0_4_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 136, 24, 24)  0           concatenate_4[0][0]              
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_0_5_bn (BatchNormalizatio (None, 136, 24, 24)  544         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 136, 24, 24)  0           dense_0_5_bn[0][0]               
__________________________________________________________________________________________________
dense_0_5_conv2D (Conv2D)       (None, 24, 24, 24)   29376       activation_7[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 24, 24, 24)   0           dense_0_5_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 160, 24, 24)  0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 160, 24, 24)  640         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 160, 24, 24)  0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 80, 24, 24)   12800       activation_8[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 80, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 80, 12, 12)   320         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 80, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 24, 12, 12)   17280       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 24, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 104, 12, 12)  0           average_pooling2d_1[0][0]        
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 104, 12, 12)  416         concatenate_7[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 104, 12, 12)  0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 24, 12, 12)   22464       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 24, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 128, 12, 12)  0           concatenate_7[0][0]              
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 128, 12, 12)  512         concatenate_8[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 128, 12, 12)  0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 24, 12, 12)   27648       activation_11[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 24, 12, 12)   0           dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_9 (Concatenate)     (None, 152, 12, 12)  0           concatenate_8[0][0]              
                                                                 dropout_9[0][0]                  
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 152, 12, 12)  608         concatenate_9[0][0]              
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 152, 12, 12)  0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 24, 12, 12)   32832       activation_12[0][0]              
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 24, 12, 12)   0           dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_10 (Concatenate)    (None, 176, 12, 12)  0           concatenate_9[0][0]              
                                                                 dropout_10[0][0]                 
__________________________________________________________________________________________________
dense_1_4_bn (BatchNormalizatio (None, 176, 12, 12)  704         concatenate_10[0][0]             
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 176, 12, 12)  0           dense_1_4_bn[0][0]               
__________________________________________________________________________________________________
dense_1_4_conv2D (Conv2D)       (None, 24, 12, 12)   38016       activation_13[0][0]              
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, 24, 12, 12)   0           dense_1_4_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_11 (Concatenate)    (None, 200, 12, 12)  0           concatenate_10[0][0]             
                                                                 dropout_11[0][0]                 
__________________________________________________________________________________________________
dense_1_5_bn (BatchNormalizatio (None, 200, 12, 12)  800         concatenate_11[0][0]             
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 200, 12, 12)  0           dense_1_5_bn[0][0]               
__________________________________________________________________________________________________
dense_1_5_conv2D (Conv2D)       (None, 24, 12, 12)   43200       activation_14[0][0]              
__________________________________________________________________________________________________
dropout_12 (Dropout)            (None, 24, 12, 12)   0           dense_1_5_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_12 (Concatenate)    (None, 224, 12, 12)  0           concatenate_11[0][0]             
                                                                 dropout_12[0][0]                 
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 224, 12, 12)  896         concatenate_12[0][0]             
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 224, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 32256)        0           activation_15[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            32257       flatten_1[0][0]                  
==================================================================================================
Total params: 333,345
Trainable params: 329,953
Non-trainable params: 3,392
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/19
 - 73s - loss: 0.4444 - acc: 0.7981 - val_loss: 0.3640 - val_acc: 0.8311
Epoch 2/19
 - 70s - loss: 0.3029 - acc: 0.8789 - val_loss: 0.5008 - val_acc: 0.7922
Epoch 3/19
 - 69s - loss: 0.2405 - acc: 0.9093 - val_loss: 0.1780 - val_acc: 0.9369
Epoch 4/19
 - 69s - loss: 0.2024 - acc: 0.9273 - val_loss: 0.1588 - val_acc: 0.9502
Epoch 5/19
 - 69s - loss: 0.1769 - acc: 0.9388 - val_loss: 0.1455 - val_acc: 0.9506
Epoch 6/19
 - 69s - loss: 0.1561 - acc: 0.9464 - val_loss: 0.1169 - val_acc: 0.9632
Epoch 7/19
 - 69s - loss: 0.1399 - acc: 0.9546 - val_loss: 0.1007 - val_acc: 0.9701
Epoch 8/19
 - 70s - loss: 0.1241 - acc: 0.9614 - val_loss: 0.0901 - val_acc: 0.9736
Epoch 9/19
 - 69s - loss: 0.1126 - acc: 0.9654 - val_loss: 0.0751 - val_acc: 0.9794
Epoch 10/19
 - 69s - loss: 0.1041 - acc: 0.9694 - val_loss: 0.0696 - val_acc: 0.9829
Epoch 11/19
 - 69s - loss: 0.0958 - acc: 0.9715 - val_loss: 0.0651 - val_acc: 0.9839
Epoch 12/19
 - 69s - loss: 0.0899 - acc: 0.9746 - val_loss: 0.0592 - val_acc: 0.9856
Epoch 13/19
 - 69s - loss: 0.0828 - acc: 0.9772 - val_loss: 0.0501 - val_acc: 0.9905
Epoch 14/19
 - 69s - loss: 0.0792 - acc: 0.9787 - val_loss: 0.0536 - val_acc: 0.9880
Epoch 15/19
 - 69s - loss: 0.0717 - acc: 0.9819 - val_loss: 0.0446 - val_acc: 0.9911
Epoch 16/19
 - 69s - loss: 0.0687 - acc: 0.9824 - val_loss: 0.0540 - val_acc: 0.9862
Epoch 17/19
 - 71s - loss: 0.0642 - acc: 0.9840 - val_loss: 0.0591 - val_acc: 0.9841
Epoch 18/19
 - 70s - loss: 0.0614 - acc: 0.9850 - val_loss: 0.0438 - val_acc: 0.9912
Epoch 19/19
 - 70s - loss: 0.0566 - acc: 0.9875 - val_loss: 0.0428 - val_acc: 0.9908
Test accuracy:0.839
current auc_score ------------------> 0.932
------------------------ current config for the test -------------------------
Layers:  [6, 6]  Growth_rate:  24  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  19  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 24, 24, 24)   3456        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 24, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 40, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 40, 24, 24)   160         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 40, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 24, 24, 24)   8640        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 64, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 64, 24, 24)   256         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 64, 24, 24)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 24, 24, 24)   13824       activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 24, 24, 24)   0           dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 88, 24, 24)   0           concatenate_2[0][0]              
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 88, 24, 24)   352         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 88, 24, 24)   0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 24, 24, 24)   19008       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 24, 24, 24)   0           dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 112, 24, 24)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
dense_0_4_bn (BatchNormalizatio (None, 112, 24, 24)  448         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 112, 24, 24)  0           dense_0_4_bn[0][0]               
__________________________________________________________________________________________________
dense_0_4_conv2D (Conv2D)       (None, 24, 24, 24)   24192       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 24, 24, 24)   0           dense_0_4_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 136, 24, 24)  0           concatenate_4[0][0]              
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_0_5_bn (BatchNormalizatio (None, 136, 24, 24)  544         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 136, 24, 24)  0           dense_0_5_bn[0][0]               
__________________________________________________________________________________________________
dense_0_5_conv2D (Conv2D)       (None, 24, 24, 24)   29376       activation_7[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 24, 24, 24)   0           dense_0_5_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 160, 24, 24)  0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 160, 24, 24)  640         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 160, 24, 24)  0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 80, 24, 24)   12800       activation_8[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 80, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 80, 12, 12)   320         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 80, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 24, 12, 12)   17280       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 24, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 104, 12, 12)  0           average_pooling2d_1[0][0]        
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 104, 12, 12)  416         concatenate_7[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 104, 12, 12)  0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 24, 12, 12)   22464       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 24, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 128, 12, 12)  0           concatenate_7[0][0]              
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 128, 12, 12)  512         concatenate_8[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 128, 12, 12)  0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 24, 12, 12)   27648       activation_11[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 24, 12, 12)   0           dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_9 (Concatenate)     (None, 152, 12, 12)  0           concatenate_8[0][0]              
                                                                 dropout_9[0][0]                  
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 152, 12, 12)  608         concatenate_9[0][0]              
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 152, 12, 12)  0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 24, 12, 12)   32832       activation_12[0][0]              
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 24, 12, 12)   0           dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_10 (Concatenate)    (None, 176, 12, 12)  0           concatenate_9[0][0]              
                                                                 dropout_10[0][0]                 
__________________________________________________________________________________________________
dense_1_4_bn (BatchNormalizatio (None, 176, 12, 12)  704         concatenate_10[0][0]             
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 176, 12, 12)  0           dense_1_4_bn[0][0]               
__________________________________________________________________________________________________
dense_1_4_conv2D (Conv2D)       (None, 24, 12, 12)   38016       activation_13[0][0]              
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, 24, 12, 12)   0           dense_1_4_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_11 (Concatenate)    (None, 200, 12, 12)  0           concatenate_10[0][0]             
                                                                 dropout_11[0][0]                 
__________________________________________________________________________________________________
dense_1_5_bn (BatchNormalizatio (None, 200, 12, 12)  800         concatenate_11[0][0]             
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 200, 12, 12)  0           dense_1_5_bn[0][0]               
__________________________________________________________________________________________________
dense_1_5_conv2D (Conv2D)       (None, 24, 12, 12)   43200       activation_14[0][0]              
__________________________________________________________________________________________________
dropout_12 (Dropout)            (None, 24, 12, 12)   0           dense_1_5_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_12 (Concatenate)    (None, 224, 12, 12)  0           concatenate_11[0][0]             
                                                                 dropout_12[0][0]                 
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 224, 12, 12)  896         concatenate_12[0][0]             
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 224, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 32256)        0           activation_15[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            32257       flatten_1[0][0]                  
==================================================================================================
Total params: 333,345
Trainable params: 329,953
Non-trainable params: 3,392
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/19
 - 74s - loss: 0.4485 - acc: 0.7944 - val_loss: 0.3624 - val_acc: 0.8400
Epoch 2/19
 - 71s - loss: 0.3115 - acc: 0.8713 - val_loss: 0.2366 - val_acc: 0.9132
Epoch 3/19
 - 71s - loss: 0.2528 - acc: 0.9023 - val_loss: 0.2355 - val_acc: 0.9080
Epoch 4/19
 - 71s - loss: 0.2134 - acc: 0.9231 - val_loss: 0.2325 - val_acc: 0.9059
Epoch 5/19
 - 71s - loss: 0.1854 - acc: 0.9346 - val_loss: 0.1544 - val_acc: 0.9493
Epoch 6/19
 - 71s - loss: 0.1615 - acc: 0.9448 - val_loss: 0.1253 - val_acc: 0.9578
Epoch 7/19
 - 71s - loss: 0.1449 - acc: 0.9531 - val_loss: 0.1959 - val_acc: 0.9249
Epoch 8/19
 - 71s - loss: 0.1285 - acc: 0.9594 - val_loss: 0.1009 - val_acc: 0.9715
Epoch 9/19
 - 71s - loss: 0.1162 - acc: 0.9640 - val_loss: 0.1151 - val_acc: 0.9661
Epoch 10/19
 - 71s - loss: 0.1061 - acc: 0.9681 - val_loss: 0.0819 - val_acc: 0.9782
Epoch 11/19
 - 70s - loss: 0.0988 - acc: 0.9714 - val_loss: 0.0657 - val_acc: 0.9852
Epoch 12/19
 - 71s - loss: 0.0901 - acc: 0.9746 - val_loss: 0.0637 - val_acc: 0.9833
Epoch 13/19
 - 71s - loss: 0.0843 - acc: 0.9767 - val_loss: 0.0545 - val_acc: 0.9882
Epoch 14/19
 - 71s - loss: 0.0796 - acc: 0.9787 - val_loss: 0.0617 - val_acc: 0.9864
Epoch 15/19
 - 71s - loss: 0.0729 - acc: 0.9811 - val_loss: 0.0475 - val_acc: 0.9898
Epoch 16/19
 - 70s - loss: 0.0676 - acc: 0.9828 - val_loss: 0.0669 - val_acc: 0.9832
Epoch 17/19
 - 70s - loss: 0.0650 - acc: 0.9839 - val_loss: 0.0409 - val_acc: 0.9925
Epoch 18/19
 - 70s - loss: 0.0599 - acc: 0.9862 - val_loss: 0.0428 - val_acc: 0.9922
Epoch 19/19
 - 71s - loss: 0.0572 - acc: 0.9865 - val_loss: 0.0347 - val_acc: 0.9959
Test accuracy:0.840
current auc_score ------------------> 0.919
------------------------ current config for the test -------------------------
Layers:  [6, 6]  Growth_rate:  24  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  19  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 24, 24, 24)   3456        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 24, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 40, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 40, 24, 24)   160         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 40, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 24, 24, 24)   8640        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 64, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 64, 24, 24)   256         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 64, 24, 24)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 24, 24, 24)   13824       activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 24, 24, 24)   0           dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 88, 24, 24)   0           concatenate_2[0][0]              
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 88, 24, 24)   352         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 88, 24, 24)   0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 24, 24, 24)   19008       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 24, 24, 24)   0           dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 112, 24, 24)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
dense_0_4_bn (BatchNormalizatio (None, 112, 24, 24)  448         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 112, 24, 24)  0           dense_0_4_bn[0][0]               
__________________________________________________________________________________________________
dense_0_4_conv2D (Conv2D)       (None, 24, 24, 24)   24192       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 24, 24, 24)   0           dense_0_4_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 136, 24, 24)  0           concatenate_4[0][0]              
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_0_5_bn (BatchNormalizatio (None, 136, 24, 24)  544         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 136, 24, 24)  0           dense_0_5_bn[0][0]               
__________________________________________________________________________________________________
dense_0_5_conv2D (Conv2D)       (None, 24, 24, 24)   29376       activation_7[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 24, 24, 24)   0           dense_0_5_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 160, 24, 24)  0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 160, 24, 24)  640         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 160, 24, 24)  0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 80, 24, 24)   12800       activation_8[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 80, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 80, 12, 12)   320         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 80, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 24, 12, 12)   17280       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 24, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 104, 12, 12)  0           average_pooling2d_1[0][0]        
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 104, 12, 12)  416         concatenate_7[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 104, 12, 12)  0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 24, 12, 12)   22464       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 24, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 128, 12, 12)  0           concatenate_7[0][0]              
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 128, 12, 12)  512         concatenate_8[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 128, 12, 12)  0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 24, 12, 12)   27648       activation_11[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 24, 12, 12)   0           dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_9 (Concatenate)     (None, 152, 12, 12)  0           concatenate_8[0][0]              
                                                                 dropout_9[0][0]                  
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 152, 12, 12)  608         concatenate_9[0][0]              
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 152, 12, 12)  0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 24, 12, 12)   32832       activation_12[0][0]              
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 24, 12, 12)   0           dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_10 (Concatenate)    (None, 176, 12, 12)  0           concatenate_9[0][0]              
                                                                 dropout_10[0][0]                 
__________________________________________________________________________________________________
dense_1_4_bn (BatchNormalizatio (None, 176, 12, 12)  704         concatenate_10[0][0]             
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 176, 12, 12)  0           dense_1_4_bn[0][0]               
__________________________________________________________________________________________________
dense_1_4_conv2D (Conv2D)       (None, 24, 12, 12)   38016       activation_13[0][0]              
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, 24, 12, 12)   0           dense_1_4_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_11 (Concatenate)    (None, 200, 12, 12)  0           concatenate_10[0][0]             
                                                                 dropout_11[0][0]                 
__________________________________________________________________________________________________
dense_1_5_bn (BatchNormalizatio (None, 200, 12, 12)  800         concatenate_11[0][0]             
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 200, 12, 12)  0           dense_1_5_bn[0][0]               
__________________________________________________________________________________________________
dense_1_5_conv2D (Conv2D)       (None, 24, 12, 12)   43200       activation_14[0][0]              
__________________________________________________________________________________________________
dropout_12 (Dropout)            (None, 24, 12, 12)   0           dense_1_5_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_12 (Concatenate)    (None, 224, 12, 12)  0           concatenate_11[0][0]             
                                                                 dropout_12[0][0]                 
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 224, 12, 12)  896         concatenate_12[0][0]             
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 224, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 32256)        0           activation_15[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            32257       flatten_1[0][0]                  
==================================================================================================
Total params: 333,345
Trainable params: 329,953
Non-trainable params: 3,392
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/19
 - 73s - loss: 0.4480 - acc: 0.7990 - val_loss: 0.3226 - val_acc: 0.8665
Epoch 2/19
 - 70s - loss: 0.3082 - acc: 0.8762 - val_loss: 0.2363 - val_acc: 0.9111
Epoch 3/19
 - 70s - loss: 0.2464 - acc: 0.9068 - val_loss: 0.2030 - val_acc: 0.9233
Epoch 4/19
 - 70s - loss: 0.2100 - acc: 0.9253 - val_loss: 0.1883 - val_acc: 0.9293
Epoch 5/19
 - 70s - loss: 0.1817 - acc: 0.9380 - val_loss: 0.1951 - val_acc: 0.9305
Epoch 6/19
 - 70s - loss: 0.1563 - acc: 0.9479 - val_loss: 0.1154 - val_acc: 0.9666
Epoch 7/19
 - 70s - loss: 0.1412 - acc: 0.9550 - val_loss: 0.1023 - val_acc: 0.9735
Epoch 8/19
 - 70s - loss: 0.1273 - acc: 0.9609 - val_loss: 0.1106 - val_acc: 0.9680
Epoch 9/19
 - 70s - loss: 0.1163 - acc: 0.9657 - val_loss: 0.0872 - val_acc: 0.9755
Epoch 10/19
 - 70s - loss: 0.1059 - acc: 0.9689 - val_loss: 0.0940 - val_acc: 0.9723
Epoch 11/19
 - 70s - loss: 0.0961 - acc: 0.9727 - val_loss: 0.0672 - val_acc: 0.9818
Epoch 12/19
 - 70s - loss: 0.0882 - acc: 0.9763 - val_loss: 0.0745 - val_acc: 0.9802
Epoch 13/19
 - 70s - loss: 0.0830 - acc: 0.9779 - val_loss: 0.0731 - val_acc: 0.9813
Epoch 14/19
 - 70s - loss: 0.0771 - acc: 0.9798 - val_loss: 0.0533 - val_acc: 0.9881
Epoch 15/19
 - 70s - loss: 0.0708 - acc: 0.9827 - val_loss: 0.0498 - val_acc: 0.9892
Epoch 16/19
 - 70s - loss: 0.0686 - acc: 0.9832 - val_loss: 0.0588 - val_acc: 0.9866
Epoch 17/19
 - 70s - loss: 0.0618 - acc: 0.9854 - val_loss: 0.0503 - val_acc: 0.9868
Epoch 18/19
 - 70s - loss: 0.0604 - acc: 0.9856 - val_loss: 0.0460 - val_acc: 0.9896
Epoch 19/19
 - 70s - loss: 0.0560 - acc: 0.9871 - val_loss: 0.0437 - val_acc: 0.9906
Test accuracy:0.804
current auc_score ------------------> 0.914
------------------------ current config for the test -------------------------
Layers:  [6, 6]  Growth_rate:  24  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  19  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 24, 24, 24)   3456        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 24, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 40, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 40, 24, 24)   160         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 40, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 24, 24, 24)   8640        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 64, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 64, 24, 24)   256         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 64, 24, 24)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 24, 24, 24)   13824       activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 24, 24, 24)   0           dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 88, 24, 24)   0           concatenate_2[0][0]              
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 88, 24, 24)   352         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 88, 24, 24)   0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 24, 24, 24)   19008       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 24, 24, 24)   0           dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 112, 24, 24)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
dense_0_4_bn (BatchNormalizatio (None, 112, 24, 24)  448         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 112, 24, 24)  0           dense_0_4_bn[0][0]               
__________________________________________________________________________________________________
dense_0_4_conv2D (Conv2D)       (None, 24, 24, 24)   24192       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 24, 24, 24)   0           dense_0_4_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 136, 24, 24)  0           concatenate_4[0][0]              
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_0_5_bn (BatchNormalizatio (None, 136, 24, 24)  544         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 136, 24, 24)  0           dense_0_5_bn[0][0]               
__________________________________________________________________________________________________
dense_0_5_conv2D (Conv2D)       (None, 24, 24, 24)   29376       activation_7[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 24, 24, 24)   0           dense_0_5_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 160, 24, 24)  0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 160, 24, 24)  640         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 160, 24, 24)  0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 80, 24, 24)   12800       activation_8[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 80, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 80, 12, 12)   320         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 80, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 24, 12, 12)   17280       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 24, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 104, 12, 12)  0           average_pooling2d_1[0][0]        
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 104, 12, 12)  416         concatenate_7[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 104, 12, 12)  0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 24, 12, 12)   22464       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 24, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 128, 12, 12)  0           concatenate_7[0][0]              
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 128, 12, 12)  512         concatenate_8[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 128, 12, 12)  0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 24, 12, 12)   27648       activation_11[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 24, 12, 12)   0           dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_9 (Concatenate)     (None, 152, 12, 12)  0           concatenate_8[0][0]              
                                                                 dropout_9[0][0]                  
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 152, 12, 12)  608         concatenate_9[0][0]              
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 152, 12, 12)  0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 24, 12, 12)   32832       activation_12[0][0]              
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 24, 12, 12)   0           dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_10 (Concatenate)    (None, 176, 12, 12)  0           concatenate_9[0][0]              
                                                                 dropout_10[0][0]                 
__________________________________________________________________________________________________
dense_1_4_bn (BatchNormalizatio (None, 176, 12, 12)  704         concatenate_10[0][0]             
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 176, 12, 12)  0           dense_1_4_bn[0][0]               
__________________________________________________________________________________________________
dense_1_4_conv2D (Conv2D)       (None, 24, 12, 12)   38016       activation_13[0][0]              
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, 24, 12, 12)   0           dense_1_4_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_11 (Concatenate)    (None, 200, 12, 12)  0           concatenate_10[0][0]             
                                                                 dropout_11[0][0]                 
__________________________________________________________________________________________________
dense_1_5_bn (BatchNormalizatio (None, 200, 12, 12)  800         concatenate_11[0][0]             
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 200, 12, 12)  0           dense_1_5_bn[0][0]               
__________________________________________________________________________________________________
dense_1_5_conv2D (Conv2D)       (None, 24, 12, 12)   43200       activation_14[0][0]              
__________________________________________________________________________________________________
dropout_12 (Dropout)            (None, 24, 12, 12)   0           dense_1_5_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_12 (Concatenate)    (None, 224, 12, 12)  0           concatenate_11[0][0]             
                                                                 dropout_12[0][0]                 
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 224, 12, 12)  896         concatenate_12[0][0]             
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 224, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 32256)        0           activation_15[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            32257       flatten_1[0][0]                  
==================================================================================================
Total params: 333,345
Trainable params: 329,953
Non-trainable params: 3,392
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/19
 - 73s - loss: 0.4444 - acc: 0.7981 - val_loss: 0.3696 - val_acc: 0.8397
Epoch 2/19
 - 70s - loss: 0.3075 - acc: 0.8751 - val_loss: 0.2940 - val_acc: 0.8764
Epoch 3/19
 - 68s - loss: 0.2519 - acc: 0.9022 - val_loss: 0.4049 - val_acc: 0.8122
Epoch 4/19
 - 68s - loss: 0.2124 - acc: 0.9228 - val_loss: 0.1801 - val_acc: 0.9357
Epoch 5/19
 - 68s - loss: 0.1871 - acc: 0.9344 - val_loss: 0.1407 - val_acc: 0.9551
Epoch 6/19
 - 68s - loss: 0.1632 - acc: 0.9450 - val_loss: 0.1479 - val_acc: 0.9493
Epoch 7/19
 - 69s - loss: 0.1452 - acc: 0.9543 - val_loss: 0.1366 - val_acc: 0.9537
Epoch 8/19
 - 69s - loss: 0.1318 - acc: 0.9591 - val_loss: 0.1026 - val_acc: 0.9682
Epoch 9/19
 - 68s - loss: 0.1188 - acc: 0.9628 - val_loss: 0.0800 - val_acc: 0.9794
Epoch 10/19
 - 68s - loss: 0.1089 - acc: 0.9683 - val_loss: 0.0767 - val_acc: 0.9802
Epoch 11/19
 - 68s - loss: 0.0996 - acc: 0.9704 - val_loss: 0.0732 - val_acc: 0.9793
Epoch 12/19
 - 68s - loss: 0.0923 - acc: 0.9746 - val_loss: 0.0787 - val_acc: 0.9777
Epoch 13/19
 - 68s - loss: 0.0847 - acc: 0.9766 - val_loss: 0.0626 - val_acc: 0.9854
Epoch 14/19
 - 68s - loss: 0.0787 - acc: 0.9791 - val_loss: 0.0870 - val_acc: 0.9721
Epoch 15/19
 - 68s - loss: 0.0725 - acc: 0.9811 - val_loss: 0.0726 - val_acc: 0.9793
Epoch 16/19
 - 68s - loss: 0.0698 - acc: 0.9818 - val_loss: 0.0652 - val_acc: 0.9813

Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Epoch 17/19
 - 68s - loss: 0.0583 - acc: 0.9872 - val_loss: 0.0388 - val_acc: 0.9935
Epoch 18/19
 - 69s - loss: 0.0578 - acc: 0.9872 - val_loss: 0.0398 - val_acc: 0.9931
Epoch 19/19
 - 68s - loss: 0.0551 - acc: 0.9886 - val_loss: 0.0381 - val_acc: 0.9939
Test accuracy:0.789
current auc_score ------------------> 0.897
------------------------ current config for the test -------------------------
Layers:  [6, 6]  Growth_rate:  24  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  19  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 24, 24, 24)   3456        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 24, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 40, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 40, 24, 24)   160         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 40, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 24, 24, 24)   8640        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 64, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 64, 24, 24)   256         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 64, 24, 24)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 24, 24, 24)   13824       activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 24, 24, 24)   0           dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 88, 24, 24)   0           concatenate_2[0][0]              
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 88, 24, 24)   352         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 88, 24, 24)   0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 24, 24, 24)   19008       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 24, 24, 24)   0           dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 112, 24, 24)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
dense_0_4_bn (BatchNormalizatio (None, 112, 24, 24)  448         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 112, 24, 24)  0           dense_0_4_bn[0][0]               
__________________________________________________________________________________________________
dense_0_4_conv2D (Conv2D)       (None, 24, 24, 24)   24192       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 24, 24, 24)   0           dense_0_4_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 136, 24, 24)  0           concatenate_4[0][0]              
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_0_5_bn (BatchNormalizatio (None, 136, 24, 24)  544         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 136, 24, 24)  0           dense_0_5_bn[0][0]               
__________________________________________________________________________________________________
dense_0_5_conv2D (Conv2D)       (None, 24, 24, 24)   29376       activation_7[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 24, 24, 24)   0           dense_0_5_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 160, 24, 24)  0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 160, 24, 24)  640         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 160, 24, 24)  0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 80, 24, 24)   12800       activation_8[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 80, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 80, 12, 12)   320         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 80, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 24, 12, 12)   17280       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 24, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 104, 12, 12)  0           average_pooling2d_1[0][0]        
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 104, 12, 12)  416         concatenate_7[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 104, 12, 12)  0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 24, 12, 12)   22464       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 24, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 128, 12, 12)  0           concatenate_7[0][0]              
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 128, 12, 12)  512         concatenate_8[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 128, 12, 12)  0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 24, 12, 12)   27648       activation_11[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 24, 12, 12)   0           dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_9 (Concatenate)     (None, 152, 12, 12)  0           concatenate_8[0][0]              
                                                                 dropout_9[0][0]                  
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 152, 12, 12)  608         concatenate_9[0][0]              
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 152, 12, 12)  0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 24, 12, 12)   32832       activation_12[0][0]              
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 24, 12, 12)   0           dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_10 (Concatenate)    (None, 176, 12, 12)  0           concatenate_9[0][0]              
                                                                 dropout_10[0][0]                 
__________________________________________________________________________________________________
dense_1_4_bn (BatchNormalizatio (None, 176, 12, 12)  704         concatenate_10[0][0]             
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 176, 12, 12)  0           dense_1_4_bn[0][0]               
__________________________________________________________________________________________________
dense_1_4_conv2D (Conv2D)       (None, 24, 12, 12)   38016       activation_13[0][0]              
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, 24, 12, 12)   0           dense_1_4_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_11 (Concatenate)    (None, 200, 12, 12)  0           concatenate_10[0][0]             
                                                                 dropout_11[0][0]                 
__________________________________________________________________________________________________
dense_1_5_bn (BatchNormalizatio (None, 200, 12, 12)  800         concatenate_11[0][0]             
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 200, 12, 12)  0           dense_1_5_bn[0][0]               
__________________________________________________________________________________________________
dense_1_5_conv2D (Conv2D)       (None, 24, 12, 12)   43200       activation_14[0][0]              
__________________________________________________________________________________________________
dropout_12 (Dropout)            (None, 24, 12, 12)   0           dense_1_5_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_12 (Concatenate)    (None, 224, 12, 12)  0           concatenate_11[0][0]             
                                                                 dropout_12[0][0]                 
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 224, 12, 12)  896         concatenate_12[0][0]             
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 224, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 32256)        0           activation_15[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            32257       flatten_1[0][0]                  
==================================================================================================
Total params: 333,345
Trainable params: 329,953
Non-trainable params: 3,392
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/19
 - 72s - loss: 0.4456 - acc: 0.7955 - val_loss: 0.3787 - val_acc: 0.8294
Epoch 2/19
 - 69s - loss: 0.3178 - acc: 0.8708 - val_loss: 0.2884 - val_acc: 0.8776
Epoch 3/19
 - 68s - loss: 0.2620 - acc: 0.8989 - val_loss: 0.2755 - val_acc: 0.8884
Epoch 4/19
 - 68s - loss: 0.2248 - acc: 0.9177 - val_loss: 0.2263 - val_acc: 0.9155
Epoch 5/19
 - 68s - loss: 0.1924 - acc: 0.9319 - val_loss: 0.2101 - val_acc: 0.9170
Epoch 6/19
 - 68s - loss: 0.1714 - acc: 0.9411 - val_loss: 0.1534 - val_acc: 0.9479
Epoch 7/19
 - 68s - loss: 0.1527 - acc: 0.9506 - val_loss: 0.1168 - val_acc: 0.9630
Epoch 8/19
 - 68s - loss: 0.1348 - acc: 0.9580 - val_loss: 0.1021 - val_acc: 0.9684
Epoch 9/19
 - 68s - loss: 0.1235 - acc: 0.9614 - val_loss: 0.0904 - val_acc: 0.9752
Epoch 10/19
 - 68s - loss: 0.1130 - acc: 0.9660 - val_loss: 0.0828 - val_acc: 0.9773
Epoch 11/19
 - 68s - loss: 0.1022 - acc: 0.9705 - val_loss: 0.0731 - val_acc: 0.9798
Epoch 12/19
 - 68s - loss: 0.0960 - acc: 0.9726 - val_loss: 0.0704 - val_acc: 0.9817
Epoch 13/19
 - 68s - loss: 0.0863 - acc: 0.9758 - val_loss: 0.0618 - val_acc: 0.9852
Epoch 14/19
 - 68s - loss: 0.0816 - acc: 0.9781 - val_loss: 0.0614 - val_acc: 0.9842
Epoch 15/19
 - 68s - loss: 0.0760 - acc: 0.9795 - val_loss: 0.0585 - val_acc: 0.9846
Epoch 16/19
 - 68s - loss: 0.0715 - acc: 0.9814 - val_loss: 0.0510 - val_acc: 0.9869
Epoch 17/19
 - 68s - loss: 0.0674 - acc: 0.9827 - val_loss: 0.0506 - val_acc: 0.9887
Epoch 18/19
 - 68s - loss: 0.0639 - acc: 0.9845 - val_loss: 0.0552 - val_acc: 0.9868
Epoch 19/19
 - 68s - loss: 0.0592 - acc: 0.9867 - val_loss: 0.0499 - val_acc: 0.9878
Test accuracy:0.827
current auc_score ------------------> 0.901
------------------------ current config for the test -------------------------
Layers:  [6, 6]  Growth_rate:  24  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  19  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 24, 24, 24)   3456        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 24, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 40, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 40, 24, 24)   160         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 40, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 24, 24, 24)   8640        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 64, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 64, 24, 24)   256         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 64, 24, 24)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 24, 24, 24)   13824       activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 24, 24, 24)   0           dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 88, 24, 24)   0           concatenate_2[0][0]              
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 88, 24, 24)   352         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 88, 24, 24)   0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 24, 24, 24)   19008       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 24, 24, 24)   0           dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 112, 24, 24)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
dense_0_4_bn (BatchNormalizatio (None, 112, 24, 24)  448         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 112, 24, 24)  0           dense_0_4_bn[0][0]               
__________________________________________________________________________________________________
dense_0_4_conv2D (Conv2D)       (None, 24, 24, 24)   24192       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 24, 24, 24)   0           dense_0_4_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 136, 24, 24)  0           concatenate_4[0][0]              
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_0_5_bn (BatchNormalizatio (None, 136, 24, 24)  544         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 136, 24, 24)  0           dense_0_5_bn[0][0]               
__________________________________________________________________________________________________
dense_0_5_conv2D (Conv2D)       (None, 24, 24, 24)   29376       activation_7[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 24, 24, 24)   0           dense_0_5_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 160, 24, 24)  0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 160, 24, 24)  640         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 160, 24, 24)  0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 80, 24, 24)   12800       activation_8[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 80, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 80, 12, 12)   320         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 80, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 24, 12, 12)   17280       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 24, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 104, 12, 12)  0           average_pooling2d_1[0][0]        
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 104, 12, 12)  416         concatenate_7[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 104, 12, 12)  0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 24, 12, 12)   22464       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 24, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 128, 12, 12)  0           concatenate_7[0][0]              
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 128, 12, 12)  512         concatenate_8[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 128, 12, 12)  0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 24, 12, 12)   27648       activation_11[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 24, 12, 12)   0           dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_9 (Concatenate)     (None, 152, 12, 12)  0           concatenate_8[0][0]              
                                                                 dropout_9[0][0]                  
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 152, 12, 12)  608         concatenate_9[0][0]              
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 152, 12, 12)  0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 24, 12, 12)   32832       activation_12[0][0]              
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 24, 12, 12)   0           dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_10 (Concatenate)    (None, 176, 12, 12)  0           concatenate_9[0][0]              
                                                                 dropout_10[0][0]                 
__________________________________________________________________________________________________
dense_1_4_bn (BatchNormalizatio (None, 176, 12, 12)  704         concatenate_10[0][0]             
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 176, 12, 12)  0           dense_1_4_bn[0][0]               
__________________________________________________________________________________________________
dense_1_4_conv2D (Conv2D)       (None, 24, 12, 12)   38016       activation_13[0][0]              
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, 24, 12, 12)   0           dense_1_4_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_11 (Concatenate)    (None, 200, 12, 12)  0           concatenate_10[0][0]             
                                                                 dropout_11[0][0]                 
__________________________________________________________________________________________________
dense_1_5_bn (BatchNormalizatio (None, 200, 12, 12)  800         concatenate_11[0][0]             
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 200, 12, 12)  0           dense_1_5_bn[0][0]               
__________________________________________________________________________________________________
dense_1_5_conv2D (Conv2D)       (None, 24, 12, 12)   43200       activation_14[0][0]              
__________________________________________________________________________________________________
dropout_12 (Dropout)            (None, 24, 12, 12)   0           dense_1_5_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_12 (Concatenate)    (None, 224, 12, 12)  0           concatenate_11[0][0]             
                                                                 dropout_12[0][0]                 
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 224, 12, 12)  896         concatenate_12[0][0]             
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 224, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 32256)        0           activation_15[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            32257       flatten_1[0][0]                  
==================================================================================================
Total params: 333,345
Trainable params: 329,953
Non-trainable params: 3,392
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/19
 - 73s - loss: 0.4374 - acc: 0.8022 - val_loss: 0.4082 - val_acc: 0.8066
Epoch 2/19
 - 69s - loss: 0.3066 - acc: 0.8749 - val_loss: 0.2654 - val_acc: 0.8916
Epoch 3/19
 - 69s - loss: 0.2520 - acc: 0.9021 - val_loss: 0.2984 - val_acc: 0.8680
Epoch 4/19
 - 70s - loss: 0.2148 - acc: 0.9232 - val_loss: 0.1818 - val_acc: 0.9378
Epoch 5/19
 - 70s - loss: 0.1839 - acc: 0.9357 - val_loss: 0.1753 - val_acc: 0.9386
Epoch 6/19
 - 69s - loss: 0.1631 - acc: 0.9455 - val_loss: 0.1487 - val_acc: 0.9517
Epoch 7/19
 - 69s - loss: 0.1456 - acc: 0.9525 - val_loss: 0.1314 - val_acc: 0.9575
Epoch 8/19
 - 72s - loss: 0.1308 - acc: 0.9590 - val_loss: 0.1165 - val_acc: 0.9644
Epoch 9/19
 - 70s - loss: 0.1188 - acc: 0.9628 - val_loss: 0.1359 - val_acc: 0.9533
Epoch 10/19
 - 70s - loss: 0.1080 - acc: 0.9679 - val_loss: 0.0962 - val_acc: 0.9708
Epoch 11/19
 - 70s - loss: 0.0996 - acc: 0.9710 - val_loss: 0.1180 - val_acc: 0.9601
Epoch 12/19
 - 69s - loss: 0.0918 - acc: 0.9736 - val_loss: 0.0736 - val_acc: 0.9797
Epoch 13/19
 - 70s - loss: 0.0857 - acc: 0.9763 - val_loss: 0.0774 - val_acc: 0.9787
Epoch 14/19
 - 71s - loss: 0.0785 - acc: 0.9781 - val_loss: 0.0649 - val_acc: 0.9826
Epoch 15/19
 - 69s - loss: 0.0750 - acc: 0.9795 - val_loss: 0.0599 - val_acc: 0.9846
Epoch 16/19
 - 69s - loss: 0.0703 - acc: 0.9820 - val_loss: 0.0460 - val_acc: 0.9913
Epoch 17/19
 - 71s - loss: 0.0649 - acc: 0.9836 - val_loss: 0.0723 - val_acc: 0.9789
Epoch 18/19
 - 70s - loss: 0.0623 - acc: 0.9848 - val_loss: 0.0542 - val_acc: 0.9874
Epoch 19/19
 - 70s - loss: 0.0575 - acc: 0.9870 - val_loss: 0.0411 - val_acc: 0.9933
Test accuracy:0.830
current auc_score ------------------> 0.935
------------------------ current config for the test -------------------------
Layers:  [6, 6]  Growth_rate:  24  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  19  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 24, 24, 24)   3456        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 24, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 40, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 40, 24, 24)   160         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 40, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 24, 24, 24)   8640        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 64, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 64, 24, 24)   256         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 64, 24, 24)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 24, 24, 24)   13824       activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 24, 24, 24)   0           dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 88, 24, 24)   0           concatenate_2[0][0]              
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 88, 24, 24)   352         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 88, 24, 24)   0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 24, 24, 24)   19008       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 24, 24, 24)   0           dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 112, 24, 24)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
dense_0_4_bn (BatchNormalizatio (None, 112, 24, 24)  448         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 112, 24, 24)  0           dense_0_4_bn[0][0]               
__________________________________________________________________________________________________
dense_0_4_conv2D (Conv2D)       (None, 24, 24, 24)   24192       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 24, 24, 24)   0           dense_0_4_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 136, 24, 24)  0           concatenate_4[0][0]              
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_0_5_bn (BatchNormalizatio (None, 136, 24, 24)  544         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 136, 24, 24)  0           dense_0_5_bn[0][0]               
__________________________________________________________________________________________________
dense_0_5_conv2D (Conv2D)       (None, 24, 24, 24)   29376       activation_7[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 24, 24, 24)   0           dense_0_5_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 160, 24, 24)  0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 160, 24, 24)  640         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 160, 24, 24)  0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 80, 24, 24)   12800       activation_8[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 80, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 80, 12, 12)   320         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 80, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 24, 12, 12)   17280       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 24, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 104, 12, 12)  0           average_pooling2d_1[0][0]        
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 104, 12, 12)  416         concatenate_7[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 104, 12, 12)  0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 24, 12, 12)   22464       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 24, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 128, 12, 12)  0           concatenate_7[0][0]              
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 128, 12, 12)  512         concatenate_8[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 128, 12, 12)  0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 24, 12, 12)   27648       activation_11[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 24, 12, 12)   0           dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_9 (Concatenate)     (None, 152, 12, 12)  0           concatenate_8[0][0]              
                                                                 dropout_9[0][0]                  
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 152, 12, 12)  608         concatenate_9[0][0]              
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 152, 12, 12)  0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 24, 12, 12)   32832       activation_12[0][0]              
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 24, 12, 12)   0           dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_10 (Concatenate)    (None, 176, 12, 12)  0           concatenate_9[0][0]              
                                                                 dropout_10[0][0]                 
__________________________________________________________________________________________________
dense_1_4_bn (BatchNormalizatio (None, 176, 12, 12)  704         concatenate_10[0][0]             
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 176, 12, 12)  0           dense_1_4_bn[0][0]               
__________________________________________________________________________________________________
dense_1_4_conv2D (Conv2D)       (None, 24, 12, 12)   38016       activation_13[0][0]              
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, 24, 12, 12)   0           dense_1_4_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_11 (Concatenate)    (None, 200, 12, 12)  0           concatenate_10[0][0]             
                                                                 dropout_11[0][0]                 
__________________________________________________________________________________________________
dense_1_5_bn (BatchNormalizatio (None, 200, 12, 12)  800         concatenate_11[0][0]             
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 200, 12, 12)  0           dense_1_5_bn[0][0]               
__________________________________________________________________________________________________
dense_1_5_conv2D (Conv2D)       (None, 24, 12, 12)   43200       activation_14[0][0]              
__________________________________________________________________________________________________
dropout_12 (Dropout)            (None, 24, 12, 12)   0           dense_1_5_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_12 (Concatenate)    (None, 224, 12, 12)  0           concatenate_11[0][0]             
                                                                 dropout_12[0][0]                 
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 224, 12, 12)  896         concatenate_12[0][0]             
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 224, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 32256)        0           activation_15[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            32257       flatten_1[0][0]                  
==================================================================================================
Total params: 333,345
Trainable params: 329,953
Non-trainable params: 3,392
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/19
 - 72s - loss: 0.4542 - acc: 0.7930 - val_loss: 0.3290 - val_acc: 0.8632
Epoch 2/19
 - 69s - loss: 0.3119 - acc: 0.8742 - val_loss: 0.2683 - val_acc: 0.8937
Epoch 3/19
 - 69s - loss: 0.2536 - acc: 0.9032 - val_loss: 0.2165 - val_acc: 0.9159
Epoch 4/19
 - 69s - loss: 0.2149 - acc: 0.9218 - val_loss: 0.1710 - val_acc: 0.9396
Epoch 5/19
 - 69s - loss: 0.1864 - acc: 0.9351 - val_loss: 0.1368 - val_acc: 0.9544
Epoch 6/19
 - 69s - loss: 0.1647 - acc: 0.9441 - val_loss: 0.1456 - val_acc: 0.9484
Epoch 7/19
 - 69s - loss: 0.1462 - acc: 0.9521 - val_loss: 0.1117 - val_acc: 0.9670
Epoch 8/19
 - 69s - loss: 0.1306 - acc: 0.9587 - val_loss: 0.0894 - val_acc: 0.9746
Epoch 9/19
 - 69s - loss: 0.1185 - acc: 0.9634 - val_loss: 0.0853 - val_acc: 0.9743
Epoch 10/19
 - 69s - loss: 0.1099 - acc: 0.9663 - val_loss: 0.0814 - val_acc: 0.9803
Epoch 11/19
 - 71s - loss: 0.0989 - acc: 0.9714 - val_loss: 0.0856 - val_acc: 0.9720
Epoch 12/19
 - 69s - loss: 0.0900 - acc: 0.9748 - val_loss: 0.0632 - val_acc: 0.9844
Epoch 13/19
 - 69s - loss: 0.0853 - acc: 0.9756 - val_loss: 0.0672 - val_acc: 0.9821
Epoch 14/19
 - 70s - loss: 0.0772 - acc: 0.9801 - val_loss: 0.0573 - val_acc: 0.9853
Epoch 15/19
 - 69s - loss: 0.0721 - acc: 0.9808 - val_loss: 0.0575 - val_acc: 0.9862
Epoch 16/19
 - 68s - loss: 0.0683 - acc: 0.9826 - val_loss: 0.0410 - val_acc: 0.9931
Epoch 17/19
 - 69s - loss: 0.0630 - acc: 0.9843 - val_loss: 0.0426 - val_acc: 0.9912
Epoch 18/19
 - 68s - loss: 0.0611 - acc: 0.9856 - val_loss: 0.0459 - val_acc: 0.9897
Epoch 19/19
 - 68s - loss: 0.0567 - acc: 0.9868 - val_loss: 0.0389 - val_acc: 0.9936
Test accuracy:0.839
current auc_score ------------------> 0.943
Saved model to disk
accuracies:  [0.8462365591397849, 0.8162634408602151, 0.8225806451612904, 0.8389784946236559, 0.8403225806451613, 0.8044354838709677, 0.7888440860215054, 0.8270161290322581, 0.8298387096774194, 0.8388440860215054]
aucs:  [0.9163, 0.9048, 0.8992, 0.9319, 0.9193, 0.9144, 0.8968, 0.9011, 0.9346, 0.9428]
mean and std AUC:  0.916+/-0.015  max:   0.9428
['6-6', '30', '2', '16', '0.2', '0.07', '18', 'adadelta', '0.5', 'FALSE', '64', 'flatten']
------------------------ current config for the test -------------------------
Layers:  [6, 6]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  18  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 30, 24, 24)   20520       activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 24, 24)   0           dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 106, 24, 24)  0           concatenate_2[0][0]              
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 106, 24, 24)  424         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 106, 24, 24)  0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 30, 24, 24)   28620       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 24, 24)   0           dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 136, 24, 24)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
dense_0_4_bn (BatchNormalizatio (None, 136, 24, 24)  544         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 136, 24, 24)  0           dense_0_4_bn[0][0]               
__________________________________________________________________________________________________
dense_0_4_conv2D (Conv2D)       (None, 30, 24, 24)   36720       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 24, 24)   0           dense_0_4_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 166, 24, 24)  0           concatenate_4[0][0]              
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_0_5_bn (BatchNormalizatio (None, 166, 24, 24)  664         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 166, 24, 24)  0           dense_0_5_bn[0][0]               
__________________________________________________________________________________________________
dense_0_5_conv2D (Conv2D)       (None, 30, 24, 24)   44820       activation_7[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 24, 24)   0           dense_0_5_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 196, 24, 24)  0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 196, 24, 24)  784         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 196, 24, 24)  0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 98, 24, 24)   19208       activation_8[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 98, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 98, 12, 12)   392         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 98, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   26460       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 128, 12, 12)  0           average_pooling2d_1[0][0]        
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 128, 12, 12)  512         concatenate_7[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 128, 12, 12)  0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   34560       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 158, 12, 12)  0           concatenate_7[0][0]              
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 158, 12, 12)  632         concatenate_8[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 158, 12, 12)  0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 30, 12, 12)   42660       activation_11[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 30, 12, 12)   0           dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_9 (Concatenate)     (None, 188, 12, 12)  0           concatenate_8[0][0]              
                                                                 dropout_9[0][0]                  
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 188, 12, 12)  752         concatenate_9[0][0]              
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 188, 12, 12)  0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 30, 12, 12)   50760       activation_12[0][0]              
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 30, 12, 12)   0           dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_10 (Concatenate)    (None, 218, 12, 12)  0           concatenate_9[0][0]              
                                                                 dropout_10[0][0]                 
__________________________________________________________________________________________________
dense_1_4_bn (BatchNormalizatio (None, 218, 12, 12)  872         concatenate_10[0][0]             
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 218, 12, 12)  0           dense_1_4_bn[0][0]               
__________________________________________________________________________________________________
dense_1_4_conv2D (Conv2D)       (None, 30, 12, 12)   58860       activation_13[0][0]              
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, 30, 12, 12)   0           dense_1_4_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_11 (Concatenate)    (None, 248, 12, 12)  0           concatenate_10[0][0]             
                                                                 dropout_11[0][0]                 
__________________________________________________________________________________________________
dense_1_5_bn (BatchNormalizatio (None, 248, 12, 12)  992         concatenate_11[0][0]             
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 248, 12, 12)  0           dense_1_5_bn[0][0]               
__________________________________________________________________________________________________
dense_1_5_conv2D (Conv2D)       (None, 30, 12, 12)   66960       activation_14[0][0]              
__________________________________________________________________________________________________
dropout_12 (Dropout)            (None, 30, 12, 12)   0           dense_1_5_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_12 (Concatenate)    (None, 278, 12, 12)  0           concatenate_11[0][0]             
                                                                 dropout_12[0][0]                 
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 278, 12, 12)  1112        concatenate_12[0][0]             
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 278, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 40032)        0           activation_15[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            40033       flatten_1[0][0]                  
==================================================================================================
Total params: 496,785
Trainable params: 492,637
Non-trainable params: 4,148
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/18
 - 95s - loss: 0.4420 - acc: 0.8037 - val_loss: 0.3243 - val_acc: 0.8618
Epoch 2/18
 - 91s - loss: 0.2962 - acc: 0.8843 - val_loss: 0.2369 - val_acc: 0.9167
Epoch 3/18
 - 91s - loss: 0.2383 - acc: 0.9129 - val_loss: 0.1820 - val_acc: 0.9400
Epoch 4/18
 - 91s - loss: 0.1948 - acc: 0.9327 - val_loss: 0.1745 - val_acc: 0.9411
Epoch 5/18
 - 91s - loss: 0.1665 - acc: 0.9449 - val_loss: 0.1260 - val_acc: 0.9656
Epoch 6/18
 - 91s - loss: 0.1476 - acc: 0.9527 - val_loss: 0.1111 - val_acc: 0.9679
Epoch 7/18
 - 91s - loss: 0.1298 - acc: 0.9603 - val_loss: 0.0957 - val_acc: 0.9764
Epoch 8/18
 - 90s - loss: 0.1175 - acc: 0.9656 - val_loss: 0.1136 - val_acc: 0.9639
Epoch 9/18
 - 91s - loss: 0.1054 - acc: 0.9712 - val_loss: 0.0896 - val_acc: 0.9741
Epoch 10/18
 - 92s - loss: 0.0966 - acc: 0.9740 - val_loss: 0.0765 - val_acc: 0.9789
Epoch 11/18
 - 91s - loss: 0.0863 - acc: 0.9772 - val_loss: 0.0590 - val_acc: 0.9881
Epoch 12/18
 - 92s - loss: 0.0813 - acc: 0.9787 - val_loss: 0.1304 - val_acc: 0.9556
Epoch 13/18
 - 92s - loss: 0.0733 - acc: 0.9825 - val_loss: 0.0652 - val_acc: 0.9833
Epoch 14/18
 - 92s - loss: 0.0686 - acc: 0.9836 - val_loss: 0.0582 - val_acc: 0.9866
Epoch 15/18
 - 92s - loss: 0.0647 - acc: 0.9851 - val_loss: 0.0646 - val_acc: 0.9827
Epoch 00015: early stopping
Test accuracy:0.823
current auc_score ------------------> 0.905
------------------------ current config for the test -------------------------
Layers:  [6, 6]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  18  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 30, 24, 24)   20520       activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 24, 24)   0           dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 106, 24, 24)  0           concatenate_2[0][0]              
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 106, 24, 24)  424         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 106, 24, 24)  0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 30, 24, 24)   28620       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 24, 24)   0           dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 136, 24, 24)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
dense_0_4_bn (BatchNormalizatio (None, 136, 24, 24)  544         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 136, 24, 24)  0           dense_0_4_bn[0][0]               
__________________________________________________________________________________________________
dense_0_4_conv2D (Conv2D)       (None, 30, 24, 24)   36720       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 24, 24)   0           dense_0_4_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 166, 24, 24)  0           concatenate_4[0][0]              
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_0_5_bn (BatchNormalizatio (None, 166, 24, 24)  664         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 166, 24, 24)  0           dense_0_5_bn[0][0]               
__________________________________________________________________________________________________
dense_0_5_conv2D (Conv2D)       (None, 30, 24, 24)   44820       activation_7[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 24, 24)   0           dense_0_5_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 196, 24, 24)  0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 196, 24, 24)  784         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 196, 24, 24)  0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 98, 24, 24)   19208       activation_8[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 98, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 98, 12, 12)   392         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 98, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   26460       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 128, 12, 12)  0           average_pooling2d_1[0][0]        
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 128, 12, 12)  512         concatenate_7[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 128, 12, 12)  0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   34560       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 158, 12, 12)  0           concatenate_7[0][0]              
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 158, 12, 12)  632         concatenate_8[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 158, 12, 12)  0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 30, 12, 12)   42660       activation_11[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 30, 12, 12)   0           dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_9 (Concatenate)     (None, 188, 12, 12)  0           concatenate_8[0][0]              
                                                                 dropout_9[0][0]                  
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 188, 12, 12)  752         concatenate_9[0][0]              
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 188, 12, 12)  0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 30, 12, 12)   50760       activation_12[0][0]              
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 30, 12, 12)   0           dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_10 (Concatenate)    (None, 218, 12, 12)  0           concatenate_9[0][0]              
                                                                 dropout_10[0][0]                 
__________________________________________________________________________________________________
dense_1_4_bn (BatchNormalizatio (None, 218, 12, 12)  872         concatenate_10[0][0]             
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 218, 12, 12)  0           dense_1_4_bn[0][0]               
__________________________________________________________________________________________________
dense_1_4_conv2D (Conv2D)       (None, 30, 12, 12)   58860       activation_13[0][0]              
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, 30, 12, 12)   0           dense_1_4_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_11 (Concatenate)    (None, 248, 12, 12)  0           concatenate_10[0][0]             
                                                                 dropout_11[0][0]                 
__________________________________________________________________________________________________
dense_1_5_bn (BatchNormalizatio (None, 248, 12, 12)  992         concatenate_11[0][0]             
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 248, 12, 12)  0           dense_1_5_bn[0][0]               
__________________________________________________________________________________________________
dense_1_5_conv2D (Conv2D)       (None, 30, 12, 12)   66960       activation_14[0][0]              
__________________________________________________________________________________________________
dropout_12 (Dropout)            (None, 30, 12, 12)   0           dense_1_5_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_12 (Concatenate)    (None, 278, 12, 12)  0           concatenate_11[0][0]             
                                                                 dropout_12[0][0]                 
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 278, 12, 12)  1112        concatenate_12[0][0]             
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 278, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 40032)        0           activation_15[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            40033       flatten_1[0][0]                  
==================================================================================================
Total params: 496,785
Trainable params: 492,637
Non-trainable params: 4,148
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/18
 - 94s - loss: 0.4468 - acc: 0.7999 - val_loss: 0.3279 - val_acc: 0.8604
Epoch 2/18
 - 91s - loss: 0.3080 - acc: 0.8779 - val_loss: 0.3109 - val_acc: 0.8613
Epoch 3/18
 - 91s - loss: 0.2413 - acc: 0.9114 - val_loss: 0.1827 - val_acc: 0.9379
Epoch 4/18
 - 91s - loss: 0.1972 - acc: 0.9308 - val_loss: 0.1676 - val_acc: 0.9443
Epoch 5/18
 - 91s - loss: 0.1675 - acc: 0.9449 - val_loss: 0.1917 - val_acc: 0.9305
Epoch 6/18
 - 91s - loss: 0.1458 - acc: 0.9542 - val_loss: 0.1122 - val_acc: 0.9694
Epoch 7/18
 - 91s - loss: 0.1284 - acc: 0.9609 - val_loss: 0.0918 - val_acc: 0.9750
Epoch 8/18
 - 91s - loss: 0.1158 - acc: 0.9652 - val_loss: 0.1182 - val_acc: 0.9644
Epoch 9/18
 - 91s - loss: 0.1024 - acc: 0.9716 - val_loss: 0.0839 - val_acc: 0.9760
Epoch 10/18
 - 92s - loss: 0.0946 - acc: 0.9739 - val_loss: 0.0838 - val_acc: 0.9787
Epoch 11/18
 - 92s - loss: 0.0855 - acc: 0.9779 - val_loss: 0.0678 - val_acc: 0.9831
Epoch 12/18
 - 92s - loss: 0.0777 - acc: 0.9806 - val_loss: 0.0754 - val_acc: 0.9788
Epoch 13/18
 - 92s - loss: 0.0726 - acc: 0.9823 - val_loss: 0.0625 - val_acc: 0.9841
Epoch 14/18
 - 92s - loss: 0.0675 - acc: 0.9837 - val_loss: 0.0566 - val_acc: 0.9868
Epoch 15/18
 - 92s - loss: 0.0646 - acc: 0.9852 - val_loss: 0.0618 - val_acc: 0.9833
Epoch 16/18
 - 92s - loss: 0.0594 - acc: 0.9868 - val_loss: 0.0463 - val_acc: 0.9911
Epoch 17/18
 - 92s - loss: 0.0546 - acc: 0.9891 - val_loss: 0.0434 - val_acc: 0.9910
Epoch 18/18
 - 92s - loss: 0.0532 - acc: 0.9887 - val_loss: 0.0397 - val_acc: 0.9928
Test accuracy:0.821
current auc_score ------------------> 0.916
------------------------ current config for the test -------------------------
Layers:  [6, 6]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  18  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 30, 24, 24)   20520       activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 24, 24)   0           dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 106, 24, 24)  0           concatenate_2[0][0]              
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 106, 24, 24)  424         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 106, 24, 24)  0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 30, 24, 24)   28620       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 24, 24)   0           dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 136, 24, 24)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
dense_0_4_bn (BatchNormalizatio (None, 136, 24, 24)  544         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 136, 24, 24)  0           dense_0_4_bn[0][0]               
__________________________________________________________________________________________________
dense_0_4_conv2D (Conv2D)       (None, 30, 24, 24)   36720       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 24, 24)   0           dense_0_4_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 166, 24, 24)  0           concatenate_4[0][0]              
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_0_5_bn (BatchNormalizatio (None, 166, 24, 24)  664         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 166, 24, 24)  0           dense_0_5_bn[0][0]               
__________________________________________________________________________________________________
dense_0_5_conv2D (Conv2D)       (None, 30, 24, 24)   44820       activation_7[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 24, 24)   0           dense_0_5_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 196, 24, 24)  0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 196, 24, 24)  784         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 196, 24, 24)  0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 98, 24, 24)   19208       activation_8[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 98, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 98, 12, 12)   392         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 98, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   26460       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 128, 12, 12)  0           average_pooling2d_1[0][0]        
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 128, 12, 12)  512         concatenate_7[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 128, 12, 12)  0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   34560       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 158, 12, 12)  0           concatenate_7[0][0]              
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 158, 12, 12)  632         concatenate_8[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 158, 12, 12)  0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 30, 12, 12)   42660       activation_11[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 30, 12, 12)   0           dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_9 (Concatenate)     (None, 188, 12, 12)  0           concatenate_8[0][0]              
                                                                 dropout_9[0][0]                  
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 188, 12, 12)  752         concatenate_9[0][0]              
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 188, 12, 12)  0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 30, 12, 12)   50760       activation_12[0][0]              
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 30, 12, 12)   0           dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_10 (Concatenate)    (None, 218, 12, 12)  0           concatenate_9[0][0]              
                                                                 dropout_10[0][0]                 
__________________________________________________________________________________________________
dense_1_4_bn (BatchNormalizatio (None, 218, 12, 12)  872         concatenate_10[0][0]             
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 218, 12, 12)  0           dense_1_4_bn[0][0]               
__________________________________________________________________________________________________
dense_1_4_conv2D (Conv2D)       (None, 30, 12, 12)   58860       activation_13[0][0]              
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, 30, 12, 12)   0           dense_1_4_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_11 (Concatenate)    (None, 248, 12, 12)  0           concatenate_10[0][0]             
                                                                 dropout_11[0][0]                 
__________________________________________________________________________________________________
dense_1_5_bn (BatchNormalizatio (None, 248, 12, 12)  992         concatenate_11[0][0]             
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 248, 12, 12)  0           dense_1_5_bn[0][0]               
__________________________________________________________________________________________________
dense_1_5_conv2D (Conv2D)       (None, 30, 12, 12)   66960       activation_14[0][0]              
__________________________________________________________________________________________________
dropout_12 (Dropout)            (None, 30, 12, 12)   0           dense_1_5_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_12 (Concatenate)    (None, 278, 12, 12)  0           concatenate_11[0][0]             
                                                                 dropout_12[0][0]                 
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 278, 12, 12)  1112        concatenate_12[0][0]             
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 278, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 40032)        0           activation_15[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            40033       flatten_1[0][0]                  
==================================================================================================
Total params: 496,785
Trainable params: 492,637
Non-trainable params: 4,148
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/18
 - 95s - loss: 0.4499 - acc: 0.7975 - val_loss: 0.8291 - val_acc: 0.6258
Epoch 2/18
 - 91s - loss: 0.3087 - acc: 0.8782 - val_loss: 0.2359 - val_acc: 0.9124
Epoch 3/18
 - 91s - loss: 0.2489 - acc: 0.9060 - val_loss: 0.3595 - val_acc: 0.8368
Epoch 4/18
 - 91s - loss: 0.2067 - acc: 0.9266 - val_loss: 0.4146 - val_acc: 0.8085
Epoch 5/18
 - 91s - loss: 0.1773 - acc: 0.9398 - val_loss: 0.2101 - val_acc: 0.9204
Epoch 6/18
 - 91s - loss: 0.1566 - acc: 0.9492 - val_loss: 0.1621 - val_acc: 0.9450
Epoch 7/18
 - 91s - loss: 0.1385 - acc: 0.9559 - val_loss: 0.1179 - val_acc: 0.9639
Epoch 8/18
 - 91s - loss: 0.1232 - acc: 0.9625 - val_loss: 0.0982 - val_acc: 0.9739
Epoch 9/18
 - 91s - loss: 0.1112 - acc: 0.9668 - val_loss: 0.0970 - val_acc: 0.9708
Epoch 10/18
 - 90s - loss: 0.1028 - acc: 0.9707 - val_loss: 0.1240 - val_acc: 0.9588
Epoch 11/18
 - 90s - loss: 0.0916 - acc: 0.9754 - val_loss: 0.0706 - val_acc: 0.9823
Epoch 12/18
 - 90s - loss: 0.0849 - acc: 0.9778 - val_loss: 0.0702 - val_acc: 0.9809
Epoch 13/18
 - 91s - loss: 0.0789 - acc: 0.9800 - val_loss: 0.0686 - val_acc: 0.9819
Epoch 14/18
 - 91s - loss: 0.0733 - acc: 0.9816 - val_loss: 0.0662 - val_acc: 0.9831
Epoch 15/18
 - 91s - loss: 0.0673 - acc: 0.9836 - val_loss: 0.0471 - val_acc: 0.9926
Epoch 16/18
 - 91s - loss: 0.0640 - acc: 0.9856 - val_loss: 0.0550 - val_acc: 0.9893
Epoch 17/18
 - 91s - loss: 0.0595 - acc: 0.9864 - val_loss: 0.0729 - val_acc: 0.9794
Epoch 18/18
 - 91s - loss: 0.0563 - acc: 0.9878 - val_loss: 0.0427 - val_acc: 0.9928
Test accuracy:0.836
current auc_score ------------------> 0.921
------------------------ current config for the test -------------------------
Layers:  [6, 6]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  18  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 30, 24, 24)   20520       activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 24, 24)   0           dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 106, 24, 24)  0           concatenate_2[0][0]              
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 106, 24, 24)  424         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 106, 24, 24)  0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 30, 24, 24)   28620       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 24, 24)   0           dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 136, 24, 24)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
dense_0_4_bn (BatchNormalizatio (None, 136, 24, 24)  544         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 136, 24, 24)  0           dense_0_4_bn[0][0]               
__________________________________________________________________________________________________
dense_0_4_conv2D (Conv2D)       (None, 30, 24, 24)   36720       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 24, 24)   0           dense_0_4_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 166, 24, 24)  0           concatenate_4[0][0]              
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_0_5_bn (BatchNormalizatio (None, 166, 24, 24)  664         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 166, 24, 24)  0           dense_0_5_bn[0][0]               
__________________________________________________________________________________________________
dense_0_5_conv2D (Conv2D)       (None, 30, 24, 24)   44820       activation_7[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 24, 24)   0           dense_0_5_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 196, 24, 24)  0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 196, 24, 24)  784         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 196, 24, 24)  0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 98, 24, 24)   19208       activation_8[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 98, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 98, 12, 12)   392         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 98, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   26460       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 128, 12, 12)  0           average_pooling2d_1[0][0]        
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 128, 12, 12)  512         concatenate_7[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 128, 12, 12)  0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   34560       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 158, 12, 12)  0           concatenate_7[0][0]              
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 158, 12, 12)  632         concatenate_8[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 158, 12, 12)  0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 30, 12, 12)   42660       activation_11[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 30, 12, 12)   0           dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_9 (Concatenate)     (None, 188, 12, 12)  0           concatenate_8[0][0]              
                                                                 dropout_9[0][0]                  
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 188, 12, 12)  752         concatenate_9[0][0]              
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 188, 12, 12)  0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 30, 12, 12)   50760       activation_12[0][0]              
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 30, 12, 12)   0           dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_10 (Concatenate)    (None, 218, 12, 12)  0           concatenate_9[0][0]              
                                                                 dropout_10[0][0]                 
__________________________________________________________________________________________________
dense_1_4_bn (BatchNormalizatio (None, 218, 12, 12)  872         concatenate_10[0][0]             
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 218, 12, 12)  0           dense_1_4_bn[0][0]               
__________________________________________________________________________________________________
dense_1_4_conv2D (Conv2D)       (None, 30, 12, 12)   58860       activation_13[0][0]              
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, 30, 12, 12)   0           dense_1_4_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_11 (Concatenate)    (None, 248, 12, 12)  0           concatenate_10[0][0]             
                                                                 dropout_11[0][0]                 
__________________________________________________________________________________________________
dense_1_5_bn (BatchNormalizatio (None, 248, 12, 12)  992         concatenate_11[0][0]             
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 248, 12, 12)  0           dense_1_5_bn[0][0]               
__________________________________________________________________________________________________
dense_1_5_conv2D (Conv2D)       (None, 30, 12, 12)   66960       activation_14[0][0]              
__________________________________________________________________________________________________
dropout_12 (Dropout)            (None, 30, 12, 12)   0           dense_1_5_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_12 (Concatenate)    (None, 278, 12, 12)  0           concatenate_11[0][0]             
                                                                 dropout_12[0][0]                 
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 278, 12, 12)  1112        concatenate_12[0][0]             
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 278, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 40032)        0           activation_15[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            40033       flatten_1[0][0]                  
==================================================================================================
Total params: 496,785
Trainable params: 492,637
Non-trainable params: 4,148
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/18
 - 95s - loss: 0.4474 - acc: 0.7990 - val_loss: 0.3463 - val_acc: 0.8538
Epoch 2/18
 - 91s - loss: 0.3080 - acc: 0.8777 - val_loss: 0.3448 - val_acc: 0.8530
Epoch 3/18
 - 91s - loss: 0.2452 - acc: 0.9074 - val_loss: 0.2238 - val_acc: 0.9152
Epoch 4/18
 - 91s - loss: 0.2039 - acc: 0.9279 - val_loss: 0.2501 - val_acc: 0.8996
Epoch 5/18
 - 91s - loss: 0.1760 - acc: 0.9405 - val_loss: 0.1451 - val_acc: 0.9514
Epoch 6/18
 - 91s - loss: 0.1538 - acc: 0.9507 - val_loss: 0.1535 - val_acc: 0.9489
Epoch 7/18
 - 92s - loss: 0.1346 - acc: 0.9589 - val_loss: 0.1071 - val_acc: 0.9677
Epoch 8/18
 - 91s - loss: 0.1209 - acc: 0.9632 - val_loss: 0.1444 - val_acc: 0.9495
Epoch 9/18
 - 91s - loss: 0.1089 - acc: 0.9689 - val_loss: 0.0750 - val_acc: 0.9839
Epoch 10/18
 - 91s - loss: 0.0981 - acc: 0.9740 - val_loss: 0.0825 - val_acc: 0.9797
Epoch 11/18
 - 92s - loss: 0.0910 - acc: 0.9748 - val_loss: 0.0594 - val_acc: 0.9887
Epoch 12/18
 - 91s - loss: 0.0826 - acc: 0.9785 - val_loss: 0.0805 - val_acc: 0.9759
Epoch 13/18
 - 90s - loss: 0.0764 - acc: 0.9811 - val_loss: 0.0718 - val_acc: 0.9802
Epoch 14/18
 - 90s - loss: 0.0706 - acc: 0.9838 - val_loss: 0.0445 - val_acc: 0.9944
Epoch 15/18
 - 90s - loss: 0.0661 - acc: 0.9848 - val_loss: 0.0481 - val_acc: 0.9905
Epoch 16/18
 - 90s - loss: 0.0613 - acc: 0.9865 - val_loss: 0.0630 - val_acc: 0.9844
Epoch 17/18
 - 90s - loss: 0.0596 - acc: 0.9871 - val_loss: 0.0400 - val_acc: 0.9945
Epoch 18/18
 - 90s - loss: 0.0536 - acc: 0.9891 - val_loss: 0.0596 - val_acc: 0.9836
Test accuracy:0.818
current auc_score ------------------> 0.895
------------------------ current config for the test -------------------------
Layers:  [6, 6]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  18  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 30, 24, 24)   20520       activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 24, 24)   0           dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 106, 24, 24)  0           concatenate_2[0][0]              
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 106, 24, 24)  424         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 106, 24, 24)  0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 30, 24, 24)   28620       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 24, 24)   0           dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 136, 24, 24)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
dense_0_4_bn (BatchNormalizatio (None, 136, 24, 24)  544         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 136, 24, 24)  0           dense_0_4_bn[0][0]               
__________________________________________________________________________________________________
dense_0_4_conv2D (Conv2D)       (None, 30, 24, 24)   36720       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 24, 24)   0           dense_0_4_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 166, 24, 24)  0           concatenate_4[0][0]              
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_0_5_bn (BatchNormalizatio (None, 166, 24, 24)  664         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 166, 24, 24)  0           dense_0_5_bn[0][0]               
__________________________________________________________________________________________________
dense_0_5_conv2D (Conv2D)       (None, 30, 24, 24)   44820       activation_7[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 24, 24)   0           dense_0_5_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 196, 24, 24)  0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 196, 24, 24)  784         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 196, 24, 24)  0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 98, 24, 24)   19208       activation_8[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 98, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 98, 12, 12)   392         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 98, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   26460       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 128, 12, 12)  0           average_pooling2d_1[0][0]        
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 128, 12, 12)  512         concatenate_7[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 128, 12, 12)  0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   34560       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 158, 12, 12)  0           concatenate_7[0][0]              
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 158, 12, 12)  632         concatenate_8[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 158, 12, 12)  0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 30, 12, 12)   42660       activation_11[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 30, 12, 12)   0           dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_9 (Concatenate)     (None, 188, 12, 12)  0           concatenate_8[0][0]              
                                                                 dropout_9[0][0]                  
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 188, 12, 12)  752         concatenate_9[0][0]              
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 188, 12, 12)  0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 30, 12, 12)   50760       activation_12[0][0]              
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 30, 12, 12)   0           dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_10 (Concatenate)    (None, 218, 12, 12)  0           concatenate_9[0][0]              
                                                                 dropout_10[0][0]                 
__________________________________________________________________________________________________
dense_1_4_bn (BatchNormalizatio (None, 218, 12, 12)  872         concatenate_10[0][0]             
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 218, 12, 12)  0           dense_1_4_bn[0][0]               
__________________________________________________________________________________________________
dense_1_4_conv2D (Conv2D)       (None, 30, 12, 12)   58860       activation_13[0][0]              
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, 30, 12, 12)   0           dense_1_4_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_11 (Concatenate)    (None, 248, 12, 12)  0           concatenate_10[0][0]             
                                                                 dropout_11[0][0]                 
__________________________________________________________________________________________________
dense_1_5_bn (BatchNormalizatio (None, 248, 12, 12)  992         concatenate_11[0][0]             
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 248, 12, 12)  0           dense_1_5_bn[0][0]               
__________________________________________________________________________________________________
dense_1_5_conv2D (Conv2D)       (None, 30, 12, 12)   66960       activation_14[0][0]              
__________________________________________________________________________________________________
dropout_12 (Dropout)            (None, 30, 12, 12)   0           dense_1_5_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_12 (Concatenate)    (None, 278, 12, 12)  0           concatenate_11[0][0]             
                                                                 dropout_12[0][0]                 
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 278, 12, 12)  1112        concatenate_12[0][0]             
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 278, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 40032)        0           activation_15[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            40033       flatten_1[0][0]                  
==================================================================================================
Total params: 496,785
Trainable params: 492,637
Non-trainable params: 4,148
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/18
 - 97s - loss: 0.4422 - acc: 0.8036 - val_loss: 0.2953 - val_acc: 0.8832
Epoch 2/18
 - 92s - loss: 0.2981 - acc: 0.8834 - val_loss: 0.2529 - val_acc: 0.9083
Epoch 3/18
 - 92s - loss: 0.2354 - acc: 0.9137 - val_loss: 0.2264 - val_acc: 0.9132
Epoch 4/18
 - 91s - loss: 0.1981 - acc: 0.9309 - val_loss: 0.1833 - val_acc: 0.9342
Epoch 5/18
 - 92s - loss: 0.1671 - acc: 0.9462 - val_loss: 0.1362 - val_acc: 0.9558
Epoch 6/18
 - 92s - loss: 0.1436 - acc: 0.9551 - val_loss: 0.1041 - val_acc: 0.9711
Epoch 7/18
 - 92s - loss: 0.1245 - acc: 0.9633 - val_loss: 0.0958 - val_acc: 0.9731
Epoch 8/18
 - 92s - loss: 0.1120 - acc: 0.9682 - val_loss: 0.0905 - val_acc: 0.9741
Epoch 9/18
 - 92s - loss: 0.1021 - acc: 0.9710 - val_loss: 0.0742 - val_acc: 0.9818
Epoch 10/18
 - 92s - loss: 0.0918 - acc: 0.9757 - val_loss: 0.0686 - val_acc: 0.9847
Epoch 11/18
 - 92s - loss: 0.0841 - acc: 0.9784 - val_loss: 0.0873 - val_acc: 0.9738
Epoch 12/18
 - 92s - loss: 0.0775 - acc: 0.9807 - val_loss: 0.0751 - val_acc: 0.9808
Epoch 13/18
 - 92s - loss: 0.0728 - acc: 0.9819 - val_loss: 0.0478 - val_acc: 0.9917
Epoch 14/18
 - 92s - loss: 0.0671 - acc: 0.9841 - val_loss: 0.0449 - val_acc: 0.9932
Epoch 15/18
 - 92s - loss: 0.0619 - acc: 0.9863 - val_loss: 0.0495 - val_acc: 0.9907
Epoch 16/18
 - 92s - loss: 0.0574 - acc: 0.9882 - val_loss: 0.0417 - val_acc: 0.9931
Epoch 17/18
 - 92s - loss: 0.0541 - acc: 0.9894 - val_loss: 0.0488 - val_acc: 0.9886
Epoch 18/18
 - 92s - loss: 0.0518 - acc: 0.9900 - val_loss: 0.0437 - val_acc: 0.9931
Epoch 00018: early stopping
Test accuracy:0.822
current auc_score ------------------> 0.922
------------------------ current config for the test -------------------------
Layers:  [6, 6]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  18  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 30, 24, 24)   20520       activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 24, 24)   0           dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 106, 24, 24)  0           concatenate_2[0][0]              
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 106, 24, 24)  424         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 106, 24, 24)  0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 30, 24, 24)   28620       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 24, 24)   0           dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 136, 24, 24)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
dense_0_4_bn (BatchNormalizatio (None, 136, 24, 24)  544         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 136, 24, 24)  0           dense_0_4_bn[0][0]               
__________________________________________________________________________________________________
dense_0_4_conv2D (Conv2D)       (None, 30, 24, 24)   36720       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 24, 24)   0           dense_0_4_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 166, 24, 24)  0           concatenate_4[0][0]              
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_0_5_bn (BatchNormalizatio (None, 166, 24, 24)  664         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 166, 24, 24)  0           dense_0_5_bn[0][0]               
__________________________________________________________________________________________________
dense_0_5_conv2D (Conv2D)       (None, 30, 24, 24)   44820       activation_7[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 24, 24)   0           dense_0_5_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 196, 24, 24)  0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 196, 24, 24)  784         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 196, 24, 24)  0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 98, 24, 24)   19208       activation_8[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 98, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 98, 12, 12)   392         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 98, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   26460       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 128, 12, 12)  0           average_pooling2d_1[0][0]        
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 128, 12, 12)  512         concatenate_7[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 128, 12, 12)  0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   34560       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 158, 12, 12)  0           concatenate_7[0][0]              
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 158, 12, 12)  632         concatenate_8[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 158, 12, 12)  0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 30, 12, 12)   42660       activation_11[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 30, 12, 12)   0           dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_9 (Concatenate)     (None, 188, 12, 12)  0           concatenate_8[0][0]              
                                                                 dropout_9[0][0]                  
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 188, 12, 12)  752         concatenate_9[0][0]              
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 188, 12, 12)  0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 30, 12, 12)   50760       activation_12[0][0]              
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 30, 12, 12)   0           dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_10 (Concatenate)    (None, 218, 12, 12)  0           concatenate_9[0][0]              
                                                                 dropout_10[0][0]                 
__________________________________________________________________________________________________
dense_1_4_bn (BatchNormalizatio (None, 218, 12, 12)  872         concatenate_10[0][0]             
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 218, 12, 12)  0           dense_1_4_bn[0][0]               
__________________________________________________________________________________________________
dense_1_4_conv2D (Conv2D)       (None, 30, 12, 12)   58860       activation_13[0][0]              
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, 30, 12, 12)   0           dense_1_4_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_11 (Concatenate)    (None, 248, 12, 12)  0           concatenate_10[0][0]             
                                                                 dropout_11[0][0]                 
__________________________________________________________________________________________________
dense_1_5_bn (BatchNormalizatio (None, 248, 12, 12)  992         concatenate_11[0][0]             
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 248, 12, 12)  0           dense_1_5_bn[0][0]               
__________________________________________________________________________________________________
dense_1_5_conv2D (Conv2D)       (None, 30, 12, 12)   66960       activation_14[0][0]              
__________________________________________________________________________________________________
dropout_12 (Dropout)            (None, 30, 12, 12)   0           dense_1_5_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_12 (Concatenate)    (None, 278, 12, 12)  0           concatenate_11[0][0]             
                                                                 dropout_12[0][0]                 
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 278, 12, 12)  1112        concatenate_12[0][0]             
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 278, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 40032)        0           activation_15[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            40033       flatten_1[0][0]                  
==================================================================================================
Total params: 496,785
Trainable params: 492,637
Non-trainable params: 4,148
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/18
 - 95s - loss: 0.4537 - acc: 0.7957 - val_loss: 0.8814 - val_acc: 0.6137
Epoch 2/18
 - 91s - loss: 0.3014 - acc: 0.8815 - val_loss: 0.2318 - val_acc: 0.9118
Epoch 3/18
 - 91s - loss: 0.2404 - acc: 0.9091 - val_loss: 0.1968 - val_acc: 0.9317
Epoch 4/18
 - 91s - loss: 0.2010 - acc: 0.9297 - val_loss: 0.2470 - val_acc: 0.8998
Epoch 5/18
 - 91s - loss: 0.1717 - acc: 0.9425 - val_loss: 0.1560 - val_acc: 0.9458
Epoch 6/18
 - 92s - loss: 0.1496 - acc: 0.9515 - val_loss: 0.1193 - val_acc: 0.9601
Epoch 7/18
 - 92s - loss: 0.1324 - acc: 0.9595 - val_loss: 0.0988 - val_acc: 0.9696
Epoch 8/18
 - 91s - loss: 0.1179 - acc: 0.9653 - val_loss: 0.0797 - val_acc: 0.9802
Epoch 9/18
 - 91s - loss: 0.1069 - acc: 0.9691 - val_loss: 0.0669 - val_acc: 0.9853
Epoch 10/18
 - 93s - loss: 0.0956 - acc: 0.9737 - val_loss: 0.1041 - val_acc: 0.9667
Epoch 11/18
 - 91s - loss: 0.0883 - acc: 0.9769 - val_loss: 0.0597 - val_acc: 0.9868
Epoch 12/18
 - 92s - loss: 0.0825 - acc: 0.9780 - val_loss: 0.0838 - val_acc: 0.9758
Epoch 13/18
 - 92s - loss: 0.0739 - acc: 0.9813 - val_loss: 0.0523 - val_acc: 0.9897
Epoch 14/18
 - 92s - loss: 0.0700 - acc: 0.9833 - val_loss: 0.0454 - val_acc: 0.9923
Epoch 15/18
 - 92s - loss: 0.0646 - acc: 0.9854 - val_loss: 0.0433 - val_acc: 0.9921
Epoch 16/18
 - 92s - loss: 0.0603 - acc: 0.9861 - val_loss: 0.0391 - val_acc: 0.9950
Epoch 17/18
 - 92s - loss: 0.0571 - acc: 0.9881 - val_loss: 0.0361 - val_acc: 0.9957
Epoch 18/18
 - 91s - loss: 0.0554 - acc: 0.9876 - val_loss: 0.0403 - val_acc: 0.9951
Test accuracy:0.731
current auc_score ------------------> 0.904
------------------------ current config for the test -------------------------
Layers:  [6, 6]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  18  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 30, 24, 24)   20520       activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 24, 24)   0           dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 106, 24, 24)  0           concatenate_2[0][0]              
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 106, 24, 24)  424         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 106, 24, 24)  0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 30, 24, 24)   28620       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 24, 24)   0           dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 136, 24, 24)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
dense_0_4_bn (BatchNormalizatio (None, 136, 24, 24)  544         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 136, 24, 24)  0           dense_0_4_bn[0][0]               
__________________________________________________________________________________________________
dense_0_4_conv2D (Conv2D)       (None, 30, 24, 24)   36720       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 24, 24)   0           dense_0_4_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 166, 24, 24)  0           concatenate_4[0][0]              
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_0_5_bn (BatchNormalizatio (None, 166, 24, 24)  664         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 166, 24, 24)  0           dense_0_5_bn[0][0]               
__________________________________________________________________________________________________
dense_0_5_conv2D (Conv2D)       (None, 30, 24, 24)   44820       activation_7[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 24, 24)   0           dense_0_5_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 196, 24, 24)  0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 196, 24, 24)  784         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 196, 24, 24)  0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 98, 24, 24)   19208       activation_8[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 98, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 98, 12, 12)   392         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 98, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   26460       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 128, 12, 12)  0           average_pooling2d_1[0][0]        
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 128, 12, 12)  512         concatenate_7[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 128, 12, 12)  0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   34560       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 158, 12, 12)  0           concatenate_7[0][0]              
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 158, 12, 12)  632         concatenate_8[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 158, 12, 12)  0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 30, 12, 12)   42660       activation_11[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 30, 12, 12)   0           dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_9 (Concatenate)     (None, 188, 12, 12)  0           concatenate_8[0][0]              
                                                                 dropout_9[0][0]                  
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 188, 12, 12)  752         concatenate_9[0][0]              
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 188, 12, 12)  0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 30, 12, 12)   50760       activation_12[0][0]              
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 30, 12, 12)   0           dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_10 (Concatenate)    (None, 218, 12, 12)  0           concatenate_9[0][0]              
                                                                 dropout_10[0][0]                 
__________________________________________________________________________________________________
dense_1_4_bn (BatchNormalizatio (None, 218, 12, 12)  872         concatenate_10[0][0]             
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 218, 12, 12)  0           dense_1_4_bn[0][0]               
__________________________________________________________________________________________________
dense_1_4_conv2D (Conv2D)       (None, 30, 12, 12)   58860       activation_13[0][0]              
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, 30, 12, 12)   0           dense_1_4_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_11 (Concatenate)    (None, 248, 12, 12)  0           concatenate_10[0][0]             
                                                                 dropout_11[0][0]                 
__________________________________________________________________________________________________
dense_1_5_bn (BatchNormalizatio (None, 248, 12, 12)  992         concatenate_11[0][0]             
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 248, 12, 12)  0           dense_1_5_bn[0][0]               
__________________________________________________________________________________________________
dense_1_5_conv2D (Conv2D)       (None, 30, 12, 12)   66960       activation_14[0][0]              
__________________________________________________________________________________________________
dropout_12 (Dropout)            (None, 30, 12, 12)   0           dense_1_5_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_12 (Concatenate)    (None, 278, 12, 12)  0           concatenate_11[0][0]             
                                                                 dropout_12[0][0]                 
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 278, 12, 12)  1112        concatenate_12[0][0]             
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 278, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 40032)        0           activation_15[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            40033       flatten_1[0][0]                  
==================================================================================================
Total params: 496,785
Trainable params: 492,637
Non-trainable params: 4,148
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/18
 - 95s - loss: 0.4462 - acc: 0.8010 - val_loss: 0.3151 - val_acc: 0.8717
Epoch 2/18
 - 91s - loss: 0.3036 - acc: 0.8800 - val_loss: 0.2244 - val_acc: 0.9147
Epoch 3/18
 - 91s - loss: 0.2429 - acc: 0.9103 - val_loss: 0.1852 - val_acc: 0.9344
Epoch 4/18
 - 91s - loss: 0.1995 - acc: 0.9301 - val_loss: 0.1735 - val_acc: 0.9388
Epoch 5/18
 - 91s - loss: 0.1696 - acc: 0.9450 - val_loss: 0.1780 - val_acc: 0.9359
Epoch 6/18
 - 91s - loss: 0.1469 - acc: 0.9546 - val_loss: 0.1254 - val_acc: 0.9600
Epoch 7/18
 - 91s - loss: 0.1284 - acc: 0.9609 - val_loss: 0.0941 - val_acc: 0.9729
Epoch 8/18
 - 91s - loss: 0.1169 - acc: 0.9658 - val_loss: 0.0824 - val_acc: 0.9819
Epoch 9/18
 - 91s - loss: 0.1035 - acc: 0.9712 - val_loss: 0.0810 - val_acc: 0.9797
Epoch 10/18
 - 91s - loss: 0.0931 - acc: 0.9746 - val_loss: 0.0886 - val_acc: 0.9763
Epoch 11/18
 - 91s - loss: 0.0866 - acc: 0.9773 - val_loss: 0.0713 - val_acc: 0.9818
Epoch 12/18
 - 91s - loss: 0.0765 - acc: 0.9814 - val_loss: 0.0620 - val_acc: 0.9847
Epoch 13/18
 - 91s - loss: 0.0708 - acc: 0.9831 - val_loss: 0.1326 - val_acc: 0.9524
Epoch 14/18
 - 91s - loss: 0.0673 - acc: 0.9842 - val_loss: 0.0488 - val_acc: 0.9901
Epoch 15/18
 - 90s - loss: 0.0624 - acc: 0.9867 - val_loss: 0.0486 - val_acc: 0.9917
Epoch 16/18
 - 91s - loss: 0.0586 - acc: 0.9872 - val_loss: 0.0647 - val_acc: 0.9846
Epoch 17/18
 - 91s - loss: 0.0553 - acc: 0.9883 - val_loss: 0.0355 - val_acc: 0.9960
Epoch 18/18
 - 91s - loss: 0.0527 - acc: 0.9900 - val_loss: 0.0408 - val_acc: 0.9925
Test accuracy:0.835
current auc_score ------------------> 0.925
------------------------ current config for the test -------------------------
Layers:  [6, 6]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  18  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 30, 24, 24)   20520       activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 24, 24)   0           dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 106, 24, 24)  0           concatenate_2[0][0]              
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 106, 24, 24)  424         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 106, 24, 24)  0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 30, 24, 24)   28620       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 24, 24)   0           dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 136, 24, 24)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
dense_0_4_bn (BatchNormalizatio (None, 136, 24, 24)  544         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 136, 24, 24)  0           dense_0_4_bn[0][0]               
__________________________________________________________________________________________________
dense_0_4_conv2D (Conv2D)       (None, 30, 24, 24)   36720       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 24, 24)   0           dense_0_4_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 166, 24, 24)  0           concatenate_4[0][0]              
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_0_5_bn (BatchNormalizatio (None, 166, 24, 24)  664         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 166, 24, 24)  0           dense_0_5_bn[0][0]               
__________________________________________________________________________________________________
dense_0_5_conv2D (Conv2D)       (None, 30, 24, 24)   44820       activation_7[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 24, 24)   0           dense_0_5_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 196, 24, 24)  0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 196, 24, 24)  784         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 196, 24, 24)  0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 98, 24, 24)   19208       activation_8[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 98, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 98, 12, 12)   392         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 98, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   26460       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 128, 12, 12)  0           average_pooling2d_1[0][0]        
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 128, 12, 12)  512         concatenate_7[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 128, 12, 12)  0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   34560       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 158, 12, 12)  0           concatenate_7[0][0]              
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 158, 12, 12)  632         concatenate_8[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 158, 12, 12)  0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 30, 12, 12)   42660       activation_11[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 30, 12, 12)   0           dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_9 (Concatenate)     (None, 188, 12, 12)  0           concatenate_8[0][0]              
                                                                 dropout_9[0][0]                  
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 188, 12, 12)  752         concatenate_9[0][0]              
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 188, 12, 12)  0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 30, 12, 12)   50760       activation_12[0][0]              
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 30, 12, 12)   0           dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_10 (Concatenate)    (None, 218, 12, 12)  0           concatenate_9[0][0]              
                                                                 dropout_10[0][0]                 
__________________________________________________________________________________________________
dense_1_4_bn (BatchNormalizatio (None, 218, 12, 12)  872         concatenate_10[0][0]             
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 218, 12, 12)  0           dense_1_4_bn[0][0]               
__________________________________________________________________________________________________
dense_1_4_conv2D (Conv2D)       (None, 30, 12, 12)   58860       activation_13[0][0]              
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, 30, 12, 12)   0           dense_1_4_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_11 (Concatenate)    (None, 248, 12, 12)  0           concatenate_10[0][0]             
                                                                 dropout_11[0][0]                 
__________________________________________________________________________________________________
dense_1_5_bn (BatchNormalizatio (None, 248, 12, 12)  992         concatenate_11[0][0]             
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 248, 12, 12)  0           dense_1_5_bn[0][0]               
__________________________________________________________________________________________________
dense_1_5_conv2D (Conv2D)       (None, 30, 12, 12)   66960       activation_14[0][0]              
__________________________________________________________________________________________________
dropout_12 (Dropout)            (None, 30, 12, 12)   0           dense_1_5_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_12 (Concatenate)    (None, 278, 12, 12)  0           concatenate_11[0][0]             
                                                                 dropout_12[0][0]                 
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 278, 12, 12)  1112        concatenate_12[0][0]             
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 278, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 40032)        0           activation_15[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            40033       flatten_1[0][0]                  
==================================================================================================
Total params: 496,785
Trainable params: 492,637
Non-trainable params: 4,148
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/18
 - 95s - loss: 0.4554 - acc: 0.7946 - val_loss: 0.3331 - val_acc: 0.8602
Epoch 2/18
 - 91s - loss: 0.3070 - acc: 0.8787 - val_loss: 0.3315 - val_acc: 0.8557
Epoch 3/18
 - 92s - loss: 0.2475 - acc: 0.9080 - val_loss: 0.2100 - val_acc: 0.9260
Epoch 4/18
 - 92s - loss: 0.2076 - acc: 0.9261 - val_loss: 0.1610 - val_acc: 0.9493
Epoch 5/18
 - 92s - loss: 0.1737 - acc: 0.9419 - val_loss: 0.1332 - val_acc: 0.9607
Epoch 6/18
 - 92s - loss: 0.1534 - acc: 0.9521 - val_loss: 0.1187 - val_acc: 0.9657
Epoch 7/18
 - 92s - loss: 0.1349 - acc: 0.9581 - val_loss: 0.1005 - val_acc: 0.9716
Epoch 8/18
 - 92s - loss: 0.1200 - acc: 0.9646 - val_loss: 0.0854 - val_acc: 0.9770
Epoch 9/18
 - 93s - loss: 0.1066 - acc: 0.9702 - val_loss: 0.0731 - val_acc: 0.9813
Epoch 10/18
 - 91s - loss: 0.0982 - acc: 0.9731 - val_loss: 0.0810 - val_acc: 0.9800
Epoch 11/18
 - 91s - loss: 0.0873 - acc: 0.9772 - val_loss: 0.0612 - val_acc: 0.9846
Epoch 12/18
 - 91s - loss: 0.0804 - acc: 0.9799 - val_loss: 0.0537 - val_acc: 0.9891
Epoch 13/18
 - 92s - loss: 0.0727 - acc: 0.9826 - val_loss: 0.0540 - val_acc: 0.9888
Epoch 14/18
 - 91s - loss: 0.0695 - acc: 0.9830 - val_loss: 0.0493 - val_acc: 0.9898
Epoch 15/18
 - 91s - loss: 0.0646 - acc: 0.9854 - val_loss: 0.0514 - val_acc: 0.9892
Epoch 16/18
 - 91s - loss: 0.0598 - acc: 0.9866 - val_loss: 0.0445 - val_acc: 0.9921
Epoch 17/18
 - 91s - loss: 0.0571 - acc: 0.9876 - val_loss: 0.0376 - val_acc: 0.9952
Epoch 18/18
 - 91s - loss: 0.0529 - acc: 0.9893 - val_loss: 0.0320 - val_acc: 0.9977
Test accuracy:0.851
current auc_score ------------------> 0.925
------------------------ current config for the test -------------------------
Layers:  [6, 6]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  18  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 30, 24, 24)   20520       activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 24, 24)   0           dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 106, 24, 24)  0           concatenate_2[0][0]              
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 106, 24, 24)  424         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 106, 24, 24)  0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 30, 24, 24)   28620       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 24, 24)   0           dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 136, 24, 24)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
dense_0_4_bn (BatchNormalizatio (None, 136, 24, 24)  544         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 136, 24, 24)  0           dense_0_4_bn[0][0]               
__________________________________________________________________________________________________
dense_0_4_conv2D (Conv2D)       (None, 30, 24, 24)   36720       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 24, 24)   0           dense_0_4_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 166, 24, 24)  0           concatenate_4[0][0]              
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_0_5_bn (BatchNormalizatio (None, 166, 24, 24)  664         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 166, 24, 24)  0           dense_0_5_bn[0][0]               
__________________________________________________________________________________________________
dense_0_5_conv2D (Conv2D)       (None, 30, 24, 24)   44820       activation_7[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 24, 24)   0           dense_0_5_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 196, 24, 24)  0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 196, 24, 24)  784         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 196, 24, 24)  0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 98, 24, 24)   19208       activation_8[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 98, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 98, 12, 12)   392         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 98, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   26460       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 128, 12, 12)  0           average_pooling2d_1[0][0]        
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 128, 12, 12)  512         concatenate_7[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 128, 12, 12)  0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   34560       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 158, 12, 12)  0           concatenate_7[0][0]              
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 158, 12, 12)  632         concatenate_8[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 158, 12, 12)  0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 30, 12, 12)   42660       activation_11[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 30, 12, 12)   0           dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_9 (Concatenate)     (None, 188, 12, 12)  0           concatenate_8[0][0]              
                                                                 dropout_9[0][0]                  
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 188, 12, 12)  752         concatenate_9[0][0]              
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 188, 12, 12)  0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 30, 12, 12)   50760       activation_12[0][0]              
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 30, 12, 12)   0           dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_10 (Concatenate)    (None, 218, 12, 12)  0           concatenate_9[0][0]              
                                                                 dropout_10[0][0]                 
__________________________________________________________________________________________________
dense_1_4_bn (BatchNormalizatio (None, 218, 12, 12)  872         concatenate_10[0][0]             
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 218, 12, 12)  0           dense_1_4_bn[0][0]               
__________________________________________________________________________________________________
dense_1_4_conv2D (Conv2D)       (None, 30, 12, 12)   58860       activation_13[0][0]              
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, 30, 12, 12)   0           dense_1_4_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_11 (Concatenate)    (None, 248, 12, 12)  0           concatenate_10[0][0]             
                                                                 dropout_11[0][0]                 
__________________________________________________________________________________________________
dense_1_5_bn (BatchNormalizatio (None, 248, 12, 12)  992         concatenate_11[0][0]             
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 248, 12, 12)  0           dense_1_5_bn[0][0]               
__________________________________________________________________________________________________
dense_1_5_conv2D (Conv2D)       (None, 30, 12, 12)   66960       activation_14[0][0]              
__________________________________________________________________________________________________
dropout_12 (Dropout)            (None, 30, 12, 12)   0           dense_1_5_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_12 (Concatenate)    (None, 278, 12, 12)  0           concatenate_11[0][0]             
                                                                 dropout_12[0][0]                 
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 278, 12, 12)  1112        concatenate_12[0][0]             
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 278, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 40032)        0           activation_15[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            40033       flatten_1[0][0]                  
==================================================================================================
Total params: 496,785
Trainable params: 492,637
Non-trainable params: 4,148
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/18
 - 96s - loss: 0.4426 - acc: 0.8034 - val_loss: 0.5080 - val_acc: 0.7618
Epoch 2/18
 - 92s - loss: 0.3070 - acc: 0.8791 - val_loss: 0.3006 - val_acc: 0.8786
Epoch 3/18
 - 93s - loss: 0.2423 - acc: 0.9105 - val_loss: 0.1997 - val_acc: 0.9261
Epoch 4/18
 - 92s - loss: 0.1997 - acc: 0.9298 - val_loss: 0.1546 - val_acc: 0.9493
Epoch 5/18
 - 92s - loss: 0.1701 - acc: 0.9450 - val_loss: 0.1276 - val_acc: 0.9597
Epoch 6/18
 - 92s - loss: 0.1472 - acc: 0.9545 - val_loss: 0.1178 - val_acc: 0.9623
Epoch 7/18
 - 92s - loss: 0.1287 - acc: 0.9614 - val_loss: 0.1259 - val_acc: 0.9559
Epoch 8/18
 - 92s - loss: 0.1133 - acc: 0.9674 - val_loss: 0.0982 - val_acc: 0.9689
Epoch 9/18
 - 92s - loss: 0.1046 - acc: 0.9710 - val_loss: 0.0722 - val_acc: 0.9816
Epoch 10/18
 - 92s - loss: 0.0932 - acc: 0.9756 - val_loss: 0.1333 - val_acc: 0.9537
Epoch 11/18
 - 94s - loss: 0.0873 - acc: 0.9770 - val_loss: 0.0607 - val_acc: 0.9858
Epoch 12/18
 - 92s - loss: 0.0799 - acc: 0.9803 - val_loss: 0.1546 - val_acc: 0.9458
Epoch 13/18
 - 92s - loss: 0.0747 - acc: 0.9811 - val_loss: 0.0842 - val_acc: 0.9743
Epoch 14/18
 - 92s - loss: 0.0683 - acc: 0.9843 - val_loss: 0.0525 - val_acc: 0.9890
Epoch 15/18
 - 92s - loss: 0.0653 - acc: 0.9847 - val_loss: 0.0442 - val_acc: 0.9922
Epoch 16/18
 - 92s - loss: 0.0605 - acc: 0.9870 - val_loss: 0.0851 - val_acc: 0.9739
Epoch 17/18
 - 92s - loss: 0.0547 - acc: 0.9893 - val_loss: 0.0628 - val_acc: 0.9827
Epoch 18/18
 - 92s - loss: 0.0531 - acc: 0.9895 - val_loss: 0.0522 - val_acc: 0.9868

Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.022135943715421873.
Test accuracy:0.842
current auc_score ------------------> 0.920
------------------------ current config for the test -------------------------
Layers:  [6, 6]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction:  0.5  bottleneck:  False
Epochs  18  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   4320        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   12420       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 24, 24)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 30, 24, 24)   20520       activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 24, 24)   0           dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 106, 24, 24)  0           concatenate_2[0][0]              
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_0_3_bn (BatchNormalizatio (None, 106, 24, 24)  424         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 106, 24, 24)  0           dense_0_3_bn[0][0]               
__________________________________________________________________________________________________
dense_0_3_conv2D (Conv2D)       (None, 30, 24, 24)   28620       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 24, 24)   0           dense_0_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 136, 24, 24)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
dense_0_4_bn (BatchNormalizatio (None, 136, 24, 24)  544         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 136, 24, 24)  0           dense_0_4_bn[0][0]               
__________________________________________________________________________________________________
dense_0_4_conv2D (Conv2D)       (None, 30, 24, 24)   36720       activation_6[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 30, 24, 24)   0           dense_0_4_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 166, 24, 24)  0           concatenate_4[0][0]              
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_0_5_bn (BatchNormalizatio (None, 166, 24, 24)  664         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 166, 24, 24)  0           dense_0_5_bn[0][0]               
__________________________________________________________________________________________________
dense_0_5_conv2D (Conv2D)       (None, 30, 24, 24)   44820       activation_7[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 30, 24, 24)   0           dense_0_5_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 196, 24, 24)  0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 196, 24, 24)  784         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 196, 24, 24)  0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 98, 24, 24)   19208       activation_8[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 98, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 98, 12, 12)   392         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 98, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   26460       activation_9[0][0]               
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 128, 12, 12)  0           average_pooling2d_1[0][0]        
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 128, 12, 12)  512         concatenate_7[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 128, 12, 12)  0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   34560       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 158, 12, 12)  0           concatenate_7[0][0]              
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 158, 12, 12)  632         concatenate_8[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 158, 12, 12)  0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 30, 12, 12)   42660       activation_11[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 30, 12, 12)   0           dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_9 (Concatenate)     (None, 188, 12, 12)  0           concatenate_8[0][0]              
                                                                 dropout_9[0][0]                  
__________________________________________________________________________________________________
dense_1_3_bn (BatchNormalizatio (None, 188, 12, 12)  752         concatenate_9[0][0]              
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 188, 12, 12)  0           dense_1_3_bn[0][0]               
__________________________________________________________________________________________________
dense_1_3_conv2D (Conv2D)       (None, 30, 12, 12)   50760       activation_12[0][0]              
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 30, 12, 12)   0           dense_1_3_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_10 (Concatenate)    (None, 218, 12, 12)  0           concatenate_9[0][0]              
                                                                 dropout_10[0][0]                 
__________________________________________________________________________________________________
dense_1_4_bn (BatchNormalizatio (None, 218, 12, 12)  872         concatenate_10[0][0]             
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 218, 12, 12)  0           dense_1_4_bn[0][0]               
__________________________________________________________________________________________________
dense_1_4_conv2D (Conv2D)       (None, 30, 12, 12)   58860       activation_13[0][0]              
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, 30, 12, 12)   0           dense_1_4_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_11 (Concatenate)    (None, 248, 12, 12)  0           concatenate_10[0][0]             
                                                                 dropout_11[0][0]                 
__________________________________________________________________________________________________
dense_1_5_bn (BatchNormalizatio (None, 248, 12, 12)  992         concatenate_11[0][0]             
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 248, 12, 12)  0           dense_1_5_bn[0][0]               
__________________________________________________________________________________________________
dense_1_5_conv2D (Conv2D)       (None, 30, 12, 12)   66960       activation_14[0][0]              
__________________________________________________________________________________________________
dropout_12 (Dropout)            (None, 30, 12, 12)   0           dense_1_5_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_12 (Concatenate)    (None, 278, 12, 12)  0           concatenate_11[0][0]             
                                                                 dropout_12[0][0]                 
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 278, 12, 12)  1112        concatenate_12[0][0]             
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 278, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 40032)        0           activation_15[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            40033       flatten_1[0][0]                  
==================================================================================================
Total params: 496,785
Trainable params: 492,637
Non-trainable params: 4,148
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/18
 - 94s - loss: 0.4552 - acc: 0.7940 - val_loss: 0.3300 - val_acc: 0.8650
Epoch 2/18
 - 90s - loss: 0.3092 - acc: 0.8785 - val_loss: 0.2392 - val_acc: 0.9120
Epoch 3/18
 - 91s - loss: 0.2483 - acc: 0.9074 - val_loss: 0.2635 - val_acc: 0.9039
Epoch 4/18
 - 91s - loss: 0.2113 - acc: 0.9257 - val_loss: 0.1598 - val_acc: 0.9447
Epoch 5/18
 - 90s - loss: 0.1817 - acc: 0.9386 - val_loss: 0.1782 - val_acc: 0.9367
Epoch 6/18
 - 90s - loss: 0.1584 - acc: 0.9486 - val_loss: 0.1252 - val_acc: 0.9611
Epoch 7/18
 - 90s - loss: 0.1414 - acc: 0.9560 - val_loss: 0.0961 - val_acc: 0.9740
Epoch 8/18
 - 90s - loss: 0.1234 - acc: 0.9630 - val_loss: 0.1227 - val_acc: 0.9616
Epoch 9/18
 - 90s - loss: 0.1107 - acc: 0.9689 - val_loss: 0.0860 - val_acc: 0.9754
Epoch 10/18
 - 90s - loss: 0.1004 - acc: 0.9716 - val_loss: 0.0697 - val_acc: 0.9837
Epoch 11/18
 - 90s - loss: 0.0937 - acc: 0.9741 - val_loss: 0.0650 - val_acc: 0.9848
Epoch 12/18
 - 90s - loss: 0.0871 - acc: 0.9769 - val_loss: 0.0665 - val_acc: 0.9824
Epoch 13/18
 - 90s - loss: 0.0794 - acc: 0.9800 - val_loss: 0.0794 - val_acc: 0.9755
Epoch 14/18
 - 90s - loss: 0.0730 - acc: 0.9822 - val_loss: 0.0595 - val_acc: 0.9848
Epoch 15/18
 - 90s - loss: 0.0675 - acc: 0.9842 - val_loss: 0.0545 - val_acc: 0.9881
Epoch 16/18
 - 90s - loss: 0.0645 - acc: 0.9852 - val_loss: 0.0425 - val_acc: 0.9945
Epoch 17/18
 - 90s - loss: 0.0598 - acc: 0.9873 - val_loss: 0.0517 - val_acc: 0.9880
Epoch 18/18
 - 91s - loss: 0.0560 - acc: 0.9889 - val_loss: 0.0352 - val_acc: 0.9969
Test accuracy:0.847
current auc_score ------------------> 0.921
accuracies:  [0.823252688172043, 0.8211021505376344, 0.8361559139784946, 0.8184139784946236, 0.8221774193548387, 0.7309139784946237, 0.8352150537634409, 0.8513440860215054, 0.8422043010752688, 0.8469086021505376]
aucs:  [0.9053, 0.9159, 0.9207, 0.8946, 0.9218, 0.9038, 0.9249, 0.9249, 0.9201, 0.9208]
mean and std AUC:  0.915+/-0.01  max:   0.9249
(['2-2', '12', '2', '16', '0.2', '0.07', '27', 'adadelta', '0.5', 'FALSE', '64', 'flatten'], '0.9+/-0.013', 0.916)
(['2-2', '18', '2', '16', '0.2', '0.07', '25', 'adadelta', '0.5', 'FALSE', '64', 'flatten'], '0.915+/-0.012', 0.935)
(['2-2', '24', '2', '16', '0.2', '0.07', '24', 'adadelta', '0.5', 'FALSE', '64', 'flatten'], '0.906+/-0.009', 0.924)
(['2-2', '30', '2', '16', '0.2', '0.07', '23', 'adadelta', '0.5', 'FALSE', '64', 'flatten'], '0.912+/-0.01', 0.935)
(['4-4', '12', '2', '16', '0.2', '0.07', '26', 'adadelta', '0.5', 'FALSE', '64', 'flatten'], '0.903+/-0.012', 0.918)
(['4-4', '18', '2', '16', '0.2', '0.07', '24', 'adadelta', '0.5', 'FALSE', '64', 'flatten'], '0.911+/-0.008', 0.929)
(['4-4', '24', '2', '16', '0.2', '0.07', '22', 'adadelta', '0.5', 'FALSE', '64', 'flatten'], '0.901+/-0.016', 0.937)
(['4-4', '30', '2', '16', '0.2', '0.07', '20', 'adadelta', '0.5', 'FALSE', '64', 'flatten'], '0.907+/-0.012', 0.93)
(['6-6', '12', '2', '16', '0.2', '0.07', '24', 'adadelta', '0.5', 'FALSE', '64', 'flatten'], '0.909+/-0.007', 0.919)
(['6-6', '18', '2', '16', '0.2', '0.07', '21', 'adadelta', '0.5', 'FALSE', '64', 'flatten'], '0.915+/-0.009', 0.93)
(['6-6', '24', '2', '16', '0.2', '0.07', '19', 'adadelta', '0.5', 'FALSE', '64', 'flatten'], '0.916+/-0.015', 0.943)
(['6-6', '30', '2', '16', '0.2', '0.07', '18', 'adadelta', '0.5', 'FALSE', '64', 'flatten'], '0.915+/-0.01', 0.925)
