python keras_dn_simple_multigpu.py
python keras_dn_simple.py
python custom_gridsearch_dn_siamese.py
python custom_gs_dn_siamese_layers_multi.py -g 1
python custom_gridsearch_dn_siamese_layers_avg.py
Column names are nb_layers_per_block, growth_rate, nb_dense_block, nb_filter, dropout, lr, epochs
Epochs  6  batch_size:  64  lr:  0.0002  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  8  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 8, 48, 48)    392         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 8, 48, 48)    32          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 8, 48, 48)    0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 8, 24, 24)    0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 8, 24, 24)    32          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 8, 24, 24)    0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  960         activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 38, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 38, 24, 24)   152         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 38, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  4560        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 68, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 68, 24, 24)   272         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 34, 24, 24)   2312        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 34, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 34, 12, 12)   136         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 34, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4080        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 64, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 64, 12, 12)   256         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 64, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  7680        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 94, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 94, 12, 12)   376         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 94, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 13536)        0           activation_11[0][0]              
==================================================================================================
Total params: 152,760
Trainable params: 151,172
Non-trainable params: 1,588
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 13536)        152760      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 27072)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          13861376    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,016,697
Trainable params: 14,014,085
Non-trainable params: 2,612
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 76s - loss: 0.5487 - acc: 0.8042 - val_loss: 0.4611 - val_acc: 0.8232

Epoch 00001: val_loss improved from inf to 0.46111, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 2/6
 - 70s - loss: 0.2831 - acc: 0.9344 - val_loss: 0.3258 - val_acc: 0.9222

Epoch 00002: val_loss improved from 0.46111 to 0.32576, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 3/6
 - 70s - loss: 0.2009 - acc: 0.9699 - val_loss: 0.1721 - val_acc: 0.9831

Epoch 00003: val_loss improved from 0.32576 to 0.17207, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 4/6
 - 70s - loss: 0.1633 - acc: 0.9830 - val_loss: 0.1399 - val_acc: 0.9915

Epoch 00004: val_loss improved from 0.17207 to 0.13993, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 5/6
 - 70s - loss: 0.1444 - acc: 0.9874 - val_loss: 0.1197 - val_acc: 0.9941

Epoch 00005: val_loss improved from 0.13993 to 0.11966, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 6/6
 - 70s - loss: 0.1266 - acc: 0.9920 - val_loss: 0.1127 - val_acc: 0.9950

Epoch 00006: val_loss improved from 0.11966 to 0.11272, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Test accuracy:0.673
current auc_score ------------------> 0.871
Epochs  6  batch_size:  64  lr:  0.0002  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  8  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 8, 48, 48)    392         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 8, 48, 48)    32          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 8, 48, 48)    0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 8, 24, 24)    0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 8, 24, 24)    32          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 8, 24, 24)    0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  960         activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 38, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 38, 24, 24)   152         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 38, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  4560        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 68, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 68, 24, 24)   272         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 34, 24, 24)   2312        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 34, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 34, 12, 12)   136         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 34, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4080        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 64, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 64, 12, 12)   256         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 64, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  7680        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 94, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 94, 12, 12)   376         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 94, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 13536)        0           activation_11[0][0]              
==================================================================================================
Total params: 152,760
Trainable params: 151,172
Non-trainable params: 1,588
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 13536)        152760      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 27072)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          13861376    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,016,697
Trainable params: 14,014,085
Non-trainable params: 2,612
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 73s - loss: 0.5516 - acc: 0.7995 - val_loss: 0.7932 - val_acc: 0.5927

Epoch 00001: val_loss improved from inf to 0.79325, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 2/6
 - 69s - loss: 0.2965 - acc: 0.9291 - val_loss: 0.2186 - val_acc: 0.9642

Epoch 00002: val_loss improved from 0.79325 to 0.21862, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 3/6
 - 69s - loss: 0.2086 - acc: 0.9659 - val_loss: 0.1620 - val_acc: 0.9867

Epoch 00003: val_loss improved from 0.21862 to 0.16204, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 4/6
 - 69s - loss: 0.1674 - acc: 0.9804 - val_loss: 0.1394 - val_acc: 0.9915

Epoch 00004: val_loss improved from 0.16204 to 0.13943, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 5/6
 - 69s - loss: 0.1442 - acc: 0.9875 - val_loss: 0.1229 - val_acc: 0.9964

Epoch 00005: val_loss improved from 0.13943 to 0.12292, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 6/6
 - 69s - loss: 0.1278 - acc: 0.9909 - val_loss: 0.1056 - val_acc: 0.9971

Epoch 00006: val_loss improved from 0.12292 to 0.10563, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Test accuracy:0.590
current auc_score ------------------> 0.885
Epochs  6  batch_size:  64  lr:  0.0002  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  8  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 8, 48, 48)    392         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 8, 48, 48)    32          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 8, 48, 48)    0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 8, 24, 24)    0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 8, 24, 24)    32          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 8, 24, 24)    0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  960         activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 38, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 38, 24, 24)   152         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 38, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  4560        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 68, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 68, 24, 24)   272         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 34, 24, 24)   2312        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 34, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 34, 12, 12)   136         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 34, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4080        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 64, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 64, 12, 12)   256         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 64, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  7680        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 94, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 94, 12, 12)   376         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 94, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 13536)        0           activation_11[0][0]              
==================================================================================================
Total params: 152,760
Trainable params: 151,172
Non-trainable params: 1,588
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 13536)        152760      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 27072)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          13861376    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,016,697
Trainable params: 14,014,085
Non-trainable params: 2,612
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 75s - loss: 0.5229 - acc: 0.8140 - val_loss: 2.8579 - val_acc: 0.5035

Epoch 00001: val_loss improved from inf to 2.85785, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 2/6
 - 71s - loss: 0.2871 - acc: 0.9310 - val_loss: 2.1632 - val_acc: 0.5035

Epoch 00002: val_loss improved from 2.85785 to 2.16315, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 3/6
 - 70s - loss: 0.2068 - acc: 0.9657 - val_loss: 1.9206 - val_acc: 0.5103

Epoch 00003: val_loss improved from 2.16315 to 1.92063, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 4/6
 - 70s - loss: 0.1600 - acc: 0.9832 - val_loss: 2.6184 - val_acc: 0.5044

Epoch 00004: val_loss did not improve from 1.92063
Epoch 5/6
 - 69s - loss: 0.1356 - acc: 0.9896 - val_loss: 2.2144 - val_acc: 0.5424

Epoch 00005: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.

Epoch 00005: val_loss did not improve from 1.92063
Epoch 6/6
 - 69s - loss: 0.1163 - acc: 0.9946 - val_loss: 2.9162 - val_acc: 0.5129

Epoch 00006: val_loss did not improve from 1.92063
Test accuracy:0.503
current auc_score ------------------> 0.617
Epochs  6  batch_size:  64  lr:  0.0002  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  8  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 8, 48, 48)    392         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 8, 48, 48)    32          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 8, 48, 48)    0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 8, 24, 24)    0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 8, 24, 24)    32          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 8, 24, 24)    0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  960         activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 38, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 38, 24, 24)   152         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 38, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  4560        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 68, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 68, 24, 24)   272         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 34, 24, 24)   2312        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 34, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 34, 12, 12)   136         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 34, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4080        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 64, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 64, 12, 12)   256         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 64, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  7680        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 94, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 94, 12, 12)   376         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 94, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 13536)        0           activation_11[0][0]              
==================================================================================================
Total params: 152,760
Trainable params: 151,172
Non-trainable params: 1,588
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 13536)        152760      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 27072)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          13861376    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,016,697
Trainable params: 14,014,085
Non-trainable params: 2,612
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 75s - loss: 0.5528 - acc: 0.8022 - val_loss: 1.5597 - val_acc: 0.5178

Epoch 00001: val_loss improved from inf to 1.55968, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 2/6
 - 70s - loss: 0.2995 - acc: 0.9263 - val_loss: 2.6169 - val_acc: 0.5041

Epoch 00002: val_loss did not improve from 1.55968
Epoch 3/6
 - 70s - loss: 0.2090 - acc: 0.9681 - val_loss: 0.6750 - val_acc: 0.7018

Epoch 00003: val_loss improved from 1.55968 to 0.67501, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 4/6
 - 70s - loss: 0.1687 - acc: 0.9806 - val_loss: 0.8951 - val_acc: 0.6578

Epoch 00004: val_loss did not improve from 0.67501
Epoch 5/6
 - 70s - loss: 0.1406 - acc: 0.9885 - val_loss: 0.1205 - val_acc: 0.9936

Epoch 00005: val_loss improved from 0.67501 to 0.12053, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 6/6
 - 70s - loss: 0.1291 - acc: 0.9908 - val_loss: 0.1111 - val_acc: 0.9966

Epoch 00006: val_loss improved from 0.12053 to 0.11111, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Test accuracy:0.594
current auc_score ------------------> 0.873
Epochs  6  batch_size:  64  lr:  0.0002  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  8  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 8, 48, 48)    392         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 8, 48, 48)    32          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 8, 48, 48)    0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 8, 24, 24)    0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 8, 24, 24)    32          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 8, 24, 24)    0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  960         activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 38, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 38, 24, 24)   152         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 38, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  4560        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 68, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 68, 24, 24)   272         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 34, 24, 24)   2312        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 34, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 34, 12, 12)   136         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 34, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4080        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 64, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 64, 12, 12)   256         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 64, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  7680        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 94, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 94, 12, 12)   376         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 94, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 13536)        0           activation_11[0][0]              
==================================================================================================
Total params: 152,760
Trainable params: 151,172
Non-trainable params: 1,588
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 13536)        152760      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 27072)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          13861376    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,016,697
Trainable params: 14,014,085
Non-trainable params: 2,612
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 74s - loss: 0.5514 - acc: 0.7995 - val_loss: 1.0861 - val_acc: 0.5333

Epoch 00001: val_loss improved from inf to 1.08607, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 2/6
 - 70s - loss: 0.2879 - acc: 0.9338 - val_loss: 0.7728 - val_acc: 0.6313

Epoch 00002: val_loss improved from 1.08607 to 0.77277, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 3/6
 - 70s - loss: 0.2034 - acc: 0.9699 - val_loss: 0.7530 - val_acc: 0.6398

Epoch 00003: val_loss improved from 0.77277 to 0.75302, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 4/6
 - 70s - loss: 0.1654 - acc: 0.9808 - val_loss: 0.9243 - val_acc: 0.5333

Epoch 00004: val_loss did not improve from 0.75302
Epoch 5/6
 - 70s - loss: 0.1385 - acc: 0.9888 - val_loss: 1.1171 - val_acc: 0.5008

Epoch 00005: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.

Epoch 00005: val_loss did not improve from 0.75302
Epoch 6/6
 - 70s - loss: 0.1204 - acc: 0.9939 - val_loss: 0.1047 - val_acc: 0.9982

Epoch 00006: val_loss improved from 0.75302 to 0.10465, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Test accuracy:0.768
current auc_score ------------------> 0.914
Epochs  6  batch_size:  64  lr:  0.0002  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  8  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 8, 48, 48)    392         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 8, 48, 48)    32          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 8, 48, 48)    0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 8, 24, 24)    0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 8, 24, 24)    32          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 8, 24, 24)    0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  960         activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 38, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 38, 24, 24)   152         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 38, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  4560        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 68, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 68, 24, 24)   272         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 34, 24, 24)   2312        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 34, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 34, 12, 12)   136         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 34, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4080        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 64, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 64, 12, 12)   256         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 64, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  7680        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 94, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 94, 12, 12)   376         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 94, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 13536)        0           activation_11[0][0]              
==================================================================================================
Total params: 152,760
Trainable params: 151,172
Non-trainable params: 1,588
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 13536)        152760      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 27072)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          13861376    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,016,697
Trainable params: 14,014,085
Non-trainable params: 2,612
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 75s - loss: 0.5046 - acc: 0.8259 - val_loss: 0.3439 - val_acc: 0.9142

Epoch 00001: val_loss improved from inf to 0.34392, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 2/6
 - 70s - loss: 0.2663 - acc: 0.9423 - val_loss: 0.2056 - val_acc: 0.9682

Epoch 00002: val_loss improved from 0.34392 to 0.20557, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 3/6
 - 71s - loss: 0.1887 - acc: 0.9735 - val_loss: 0.1811 - val_acc: 0.9833

Epoch 00003: val_loss improved from 0.20557 to 0.18109, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 4/6
 - 70s - loss: 0.1559 - acc: 0.9850 - val_loss: 0.1284 - val_acc: 0.9931

Epoch 00004: val_loss improved from 0.18109 to 0.12844, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 5/6
 - 70s - loss: 0.1346 - acc: 0.9903 - val_loss: 0.1302 - val_acc: 0.9922

Epoch 00005: val_loss did not improve from 0.12844
Epoch 6/6
 - 70s - loss: 0.1217 - acc: 0.9926 - val_loss: 0.1041 - val_acc: 0.9977

Epoch 00006: val_loss improved from 0.12844 to 0.10410, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Test accuracy:0.731
current auc_score ------------------> 0.888
Epochs  6  batch_size:  64  lr:  0.0002  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  8  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 8, 48, 48)    392         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 8, 48, 48)    32          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 8, 48, 48)    0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 8, 24, 24)    0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 8, 24, 24)    32          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 8, 24, 24)    0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  960         activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 38, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 38, 24, 24)   152         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 38, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  4560        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 68, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 68, 24, 24)   272         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 34, 24, 24)   2312        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 34, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 34, 12, 12)   136         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 34, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4080        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 64, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 64, 12, 12)   256         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 64, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  7680        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 94, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 94, 12, 12)   376         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 94, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 13536)        0           activation_11[0][0]              
==================================================================================================
Total params: 152,760
Trainable params: 151,172
Non-trainable params: 1,588
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 13536)        152760      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 27072)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          13861376    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,016,697
Trainable params: 14,014,085
Non-trainable params: 2,612
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 74s - loss: 0.5228 - acc: 0.8189 - val_loss: 1.2151 - val_acc: 0.5551

Epoch 00001: val_loss improved from inf to 1.21514, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 2/6
 - 69s - loss: 0.2750 - acc: 0.9375 - val_loss: 1.4119 - val_acc: 0.5417

Epoch 00002: val_loss did not improve from 1.21514
Epoch 3/6
 - 69s - loss: 0.1902 - acc: 0.9737 - val_loss: 1.7599 - val_acc: 0.5184

Epoch 00003: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.

Epoch 00003: val_loss did not improve from 1.21514
Epoch 4/6
 - 70s - loss: 0.1469 - acc: 0.9884 - val_loss: 1.3077 - val_acc: 0.5774

Epoch 00004: val_loss did not improve from 1.21514
Epoch 5/6
 - 69s - loss: 0.1328 - acc: 0.9925 - val_loss: 1.7659 - val_acc: 0.5432

Epoch 00005: ReduceLROnPlateau reducing learning rate to 1.999999851818061e-05.

Epoch 00005: val_loss did not improve from 1.21514
Epoch 6/6
 - 69s - loss: 0.1228 - acc: 0.9955 - val_loss: 1.8126 - val_acc: 0.5410

Epoch 00006: val_loss did not improve from 1.21514
Test accuracy:0.605
current auc_score ------------------> 0.581
Epochs  6  batch_size:  64  lr:  0.0002  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  8  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 8, 48, 48)    392         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 8, 48, 48)    32          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 8, 48, 48)    0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 8, 24, 24)    0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 8, 24, 24)    32          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 8, 24, 24)    0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  960         activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 38, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 38, 24, 24)   152         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 38, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  4560        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 68, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 68, 24, 24)   272         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 34, 24, 24)   2312        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 34, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 34, 12, 12)   136         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 34, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4080        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 64, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 64, 12, 12)   256         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 64, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  7680        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 94, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 94, 12, 12)   376         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 94, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 13536)        0           activation_11[0][0]              
==================================================================================================
Total params: 152,760
Trainable params: 151,172
Non-trainable params: 1,588
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 13536)        152760      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 27072)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          13861376    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,016,697
Trainable params: 14,014,085
Non-trainable params: 2,612
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 75s - loss: 0.5744 - acc: 0.7872 - val_loss: 0.3694 - val_acc: 0.8934

Epoch 00001: val_loss improved from inf to 0.36936, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 2/6
 - 71s - loss: 0.3090 - acc: 0.9221 - val_loss: 0.2163 - val_acc: 0.9688

Epoch 00002: val_loss improved from 0.36936 to 0.21629, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 3/6
 - 71s - loss: 0.2131 - acc: 0.9655 - val_loss: 0.1564 - val_acc: 0.9872

Epoch 00003: val_loss improved from 0.21629 to 0.15641, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 4/6
 - 70s - loss: 0.1678 - acc: 0.9808 - val_loss: 0.1286 - val_acc: 0.9911

Epoch 00004: val_loss improved from 0.15641 to 0.12859, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 5/6
 - 70s - loss: 0.1408 - acc: 0.9886 - val_loss: 0.1194 - val_acc: 0.9970

Epoch 00005: val_loss improved from 0.12859 to 0.11944, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 6/6
 - 70s - loss: 0.1246 - acc: 0.9923 - val_loss: 0.1017 - val_acc: 0.9989

Epoch 00006: val_loss improved from 0.11944 to 0.10173, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Test accuracy:0.615
current auc_score ------------------> 0.900
Epochs  6  batch_size:  64  lr:  0.0002  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  8  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 8, 48, 48)    392         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 8, 48, 48)    32          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 8, 48, 48)    0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 8, 24, 24)    0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 8, 24, 24)    32          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 8, 24, 24)    0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  960         activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 38, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 38, 24, 24)   152         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 38, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  4560        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 68, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 68, 24, 24)   272         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 34, 24, 24)   2312        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 34, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 34, 12, 12)   136         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 34, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4080        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 64, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 64, 12, 12)   256         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 64, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  7680        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 94, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 94, 12, 12)   376         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 94, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 13536)        0           activation_11[0][0]              
==================================================================================================
Total params: 152,760
Trainable params: 151,172
Non-trainable params: 1,588
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 13536)        152760      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 27072)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          13861376    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,016,697
Trainable params: 14,014,085
Non-trainable params: 2,612
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 75s - loss: 0.5543 - acc: 0.7985 - val_loss: 0.3362 - val_acc: 0.9129

Epoch 00001: val_loss improved from inf to 0.33620, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 2/6
 - 71s - loss: 0.2933 - acc: 0.9299 - val_loss: 0.2126 - val_acc: 0.9695

Epoch 00002: val_loss improved from 0.33620 to 0.21260, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 3/6
 - 71s - loss: 0.2009 - acc: 0.9693 - val_loss: 0.1801 - val_acc: 0.9810

Epoch 00003: val_loss improved from 0.21260 to 0.18009, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 4/6
 - 71s - loss: 0.1610 - acc: 0.9830 - val_loss: 0.1295 - val_acc: 0.9928

Epoch 00004: val_loss improved from 0.18009 to 0.12954, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 5/6
 - 71s - loss: 0.1430 - acc: 0.9880 - val_loss: 0.1163 - val_acc: 0.9965

Epoch 00005: val_loss improved from 0.12954 to 0.11634, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 6/6
 - 71s - loss: 0.1254 - acc: 0.9930 - val_loss: 0.1063 - val_acc: 0.9984

Epoch 00006: val_loss improved from 0.11634 to 0.10632, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Test accuracy:0.639
current auc_score ------------------> 0.927
Epochs  6  batch_size:  64  lr:  0.0002  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  8  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 8, 48, 48)    392         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 8, 48, 48)    32          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 8, 48, 48)    0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 8, 24, 24)    0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 8, 24, 24)    32          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 8, 24, 24)    0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  960         activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 38, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 38, 24, 24)   152         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 38, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  4560        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 68, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 68, 24, 24)   272         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 34, 24, 24)   2312        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 34, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 34, 12, 12)   136         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 34, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4080        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 64, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 64, 12, 12)   256         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 64, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  7680        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 94, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 94, 12, 12)   376         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 94, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 13536)        0           activation_11[0][0]              
==================================================================================================
Total params: 152,760
Trainable params: 151,172
Non-trainable params: 1,588
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 13536)        152760      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 27072)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          13861376    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,016,697
Trainable params: 14,014,085
Non-trainable params: 2,612
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 73s - loss: 0.5548 - acc: 0.7969 - val_loss: 0.9487 - val_acc: 0.5863

Epoch 00001: val_loss improved from inf to 0.94866, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 2/6
 - 69s - loss: 0.2960 - acc: 0.9272 - val_loss: 0.7030 - val_acc: 0.6701

Epoch 00002: val_loss improved from 0.94866 to 0.70302, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 3/6
 - 69s - loss: 0.2086 - acc: 0.9647 - val_loss: 0.8643 - val_acc: 0.5689

Epoch 00003: val_loss did not improve from 0.70302
Epoch 4/6
 - 69s - loss: 0.1626 - acc: 0.9818 - val_loss: 0.7342 - val_acc: 0.6234

Epoch 00004: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.

Epoch 00004: val_loss did not improve from 0.70302
Epoch 5/6
 - 69s - loss: 0.1312 - acc: 0.9913 - val_loss: 0.7966 - val_acc: 0.5722

Epoch 00005: val_loss did not improve from 0.70302
Epoch 6/6
 - 69s - loss: 0.1215 - acc: 0.9938 - val_loss: 0.6890 - val_acc: 0.6985

Epoch 00006: val_loss improved from 0.70302 to 0.68904, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Test accuracy:0.531
current auc_score ------------------> 0.583
accuracies:  [0.6727150537634409, 0.5896505376344086, 0.5032258064516129, 0.5939516129032258, 0.7682795698924731, 0.7310483870967742, 0.605241935483871, 0.6146505376344086, 0.6391129032258065, 0.5311827956989247]
aucs:  [0.8714, 0.8846, 0.6168, 0.8726, 0.9136, 0.8883, 0.5808, 0.9004, 0.9274, 0.5825]
mean and std AUC:  0.804+/-0.139  max:   0.9274
Epochs  6  batch_size:  64  lr:  0.0002  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_11[0][0]              
==================================================================================================
Total params: 156,784
Trainable params: 155,108
Non-trainable params: 1,676
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 14112)        156784      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 28224)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          14451200    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,610,545
Trainable params: 14,607,845
Non-trainable params: 2,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 78s - loss: 0.5207 - acc: 0.8183 - val_loss: 0.3331 - val_acc: 0.9134

Epoch 00001: val_loss improved from inf to 0.33310, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 2/6
 - 73s - loss: 0.2700 - acc: 0.9416 - val_loss: 0.2017 - val_acc: 0.9684

Epoch 00002: val_loss improved from 0.33310 to 0.20170, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 3/6
 - 73s - loss: 0.1895 - acc: 0.9746 - val_loss: 0.1540 - val_acc: 0.9893

Epoch 00003: val_loss improved from 0.20170 to 0.15402, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 4/6
 - 73s - loss: 0.1536 - acc: 0.9859 - val_loss: 0.1527 - val_acc: 0.9856

Epoch 00004: val_loss improved from 0.15402 to 0.15273, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 5/6
 - 73s - loss: 0.1349 - acc: 0.9912 - val_loss: 0.1183 - val_acc: 0.9964

Epoch 00005: val_loss improved from 0.15273 to 0.11826, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 6/6
 - 73s - loss: 0.1213 - acc: 0.9935 - val_loss: 0.1102 - val_acc: 0.9969

Epoch 00006: val_loss improved from 0.11826 to 0.11019, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Test accuracy:0.703
current auc_score ------------------> 0.878
Epochs  6  batch_size:  64  lr:  0.0002  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_11[0][0]              
==================================================================================================
Total params: 156,784
Trainable params: 155,108
Non-trainable params: 1,676
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 14112)        156784      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 28224)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          14451200    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,610,545
Trainable params: 14,607,845
Non-trainable params: 2,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 76s - loss: 0.5112 - acc: 0.8234 - val_loss: 2.1823 - val_acc: 0.4974

Epoch 00001: val_loss improved from inf to 2.18235, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 2/6
 - 72s - loss: 0.2596 - acc: 0.9431 - val_loss: 1.1123 - val_acc: 0.5246

Epoch 00002: val_loss improved from 2.18235 to 1.11233, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 3/6
 - 72s - loss: 0.1829 - acc: 0.9755 - val_loss: 0.7165 - val_acc: 0.6219

Epoch 00003: val_loss improved from 1.11233 to 0.71653, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 4/6
 - 72s - loss: 0.1501 - acc: 0.9858 - val_loss: 0.1283 - val_acc: 0.9936

Epoch 00004: val_loss improved from 0.71653 to 0.12832, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 5/6
 - 72s - loss: 0.1284 - acc: 0.9921 - val_loss: 0.1170 - val_acc: 0.9969

Epoch 00005: val_loss improved from 0.12832 to 0.11696, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 6/6
 - 72s - loss: 0.1178 - acc: 0.9942 - val_loss: 0.1103 - val_acc: 0.9964

Epoch 00006: val_loss improved from 0.11696 to 0.11027, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Test accuracy:0.722
current auc_score ------------------> 0.867
Epochs  6  batch_size:  64  lr:  0.0002  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_11[0][0]              
==================================================================================================
Total params: 156,784
Trainable params: 155,108
Non-trainable params: 1,676
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 14112)        156784      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 28224)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          14451200    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,610,545
Trainable params: 14,607,845
Non-trainable params: 2,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 78s - loss: 0.5074 - acc: 0.8258 - val_loss: 0.3079 - val_acc: 0.9276

Epoch 00001: val_loss improved from inf to 0.30795, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 2/6
 - 73s - loss: 0.2703 - acc: 0.9410 - val_loss: 0.2098 - val_acc: 0.9788

Epoch 00002: val_loss improved from 0.30795 to 0.20976, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 3/6
 - 73s - loss: 0.1996 - acc: 0.9708 - val_loss: 0.1557 - val_acc: 0.9896

Epoch 00003: val_loss improved from 0.20976 to 0.15574, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 4/6
 - 73s - loss: 0.1621 - acc: 0.9825 - val_loss: 0.1280 - val_acc: 0.9935

Epoch 00004: val_loss improved from 0.15574 to 0.12803, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 5/6
 - 73s - loss: 0.1373 - acc: 0.9899 - val_loss: 0.1277 - val_acc: 0.9960

Epoch 00005: val_loss improved from 0.12803 to 0.12772, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 6/6
 - 73s - loss: 0.1228 - acc: 0.9931 - val_loss: 0.1076 - val_acc: 0.9982

Epoch 00006: val_loss improved from 0.12772 to 0.10756, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Test accuracy:0.705
current auc_score ------------------> 0.943
Saved model to disk
Epochs  6  batch_size:  64  lr:  0.0002  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_11[0][0]              
==================================================================================================
Total params: 156,784
Trainable params: 155,108
Non-trainable params: 1,676
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 14112)        156784      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 28224)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          14451200    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,610,545
Trainable params: 14,607,845
Non-trainable params: 2,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 76s - loss: 0.5438 - acc: 0.8058 - val_loss: 0.9219 - val_acc: 0.5713

Epoch 00001: val_loss improved from inf to 0.92194, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 2/6
 - 72s - loss: 0.2847 - acc: 0.9341 - val_loss: 0.2209 - val_acc: 0.9705

Epoch 00002: val_loss improved from 0.92194 to 0.22085, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 3/6
 - 72s - loss: 0.2055 - acc: 0.9675 - val_loss: 0.1673 - val_acc: 0.9816

Epoch 00003: val_loss improved from 0.22085 to 0.16732, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 4/6
 - 72s - loss: 0.1647 - acc: 0.9819 - val_loss: 0.1359 - val_acc: 0.9905

Epoch 00004: val_loss improved from 0.16732 to 0.13589, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 5/6
 - 72s - loss: 0.1409 - acc: 0.9878 - val_loss: 0.1191 - val_acc: 0.9947

Epoch 00005: val_loss improved from 0.13589 to 0.11908, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 6/6
 - 72s - loss: 0.1234 - acc: 0.9922 - val_loss: 0.1098 - val_acc: 0.9957

Epoch 00006: val_loss improved from 0.11908 to 0.10980, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Test accuracy:0.706
current auc_score ------------------> 0.854
Epochs  6  batch_size:  64  lr:  0.0002  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_11[0][0]              
==================================================================================================
Total params: 156,784
Trainable params: 155,108
Non-trainable params: 1,676
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 14112)        156784      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 28224)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          14451200    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,610,545
Trainable params: 14,607,845
Non-trainable params: 2,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 77s - loss: 0.5240 - acc: 0.8154 - val_loss: 2.4916 - val_acc: 0.5036

Epoch 00001: val_loss improved from inf to 2.49159, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 2/6
 - 72s - loss: 0.2792 - acc: 0.9377 - val_loss: 2.1994 - val_acc: 0.5060

Epoch 00002: val_loss improved from 2.49159 to 2.19940, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 3/6
 - 72s - loss: 0.1972 - acc: 0.9708 - val_loss: 1.7976 - val_acc: 0.5555

Epoch 00003: val_loss improved from 2.19940 to 1.79757, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 4/6
 - 72s - loss: 0.1569 - acc: 0.9844 - val_loss: 1.7621 - val_acc: 0.5478

Epoch 00004: val_loss improved from 1.79757 to 1.76215, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 5/6
 - 72s - loss: 0.1378 - acc: 0.9896 - val_loss: 0.7414 - val_acc: 0.6788

Epoch 00005: val_loss improved from 1.76215 to 0.74140, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 6/6
 - 72s - loss: 0.1244 - acc: 0.9921 - val_loss: 3.2743 - val_acc: 0.5067

Epoch 00006: val_loss did not improve from 0.74140
Test accuracy:0.567
current auc_score ------------------> 0.762
Epochs  6  batch_size:  64  lr:  0.0002  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_11[0][0]              
==================================================================================================
Total params: 156,784
Trainable params: 155,108
Non-trainable params: 1,676
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 14112)        156784      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 28224)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          14451200    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,610,545
Trainable params: 14,607,845
Non-trainable params: 2,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 76s - loss: 0.5574 - acc: 0.7967 - val_loss: 0.3298 - val_acc: 0.9222

Epoch 00001: val_loss improved from inf to 0.32979, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 2/6
 - 72s - loss: 0.2865 - acc: 0.9355 - val_loss: 0.2216 - val_acc: 0.9685

Epoch 00002: val_loss improved from 0.32979 to 0.22161, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 3/6
 - 72s - loss: 0.1985 - acc: 0.9706 - val_loss: 0.1602 - val_acc: 0.9849

Epoch 00003: val_loss improved from 0.22161 to 0.16017, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 4/6
 - 72s - loss: 0.1563 - acc: 0.9846 - val_loss: 0.1334 - val_acc: 0.9921

Epoch 00004: val_loss improved from 0.16017 to 0.13339, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 5/6
 - 72s - loss: 0.1338 - acc: 0.9903 - val_loss: 0.1166 - val_acc: 0.9972

Epoch 00005: val_loss improved from 0.13339 to 0.11659, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 6/6
 - 72s - loss: 0.1212 - acc: 0.9932 - val_loss: 0.1149 - val_acc: 0.9971

Epoch 00006: val_loss improved from 0.11659 to 0.11491, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Test accuracy:0.646
current auc_score ------------------> 0.935
Saved model to disk
Epochs  6  batch_size:  64  lr:  0.0002  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_11[0][0]              
==================================================================================================
Total params: 156,784
Trainable params: 155,108
Non-trainable params: 1,676
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 14112)        156784      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 28224)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          14451200    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,610,545
Trainable params: 14,607,845
Non-trainable params: 2,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 76s - loss: 0.5466 - acc: 0.8061 - val_loss: 1.4843 - val_acc: 0.5141

Epoch 00001: val_loss improved from inf to 1.48427, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 2/6
 - 72s - loss: 0.2977 - acc: 0.9299 - val_loss: 1.0952 - val_acc: 0.5837

Epoch 00002: val_loss improved from 1.48427 to 1.09520, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 3/6
 - 71s - loss: 0.2036 - acc: 0.9693 - val_loss: 1.4883 - val_acc: 0.5203

Epoch 00003: val_loss did not improve from 1.09520
Epoch 4/6
 - 71s - loss: 0.1609 - acc: 0.9843 - val_loss: 0.9447 - val_acc: 0.6330

Epoch 00004: val_loss improved from 1.09520 to 0.94466, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 5/6
 - 71s - loss: 0.1383 - acc: 0.9895 - val_loss: 0.1220 - val_acc: 0.9939

Epoch 00005: val_loss improved from 0.94466 to 0.12196, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 6/6
 - 71s - loss: 0.1235 - acc: 0.9928 - val_loss: 0.1171 - val_acc: 0.9942

Epoch 00006: val_loss improved from 0.12196 to 0.11709, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Test accuracy:0.672
current auc_score ------------------> 0.874
Epochs  6  batch_size:  64  lr:  0.0002  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_11[0][0]              
==================================================================================================
Total params: 156,784
Trainable params: 155,108
Non-trainable params: 1,676
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 14112)        156784      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 28224)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          14451200    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,610,545
Trainable params: 14,607,845
Non-trainable params: 2,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 76s - loss: 0.5253 - acc: 0.8165 - val_loss: 0.8426 - val_acc: 0.6362

Epoch 00001: val_loss improved from inf to 0.84261, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 2/6
 - 71s - loss: 0.2808 - acc: 0.9367 - val_loss: 3.5970 - val_acc: 0.5035

Epoch 00002: val_loss did not improve from 0.84261
Epoch 3/6
 - 71s - loss: 0.1941 - acc: 0.9734 - val_loss: 2.1327 - val_acc: 0.5051

Epoch 00003: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.

Epoch 00003: val_loss did not improve from 0.84261
Epoch 4/6
 - 71s - loss: 0.1497 - acc: 0.9889 - val_loss: 1.5468 - val_acc: 0.5272

Epoch 00004: val_loss did not improve from 0.84261
Epoch 5/6
 - 71s - loss: 0.1370 - acc: 0.9920 - val_loss: 0.7763 - val_acc: 0.7279

Epoch 00005: val_loss improved from 0.84261 to 0.77629, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 6/6
 - 71s - loss: 0.1264 - acc: 0.9948 - val_loss: 0.7183 - val_acc: 0.7469

Epoch 00006: val_loss improved from 0.77629 to 0.71832, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Test accuracy:0.766
current auc_score ------------------> 0.787
Epochs  6  batch_size:  64  lr:  0.0002  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_11[0][0]              
==================================================================================================
Total params: 156,784
Trainable params: 155,108
Non-trainable params: 1,676
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 14112)        156784      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 28224)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          14451200    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,610,545
Trainable params: 14,607,845
Non-trainable params: 2,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 77s - loss: 0.5051 - acc: 0.8269 - val_loss: 0.3168 - val_acc: 0.9224

Epoch 00001: val_loss improved from inf to 0.31677, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 2/6
 - 73s - loss: 0.2604 - acc: 0.9449 - val_loss: 0.1941 - val_acc: 0.9794

Epoch 00002: val_loss improved from 0.31677 to 0.19406, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 3/6
 - 73s - loss: 0.1880 - acc: 0.9744 - val_loss: 0.1536 - val_acc: 0.9880

Epoch 00003: val_loss improved from 0.19406 to 0.15358, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 4/6
 - 73s - loss: 0.1520 - acc: 0.9873 - val_loss: 0.1263 - val_acc: 0.9957

Epoch 00004: val_loss improved from 0.15358 to 0.12632, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 5/6
 - 73s - loss: 0.1322 - acc: 0.9921 - val_loss: 0.1183 - val_acc: 0.9961

Epoch 00005: val_loss improved from 0.12632 to 0.11826, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 6/6
 - 74s - loss: 0.1183 - acc: 0.9946 - val_loss: 0.1155 - val_acc: 0.9950

Epoch 00006: val_loss improved from 0.11826 to 0.11548, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Test accuracy:0.663
current auc_score ------------------> 0.892
Epochs  6  batch_size:  64  lr:  0.0002  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 38, 24, 24)   2888        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 38, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 38, 12, 12)   152         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  4560        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  8160        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 98, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 98, 12, 12)   392         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 98, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 14112)        0           activation_11[0][0]              
==================================================================================================
Total params: 156,784
Trainable params: 155,108
Non-trainable params: 1,676
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 14112)        156784      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 28224)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          14451200    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 14,610,545
Trainable params: 14,607,845
Non-trainable params: 2,700
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 79s - loss: 0.5838 - acc: 0.7859 - val_loss: 0.3712 - val_acc: 0.9017

Epoch 00001: val_loss improved from inf to 0.37122, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 2/6
 - 73s - loss: 0.2945 - acc: 0.9316 - val_loss: 0.2122 - val_acc: 0.9700

Epoch 00002: val_loss improved from 0.37122 to 0.21223, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 3/6
 - 73s - loss: 0.2025 - acc: 0.9710 - val_loss: 0.1652 - val_acc: 0.9852

Epoch 00003: val_loss improved from 0.21223 to 0.16524, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 4/6
 - 73s - loss: 0.1623 - acc: 0.9832 - val_loss: 0.1337 - val_acc: 0.9960

Epoch 00004: val_loss improved from 0.16524 to 0.13372, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 5/6
 - 73s - loss: 0.1402 - acc: 0.9899 - val_loss: 0.1180 - val_acc: 0.9965

Epoch 00005: val_loss improved from 0.13372 to 0.11797, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 6/6
 - 72s - loss: 0.1254 - acc: 0.9928 - val_loss: 0.1085 - val_acc: 0.9965

Epoch 00006: val_loss improved from 0.11797 to 0.10855, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Test accuracy:0.724
current auc_score ------------------> 0.905
accuracies:  [0.703494623655914, 0.7223118279569892, 0.7045698924731183, 0.7060483870967742, 0.5666666666666667, 0.6456989247311828, 0.6720430107526881, 0.7663978494623656, 0.6626344086021505, 0.7244623655913979]
aucs:  [0.8777, 0.8671, 0.9428, 0.8541, 0.7622, 0.9355, 0.8741, 0.7867, 0.8921, 0.9052]
mean and std AUC:  0.87+/-0.055  max:   0.9428
Epochs  6  batch_size:  64  lr:  0.0002  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  32  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 32, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 32, 48, 48)   128         initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 32, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 32, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 32, 24, 24)   128         max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 32, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  3840        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 62, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 62, 24, 24)   248         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 62, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  7440        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 92, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 92, 24, 24)   368         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 92, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 46, 24, 24)   4232        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 46, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 46, 12, 12)   184         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 46, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  5520        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 76, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 76, 12, 12)   304         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 76, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  9120        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 106, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 106, 12, 12)  424         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 106, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 15264)        0           activation_11[0][0]              
==================================================================================================
Total params: 165,024
Trainable params: 163,172
Non-trainable params: 1,852
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 15264)        165024      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 30528)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          15630848    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 15,798,433
Trainable params: 15,795,557
Non-trainable params: 2,876
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 80s - loss: 0.5109 - acc: 0.8239 - val_loss: 0.8694 - val_acc: 0.6202

Epoch 00001: val_loss improved from inf to 0.86938, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 2/6
 - 76s - loss: 0.2588 - acc: 0.9497 - val_loss: 2.0348 - val_acc: 0.5107

Epoch 00002: val_loss did not improve from 0.86938
Epoch 3/6
 - 76s - loss: 0.1832 - acc: 0.9771 - val_loss: 2.8936 - val_acc: 0.5102

Epoch 00003: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.

Epoch 00003: val_loss did not improve from 0.86938
Epoch 4/6
 - 76s - loss: 0.1441 - acc: 0.9910 - val_loss: 3.1762 - val_acc: 0.5090

Epoch 00004: val_loss did not improve from 0.86938
Epoch 5/6
 - 76s - loss: 0.1326 - acc: 0.9933 - val_loss: 2.5569 - val_acc: 0.5296

Epoch 00005: ReduceLROnPlateau reducing learning rate to 1.999999851818061e-05.

Epoch 00005: val_loss did not improve from 0.86938
Epoch 00005: early stopping
Test accuracy:0.550
current auc_score ------------------> 0.595
Epochs  6  batch_size:  64  lr:  0.0002  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  32  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 32, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 32, 48, 48)   128         initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 32, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 32, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 32, 24, 24)   128         max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 32, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  3840        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 62, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 62, 24, 24)   248         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 62, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  7440        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 92, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 92, 24, 24)   368         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 92, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 46, 24, 24)   4232        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 46, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 46, 12, 12)   184         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 46, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  5520        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 76, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 76, 12, 12)   304         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 76, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  9120        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 106, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 106, 12, 12)  424         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 106, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 15264)        0           activation_11[0][0]              
==================================================================================================
Total params: 165,024
Trainable params: 163,172
Non-trainable params: 1,852
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 15264)        165024      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 30528)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          15630848    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 15,798,433
Trainable params: 15,795,557
Non-trainable params: 2,876
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 80s - loss: 0.5185 - acc: 0.8235 - val_loss: 0.9903 - val_acc: 0.5956

Epoch 00001: val_loss improved from inf to 0.99031, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 2/6
 - 76s - loss: 0.2638 - acc: 0.9469 - val_loss: 1.2323 - val_acc: 0.6155

Epoch 00002: val_loss did not improve from 0.99031
Epoch 3/6
 - 77s - loss: 0.1889 - acc: 0.9760 - val_loss: 0.1477 - val_acc: 0.9910

Epoch 00003: val_loss improved from 0.99031 to 0.14770, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 4/6
 - 77s - loss: 0.1527 - acc: 0.9867 - val_loss: 0.1345 - val_acc: 0.9928

Epoch 00004: val_loss improved from 0.14770 to 0.13448, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 5/6
 - 76s - loss: 0.1352 - acc: 0.9912 - val_loss: 0.1154 - val_acc: 0.9969

Epoch 00005: val_loss improved from 0.13448 to 0.11543, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 6/6
 - 77s - loss: 0.1227 - acc: 0.9938 - val_loss: 0.1068 - val_acc: 0.9970

Epoch 00006: val_loss improved from 0.11543 to 0.10684, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Test accuracy:0.624
current auc_score ------------------> 0.893
Epochs  6  batch_size:  64  lr:  0.0002  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  32  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 32, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 32, 48, 48)   128         initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 32, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 32, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 32, 24, 24)   128         max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 32, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  3840        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 62, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 62, 24, 24)   248         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 62, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  7440        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 92, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 92, 24, 24)   368         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 92, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 46, 24, 24)   4232        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 46, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 46, 12, 12)   184         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 46, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  5520        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 76, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 76, 12, 12)   304         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 76, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  9120        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 106, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 106, 12, 12)  424         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 106, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 15264)        0           activation_11[0][0]              
==================================================================================================
Total params: 165,024
Trainable params: 163,172
Non-trainable params: 1,852
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 15264)        165024      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 30528)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          15630848    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 15,798,433
Trainable params: 15,795,557
Non-trainable params: 2,876
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 80s - loss: 0.5261 - acc: 0.8206 - val_loss: 0.6772 - val_acc: 0.7120

Epoch 00001: val_loss improved from inf to 0.67719, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 2/6
 - 76s - loss: 0.2590 - acc: 0.9495 - val_loss: 0.6212 - val_acc: 0.7570

Epoch 00002: val_loss improved from 0.67719 to 0.62117, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 3/6
 - 76s - loss: 0.1894 - acc: 0.9760 - val_loss: 0.1681 - val_acc: 0.9863

Epoch 00003: val_loss improved from 0.62117 to 0.16807, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 4/6
 - 77s - loss: 0.1543 - acc: 0.9869 - val_loss: 0.1262 - val_acc: 0.9955

Epoch 00004: val_loss improved from 0.16807 to 0.12618, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 5/6
 - 77s - loss: 0.1363 - acc: 0.9915 - val_loss: 0.1162 - val_acc: 0.9975

Epoch 00005: val_loss improved from 0.12618 to 0.11625, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 6/6
 - 77s - loss: 0.1214 - acc: 0.9947 - val_loss: 0.1054 - val_acc: 0.9980

Epoch 00006: val_loss improved from 0.11625 to 0.10537, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Test accuracy:0.679
current auc_score ------------------> 0.878
Epochs  6  batch_size:  64  lr:  0.0002  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  32  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 32, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 32, 48, 48)   128         initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 32, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 32, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 32, 24, 24)   128         max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 32, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  3840        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 62, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 62, 24, 24)   248         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 62, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  7440        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 92, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 92, 24, 24)   368         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 92, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 46, 24, 24)   4232        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 46, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 46, 12, 12)   184         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 46, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  5520        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 76, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 76, 12, 12)   304         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 76, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  9120        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 106, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 106, 12, 12)  424         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 106, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 15264)        0           activation_11[0][0]              
==================================================================================================
Total params: 165,024
Trainable params: 163,172
Non-trainable params: 1,852
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 15264)        165024      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 30528)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          15630848    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 15,798,433
Trainable params: 15,795,557
Non-trainable params: 2,876
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 84s - loss: 0.4953 - acc: 0.8349 - val_loss: 0.2819 - val_acc: 0.9438

Epoch 00001: val_loss improved from inf to 0.28192, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 2/6
 - 79s - loss: 0.2554 - acc: 0.9487 - val_loss: 0.2104 - val_acc: 0.9698

Epoch 00002: val_loss improved from 0.28192 to 0.21039, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 3/6
 - 78s - loss: 0.1788 - acc: 0.9804 - val_loss: 0.1474 - val_acc: 0.9885

Epoch 00003: val_loss improved from 0.21039 to 0.14739, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 4/6
 - 80s - loss: 0.1499 - acc: 0.9883 - val_loss: 0.1294 - val_acc: 0.9949

Epoch 00004: val_loss improved from 0.14739 to 0.12939, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 5/6
 - 78s - loss: 0.1310 - acc: 0.9923 - val_loss: 0.1141 - val_acc: 0.9980

Epoch 00005: val_loss improved from 0.12939 to 0.11407, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 6/6
 - 78s - loss: 0.1181 - acc: 0.9949 - val_loss: 0.1068 - val_acc: 0.9981

Epoch 00006: val_loss improved from 0.11407 to 0.10678, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Test accuracy:0.688
current auc_score ------------------> 0.879
Epochs  6  batch_size:  64  lr:  0.0002  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  32  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 32, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 32, 48, 48)   128         initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 32, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 32, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 32, 24, 24)   128         max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 32, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  3840        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 62, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 62, 24, 24)   248         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 62, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  7440        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 92, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 92, 24, 24)   368         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 92, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 46, 24, 24)   4232        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 46, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 46, 12, 12)   184         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 46, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  5520        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 76, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 76, 12, 12)   304         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 76, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  9120        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 106, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 106, 12, 12)  424         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 106, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 15264)        0           activation_11[0][0]              
==================================================================================================
Total params: 165,024
Trainable params: 163,172
Non-trainable params: 1,852
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 15264)        165024      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 30528)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          15630848    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 15,798,433
Trainable params: 15,795,557
Non-trainable params: 2,876
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 84s - loss: 0.4949 - acc: 0.8348 - val_loss: 0.3032 - val_acc: 0.9321

Epoch 00001: val_loss improved from inf to 0.30325, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 2/6
 - 78s - loss: 0.2629 - acc: 0.9462 - val_loss: 0.2102 - val_acc: 0.9769

Epoch 00002: val_loss improved from 0.30325 to 0.21023, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 3/6
 - 78s - loss: 0.1827 - acc: 0.9790 - val_loss: 0.1468 - val_acc: 0.9911

Epoch 00003: val_loss improved from 0.21023 to 0.14683, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 4/6
 - 78s - loss: 0.1539 - acc: 0.9876 - val_loss: 0.1233 - val_acc: 0.9959

Epoch 00004: val_loss improved from 0.14683 to 0.12328, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 5/6
 - 78s - loss: 0.1312 - acc: 0.9931 - val_loss: 0.1095 - val_acc: 0.9979

Epoch 00005: val_loss improved from 0.12328 to 0.10951, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 6/6
 - 78s - loss: 0.1179 - acc: 0.9954 - val_loss: 0.1043 - val_acc: 0.9976

Epoch 00006: val_loss improved from 0.10951 to 0.10429, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Test accuracy:0.686
current auc_score ------------------> 0.896
Epochs  6  batch_size:  64  lr:  0.0002  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  32  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 32, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 32, 48, 48)   128         initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 32, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 32, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 32, 24, 24)   128         max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 32, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  3840        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 62, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 62, 24, 24)   248         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 62, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  7440        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 92, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 92, 24, 24)   368         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 92, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 46, 24, 24)   4232        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 46, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 46, 12, 12)   184         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 46, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  5520        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 76, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 76, 12, 12)   304         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 76, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  9120        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 106, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 106, 12, 12)  424         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 106, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 15264)        0           activation_11[0][0]              
==================================================================================================
Total params: 165,024
Trainable params: 163,172
Non-trainable params: 1,852
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 15264)        165024      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 30528)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          15630848    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 15,798,433
Trainable params: 15,795,557
Non-trainable params: 2,876
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 82s - loss: 0.5459 - acc: 0.8077 - val_loss: 0.3493 - val_acc: 0.9140

Epoch 00001: val_loss improved from inf to 0.34926, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 2/6
 - 78s - loss: 0.2923 - acc: 0.9341 - val_loss: 0.2174 - val_acc: 0.9714

Epoch 00002: val_loss improved from 0.34926 to 0.21745, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 3/6
 - 77s - loss: 0.2023 - acc: 0.9727 - val_loss: 0.1735 - val_acc: 0.9890

Epoch 00003: val_loss improved from 0.21745 to 0.17346, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 4/6
 - 78s - loss: 0.1661 - acc: 0.9839 - val_loss: 0.1426 - val_acc: 0.9936

Epoch 00004: val_loss improved from 0.17346 to 0.14255, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 5/6
 - 78s - loss: 0.1414 - acc: 0.9899 - val_loss: 0.1243 - val_acc: 0.9974

Epoch 00005: val_loss improved from 0.14255 to 0.12427, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 6/6
 - 78s - loss: 0.1270 - acc: 0.9927 - val_loss: 0.1228 - val_acc: 0.9969

Epoch 00006: val_loss improved from 0.12427 to 0.12276, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Test accuracy:0.619
current auc_score ------------------> 0.894
Epochs  6  batch_size:  64  lr:  0.0002  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  32  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 32, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 32, 48, 48)   128         initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 32, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 32, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 32, 24, 24)   128         max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 32, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  3840        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 62, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 62, 24, 24)   248         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 62, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  7440        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 92, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 92, 24, 24)   368         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 92, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 46, 24, 24)   4232        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 46, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 46, 12, 12)   184         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 46, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  5520        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 76, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 76, 12, 12)   304         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 76, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  9120        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 106, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 106, 12, 12)  424         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 106, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 15264)        0           activation_11[0][0]              
==================================================================================================
Total params: 165,024
Trainable params: 163,172
Non-trainable params: 1,852
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 15264)        165024      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 30528)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          15630848    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 15,798,433
Trainable params: 15,795,557
Non-trainable params: 2,876
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 83s - loss: 0.5338 - acc: 0.8087 - val_loss: 0.3257 - val_acc: 0.9224

Epoch 00001: val_loss improved from inf to 0.32572, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 2/6
 - 79s - loss: 0.2962 - acc: 0.9319 - val_loss: 0.2198 - val_acc: 0.9681

Epoch 00002: val_loss improved from 0.32572 to 0.21976, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 3/6
 - 79s - loss: 0.2058 - acc: 0.9698 - val_loss: 0.1697 - val_acc: 0.9886

Epoch 00003: val_loss improved from 0.21976 to 0.16966, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 4/6
 - 78s - loss: 0.1664 - acc: 0.9841 - val_loss: 0.1545 - val_acc: 0.9925

Epoch 00004: val_loss improved from 0.16966 to 0.15447, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 5/6
 - 79s - loss: 0.1433 - acc: 0.9888 - val_loss: 0.1256 - val_acc: 0.9966

Epoch 00005: val_loss improved from 0.15447 to 0.12557, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 6/6
 - 78s - loss: 0.1272 - acc: 0.9923 - val_loss: 0.1184 - val_acc: 0.9961

Epoch 00006: val_loss improved from 0.12557 to 0.11844, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Test accuracy:0.648
current auc_score ------------------> 0.849
Epochs  6  batch_size:  64  lr:  0.0002  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  32  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 32, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 32, 48, 48)   128         initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 32, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 32, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 32, 24, 24)   128         max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 32, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  3840        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 62, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 62, 24, 24)   248         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 62, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  7440        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 92, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 92, 24, 24)   368         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 92, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 46, 24, 24)   4232        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 46, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 46, 12, 12)   184         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 46, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  5520        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 76, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 76, 12, 12)   304         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 76, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  9120        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 106, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 106, 12, 12)  424         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 106, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 15264)        0           activation_11[0][0]              
==================================================================================================
Total params: 165,024
Trainable params: 163,172
Non-trainable params: 1,852
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 15264)        165024      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 30528)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          15630848    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 15,798,433
Trainable params: 15,795,557
Non-trainable params: 2,876
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 83s - loss: 0.4997 - acc: 0.8288 - val_loss: 0.3250 - val_acc: 0.9244

Epoch 00001: val_loss improved from inf to 0.32500, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 2/6
 - 78s - loss: 0.2587 - acc: 0.9488 - val_loss: 0.1973 - val_acc: 0.9789

Epoch 00002: val_loss improved from 0.32500 to 0.19734, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 3/6
 - 78s - loss: 0.1866 - acc: 0.9778 - val_loss: 0.1458 - val_acc: 0.9915

Epoch 00003: val_loss improved from 0.19734 to 0.14577, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 4/6
 - 78s - loss: 0.1538 - acc: 0.9867 - val_loss: 0.1280 - val_acc: 0.9961

Epoch 00004: val_loss improved from 0.14577 to 0.12797, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 5/6
 - 78s - loss: 0.1331 - acc: 0.9916 - val_loss: 0.1115 - val_acc: 0.9975

Epoch 00005: val_loss improved from 0.12797 to 0.11147, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 6/6
 - 78s - loss: 0.1206 - acc: 0.9945 - val_loss: 0.1044 - val_acc: 0.9982

Epoch 00006: val_loss improved from 0.11147 to 0.10440, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Test accuracy:0.740
current auc_score ------------------> 0.888
Epochs  6  batch_size:  64  lr:  0.0002  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  32  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 32, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 32, 48, 48)   128         initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 32, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 32, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 32, 24, 24)   128         max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 32, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  3840        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 62, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 62, 24, 24)   248         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 62, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  7440        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 92, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 92, 24, 24)   368         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 92, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 46, 24, 24)   4232        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 46, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 46, 12, 12)   184         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 46, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  5520        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 76, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 76, 12, 12)   304         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 76, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  9120        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 106, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 106, 12, 12)  424         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 106, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 15264)        0           activation_11[0][0]              
==================================================================================================
Total params: 165,024
Trainable params: 163,172
Non-trainable params: 1,852
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 15264)        165024      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 30528)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          15630848    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 15,798,433
Trainable params: 15,795,557
Non-trainable params: 2,876
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 82s - loss: 0.5027 - acc: 0.8335 - val_loss: 0.2940 - val_acc: 0.9469

Epoch 00001: val_loss improved from inf to 0.29405, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 2/6
 - 78s - loss: 0.2631 - acc: 0.9461 - val_loss: 0.2016 - val_acc: 0.9821

Epoch 00002: val_loss improved from 0.29405 to 0.20163, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 3/6
 - 77s - loss: 0.1884 - acc: 0.9775 - val_loss: 0.1513 - val_acc: 0.9936

Epoch 00003: val_loss improved from 0.20163 to 0.15128, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 4/6
 - 78s - loss: 0.1556 - acc: 0.9861 - val_loss: 0.1289 - val_acc: 0.9951

Epoch 00004: val_loss improved from 0.15128 to 0.12891, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 5/6
 - 78s - loss: 0.1344 - acc: 0.9917 - val_loss: 0.1412 - val_acc: 0.9905

Epoch 00005: val_loss did not improve from 0.12891
Epoch 6/6
 - 78s - loss: 0.1230 - acc: 0.9933 - val_loss: 0.1069 - val_acc: 0.9987

Epoch 00006: val_loss improved from 0.12891 to 0.10694, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Test accuracy:0.660
current auc_score ------------------> 0.872
Epochs  6  batch_size:  64  lr:  0.0002  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  32  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 32, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 32, 48, 48)   128         initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 32, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 32, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 32, 24, 24)   128         max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 32, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  3840        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 62, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 62, 24, 24)   248         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 62, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  7440        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 92, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 92, 24, 24)   368         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 92, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 46, 24, 24)   4232        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 46, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 46, 12, 12)   184         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 46, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  5520        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 76, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 76, 12, 12)   304         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 76, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  9120        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 106, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 106, 12, 12)  424         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 106, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 15264)        0           activation_11[0][0]              
==================================================================================================
Total params: 165,024
Trainable params: 163,172
Non-trainable params: 1,852
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 15264)        165024      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 30528)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          15630848    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 15,798,433
Trainable params: 15,795,557
Non-trainable params: 2,876
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 82s - loss: 0.4968 - acc: 0.8347 - val_loss: 0.3126 - val_acc: 0.9316

Epoch 00001: val_loss improved from inf to 0.31259, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 2/6
 - 78s - loss: 0.2596 - acc: 0.9503 - val_loss: 0.1915 - val_acc: 0.9859

Epoch 00002: val_loss improved from 0.31259 to 0.19148, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 3/6
 - 78s - loss: 0.1839 - acc: 0.9789 - val_loss: 0.1427 - val_acc: 0.9941

Epoch 00003: val_loss improved from 0.19148 to 0.14274, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 4/6
 - 79s - loss: 0.1502 - acc: 0.9884 - val_loss: 0.1249 - val_acc: 0.9960

Epoch 00004: val_loss improved from 0.14274 to 0.12489, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 5/6
 - 79s - loss: 0.1318 - acc: 0.9929 - val_loss: 0.1197 - val_acc: 0.9951

Epoch 00005: val_loss improved from 0.12489 to 0.11969, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 6/6
 - 79s - loss: 0.1222 - acc: 0.9942 - val_loss: 0.1117 - val_acc: 0.9977

Epoch 00006: val_loss improved from 0.11969 to 0.11175, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Test accuracy:0.672
current auc_score ------------------> 0.874
accuracies:  [0.5495967741935484, 0.6243279569892473, 0.6786290322580645, 0.6876344086021505, 0.6861559139784946, 0.6188172043010752, 0.6477150537634409, 0.7397849462365591, 0.6596774193548387, 0.6721774193548387]
aucs:  [0.5945, 0.8928, 0.8779, 0.8787, 0.8963, 0.8938, 0.8487, 0.8882, 0.8716, 0.8743]
mean and std AUC:  0.852+/-0.087  max:   0.8963
Epochs  6  batch_size:  64  lr:  0.0002  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  64  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 64, 48, 48)   3136        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 64, 48, 48)   256         initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 64, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 64, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 64, 24, 24)   256         max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 64, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  7680        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 94, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 94, 24, 24)   376         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 94, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  11280       activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 124, 24, 24)  0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 124, 24, 24)  496         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 124, 24, 24)  0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 62, 24, 24)   7688        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 62, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 62, 12, 12)   248         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 62, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  7440        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 92, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 92, 12, 12)   368         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 92, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  11040       activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 122, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 122, 12, 12)  488         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 122, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 17568)        0           activation_11[0][0]              
==================================================================================================
Total params: 182,272
Trainable params: 180,068
Non-trainable params: 2,204
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 17568)        182272      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 35136)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          17990144    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 18,174,977
Trainable params: 18,171,749
Non-trainable params: 3,228
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 93s - loss: 0.5541 - acc: 0.8065 - val_loss: 1.0711 - val_acc: 0.5681

Epoch 00001: val_loss improved from inf to 1.07107, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 2/6
 - 88s - loss: 0.2966 - acc: 0.9375 - val_loss: 2.3993 - val_acc: 0.5114

Epoch 00002: val_loss did not improve from 1.07107
Epoch 3/6
 - 88s - loss: 0.2059 - acc: 0.9753 - val_loss: 1.5889 - val_acc: 0.5548

Epoch 00003: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.

Epoch 00003: val_loss did not improve from 1.07107
Epoch 4/6
 - 88s - loss: 0.1630 - acc: 0.9901 - val_loss: 1.3206 - val_acc: 0.5956

Epoch 00004: val_loss did not improve from 1.07107
Epoch 5/6
 - 88s - loss: 0.1489 - acc: 0.9927 - val_loss: 1.6624 - val_acc: 0.5737

Epoch 00005: ReduceLROnPlateau reducing learning rate to 1.999999851818061e-05.

Epoch 00005: val_loss did not improve from 1.07107
Epoch 6/6
 - 88s - loss: 0.1384 - acc: 0.9952 - val_loss: 1.7473 - val_acc: 0.5685

Epoch 00006: val_loss did not improve from 1.07107
Test accuracy:0.489
current auc_score ------------------> 0.694
Epochs  6  batch_size:  64  lr:  0.0002  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  64  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 64, 48, 48)   3136        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 64, 48, 48)   256         initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 64, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 64, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 64, 24, 24)   256         max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 64, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  7680        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 94, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 94, 24, 24)   376         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 94, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  11280       activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 124, 24, 24)  0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 124, 24, 24)  496         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 124, 24, 24)  0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 62, 24, 24)   7688        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 62, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 62, 12, 12)   248         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 62, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  7440        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 92, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 92, 12, 12)   368         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 92, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  11040       activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 122, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 122, 12, 12)  488         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 122, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 17568)        0           activation_11[0][0]              
==================================================================================================
Total params: 182,272
Trainable params: 180,068
Non-trainable params: 2,204
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 17568)        182272      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 35136)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          17990144    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 18,174,977
Trainable params: 18,171,749
Non-trainable params: 3,228
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 96s - loss: 0.5181 - acc: 0.8282 - val_loss: 0.3195 - val_acc: 0.9303

Epoch 00001: val_loss improved from inf to 0.31947, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 2/6
 - 91s - loss: 0.2723 - acc: 0.9462 - val_loss: 0.2013 - val_acc: 0.9782

Epoch 00002: val_loss improved from 0.31947 to 0.20129, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 3/6
 - 91s - loss: 0.1939 - acc: 0.9785 - val_loss: 0.1622 - val_acc: 0.9920

Epoch 00003: val_loss improved from 0.20129 to 0.16218, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 4/6
 - 91s - loss: 0.1595 - acc: 0.9879 - val_loss: 0.1335 - val_acc: 0.9959

Epoch 00004: val_loss improved from 0.16218 to 0.13348, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 5/6
 - 91s - loss: 0.1406 - acc: 0.9931 - val_loss: 0.1183 - val_acc: 0.9976

Epoch 00005: val_loss improved from 0.13348 to 0.11825, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 6/6
 - 91s - loss: 0.1277 - acc: 0.9941 - val_loss: 0.1206 - val_acc: 0.9957

Epoch 00006: val_loss did not improve from 0.11825
Test accuracy:0.571
current auc_score ------------------> 0.886
Epochs  6  batch_size:  64  lr:  0.0002  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  64  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 64, 48, 48)   3136        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 64, 48, 48)   256         initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 64, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 64, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 64, 24, 24)   256         max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 64, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  7680        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 94, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 94, 24, 24)   376         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 94, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  11280       activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 124, 24, 24)  0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 124, 24, 24)  496         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 124, 24, 24)  0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 62, 24, 24)   7688        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 62, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 62, 12, 12)   248         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 62, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  7440        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 92, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 92, 12, 12)   368         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 92, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  11040       activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 122, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 122, 12, 12)  488         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 122, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 17568)        0           activation_11[0][0]              
==================================================================================================
Total params: 182,272
Trainable params: 180,068
Non-trainable params: 2,204
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 17568)        182272      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 35136)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          17990144    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 18,174,977
Trainable params: 18,171,749
Non-trainable params: 3,228
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 96s - loss: 0.5422 - acc: 0.8154 - val_loss: 0.3293 - val_acc: 0.9273

Epoch 00001: val_loss improved from inf to 0.32931, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 2/6
 - 91s - loss: 0.2856 - acc: 0.9401 - val_loss: 0.2271 - val_acc: 0.9757

Epoch 00002: val_loss improved from 0.32931 to 0.22713, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 3/6
 - 91s - loss: 0.2034 - acc: 0.9749 - val_loss: 0.1799 - val_acc: 0.9876

Epoch 00003: val_loss improved from 0.22713 to 0.17993, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 4/6
 - 91s - loss: 0.1650 - acc: 0.9869 - val_loss: 0.1498 - val_acc: 0.9915

Epoch 00004: val_loss improved from 0.17993 to 0.14985, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 5/6
 - 91s - loss: 0.1439 - acc: 0.9916 - val_loss: 0.1247 - val_acc: 0.9969

Epoch 00005: val_loss improved from 0.14985 to 0.12472, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 6/6
 - 91s - loss: 0.1279 - acc: 0.9947 - val_loss: 0.1212 - val_acc: 0.9962

Epoch 00006: val_loss improved from 0.12472 to 0.12124, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Test accuracy:0.637
current auc_score ------------------> 0.893
Epochs  6  batch_size:  64  lr:  0.0002  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  64  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 64, 48, 48)   3136        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 64, 48, 48)   256         initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 64, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 64, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 64, 24, 24)   256         max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 64, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  7680        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 94, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 94, 24, 24)   376         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 94, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  11280       activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 124, 24, 24)  0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 124, 24, 24)  496         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 124, 24, 24)  0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 62, 24, 24)   7688        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 62, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 62, 12, 12)   248         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 62, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  7440        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 92, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 92, 12, 12)   368         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 92, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  11040       activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 122, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 122, 12, 12)  488         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 122, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 17568)        0           activation_11[0][0]              
==================================================================================================
Total params: 182,272
Trainable params: 180,068
Non-trainable params: 2,204
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 17568)        182272      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 35136)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          17990144    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 18,174,977
Trainable params: 18,171,749
Non-trainable params: 3,228
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 95s - loss: 0.5052 - acc: 0.8342 - val_loss: 0.3024 - val_acc: 0.9381

Epoch 00001: val_loss improved from inf to 0.30236, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 2/6
 - 91s - loss: 0.2693 - acc: 0.9477 - val_loss: 0.2129 - val_acc: 0.9821

Epoch 00002: val_loss improved from 0.30236 to 0.21287, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 3/6
 - 91s - loss: 0.1971 - acc: 0.9775 - val_loss: 0.1666 - val_acc: 0.9922

Epoch 00003: val_loss improved from 0.21287 to 0.16661, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 4/6
 - 91s - loss: 0.1675 - acc: 0.9851 - val_loss: 0.1406 - val_acc: 0.9962

Epoch 00004: val_loss improved from 0.16661 to 0.14060, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 5/6
 - 91s - loss: 0.1451 - acc: 0.9906 - val_loss: 0.1259 - val_acc: 0.9969

Epoch 00005: val_loss improved from 0.14060 to 0.12587, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 6/6
 - 91s - loss: 0.1291 - acc: 0.9941 - val_loss: 0.1128 - val_acc: 0.9980

Epoch 00006: val_loss improved from 0.12587 to 0.11281, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Test accuracy:0.561
current auc_score ------------------> 0.897
Epochs  6  batch_size:  64  lr:  0.0002  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  64  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 64, 48, 48)   3136        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 64, 48, 48)   256         initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 64, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 64, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 64, 24, 24)   256         max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 64, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  7680        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 94, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 94, 24, 24)   376         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 94, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  11280       activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 124, 24, 24)  0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 124, 24, 24)  496         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 124, 24, 24)  0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 62, 24, 24)   7688        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 62, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 62, 12, 12)   248         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 62, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  7440        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 92, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 92, 12, 12)   368         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 92, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  11040       activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 122, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 122, 12, 12)  488         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 122, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 17568)        0           activation_11[0][0]              
==================================================================================================
Total params: 182,272
Trainable params: 180,068
Non-trainable params: 2,204
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 17568)        182272      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 35136)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          17990144    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 18,174,977
Trainable params: 18,171,749
Non-trainable params: 3,228
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 95s - loss: 0.5571 - acc: 0.8026 - val_loss: 0.3836 - val_acc: 0.8872

Epoch 00001: val_loss improved from inf to 0.38365, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 2/6
 - 90s - loss: 0.2902 - acc: 0.9394 - val_loss: 0.2319 - val_acc: 0.9676

Epoch 00002: val_loss improved from 0.38365 to 0.23192, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 3/6
 - 91s - loss: 0.2117 - acc: 0.9715 - val_loss: 0.1703 - val_acc: 0.9913

Epoch 00003: val_loss improved from 0.23192 to 0.17034, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 4/6
 - 91s - loss: 0.1672 - acc: 0.9854 - val_loss: 0.1485 - val_acc: 0.9926

Epoch 00004: val_loss improved from 0.17034 to 0.14853, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 5/6
 - 91s - loss: 0.1449 - acc: 0.9913 - val_loss: 0.1345 - val_acc: 0.9962

Epoch 00005: val_loss improved from 0.14853 to 0.13450, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 6/6
 - 91s - loss: 0.1273 - acc: 0.9943 - val_loss: 0.1180 - val_acc: 0.9984

Epoch 00006: val_loss improved from 0.13450 to 0.11796, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Test accuracy:0.672
current auc_score ------------------> 0.859
Epochs  6  batch_size:  64  lr:  0.0002  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  64  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 64, 48, 48)   3136        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 64, 48, 48)   256         initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 64, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 64, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 64, 24, 24)   256         max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 64, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  7680        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 94, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 94, 24, 24)   376         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 94, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  11280       activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 124, 24, 24)  0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 124, 24, 24)  496         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 124, 24, 24)  0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 62, 24, 24)   7688        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 62, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 62, 12, 12)   248         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 62, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  7440        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 92, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 92, 12, 12)   368         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 92, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  11040       activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 122, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 122, 12, 12)  488         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 122, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 17568)        0           activation_11[0][0]              
==================================================================================================
Total params: 182,272
Trainable params: 180,068
Non-trainable params: 2,204
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 17568)        182272      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 35136)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          17990144    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 18,174,977
Trainable params: 18,171,749
Non-trainable params: 3,228
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 93s - loss: 0.5325 - acc: 0.8180 - val_loss: 0.7336 - val_acc: 0.6870

Epoch 00001: val_loss improved from inf to 0.73363, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 2/6
 - 89s - loss: 0.2851 - acc: 0.9405 - val_loss: 1.6747 - val_acc: 0.5240

Epoch 00002: val_loss did not improve from 0.73363
Epoch 3/6
 - 89s - loss: 0.2013 - acc: 0.9747 - val_loss: 2.4810 - val_acc: 0.5051

Epoch 00003: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.

Epoch 00003: val_loss did not improve from 0.73363
Epoch 4/6
 - 89s - loss: 0.1577 - acc: 0.9896 - val_loss: 1.8172 - val_acc: 0.5198

Epoch 00004: val_loss did not improve from 0.73363
Epoch 5/6
 - 89s - loss: 0.1425 - acc: 0.9933 - val_loss: 1.4726 - val_acc: 0.5648

Epoch 00005: ReduceLROnPlateau reducing learning rate to 1.999999851818061e-05.

Epoch 00005: val_loss did not improve from 0.73363
Epoch 00005: early stopping
Test accuracy:0.563
current auc_score ------------------> 0.645
Epochs  6  batch_size:  64  lr:  0.0002  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  64  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 64, 48, 48)   3136        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 64, 48, 48)   256         initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 64, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 64, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 64, 24, 24)   256         max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 64, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  7680        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 94, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 94, 24, 24)   376         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 94, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  11280       activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 124, 24, 24)  0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 124, 24, 24)  496         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 124, 24, 24)  0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 62, 24, 24)   7688        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 62, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 62, 12, 12)   248         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 62, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  7440        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 92, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 92, 12, 12)   368         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 92, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  11040       activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 122, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 122, 12, 12)  488         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 122, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 17568)        0           activation_11[0][0]              
==================================================================================================
Total params: 182,272
Trainable params: 180,068
Non-trainable params: 2,204
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 17568)        182272      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 35136)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          17990144    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 18,174,977
Trainable params: 18,171,749
Non-trainable params: 3,228
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 95s - loss: 0.5377 - acc: 0.8170 - val_loss: 0.3365 - val_acc: 0.9291

Epoch 00001: val_loss improved from inf to 0.33654, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 2/6
 - 91s - loss: 0.2777 - acc: 0.9444 - val_loss: 0.2565 - val_acc: 0.9549

Epoch 00002: val_loss improved from 0.33654 to 0.25655, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 3/6
 - 91s - loss: 0.1983 - acc: 0.9770 - val_loss: 0.1533 - val_acc: 0.9930

Epoch 00003: val_loss improved from 0.25655 to 0.15325, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 4/6
 - 91s - loss: 0.1620 - acc: 0.9875 - val_loss: 0.1499 - val_acc: 0.9949

Epoch 00004: val_loss improved from 0.15325 to 0.14986, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 5/6
 - 90s - loss: 0.1376 - acc: 0.9939 - val_loss: 0.1181 - val_acc: 0.9984

Epoch 00005: val_loss improved from 0.14986 to 0.11811, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 6/6
 - 90s - loss: 0.1277 - acc: 0.9948 - val_loss: 0.1126 - val_acc: 0.9987

Epoch 00006: val_loss improved from 0.11811 to 0.11265, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Test accuracy:0.675
current auc_score ------------------> 0.860
Epochs  6  batch_size:  64  lr:  0.0002  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  64  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 64, 48, 48)   3136        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 64, 48, 48)   256         initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 64, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 64, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 64, 24, 24)   256         max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 64, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  7680        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 94, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 94, 24, 24)   376         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 94, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  11280       activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 124, 24, 24)  0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 124, 24, 24)  496         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 124, 24, 24)  0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 62, 24, 24)   7688        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 62, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 62, 12, 12)   248         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 62, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  7440        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 92, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 92, 12, 12)   368         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 92, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  11040       activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 122, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 122, 12, 12)  488         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 122, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 17568)        0           activation_11[0][0]              
==================================================================================================
Total params: 182,272
Trainable params: 180,068
Non-trainable params: 2,204
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 17568)        182272      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 35136)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          17990144    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 18,174,977
Trainable params: 18,171,749
Non-trainable params: 3,228
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 95s - loss: 0.5079 - acc: 0.8327 - val_loss: 0.3220 - val_acc: 0.9163

Epoch 00001: val_loss improved from inf to 0.32204, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 2/6
 - 92s - loss: 0.2638 - acc: 0.9493 - val_loss: 0.2004 - val_acc: 0.9764

Epoch 00002: val_loss improved from 0.32204 to 0.20043, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 3/6
 - 90s - loss: 0.1894 - acc: 0.9789 - val_loss: 0.1647 - val_acc: 0.9898

Epoch 00003: val_loss improved from 0.20043 to 0.16466, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 4/6
 - 90s - loss: 0.1572 - acc: 0.9886 - val_loss: 0.1361 - val_acc: 0.9974

Epoch 00004: val_loss improved from 0.16466 to 0.13609, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 5/6
 - 90s - loss: 0.1343 - acc: 0.9937 - val_loss: 0.1153 - val_acc: 0.9976

Epoch 00005: val_loss improved from 0.13609 to 0.11534, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 6/6
 - 90s - loss: 0.1209 - acc: 0.9957 - val_loss: 0.1112 - val_acc: 0.9977

Epoch 00006: val_loss improved from 0.11534 to 0.11119, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Test accuracy:0.681
current auc_score ------------------> 0.872
Epochs  6  batch_size:  64  lr:  0.0002  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  64  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 64, 48, 48)   3136        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 64, 48, 48)   256         initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 64, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 64, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 64, 24, 24)   256         max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 64, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  7680        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 94, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 94, 24, 24)   376         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 94, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  11280       activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 124, 24, 24)  0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 124, 24, 24)  496         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 124, 24, 24)  0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 62, 24, 24)   7688        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 62, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 62, 12, 12)   248         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 62, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  7440        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 92, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 92, 12, 12)   368         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 92, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  11040       activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 122, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 122, 12, 12)  488         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 122, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 17568)        0           activation_11[0][0]              
==================================================================================================
Total params: 182,272
Trainable params: 180,068
Non-trainable params: 2,204
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 17568)        182272      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 35136)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          17990144    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 18,174,977
Trainable params: 18,171,749
Non-trainable params: 3,228
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 96s - loss: 0.5124 - acc: 0.8286 - val_loss: 0.3273 - val_acc: 0.9369

Epoch 00001: val_loss improved from inf to 0.32733, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 2/6
 - 91s - loss: 0.2651 - acc: 0.9511 - val_loss: 0.2077 - val_acc: 0.9775

Epoch 00002: val_loss improved from 0.32733 to 0.20767, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 3/6
 - 91s - loss: 0.1922 - acc: 0.9785 - val_loss: 0.1465 - val_acc: 0.9932

Epoch 00003: val_loss improved from 0.20767 to 0.14653, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 4/6
 - 91s - loss: 0.1579 - acc: 0.9886 - val_loss: 0.1410 - val_acc: 0.9940

Epoch 00004: val_loss improved from 0.14653 to 0.14100, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 5/6
 - 91s - loss: 0.1392 - acc: 0.9924 - val_loss: 0.1212 - val_acc: 0.9966

Epoch 00005: val_loss improved from 0.14100 to 0.12125, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 6/6
 - 91s - loss: 0.1259 - acc: 0.9946 - val_loss: 0.2207 - val_acc: 0.9590

Epoch 00006: val_loss did not improve from 0.12125
Test accuracy:0.594
current auc_score ------------------> 0.928
Epochs  6  batch_size:  64  lr:  0.0002  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  64  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 64, 48, 48)   3136        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 64, 48, 48)   256         initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 64, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 64, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 64, 24, 24)   256         max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 64, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  7680        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 94, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 94, 24, 24)   376         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 94, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  11280       activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 124, 24, 24)  0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 124, 24, 24)  496         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 124, 24, 24)  0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 62, 24, 24)   7688        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 62, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 62, 12, 12)   248         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 62, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  7440        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 92, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 92, 12, 12)   368         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 92, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  11040       activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 122, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 122, 12, 12)  488         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 122, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 17568)        0           activation_11[0][0]              
==================================================================================================
Total params: 182,272
Trainable params: 180,068
Non-trainable params: 2,204
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 17568)        182272      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 35136)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          17990144    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 18,174,977
Trainable params: 18,171,749
Non-trainable params: 3,228
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 93s - loss: 0.5191 - acc: 0.8253 - val_loss: 0.3296 - val_acc: 0.9219

Epoch 00001: val_loss improved from inf to 0.32958, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 2/6
 - 88s - loss: 0.2789 - acc: 0.9427 - val_loss: 0.2012 - val_acc: 0.9792

Epoch 00002: val_loss improved from 0.32958 to 0.20121, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 3/6
 - 89s - loss: 0.2023 - acc: 0.9742 - val_loss: 0.1699 - val_acc: 0.9902

Epoch 00003: val_loss improved from 0.20121 to 0.16991, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 4/6
 - 89s - loss: 0.1612 - acc: 0.9880 - val_loss: 0.1358 - val_acc: 0.9942

Epoch 00004: val_loss improved from 0.16991 to 0.13585, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 5/6
 - 88s - loss: 0.1381 - acc: 0.9935 - val_loss: 0.1191 - val_acc: 0.9972

Epoch 00005: val_loss improved from 0.13585 to 0.11907, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 6/6
 - 89s - loss: 0.1247 - acc: 0.9954 - val_loss: 0.1146 - val_acc: 0.9974

Epoch 00006: val_loss improved from 0.11907 to 0.11460, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Test accuracy:0.670
current auc_score ------------------> 0.887
accuracies:  [0.48870967741935484, 0.5708333333333333, 0.6375, 0.5610215053763441, 0.671505376344086, 0.5633064516129033, 0.6745967741935484, 0.6807795698924731, 0.5940860215053764, 0.6697580645161291]
aucs:  [0.6938, 0.886, 0.8932, 0.897, 0.8586, 0.6446, 0.8601, 0.8722, 0.9281, 0.8873]
mean and std AUC:  0.842+/-0.089  max:   0.9281
Epochs  6  batch_size:  64  lr:  0.0002  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  18  nb_filter:  8  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 8, 48, 48)    392         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 8, 48, 48)    32          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 8, 48, 48)    0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 8, 24, 24)    0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 8, 24, 24)    32          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 8, 24, 24)    0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 72, 24, 24)   576         activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 72, 24, 24)   288         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 72, 24, 24)   0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   11664       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 26, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 26, 24, 24)   104         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 72, 24, 24)   1872        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 72, 24, 24)   288         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 72, 24, 24)   0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   11664       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 44, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 44, 24, 24)   176         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 44, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 22, 24, 24)   968         activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 22, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 22, 12, 12)   88          max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 22, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 72, 12, 12)   1584        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 72, 12, 12)   288         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 72, 12, 12)   0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   11664       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 40, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 40, 12, 12)   160         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 40, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 72, 12, 12)   2880        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 72, 12, 12)   288         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 72, 12, 12)   0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   11664       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 58, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 58, 12, 12)   232         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 58, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 8352)         0           activation_11[0][0]              
==================================================================================================
Total params: 56,904
Trainable params: 55,916
Non-trainable params: 988
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 8352)         56904       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 16704)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          8552960     merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 8,612,425
Trainable params: 8,610,413
Non-trainable params: 2,012
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 50s - loss: 0.5341 - acc: 0.7925 - val_loss: 0.3251 - val_acc: 0.9009

Epoch 00001: val_loss improved from inf to 0.32511, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 2/6
 - 45s - loss: 0.2664 - acc: 0.9217 - val_loss: 0.1862 - val_acc: 0.9647

Epoch 00002: val_loss improved from 0.32511 to 0.18619, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 3/6
 - 46s - loss: 0.1758 - acc: 0.9636 - val_loss: 0.1202 - val_acc: 0.9859

Epoch 00003: val_loss improved from 0.18619 to 0.12020, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 4/6
 - 45s - loss: 0.1329 - acc: 0.9795 - val_loss: 0.1014 - val_acc: 0.9920

Epoch 00004: val_loss improved from 0.12020 to 0.10136, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 5/6
 - 45s - loss: 0.1155 - acc: 0.9847 - val_loss: 0.0890 - val_acc: 0.9926

Epoch 00005: val_loss improved from 0.10136 to 0.08904, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 6/6
 - 46s - loss: 0.0997 - acc: 0.9890 - val_loss: 0.0787 - val_acc: 0.9960

Epoch 00006: val_loss improved from 0.08904 to 0.07872, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Test accuracy:0.707
current auc_score ------------------> 0.893
Epochs  6  batch_size:  64  lr:  0.0002  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  18  nb_filter:  8  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 8, 48, 48)    392         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 8, 48, 48)    32          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 8, 48, 48)    0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 8, 24, 24)    0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 8, 24, 24)    32          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 8, 24, 24)    0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 72, 24, 24)   576         activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 72, 24, 24)   288         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 72, 24, 24)   0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   11664       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 26, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 26, 24, 24)   104         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 72, 24, 24)   1872        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 72, 24, 24)   288         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 72, 24, 24)   0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   11664       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 44, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 44, 24, 24)   176         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 44, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 22, 24, 24)   968         activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 22, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 22, 12, 12)   88          max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 22, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 72, 12, 12)   1584        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 72, 12, 12)   288         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 72, 12, 12)   0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   11664       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 40, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 40, 12, 12)   160         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 40, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 72, 12, 12)   2880        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 72, 12, 12)   288         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 72, 12, 12)   0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   11664       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 58, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 58, 12, 12)   232         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 58, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 8352)         0           activation_11[0][0]              
==================================================================================================
Total params: 56,904
Trainable params: 55,916
Non-trainable params: 988
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 8352)         56904       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 16704)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          8552960     merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 8,612,425
Trainable params: 8,610,413
Non-trainable params: 2,012
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 50s - loss: 0.5151 - acc: 0.8032 - val_loss: 0.2955 - val_acc: 0.9185

Epoch 00001: val_loss improved from inf to 0.29548, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 2/6
 - 46s - loss: 0.2392 - acc: 0.9336 - val_loss: 0.1603 - val_acc: 0.9741

Epoch 00002: val_loss improved from 0.29548 to 0.16031, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 3/6
 - 46s - loss: 0.1566 - acc: 0.9698 - val_loss: 0.1247 - val_acc: 0.9877

Epoch 00003: val_loss improved from 0.16031 to 0.12466, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 4/6
 - 46s - loss: 0.1246 - acc: 0.9821 - val_loss: 0.0983 - val_acc: 0.9922

Epoch 00004: val_loss improved from 0.12466 to 0.09834, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 5/6
 - 46s - loss: 0.1052 - acc: 0.9870 - val_loss: 0.0826 - val_acc: 0.9961

Epoch 00005: val_loss improved from 0.09834 to 0.08261, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 6/6
 - 46s - loss: 0.0920 - acc: 0.9913 - val_loss: 0.0718 - val_acc: 0.9975

Epoch 00006: val_loss improved from 0.08261 to 0.07178, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Test accuracy:0.558
current auc_score ------------------> 0.865
Epochs  6  batch_size:  64  lr:  0.0002  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  18  nb_filter:  8  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 8, 48, 48)    392         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 8, 48, 48)    32          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 8, 48, 48)    0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 8, 24, 24)    0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 8, 24, 24)    32          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 8, 24, 24)    0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 72, 24, 24)   576         activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 72, 24, 24)   288         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 72, 24, 24)   0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   11664       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 26, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 26, 24, 24)   104         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 72, 24, 24)   1872        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 72, 24, 24)   288         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 72, 24, 24)   0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   11664       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 44, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 44, 24, 24)   176         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 44, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 22, 24, 24)   968         activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 22, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 22, 12, 12)   88          max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 22, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 72, 12, 12)   1584        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 72, 12, 12)   288         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 72, 12, 12)   0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   11664       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 40, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 40, 12, 12)   160         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 40, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 72, 12, 12)   2880        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 72, 12, 12)   288         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 72, 12, 12)   0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   11664       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 58, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 58, 12, 12)   232         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 58, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 8352)         0           activation_11[0][0]              
==================================================================================================
Total params: 56,904
Trainable params: 55,916
Non-trainable params: 988
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 8352)         56904       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 16704)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          8552960     merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 8,612,425
Trainable params: 8,610,413
Non-trainable params: 2,012
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 50s - loss: 0.4742 - acc: 0.8199 - val_loss: 0.3228 - val_acc: 0.8971

Epoch 00001: val_loss improved from inf to 0.32280, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 2/6
 - 46s - loss: 0.2433 - acc: 0.9308 - val_loss: 0.1741 - val_acc: 0.9593

Epoch 00002: val_loss improved from 0.32280 to 0.17411, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 3/6
 - 46s - loss: 0.1663 - acc: 0.9670 - val_loss: 0.1226 - val_acc: 0.9861

Epoch 00003: val_loss improved from 0.17411 to 0.12263, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 4/6
 - 46s - loss: 0.1253 - acc: 0.9804 - val_loss: 0.1001 - val_acc: 0.9927

Epoch 00004: val_loss improved from 0.12263 to 0.10007, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 5/6
 - 46s - loss: 0.1027 - acc: 0.9896 - val_loss: 0.0766 - val_acc: 0.9965

Epoch 00005: val_loss improved from 0.10007 to 0.07655, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 6/6
 - 45s - loss: 0.0906 - acc: 0.9921 - val_loss: 0.0787 - val_acc: 0.9967

Epoch 00006: val_loss did not improve from 0.07655
Test accuracy:0.665
current auc_score ------------------> 0.926
Epochs  6  batch_size:  64  lr:  0.0002  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  18  nb_filter:  8  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 8, 48, 48)    392         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 8, 48, 48)    32          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 8, 48, 48)    0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 8, 24, 24)    0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 8, 24, 24)    32          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 8, 24, 24)    0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 72, 24, 24)   576         activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 72, 24, 24)   288         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 72, 24, 24)   0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   11664       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 26, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 26, 24, 24)   104         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 72, 24, 24)   1872        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 72, 24, 24)   288         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 72, 24, 24)   0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   11664       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 44, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 44, 24, 24)   176         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 44, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 22, 24, 24)   968         activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 22, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 22, 12, 12)   88          max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 22, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 72, 12, 12)   1584        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 72, 12, 12)   288         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 72, 12, 12)   0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   11664       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 40, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 40, 12, 12)   160         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 40, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 72, 12, 12)   2880        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 72, 12, 12)   288         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 72, 12, 12)   0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   11664       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 58, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 58, 12, 12)   232         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 58, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 8352)         0           activation_11[0][0]              
==================================================================================================
Total params: 56,904
Trainable params: 55,916
Non-trainable params: 988
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 8352)         56904       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 16704)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          8552960     merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 8,612,425
Trainable params: 8,610,413
Non-trainable params: 2,012
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 49s - loss: 0.5016 - acc: 0.8093 - val_loss: 0.2732 - val_acc: 0.9192

Epoch 00001: val_loss improved from inf to 0.27316, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 2/6
 - 44s - loss: 0.2304 - acc: 0.9394 - val_loss: 0.1635 - val_acc: 0.9758

Epoch 00002: val_loss improved from 0.27316 to 0.16346, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 3/6
 - 45s - loss: 0.1558 - acc: 0.9716 - val_loss: 0.1130 - val_acc: 0.9887

Epoch 00003: val_loss improved from 0.16346 to 0.11298, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 4/6
 - 45s - loss: 0.1223 - acc: 0.9829 - val_loss: 0.0925 - val_acc: 0.9923

Epoch 00004: val_loss improved from 0.11298 to 0.09245, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 5/6
 - 45s - loss: 0.1015 - acc: 0.9890 - val_loss: 0.0866 - val_acc: 0.9957

Epoch 00005: val_loss improved from 0.09245 to 0.08662, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 6/6
 - 45s - loss: 0.0916 - acc: 0.9916 - val_loss: 0.0788 - val_acc: 0.9962

Epoch 00006: val_loss improved from 0.08662 to 0.07881, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Test accuracy:0.664
current auc_score ------------------> 0.844
Epochs  6  batch_size:  64  lr:  0.0002  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  18  nb_filter:  8  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 8, 48, 48)    392         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 8, 48, 48)    32          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 8, 48, 48)    0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 8, 24, 24)    0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 8, 24, 24)    32          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 8, 24, 24)    0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 72, 24, 24)   576         activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 72, 24, 24)   288         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 72, 24, 24)   0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   11664       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 26, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 26, 24, 24)   104         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 72, 24, 24)   1872        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 72, 24, 24)   288         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 72, 24, 24)   0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   11664       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 44, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 44, 24, 24)   176         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 44, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 22, 24, 24)   968         activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 22, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 22, 12, 12)   88          max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 22, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 72, 12, 12)   1584        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 72, 12, 12)   288         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 72, 12, 12)   0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   11664       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 40, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 40, 12, 12)   160         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 40, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 72, 12, 12)   2880        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 72, 12, 12)   288         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 72, 12, 12)   0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   11664       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 58, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 58, 12, 12)   232         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 58, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 8352)         0           activation_11[0][0]              
==================================================================================================
Total params: 56,904
Trainable params: 55,916
Non-trainable params: 988
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 8352)         56904       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 16704)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          8552960     merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 8,612,425
Trainable params: 8,610,413
Non-trainable params: 2,012
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 49s - loss: 0.5237 - acc: 0.7943 - val_loss: 1.3753 - val_acc: 0.5190

Epoch 00001: val_loss improved from inf to 1.37527, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 2/6
 - 45s - loss: 0.2576 - acc: 0.9284 - val_loss: 1.2230 - val_acc: 0.5585

Epoch 00002: val_loss improved from 1.37527 to 1.22297, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 3/6
 - 45s - loss: 0.1660 - acc: 0.9687 - val_loss: 0.7072 - val_acc: 0.7180

Epoch 00003: val_loss improved from 1.22297 to 0.70719, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 4/6
 - 45s - loss: 0.1254 - acc: 0.9826 - val_loss: 0.6322 - val_acc: 0.7628

Epoch 00004: val_loss improved from 0.70719 to 0.63220, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 5/6
 - 45s - loss: 0.1041 - acc: 0.9889 - val_loss: 0.6731 - val_acc: 0.7595

Epoch 00005: val_loss did not improve from 0.63220
Epoch 6/6
 - 45s - loss: 0.0914 - acc: 0.9922 - val_loss: 0.0686 - val_acc: 0.9975

Epoch 00006: val_loss improved from 0.63220 to 0.06857, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Test accuracy:0.661
current auc_score ------------------> 0.872
Epochs  6  batch_size:  64  lr:  0.0002  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  18  nb_filter:  8  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 8, 48, 48)    392         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 8, 48, 48)    32          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 8, 48, 48)    0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 8, 24, 24)    0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 8, 24, 24)    32          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 8, 24, 24)    0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 72, 24, 24)   576         activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 72, 24, 24)   288         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 72, 24, 24)   0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   11664       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 26, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 26, 24, 24)   104         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 72, 24, 24)   1872        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 72, 24, 24)   288         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 72, 24, 24)   0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   11664       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 44, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 44, 24, 24)   176         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 44, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 22, 24, 24)   968         activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 22, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 22, 12, 12)   88          max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 22, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 72, 12, 12)   1584        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 72, 12, 12)   288         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 72, 12, 12)   0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   11664       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 40, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 40, 12, 12)   160         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 40, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 72, 12, 12)   2880        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 72, 12, 12)   288         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 72, 12, 12)   0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   11664       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 58, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 58, 12, 12)   232         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 58, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 8352)         0           activation_11[0][0]              
==================================================================================================
Total params: 56,904
Trainable params: 55,916
Non-trainable params: 988
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 8352)         56904       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 16704)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          8552960     merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 8,612,425
Trainable params: 8,610,413
Non-trainable params: 2,012
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 50s - loss: 0.4799 - acc: 0.8219 - val_loss: 0.2802 - val_acc: 0.9246

Epoch 00001: val_loss improved from inf to 0.28025, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 2/6
 - 45s - loss: 0.2250 - acc: 0.9427 - val_loss: 0.1890 - val_acc: 0.9640

Epoch 00002: val_loss improved from 0.28025 to 0.18896, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 3/6
 - 45s - loss: 0.1487 - acc: 0.9736 - val_loss: 0.1327 - val_acc: 0.9834

Epoch 00003: val_loss improved from 0.18896 to 0.13271, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 4/6
 - 45s - loss: 0.1181 - acc: 0.9843 - val_loss: 0.0944 - val_acc: 0.9935

Epoch 00004: val_loss improved from 0.13271 to 0.09435, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 5/6
 - 45s - loss: 0.0996 - acc: 0.9901 - val_loss: 0.0821 - val_acc: 0.9967

Epoch 00005: val_loss improved from 0.09435 to 0.08210, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 6/6
 - 45s - loss: 0.0892 - acc: 0.9920 - val_loss: 0.0730 - val_acc: 0.9965

Epoch 00006: val_loss improved from 0.08210 to 0.07295, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Test accuracy:0.691
current auc_score ------------------> 0.886
Epochs  6  batch_size:  64  lr:  0.0002  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  18  nb_filter:  8  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 8, 48, 48)    392         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 8, 48, 48)    32          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 8, 48, 48)    0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 8, 24, 24)    0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 8, 24, 24)    32          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 8, 24, 24)    0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 72, 24, 24)   576         activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 72, 24, 24)   288         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 72, 24, 24)   0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   11664       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 26, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 26, 24, 24)   104         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 72, 24, 24)   1872        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 72, 24, 24)   288         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 72, 24, 24)   0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   11664       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 44, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 44, 24, 24)   176         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 44, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 22, 24, 24)   968         activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 22, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 22, 12, 12)   88          max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 22, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 72, 12, 12)   1584        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 72, 12, 12)   288         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 72, 12, 12)   0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   11664       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 40, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 40, 12, 12)   160         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 40, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 72, 12, 12)   2880        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 72, 12, 12)   288         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 72, 12, 12)   0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   11664       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 58, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 58, 12, 12)   232         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 58, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 8352)         0           activation_11[0][0]              
==================================================================================================
Total params: 56,904
Trainable params: 55,916
Non-trainable params: 988
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 8352)         56904       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 16704)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          8552960     merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 8,612,425
Trainable params: 8,610,413
Non-trainable params: 2,012
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 51s - loss: 0.5401 - acc: 0.7874 - val_loss: 0.3535 - val_acc: 0.8870

Epoch 00001: val_loss improved from inf to 0.35355, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 2/6
 - 46s - loss: 0.2697 - acc: 0.9217 - val_loss: 0.2022 - val_acc: 0.9582

Epoch 00002: val_loss improved from 0.35355 to 0.20217, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 3/6
 - 45s - loss: 0.1779 - acc: 0.9631 - val_loss: 0.1441 - val_acc: 0.9821

Epoch 00003: val_loss improved from 0.20217 to 0.14414, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 4/6
 - 46s - loss: 0.1369 - acc: 0.9778 - val_loss: 0.1489 - val_acc: 0.9735

Epoch 00004: val_loss did not improve from 0.14414
Epoch 5/6
 - 46s - loss: 0.1106 - acc: 0.9866 - val_loss: 0.0878 - val_acc: 0.9947

Epoch 00005: val_loss improved from 0.14414 to 0.08775, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 6/6
 - 46s - loss: 0.0964 - acc: 0.9911 - val_loss: 0.0803 - val_acc: 0.9960

Epoch 00006: val_loss improved from 0.08775 to 0.08030, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Test accuracy:0.781
current auc_score ------------------> 0.920
Epochs  6  batch_size:  64  lr:  0.0002  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  18  nb_filter:  8  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 8, 48, 48)    392         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 8, 48, 48)    32          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 8, 48, 48)    0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 8, 24, 24)    0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 8, 24, 24)    32          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 8, 24, 24)    0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 72, 24, 24)   576         activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 72, 24, 24)   288         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 72, 24, 24)   0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   11664       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 26, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 26, 24, 24)   104         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 72, 24, 24)   1872        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 72, 24, 24)   288         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 72, 24, 24)   0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   11664       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 44, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 44, 24, 24)   176         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 44, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 22, 24, 24)   968         activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 22, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 22, 12, 12)   88          max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 22, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 72, 12, 12)   1584        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 72, 12, 12)   288         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 72, 12, 12)   0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   11664       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 40, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 40, 12, 12)   160         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 40, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 72, 12, 12)   2880        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 72, 12, 12)   288         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 72, 12, 12)   0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   11664       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 58, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 58, 12, 12)   232         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 58, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 8352)         0           activation_11[0][0]              
==================================================================================================
Total params: 56,904
Trainable params: 55,916
Non-trainable params: 988
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 8352)         56904       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 16704)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          8552960     merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 8,612,425
Trainable params: 8,610,413
Non-trainable params: 2,012
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 50s - loss: 0.5154 - acc: 0.7984 - val_loss: 0.2968 - val_acc: 0.9155

Epoch 00001: val_loss improved from inf to 0.29676, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 2/6
 - 45s - loss: 0.2536 - acc: 0.9274 - val_loss: 0.1926 - val_acc: 0.9617

Epoch 00002: val_loss improved from 0.29676 to 0.19260, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 3/6
 - 45s - loss: 0.1669 - acc: 0.9663 - val_loss: 0.1206 - val_acc: 0.9829

Epoch 00003: val_loss improved from 0.19260 to 0.12059, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 4/6
 - 45s - loss: 0.1270 - acc: 0.9814 - val_loss: 0.0957 - val_acc: 0.9930

Epoch 00004: val_loss improved from 0.12059 to 0.09570, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 5/6
 - 45s - loss: 0.1028 - acc: 0.9897 - val_loss: 0.0804 - val_acc: 0.9966

Epoch 00005: val_loss improved from 0.09570 to 0.08044, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 6/6
 - 45s - loss: 0.0911 - acc: 0.9923 - val_loss: 0.0778 - val_acc: 0.9959

Epoch 00006: val_loss improved from 0.08044 to 0.07783, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Test accuracy:0.648
current auc_score ------------------> 0.877
Epochs  6  batch_size:  64  lr:  0.0002  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  18  nb_filter:  8  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 8, 48, 48)    392         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 8, 48, 48)    32          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 8, 48, 48)    0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 8, 24, 24)    0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 8, 24, 24)    32          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 8, 24, 24)    0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 72, 24, 24)   576         activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 72, 24, 24)   288         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 72, 24, 24)   0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   11664       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 26, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 26, 24, 24)   104         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 72, 24, 24)   1872        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 72, 24, 24)   288         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 72, 24, 24)   0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   11664       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 44, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 44, 24, 24)   176         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 44, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 22, 24, 24)   968         activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 22, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 22, 12, 12)   88          max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 22, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 72, 12, 12)   1584        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 72, 12, 12)   288         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 72, 12, 12)   0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   11664       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 40, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 40, 12, 12)   160         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 40, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 72, 12, 12)   2880        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 72, 12, 12)   288         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 72, 12, 12)   0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   11664       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 58, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 58, 12, 12)   232         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 58, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 8352)         0           activation_11[0][0]              
==================================================================================================
Total params: 56,904
Trainable params: 55,916
Non-trainable params: 988
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 8352)         56904       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 16704)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          8552960     merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 8,612,425
Trainable params: 8,610,413
Non-trainable params: 2,012
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 50s - loss: 0.4924 - acc: 0.8143 - val_loss: 0.2761 - val_acc: 0.9247

Epoch 00001: val_loss improved from inf to 0.27607, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 2/6
 - 45s - loss: 0.2408 - acc: 0.9344 - val_loss: 0.1789 - val_acc: 0.9655

Epoch 00002: val_loss improved from 0.27607 to 0.17886, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 3/6
 - 45s - loss: 0.1656 - acc: 0.9655 - val_loss: 0.1272 - val_acc: 0.9836

Epoch 00003: val_loss improved from 0.17886 to 0.12716, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 4/6
 - 45s - loss: 0.1238 - acc: 0.9821 - val_loss: 0.1033 - val_acc: 0.9932

Epoch 00004: val_loss improved from 0.12716 to 0.10326, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 5/6
 - 45s - loss: 0.1044 - acc: 0.9886 - val_loss: 0.0869 - val_acc: 0.9936

Epoch 00005: val_loss improved from 0.10326 to 0.08695, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 6/6
 - 45s - loss: 0.0922 - acc: 0.9912 - val_loss: 0.0743 - val_acc: 0.9966

Epoch 00006: val_loss improved from 0.08695 to 0.07432, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Test accuracy:0.658
current auc_score ------------------> 0.876
Epochs  6  batch_size:  64  lr:  0.0002  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  18  nb_filter:  8  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 8, 48, 48)    392         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 8, 48, 48)    32          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 8, 48, 48)    0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 8, 24, 24)    0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 8, 24, 24)    32          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 8, 24, 24)    0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 72, 24, 24)   576         activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 72, 24, 24)   288         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 72, 24, 24)   0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   11664       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 26, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 26, 24, 24)   104         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 72, 24, 24)   1872        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 72, 24, 24)   288         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 72, 24, 24)   0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   11664       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 44, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 44, 24, 24)   176         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 44, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 22, 24, 24)   968         activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 22, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 22, 12, 12)   88          max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 22, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 72, 12, 12)   1584        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 72, 12, 12)   288         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 72, 12, 12)   0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   11664       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 40, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 40, 12, 12)   160         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 40, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 72, 12, 12)   2880        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 72, 12, 12)   288         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 72, 12, 12)   0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   11664       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 58, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 58, 12, 12)   232         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 58, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 8352)         0           activation_11[0][0]              
==================================================================================================
Total params: 56,904
Trainable params: 55,916
Non-trainable params: 988
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 8352)         56904       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 16704)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          8552960     merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 8,612,425
Trainable params: 8,610,413
Non-trainable params: 2,012
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 50s - loss: 0.4684 - acc: 0.8224 - val_loss: 0.2947 - val_acc: 0.9115

Epoch 00001: val_loss improved from inf to 0.29472, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 2/6
 - 46s - loss: 0.2307 - acc: 0.9383 - val_loss: 0.1953 - val_acc: 0.9585

Epoch 00002: val_loss improved from 0.29472 to 0.19525, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 3/6
 - 46s - loss: 0.1617 - acc: 0.9682 - val_loss: 0.1643 - val_acc: 0.9685

Epoch 00003: val_loss improved from 0.19525 to 0.16425, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 4/6
 - 46s - loss: 0.1226 - acc: 0.9819 - val_loss: 0.1143 - val_acc: 0.9857

Epoch 00004: val_loss improved from 0.16425 to 0.11428, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 5/6
 - 45s - loss: 0.1024 - acc: 0.9879 - val_loss: 0.0861 - val_acc: 0.9921

Epoch 00005: val_loss improved from 0.11428 to 0.08611, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 6/6
 - 46s - loss: 0.0912 - acc: 0.9910 - val_loss: 0.0766 - val_acc: 0.9957

Epoch 00006: val_loss improved from 0.08611 to 0.07661, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Test accuracy:0.651
current auc_score ------------------> 0.896
accuracies:  [0.7071236559139785, 0.5577956989247311, 0.6647849462365591, 0.6641129032258064, 0.6614247311827957, 0.6908602150537635, 0.7814516129032258, 0.6477150537634409, 0.6575268817204301, 0.6513440860215054]
aucs:  [0.8932, 0.8649, 0.9265, 0.8441, 0.8719, 0.8858, 0.9198, 0.8773, 0.8762, 0.8962]
mean and std AUC:  0.886+/-0.023  max:   0.9265
Epochs  6  batch_size:  64  lr:  0.0002  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 72, 24, 24)   1152        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 72, 24, 24)   288         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 72, 24, 24)   0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   11664       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 34, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 34, 24, 24)   136         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 34, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 72, 24, 24)   2448        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 72, 24, 24)   288         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 72, 24, 24)   0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   11664       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 52, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 52, 24, 24)   208         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 52, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 26, 24, 24)   1352        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 26, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 26, 12, 12)   104         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 26, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 72, 12, 12)   1872        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 72, 12, 12)   288         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 72, 12, 12)   0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   11664       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 44, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 44, 12, 12)   176         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 44, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 72, 12, 12)   3168        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 72, 12, 12)   288         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 72, 12, 12)   0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   11664       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 62, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 62, 12, 12)   248         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 62, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 8928)         0           activation_11[0][0]              
==================================================================================================
Total params: 59,584
Trainable params: 58,508
Non-trainable params: 1,076
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 8928)         59584       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 17856)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          9142784     merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 9,204,929
Trainable params: 9,202,829
Non-trainable params: 2,100
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 51s - loss: 0.4806 - acc: 0.8161 - val_loss: 1.0286 - val_acc: 0.5628

Epoch 00001: val_loss improved from inf to 1.02864, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 2/6
 - 46s - loss: 0.2368 - acc: 0.9377 - val_loss: 0.7710 - val_acc: 0.5973

Epoch 00002: val_loss improved from 1.02864 to 0.77097, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 3/6
 - 47s - loss: 0.1625 - acc: 0.9694 - val_loss: 0.1246 - val_acc: 0.9844

Epoch 00003: val_loss improved from 0.77097 to 0.12456, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 4/6
 - 47s - loss: 0.1323 - acc: 0.9810 - val_loss: 0.1029 - val_acc: 0.9864

Epoch 00004: val_loss improved from 0.12456 to 0.10295, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 5/6
 - 46s - loss: 0.1059 - acc: 0.9886 - val_loss: 0.0797 - val_acc: 0.9956

Epoch 00005: val_loss improved from 0.10295 to 0.07972, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 6/6
 - 47s - loss: 0.0924 - acc: 0.9920 - val_loss: 0.0743 - val_acc: 0.9971

Epoch 00006: val_loss improved from 0.07972 to 0.07434, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Test accuracy:0.658
current auc_score ------------------> 0.880
Epochs  6  batch_size:  64  lr:  0.0002  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 72, 24, 24)   1152        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 72, 24, 24)   288         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 72, 24, 24)   0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   11664       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 34, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 34, 24, 24)   136         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 34, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 72, 24, 24)   2448        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 72, 24, 24)   288         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 72, 24, 24)   0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   11664       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 52, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 52, 24, 24)   208         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 52, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 26, 24, 24)   1352        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 26, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 26, 12, 12)   104         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 26, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 72, 12, 12)   1872        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 72, 12, 12)   288         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 72, 12, 12)   0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   11664       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 44, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 44, 12, 12)   176         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 44, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 72, 12, 12)   3168        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 72, 12, 12)   288         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 72, 12, 12)   0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   11664       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 62, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 62, 12, 12)   248         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 62, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 8928)         0           activation_11[0][0]              
==================================================================================================
Total params: 59,584
Trainable params: 58,508
Non-trainable params: 1,076
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 8928)         59584       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 17856)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          9142784     merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 9,204,929
Trainable params: 9,202,829
Non-trainable params: 2,100
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 51s - loss: 0.5335 - acc: 0.7943 - val_loss: 2.3632 - val_acc: 0.5067

Epoch 00001: val_loss improved from inf to 2.36322, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 2/6
 - 47s - loss: 0.2705 - acc: 0.9208 - val_loss: 0.2316 - val_acc: 0.9482

Epoch 00002: val_loss improved from 2.36322 to 0.23162, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 3/6
 - 46s - loss: 0.1764 - acc: 0.9642 - val_loss: 0.1268 - val_acc: 0.9874

Epoch 00003: val_loss improved from 0.23162 to 0.12683, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 4/6
 - 46s - loss: 0.1324 - acc: 0.9805 - val_loss: 0.1020 - val_acc: 0.9913

Epoch 00004: val_loss improved from 0.12683 to 0.10203, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 5/6
 - 46s - loss: 0.1078 - acc: 0.9872 - val_loss: 0.1004 - val_acc: 0.9928

Epoch 00005: val_loss improved from 0.10203 to 0.10039, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 6/6
 - 46s - loss: 0.0976 - acc: 0.9912 - val_loss: 0.0824 - val_acc: 0.9959

Epoch 00006: val_loss improved from 0.10039 to 0.08243, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Test accuracy:0.655
current auc_score ------------------> 0.907
Epochs  6  batch_size:  64  lr:  0.0002  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 72, 24, 24)   1152        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 72, 24, 24)   288         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 72, 24, 24)   0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   11664       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 34, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 34, 24, 24)   136         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 34, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 72, 24, 24)   2448        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 72, 24, 24)   288         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 72, 24, 24)   0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   11664       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 52, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 52, 24, 24)   208         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 52, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 26, 24, 24)   1352        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 26, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 26, 12, 12)   104         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 26, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 72, 12, 12)   1872        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 72, 12, 12)   288         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 72, 12, 12)   0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   11664       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 44, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 44, 12, 12)   176         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 44, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 72, 12, 12)   3168        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 72, 12, 12)   288         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 72, 12, 12)   0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   11664       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 62, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 62, 12, 12)   248         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 62, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 8928)         0           activation_11[0][0]              
==================================================================================================
Total params: 59,584
Trainable params: 58,508
Non-trainable params: 1,076
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 8928)         59584       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 17856)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          9142784     merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 9,204,929
Trainable params: 9,202,829
Non-trainable params: 2,100
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 51s - loss: 0.5222 - acc: 0.7973 - val_loss: 0.3360 - val_acc: 0.8907

Epoch 00001: val_loss improved from inf to 0.33596, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 2/6
 - 46s - loss: 0.2605 - acc: 0.9250 - val_loss: 0.1613 - val_acc: 0.9724

Epoch 00002: val_loss improved from 0.33596 to 0.16127, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 3/6
 - 47s - loss: 0.1688 - acc: 0.9675 - val_loss: 0.1278 - val_acc: 0.9826

Epoch 00003: val_loss improved from 0.16127 to 0.12775, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 4/6
 - 46s - loss: 0.1313 - acc: 0.9805 - val_loss: 0.0984 - val_acc: 0.9930

Epoch 00004: val_loss improved from 0.12775 to 0.09837, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 5/6
 - 47s - loss: 0.1108 - acc: 0.9873 - val_loss: 0.0862 - val_acc: 0.9931

Epoch 00005: val_loss improved from 0.09837 to 0.08621, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 6/6
 - 47s - loss: 0.1011 - acc: 0.9894 - val_loss: 0.0813 - val_acc: 0.9955

Epoch 00006: val_loss improved from 0.08621 to 0.08128, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Test accuracy:0.625
current auc_score ------------------> 0.897
Epochs  6  batch_size:  64  lr:  0.0002  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 72, 24, 24)   1152        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 72, 24, 24)   288         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 72, 24, 24)   0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   11664       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 34, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 34, 24, 24)   136         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 34, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 72, 24, 24)   2448        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 72, 24, 24)   288         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 72, 24, 24)   0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   11664       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 52, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 52, 24, 24)   208         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 52, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 26, 24, 24)   1352        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 26, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 26, 12, 12)   104         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 26, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 72, 12, 12)   1872        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 72, 12, 12)   288         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 72, 12, 12)   0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   11664       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 44, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 44, 12, 12)   176         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 44, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 72, 12, 12)   3168        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 72, 12, 12)   288         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 72, 12, 12)   0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   11664       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 62, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 62, 12, 12)   248         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 62, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 8928)         0           activation_11[0][0]              
==================================================================================================
Total params: 59,584
Trainable params: 58,508
Non-trainable params: 1,076
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 8928)         59584       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 17856)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          9142784     merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 9,204,929
Trainable params: 9,202,829
Non-trainable params: 2,100
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 51s - loss: 0.4990 - acc: 0.8117 - val_loss: 0.3478 - val_acc: 0.8790

Epoch 00001: val_loss improved from inf to 0.34776, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 2/6
 - 46s - loss: 0.2418 - acc: 0.9338 - val_loss: 0.1827 - val_acc: 0.9684

Epoch 00002: val_loss improved from 0.34776 to 0.18272, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 3/6
 - 46s - loss: 0.1635 - acc: 0.9693 - val_loss: 0.1171 - val_acc: 0.9905

Epoch 00003: val_loss improved from 0.18272 to 0.11712, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 4/6
 - 46s - loss: 0.1257 - acc: 0.9827 - val_loss: 0.1072 - val_acc: 0.9913

Epoch 00004: val_loss improved from 0.11712 to 0.10720, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 5/6
 - 46s - loss: 0.1072 - acc: 0.9873 - val_loss: 0.0998 - val_acc: 0.9931

Epoch 00005: val_loss improved from 0.10720 to 0.09979, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 6/6
 - 46s - loss: 0.0956 - acc: 0.9900 - val_loss: 0.0797 - val_acc: 0.9962

Epoch 00006: val_loss improved from 0.09979 to 0.07970, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Test accuracy:0.713
current auc_score ------------------> 0.883
Epochs  6  batch_size:  64  lr:  0.0002  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 72, 24, 24)   1152        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 72, 24, 24)   288         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 72, 24, 24)   0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   11664       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 34, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 34, 24, 24)   136         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 34, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 72, 24, 24)   2448        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 72, 24, 24)   288         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 72, 24, 24)   0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   11664       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 52, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 52, 24, 24)   208         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 52, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 26, 24, 24)   1352        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 26, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 26, 12, 12)   104         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 26, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 72, 12, 12)   1872        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 72, 12, 12)   288         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 72, 12, 12)   0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   11664       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 44, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 44, 12, 12)   176         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 44, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 72, 12, 12)   3168        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 72, 12, 12)   288         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 72, 12, 12)   0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   11664       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 62, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 62, 12, 12)   248         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 62, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 8928)         0           activation_11[0][0]              
==================================================================================================
Total params: 59,584
Trainable params: 58,508
Non-trainable params: 1,076
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 8928)         59584       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 17856)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          9142784     merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 9,204,929
Trainable params: 9,202,829
Non-trainable params: 2,100
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 51s - loss: 0.5020 - acc: 0.8127 - val_loss: 0.3254 - val_acc: 0.8986

Epoch 00001: val_loss improved from inf to 0.32545, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 2/6
 - 47s - loss: 0.2390 - acc: 0.9384 - val_loss: 0.1680 - val_acc: 0.9701

Epoch 00002: val_loss improved from 0.32545 to 0.16805, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 3/6
 - 47s - loss: 0.1662 - acc: 0.9680 - val_loss: 0.1294 - val_acc: 0.9822

Epoch 00003: val_loss improved from 0.16805 to 0.12942, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 4/6
 - 47s - loss: 0.1296 - acc: 0.9814 - val_loss: 0.1019 - val_acc: 0.9907

Epoch 00004: val_loss improved from 0.12942 to 0.10195, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 5/6
 - 46s - loss: 0.1064 - acc: 0.9882 - val_loss: 0.0954 - val_acc: 0.9926

Epoch 00005: val_loss improved from 0.10195 to 0.09537, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 6/6
 - 46s - loss: 0.0954 - acc: 0.9919 - val_loss: 0.0762 - val_acc: 0.9974

Epoch 00006: val_loss improved from 0.09537 to 0.07618, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Test accuracy:0.577
current auc_score ------------------> 0.870
Epochs  6  batch_size:  64  lr:  0.0002  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 72, 24, 24)   1152        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 72, 24, 24)   288         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 72, 24, 24)   0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   11664       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 34, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 34, 24, 24)   136         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 34, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 72, 24, 24)   2448        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 72, 24, 24)   288         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 72, 24, 24)   0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   11664       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 52, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 52, 24, 24)   208         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 52, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 26, 24, 24)   1352        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 26, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 26, 12, 12)   104         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 26, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 72, 12, 12)   1872        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 72, 12, 12)   288         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 72, 12, 12)   0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   11664       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 44, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 44, 12, 12)   176         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 44, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 72, 12, 12)   3168        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 72, 12, 12)   288         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 72, 12, 12)   0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   11664       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 62, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 62, 12, 12)   248         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 62, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 8928)         0           activation_11[0][0]              
==================================================================================================
Total params: 59,584
Trainable params: 58,508
Non-trainable params: 1,076
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 8928)         59584       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 17856)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          9142784     merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 9,204,929
Trainable params: 9,202,829
Non-trainable params: 2,100
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 51s - loss: 0.5114 - acc: 0.8020 - val_loss: 0.6626 - val_acc: 0.6957

Epoch 00001: val_loss improved from inf to 0.66257, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 2/6
 - 47s - loss: 0.2611 - acc: 0.9262 - val_loss: 0.7400 - val_acc: 0.6509

Epoch 00002: val_loss did not improve from 0.66257
Epoch 3/6
 - 46s - loss: 0.1726 - acc: 0.9661 - val_loss: 0.6684 - val_acc: 0.7019

Epoch 00003: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.

Epoch 00003: val_loss did not improve from 0.66257
Epoch 4/6
 - 47s - loss: 0.1244 - acc: 0.9848 - val_loss: 0.5635 - val_acc: 0.7617

Epoch 00004: val_loss improved from 0.66257 to 0.56353, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 5/6
 - 47s - loss: 0.1090 - acc: 0.9895 - val_loss: 0.5643 - val_acc: 0.7661

Epoch 00005: val_loss did not improve from 0.56353
Epoch 6/6
 - 47s - loss: 0.0994 - acc: 0.9922 - val_loss: 0.5945 - val_acc: 0.7437

Epoch 00006: ReduceLROnPlateau reducing learning rate to 1.999999851818061e-05.

Epoch 00006: val_loss did not improve from 0.56353
Test accuracy:0.731
current auc_score ------------------> 0.801
Epochs  6  batch_size:  64  lr:  0.0002  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 72, 24, 24)   1152        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 72, 24, 24)   288         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 72, 24, 24)   0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   11664       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 34, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 34, 24, 24)   136         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 34, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 72, 24, 24)   2448        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 72, 24, 24)   288         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 72, 24, 24)   0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   11664       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 52, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 52, 24, 24)   208         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 52, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 26, 24, 24)   1352        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 26, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 26, 12, 12)   104         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 26, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 72, 12, 12)   1872        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 72, 12, 12)   288         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 72, 12, 12)   0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   11664       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 44, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 44, 12, 12)   176         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 44, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 72, 12, 12)   3168        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 72, 12, 12)   288         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 72, 12, 12)   0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   11664       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 62, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 62, 12, 12)   248         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 62, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 8928)         0           activation_11[0][0]              
==================================================================================================
Total params: 59,584
Trainable params: 58,508
Non-trainable params: 1,076
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 8928)         59584       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 17856)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          9142784     merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 9,204,929
Trainable params: 9,202,829
Non-trainable params: 2,100
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 51s - loss: 0.5025 - acc: 0.8095 - val_loss: 0.2908 - val_acc: 0.9163

Epoch 00001: val_loss improved from inf to 0.29075, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 2/6
 - 47s - loss: 0.2536 - acc: 0.9289 - val_loss: 0.1746 - val_acc: 0.9735

Epoch 00002: val_loss improved from 0.29075 to 0.17460, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 3/6
 - 47s - loss: 0.1698 - acc: 0.9659 - val_loss: 0.1347 - val_acc: 0.9868

Epoch 00003: val_loss improved from 0.17460 to 0.13473, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 4/6
 - 47s - loss: 0.1249 - acc: 0.9828 - val_loss: 0.0943 - val_acc: 0.9931

Epoch 00004: val_loss improved from 0.13473 to 0.09435, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 5/6
 - 47s - loss: 0.1083 - acc: 0.9873 - val_loss: 0.0842 - val_acc: 0.9962

Epoch 00005: val_loss improved from 0.09435 to 0.08419, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 6/6
 - 47s - loss: 0.0937 - acc: 0.9920 - val_loss: 0.0770 - val_acc: 0.9971

Epoch 00006: val_loss improved from 0.08419 to 0.07700, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Test accuracy:0.668
current auc_score ------------------> 0.895
Epochs  6  batch_size:  64  lr:  0.0002  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 72, 24, 24)   1152        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 72, 24, 24)   288         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 72, 24, 24)   0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   11664       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 34, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 34, 24, 24)   136         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 34, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 72, 24, 24)   2448        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 72, 24, 24)   288         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 72, 24, 24)   0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   11664       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 52, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 52, 24, 24)   208         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 52, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 26, 24, 24)   1352        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 26, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 26, 12, 12)   104         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 26, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 72, 12, 12)   1872        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 72, 12, 12)   288         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 72, 12, 12)   0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   11664       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 44, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 44, 12, 12)   176         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 44, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 72, 12, 12)   3168        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 72, 12, 12)   288         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 72, 12, 12)   0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   11664       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 62, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 62, 12, 12)   248         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 62, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 8928)         0           activation_11[0][0]              
==================================================================================================
Total params: 59,584
Trainable params: 58,508
Non-trainable params: 1,076
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 8928)         59584       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 17856)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          9142784     merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 9,204,929
Trainable params: 9,202,829
Non-trainable params: 2,100
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 51s - loss: 0.5047 - acc: 0.8066 - val_loss: 0.2912 - val_acc: 0.9196

Epoch 00001: val_loss improved from inf to 0.29119, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 2/6
 - 47s - loss: 0.2611 - acc: 0.9269 - val_loss: 0.1768 - val_acc: 0.9647

Epoch 00002: val_loss improved from 0.29119 to 0.17675, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 3/6
 - 47s - loss: 0.1744 - acc: 0.9653 - val_loss: 0.1227 - val_acc: 0.9866

Epoch 00003: val_loss improved from 0.17675 to 0.12274, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 4/6
 - 47s - loss: 0.1339 - acc: 0.9795 - val_loss: 0.1044 - val_acc: 0.9908

Epoch 00004: val_loss improved from 0.12274 to 0.10439, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 5/6
 - 47s - loss: 0.1084 - acc: 0.9876 - val_loss: 0.0886 - val_acc: 0.9956

Epoch 00005: val_loss improved from 0.10439 to 0.08859, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 6/6
 - 47s - loss: 0.0943 - acc: 0.9914 - val_loss: 0.0784 - val_acc: 0.9966

Epoch 00006: val_loss improved from 0.08859 to 0.07842, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Test accuracy:0.635
current auc_score ------------------> 0.907
Epochs  6  batch_size:  64  lr:  0.0002  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 72, 24, 24)   1152        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 72, 24, 24)   288         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 72, 24, 24)   0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   11664       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 34, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 34, 24, 24)   136         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 34, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 72, 24, 24)   2448        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 72, 24, 24)   288         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 72, 24, 24)   0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   11664       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 52, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 52, 24, 24)   208         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 52, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 26, 24, 24)   1352        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 26, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 26, 12, 12)   104         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 26, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 72, 12, 12)   1872        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 72, 12, 12)   288         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 72, 12, 12)   0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   11664       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 44, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 44, 12, 12)   176         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 44, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 72, 12, 12)   3168        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 72, 12, 12)   288         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 72, 12, 12)   0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   11664       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 62, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 62, 12, 12)   248         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 62, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 8928)         0           activation_11[0][0]              
==================================================================================================
Total params: 59,584
Trainable params: 58,508
Non-trainable params: 1,076
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 8928)         59584       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 17856)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          9142784     merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 9,204,929
Trainable params: 9,202,829
Non-trainable params: 2,100
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 51s - loss: 0.4774 - acc: 0.8215 - val_loss: 0.2685 - val_acc: 0.9298

Epoch 00001: val_loss improved from inf to 0.26852, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 2/6
 - 46s - loss: 0.2392 - acc: 0.9361 - val_loss: 0.1617 - val_acc: 0.9700

Epoch 00002: val_loss improved from 0.26852 to 0.16169, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 3/6
 - 46s - loss: 0.1587 - acc: 0.9710 - val_loss: 0.1091 - val_acc: 0.9907

Epoch 00003: val_loss improved from 0.16169 to 0.10914, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 4/6
 - 47s - loss: 0.1217 - acc: 0.9840 - val_loss: 0.0972 - val_acc: 0.9917

Epoch 00004: val_loss improved from 0.10914 to 0.09717, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 5/6
 - 48s - loss: 0.1014 - acc: 0.9899 - val_loss: 0.0810 - val_acc: 0.9947

Epoch 00005: val_loss improved from 0.09717 to 0.08101, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 6/6
 - 47s - loss: 0.0909 - acc: 0.9918 - val_loss: 0.0730 - val_acc: 0.9974

Epoch 00006: val_loss improved from 0.08101 to 0.07302, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Test accuracy:0.743
current auc_score ------------------> 0.848
Epochs  6  batch_size:  64  lr:  0.0002  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  18  nb_filter:  16  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 72, 24, 24)   1152        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 72, 24, 24)   288         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 72, 24, 24)   0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   11664       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 34, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 34, 24, 24)   136         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 34, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 72, 24, 24)   2448        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 72, 24, 24)   288         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 72, 24, 24)   0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   11664       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 52, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 52, 24, 24)   208         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 52, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 26, 24, 24)   1352        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 26, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 26, 12, 12)   104         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 26, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 72, 12, 12)   1872        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 72, 12, 12)   288         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 72, 12, 12)   0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   11664       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 44, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 44, 12, 12)   176         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 44, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 72, 12, 12)   3168        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 72, 12, 12)   288         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 72, 12, 12)   0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   11664       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 62, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 62, 12, 12)   248         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 62, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 8928)         0           activation_11[0][0]              
==================================================================================================
Total params: 59,584
Trainable params: 58,508
Non-trainable params: 1,076
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 8928)         59584       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 17856)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          9142784     merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 9,204,929
Trainable params: 9,202,829
Non-trainable params: 2,100
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 52s - loss: 0.4663 - acc: 0.8275 - val_loss: 0.3088 - val_acc: 0.9044

Epoch 00001: val_loss improved from inf to 0.30881, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 2/6
 - 47s - loss: 0.2256 - acc: 0.9419 - val_loss: 0.1564 - val_acc: 0.9762

Epoch 00002: val_loss improved from 0.30881 to 0.15638, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 3/6
 - 47s - loss: 0.1566 - acc: 0.9714 - val_loss: 0.1275 - val_acc: 0.9893

Epoch 00003: val_loss improved from 0.15638 to 0.12749, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 4/6
 - 47s - loss: 0.1240 - acc: 0.9827 - val_loss: 0.0951 - val_acc: 0.9954

Epoch 00004: val_loss improved from 0.12749 to 0.09510, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 5/6
 - 47s - loss: 0.1035 - acc: 0.9888 - val_loss: 0.0808 - val_acc: 0.9969

Epoch 00005: val_loss improved from 0.09510 to 0.08081, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 6/6
 - 47s - loss: 0.0904 - acc: 0.9919 - val_loss: 0.0790 - val_acc: 0.9951

Epoch 00006: val_loss improved from 0.08081 to 0.07896, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Test accuracy:0.674
current auc_score ------------------> 0.892
accuracies:  [0.6579301075268817, 0.6545698924731183, 0.6248655913978495, 0.7134408602150538, 0.5772849462365591, 0.7314516129032258, 0.6676075268817204, 0.635483870967742, 0.7432795698924731, 0.6740591397849462]
aucs:  [0.8801, 0.9068, 0.8971, 0.8828, 0.8699, 0.8013, 0.8955, 0.907, 0.8477, 0.8919]
mean and std AUC:  0.878+/-0.031  max:   0.907
Epochs  6  batch_size:  64  lr:  0.0002  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  18  nb_filter:  32  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 32, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 32, 48, 48)   128         initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 32, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 32, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 32, 24, 24)   128         max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 32, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 72, 24, 24)   2304        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 72, 24, 24)   288         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 72, 24, 24)   0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   11664       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 50, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 50, 24, 24)   200         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 50, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 72, 24, 24)   3600        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 72, 24, 24)   288         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 72, 24, 24)   0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   11664       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 68, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 68, 24, 24)   272         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 34, 24, 24)   2312        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 34, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 34, 12, 12)   136         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 34, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 72, 12, 12)   2448        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 72, 12, 12)   288         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 72, 12, 12)   0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   11664       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 52, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 52, 12, 12)   208         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 72, 12, 12)   3744        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 72, 12, 12)   288         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 72, 12, 12)   0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   11664       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 70, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 70, 12, 12)   280         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 70, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 10080)        0           activation_11[0][0]              
==================================================================================================
Total params: 65,136
Trainable params: 63,884
Non-trainable params: 1,252
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 10080)        65136       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 20160)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          10322432    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 10,390,129
Trainable params: 10,387,853
Non-trainable params: 2,276
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 57s - loss: 0.4997 - acc: 0.8100 - val_loss: 0.2825 - val_acc: 0.9278

Epoch 00001: val_loss improved from inf to 0.28252, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 2/6
 - 53s - loss: 0.2471 - acc: 0.9346 - val_loss: 0.1749 - val_acc: 0.9729

Epoch 00002: val_loss improved from 0.28252 to 0.17489, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 3/6
 - 53s - loss: 0.1583 - acc: 0.9726 - val_loss: 0.1268 - val_acc: 0.9876

Epoch 00003: val_loss improved from 0.17489 to 0.12682, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 4/6
 - 53s - loss: 0.1267 - acc: 0.9841 - val_loss: 0.0972 - val_acc: 0.9935

Epoch 00004: val_loss improved from 0.12682 to 0.09723, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 5/6
 - 53s - loss: 0.1044 - acc: 0.9904 - val_loss: 0.0812 - val_acc: 0.9972

Epoch 00005: val_loss improved from 0.09723 to 0.08119, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 6/6
 - 53s - loss: 0.0909 - acc: 0.9941 - val_loss: 0.0755 - val_acc: 0.9984

Epoch 00006: val_loss improved from 0.08119 to 0.07552, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Test accuracy:0.702
current auc_score ------------------> 0.887
Epochs  6  batch_size:  64  lr:  0.0002  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  18  nb_filter:  32  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 32, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 32, 48, 48)   128         initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 32, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 32, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 32, 24, 24)   128         max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 32, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 72, 24, 24)   2304        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 72, 24, 24)   288         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 72, 24, 24)   0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   11664       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 50, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 50, 24, 24)   200         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 50, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 72, 24, 24)   3600        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 72, 24, 24)   288         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 72, 24, 24)   0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   11664       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 68, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 68, 24, 24)   272         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 34, 24, 24)   2312        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 34, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 34, 12, 12)   136         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 34, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 72, 12, 12)   2448        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 72, 12, 12)   288         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 72, 12, 12)   0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   11664       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 52, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 52, 12, 12)   208         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 72, 12, 12)   3744        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 72, 12, 12)   288         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 72, 12, 12)   0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   11664       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 70, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 70, 12, 12)   280         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 70, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 10080)        0           activation_11[0][0]              
==================================================================================================
Total params: 65,136
Trainable params: 63,884
Non-trainable params: 1,252
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 10080)        65136       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 20160)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          10322432    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 10,390,129
Trainable params: 10,387,853
Non-trainable params: 2,276
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 58s - loss: 0.4568 - acc: 0.8357 - val_loss: 0.2582 - val_acc: 0.9404

Epoch 00001: val_loss improved from inf to 0.25822, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 2/6
 - 52s - loss: 0.2262 - acc: 0.9448 - val_loss: 0.1545 - val_acc: 0.9783

Epoch 00002: val_loss improved from 0.25822 to 0.15448, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 3/6
 - 52s - loss: 0.1555 - acc: 0.9737 - val_loss: 0.1139 - val_acc: 0.9893

Epoch 00003: val_loss improved from 0.15448 to 0.11394, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 4/6
 - 52s - loss: 0.1198 - acc: 0.9866 - val_loss: 0.0930 - val_acc: 0.9960

Epoch 00004: val_loss improved from 0.11394 to 0.09297, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 5/6
 - 52s - loss: 0.1040 - acc: 0.9907 - val_loss: 0.0817 - val_acc: 0.9957

Epoch 00005: val_loss improved from 0.09297 to 0.08173, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 6/6
 - 52s - loss: 0.0921 - acc: 0.9931 - val_loss: 0.0768 - val_acc: 0.9967

Epoch 00006: val_loss improved from 0.08173 to 0.07679, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Test accuracy:0.688
current auc_score ------------------> 0.873
Epochs  6  batch_size:  64  lr:  0.0002  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  18  nb_filter:  32  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 32, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 32, 48, 48)   128         initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 32, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 32, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 32, 24, 24)   128         max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 32, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 72, 24, 24)   2304        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 72, 24, 24)   288         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 72, 24, 24)   0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   11664       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 50, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 50, 24, 24)   200         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 50, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 72, 24, 24)   3600        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 72, 24, 24)   288         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 72, 24, 24)   0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   11664       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 68, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 68, 24, 24)   272         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 34, 24, 24)   2312        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 34, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 34, 12, 12)   136         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 34, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 72, 12, 12)   2448        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 72, 12, 12)   288         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 72, 12, 12)   0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   11664       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 52, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 52, 12, 12)   208         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 72, 12, 12)   3744        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 72, 12, 12)   288         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 72, 12, 12)   0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   11664       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 70, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 70, 12, 12)   280         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 70, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 10080)        0           activation_11[0][0]              
==================================================================================================
Total params: 65,136
Trainable params: 63,884
Non-trainable params: 1,252
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 10080)        65136       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 20160)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          10322432    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 10,390,129
Trainable params: 10,387,853
Non-trainable params: 2,276
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 57s - loss: 0.4718 - acc: 0.8237 - val_loss: 0.2732 - val_acc: 0.9272

Epoch 00001: val_loss improved from inf to 0.27317, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 2/6
 - 52s - loss: 0.2320 - acc: 0.9436 - val_loss: 0.1721 - val_acc: 0.9726

Epoch 00002: val_loss improved from 0.27317 to 0.17206, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 3/6
 - 53s - loss: 0.1602 - acc: 0.9728 - val_loss: 0.1200 - val_acc: 0.9885

Epoch 00003: val_loss improved from 0.17206 to 0.12002, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 4/6
 - 52s - loss: 0.1264 - acc: 0.9845 - val_loss: 0.1004 - val_acc: 0.9902

Epoch 00004: val_loss improved from 0.12002 to 0.10037, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 5/6
 - 52s - loss: 0.1046 - acc: 0.9903 - val_loss: 0.0910 - val_acc: 0.9942

Epoch 00005: val_loss improved from 0.10037 to 0.09100, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 6/6
 - 53s - loss: 0.0949 - acc: 0.9922 - val_loss: 0.0787 - val_acc: 0.9971

Epoch 00006: val_loss improved from 0.09100 to 0.07866, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Test accuracy:0.658
current auc_score ------------------> 0.905
Epochs  6  batch_size:  64  lr:  0.0002  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  18  nb_filter:  32  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 32, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 32, 48, 48)   128         initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 32, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 32, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 32, 24, 24)   128         max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 32, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 72, 24, 24)   2304        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 72, 24, 24)   288         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 72, 24, 24)   0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   11664       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 50, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 50, 24, 24)   200         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 50, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 72, 24, 24)   3600        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 72, 24, 24)   288         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 72, 24, 24)   0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   11664       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 68, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 68, 24, 24)   272         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 34, 24, 24)   2312        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 34, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 34, 12, 12)   136         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 34, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 72, 12, 12)   2448        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 72, 12, 12)   288         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 72, 12, 12)   0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   11664       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 52, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 52, 12, 12)   208         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 72, 12, 12)   3744        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 72, 12, 12)   288         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 72, 12, 12)   0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   11664       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 70, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 70, 12, 12)   280         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 70, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 10080)        0           activation_11[0][0]              
==================================================================================================
Total params: 65,136
Trainable params: 63,884
Non-trainable params: 1,252
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 10080)        65136       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 20160)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          10322432    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 10,390,129
Trainable params: 10,387,853
Non-trainable params: 2,276
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 57s - loss: 0.4807 - acc: 0.8193 - val_loss: 0.2675 - val_acc: 0.9335

Epoch 00001: val_loss improved from inf to 0.26751, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 2/6
 - 53s - loss: 0.2311 - acc: 0.9412 - val_loss: 0.1654 - val_acc: 0.9777

Epoch 00002: val_loss improved from 0.26751 to 0.16541, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 3/6
 - 53s - loss: 0.1582 - acc: 0.9723 - val_loss: 0.1165 - val_acc: 0.9887

Epoch 00003: val_loss improved from 0.16541 to 0.11653, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 4/6
 - 53s - loss: 0.1222 - acc: 0.9856 - val_loss: 0.1027 - val_acc: 0.9939

Epoch 00004: val_loss improved from 0.11653 to 0.10266, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 5/6
 - 53s - loss: 0.1033 - acc: 0.9907 - val_loss: 0.0867 - val_acc: 0.9954

Epoch 00005: val_loss improved from 0.10266 to 0.08670, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 6/6
 - 53s - loss: 0.0917 - acc: 0.9939 - val_loss: 0.0761 - val_acc: 0.9984

Epoch 00006: val_loss improved from 0.08670 to 0.07610, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Test accuracy:0.606
current auc_score ------------------> 0.875
Epochs  6  batch_size:  64  lr:  0.0002  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  18  nb_filter:  32  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 32, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 32, 48, 48)   128         initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 32, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 32, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 32, 24, 24)   128         max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 32, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 72, 24, 24)   2304        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 72, 24, 24)   288         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 72, 24, 24)   0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   11664       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 50, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 50, 24, 24)   200         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 50, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 72, 24, 24)   3600        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 72, 24, 24)   288         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 72, 24, 24)   0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   11664       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 68, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 68, 24, 24)   272         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 34, 24, 24)   2312        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 34, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 34, 12, 12)   136         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 34, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 72, 12, 12)   2448        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 72, 12, 12)   288         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 72, 12, 12)   0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   11664       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 52, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 52, 12, 12)   208         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 72, 12, 12)   3744        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 72, 12, 12)   288         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 72, 12, 12)   0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   11664       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 70, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 70, 12, 12)   280         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 70, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 10080)        0           activation_11[0][0]              
==================================================================================================
Total params: 65,136
Trainable params: 63,884
Non-trainable params: 1,252
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 10080)        65136       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 20160)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          10322432    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 10,390,129
Trainable params: 10,387,853
Non-trainable params: 2,276
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 57s - loss: 0.5023 - acc: 0.8094 - val_loss: 0.3125 - val_acc: 0.9086

Epoch 00001: val_loss improved from inf to 0.31254, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 2/6
 - 53s - loss: 0.2564 - acc: 0.9325 - val_loss: 0.1900 - val_acc: 0.9704

Epoch 00002: val_loss improved from 0.31254 to 0.18998, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 3/6
 - 52s - loss: 0.1716 - acc: 0.9695 - val_loss: 0.1307 - val_acc: 0.9900

Epoch 00003: val_loss improved from 0.18998 to 0.13067, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 4/6
 - 52s - loss: 0.1302 - acc: 0.9831 - val_loss: 0.1034 - val_acc: 0.9928

Epoch 00004: val_loss improved from 0.13067 to 0.10341, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 5/6
 - 52s - loss: 0.1103 - acc: 0.9886 - val_loss: 0.0946 - val_acc: 0.9949

Epoch 00005: val_loss improved from 0.10341 to 0.09457, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 6/6
 - 52s - loss: 0.0969 - acc: 0.9919 - val_loss: 0.0784 - val_acc: 0.9972

Epoch 00006: val_loss improved from 0.09457 to 0.07840, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Test accuracy:0.772
current auc_score ------------------> 0.918
Epochs  6  batch_size:  64  lr:  0.0002  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  18  nb_filter:  32  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 32, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 32, 48, 48)   128         initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 32, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 32, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 32, 24, 24)   128         max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 32, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 72, 24, 24)   2304        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 72, 24, 24)   288         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 72, 24, 24)   0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   11664       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 50, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 50, 24, 24)   200         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 50, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 72, 24, 24)   3600        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 72, 24, 24)   288         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 72, 24, 24)   0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   11664       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 68, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 68, 24, 24)   272         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 34, 24, 24)   2312        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 34, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 34, 12, 12)   136         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 34, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 72, 12, 12)   2448        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 72, 12, 12)   288         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 72, 12, 12)   0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   11664       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 52, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 52, 12, 12)   208         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 72, 12, 12)   3744        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 72, 12, 12)   288         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 72, 12, 12)   0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   11664       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 70, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 70, 12, 12)   280         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 70, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 10080)        0           activation_11[0][0]              
==================================================================================================
Total params: 65,136
Trainable params: 63,884
Non-trainable params: 1,252
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 10080)        65136       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 20160)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          10322432    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 10,390,129
Trainable params: 10,387,853
Non-trainable params: 2,276
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 57s - loss: 0.5044 - acc: 0.8073 - val_loss: 0.3031 - val_acc: 0.9094

Epoch 00001: val_loss improved from inf to 0.30308, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 2/6
 - 53s - loss: 0.2559 - acc: 0.9291 - val_loss: 0.1946 - val_acc: 0.9669

Epoch 00002: val_loss improved from 0.30308 to 0.19456, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 3/6
 - 52s - loss: 0.1726 - acc: 0.9681 - val_loss: 0.1230 - val_acc: 0.9848

Epoch 00003: val_loss improved from 0.19456 to 0.12299, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 4/6
 - 52s - loss: 0.1344 - acc: 0.9821 - val_loss: 0.0993 - val_acc: 0.9922

Epoch 00004: val_loss improved from 0.12299 to 0.09929, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 5/6
 - 52s - loss: 0.1131 - acc: 0.9870 - val_loss: 0.0853 - val_acc: 0.9960

Epoch 00005: val_loss improved from 0.09929 to 0.08532, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 6/6
 - 52s - loss: 0.0999 - acc: 0.9913 - val_loss: 0.0822 - val_acc: 0.9957

Epoch 00006: val_loss improved from 0.08532 to 0.08221, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Test accuracy:0.656
current auc_score ------------------> 0.898
Epochs  6  batch_size:  64  lr:  0.0002  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  18  nb_filter:  32  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 32, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 32, 48, 48)   128         initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 32, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 32, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 32, 24, 24)   128         max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 32, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 72, 24, 24)   2304        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 72, 24, 24)   288         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 72, 24, 24)   0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   11664       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 50, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 50, 24, 24)   200         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 50, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 72, 24, 24)   3600        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 72, 24, 24)   288         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 72, 24, 24)   0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   11664       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 68, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 68, 24, 24)   272         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 34, 24, 24)   2312        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 34, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 34, 12, 12)   136         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 34, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 72, 12, 12)   2448        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 72, 12, 12)   288         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 72, 12, 12)   0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   11664       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 52, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 52, 12, 12)   208         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 72, 12, 12)   3744        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 72, 12, 12)   288         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 72, 12, 12)   0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   11664       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 70, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 70, 12, 12)   280         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 70, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 10080)        0           activation_11[0][0]              
==================================================================================================
Total params: 65,136
Trainable params: 63,884
Non-trainable params: 1,252
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 10080)        65136       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 20160)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          10322432    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 10,390,129
Trainable params: 10,387,853
Non-trainable params: 2,276
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 56s - loss: 0.4782 - acc: 0.8211 - val_loss: 0.2661 - val_acc: 0.9272

Epoch 00001: val_loss improved from inf to 0.26615, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 2/6
 - 52s - loss: 0.2325 - acc: 0.9420 - val_loss: 0.1517 - val_acc: 0.9793

Epoch 00002: val_loss improved from 0.26615 to 0.15170, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 3/6
 - 52s - loss: 0.1566 - acc: 0.9746 - val_loss: 0.1170 - val_acc: 0.9905

Epoch 00003: val_loss improved from 0.15170 to 0.11701, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 4/6
 - 52s - loss: 0.1220 - acc: 0.9861 - val_loss: 0.0956 - val_acc: 0.9946

Epoch 00004: val_loss improved from 0.11701 to 0.09562, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 5/6
 - 53s - loss: 0.1079 - acc: 0.9891 - val_loss: 0.0857 - val_acc: 0.9959

Epoch 00005: val_loss improved from 0.09562 to 0.08572, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 6/6
 - 53s - loss: 0.0920 - acc: 0.9933 - val_loss: 0.0742 - val_acc: 0.9971

Epoch 00006: val_loss improved from 0.08572 to 0.07419, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Test accuracy:0.713
current auc_score ------------------> 0.894
Epochs  6  batch_size:  64  lr:  0.0002  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  18  nb_filter:  32  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 32, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 32, 48, 48)   128         initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 32, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 32, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 32, 24, 24)   128         max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 32, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 72, 24, 24)   2304        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 72, 24, 24)   288         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 72, 24, 24)   0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   11664       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 50, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 50, 24, 24)   200         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 50, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 72, 24, 24)   3600        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 72, 24, 24)   288         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 72, 24, 24)   0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   11664       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 68, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 68, 24, 24)   272         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 34, 24, 24)   2312        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 34, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 34, 12, 12)   136         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 34, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 72, 12, 12)   2448        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 72, 12, 12)   288         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 72, 12, 12)   0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   11664       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 52, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 52, 12, 12)   208         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 72, 12, 12)   3744        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 72, 12, 12)   288         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 72, 12, 12)   0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   11664       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 70, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 70, 12, 12)   280         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 70, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 10080)        0           activation_11[0][0]              
==================================================================================================
Total params: 65,136
Trainable params: 63,884
Non-trainable params: 1,252
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 10080)        65136       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 20160)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          10322432    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 10,390,129
Trainable params: 10,387,853
Non-trainable params: 2,276
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 57s - loss: 0.5034 - acc: 0.8082 - val_loss: 0.3851 - val_acc: 0.8424

Epoch 00001: val_loss improved from inf to 0.38510, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 2/6
 - 53s - loss: 0.2444 - acc: 0.9353 - val_loss: 0.1725 - val_acc: 0.9696

Epoch 00002: val_loss improved from 0.38510 to 0.17249, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 3/6
 - 53s - loss: 0.1657 - acc: 0.9708 - val_loss: 0.1207 - val_acc: 0.9876

Epoch 00003: val_loss improved from 0.17249 to 0.12075, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 4/6
 - 53s - loss: 0.1296 - acc: 0.9827 - val_loss: 0.1090 - val_acc: 0.9911

Epoch 00004: val_loss improved from 0.12075 to 0.10902, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 5/6
 - 53s - loss: 0.1093 - acc: 0.9892 - val_loss: 0.0865 - val_acc: 0.9957

Epoch 00005: val_loss improved from 0.10902 to 0.08648, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 6/6
 - 53s - loss: 0.0933 - acc: 0.9928 - val_loss: 0.0772 - val_acc: 0.9966

Epoch 00006: val_loss improved from 0.08648 to 0.07719, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Test accuracy:0.702
current auc_score ------------------> 0.837
Epochs  6  batch_size:  64  lr:  0.0002  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  18  nb_filter:  32  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 32, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 32, 48, 48)   128         initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 32, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 32, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 32, 24, 24)   128         max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 32, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 72, 24, 24)   2304        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 72, 24, 24)   288         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 72, 24, 24)   0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   11664       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 50, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 50, 24, 24)   200         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 50, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 72, 24, 24)   3600        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 72, 24, 24)   288         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 72, 24, 24)   0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   11664       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 68, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 68, 24, 24)   272         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 34, 24, 24)   2312        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 34, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 34, 12, 12)   136         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 34, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 72, 12, 12)   2448        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 72, 12, 12)   288         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 72, 12, 12)   0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   11664       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 52, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 52, 12, 12)   208         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 72, 12, 12)   3744        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 72, 12, 12)   288         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 72, 12, 12)   0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   11664       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 70, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 70, 12, 12)   280         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 70, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 10080)        0           activation_11[0][0]              
==================================================================================================
Total params: 65,136
Trainable params: 63,884
Non-trainable params: 1,252
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 10080)        65136       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 20160)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          10322432    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 10,390,129
Trainable params: 10,387,853
Non-trainable params: 2,276
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 57s - loss: 0.5170 - acc: 0.8020 - val_loss: 0.2987 - val_acc: 0.9115

Epoch 00001: val_loss improved from inf to 0.29869, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 2/6
 - 53s - loss: 0.2434 - acc: 0.9371 - val_loss: 0.1711 - val_acc: 0.9667

Epoch 00002: val_loss improved from 0.29869 to 0.17110, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 3/6
 - 53s - loss: 0.1684 - acc: 0.9695 - val_loss: 0.1249 - val_acc: 0.9891

Epoch 00003: val_loss improved from 0.17110 to 0.12491, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 4/6
 - 53s - loss: 0.1290 - acc: 0.9839 - val_loss: 0.1066 - val_acc: 0.9913

Epoch 00004: val_loss improved from 0.12491 to 0.10661, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 5/6
 - 53s - loss: 0.1084 - acc: 0.9893 - val_loss: 0.0872 - val_acc: 0.9955

Epoch 00005: val_loss improved from 0.10661 to 0.08720, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 6/6
 - 53s - loss: 0.0969 - acc: 0.9921 - val_loss: 0.0806 - val_acc: 0.9966

Epoch 00006: val_loss improved from 0.08720 to 0.08063, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Test accuracy:0.691
current auc_score ------------------> 0.847
Epochs  6  batch_size:  64  lr:  0.0002  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  18  nb_filter:  32  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 32, 48, 48)   1568        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 32, 48, 48)   128         initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 32, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 32, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 32, 24, 24)   128         max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 32, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 72, 24, 24)   2304        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 72, 24, 24)   288         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 72, 24, 24)   0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   11664       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 50, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 50, 24, 24)   200         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 50, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 72, 24, 24)   3600        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 72, 24, 24)   288         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 72, 24, 24)   0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   11664       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 68, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 68, 24, 24)   272         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 68, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 34, 24, 24)   2312        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 34, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 34, 12, 12)   136         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 34, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 72, 12, 12)   2448        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 72, 12, 12)   288         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 72, 12, 12)   0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   11664       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 52, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 52, 12, 12)   208         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 72, 12, 12)   3744        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 72, 12, 12)   288         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 72, 12, 12)   0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   11664       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 70, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 70, 12, 12)   280         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 70, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 10080)        0           activation_11[0][0]              
==================================================================================================
Total params: 65,136
Trainable params: 63,884
Non-trainable params: 1,252
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 10080)        65136       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 20160)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          10322432    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 10,390,129
Trainable params: 10,387,853
Non-trainable params: 2,276
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 58s - loss: 0.4763 - acc: 0.8247 - val_loss: 0.2786 - val_acc: 0.9267

Epoch 00001: val_loss improved from inf to 0.27863, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 2/6
 - 53s - loss: 0.2313 - acc: 0.9443 - val_loss: 0.1800 - val_acc: 0.9743

Epoch 00002: val_loss improved from 0.27863 to 0.18002, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 3/6
 - 53s - loss: 0.1607 - acc: 0.9726 - val_loss: 0.1322 - val_acc: 0.9864

Epoch 00003: val_loss improved from 0.18002 to 0.13221, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 4/6
 - 54s - loss: 0.1263 - acc: 0.9844 - val_loss: 0.1007 - val_acc: 0.9922

Epoch 00004: val_loss improved from 0.13221 to 0.10075, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 5/6
 - 53s - loss: 0.1078 - acc: 0.9890 - val_loss: 0.1024 - val_acc: 0.9916

Epoch 00005: val_loss did not improve from 0.10075
Epoch 6/6
 - 53s - loss: 0.0953 - acc: 0.9923 - val_loss: 0.0765 - val_acc: 0.9979

Epoch 00006: val_loss improved from 0.10075 to 0.07648, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Test accuracy:0.715
current auc_score ------------------> 0.931
Saved model to disk
accuracies:  [0.7020161290322581, 0.6879032258064516, 0.6580645161290323, 0.6059139784946237, 0.771505376344086, 0.6559139784946236, 0.7126344086021505, 0.7018817204301075, 0.6908602150537635, 0.7146505376344086]
aucs:  [0.8866, 0.8732, 0.9053, 0.8753, 0.9184, 0.8985, 0.8937, 0.8371, 0.847, 0.9312]
mean and std AUC:  0.887+/-0.028  max:   0.9312
Epochs  6  batch_size:  64  lr:  0.0002  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  18  nb_filter:  64  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 64, 48, 48)   3136        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 64, 48, 48)   256         initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 64, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 64, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 64, 24, 24)   256         max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 64, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 72, 24, 24)   4608        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 72, 24, 24)   288         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 72, 24, 24)   0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   11664       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 82, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 82, 24, 24)   328         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 82, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 72, 24, 24)   5904        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 72, 24, 24)   288         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 72, 24, 24)   0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   11664       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 100, 24, 24)  0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 100, 24, 24)  400         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 100, 24, 24)  0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 50, 24, 24)   5000        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 50, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 50, 12, 12)   200         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 50, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 72, 12, 12)   3600        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 72, 12, 12)   288         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 72, 12, 12)   0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   11664       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 72, 12, 12)   4896        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 72, 12, 12)   288         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 72, 12, 12)   0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   11664       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 86, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 86, 12, 12)   344         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 86, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 12384)        0           activation_11[0][0]              
==================================================================================================
Total params: 77,008
Trainable params: 75,404
Non-trainable params: 1,604
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 12384)        77008       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 24768)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          12681728    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 12,761,297
Trainable params: 12,758,669
Non-trainable params: 2,628
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 69s - loss: 0.4456 - acc: 0.8431 - val_loss: 0.8108 - val_acc: 0.6504

Epoch 00001: val_loss improved from inf to 0.81082, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 2/6
 - 64s - loss: 0.2187 - acc: 0.9513 - val_loss: 1.1988 - val_acc: 0.5812

Epoch 00002: val_loss did not improve from 0.81082
Epoch 3/6
 - 64s - loss: 0.1520 - acc: 0.9789 - val_loss: 1.6528 - val_acc: 0.5413

Epoch 00003: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.

Epoch 00003: val_loss did not improve from 0.81082
Epoch 4/6
 - 64s - loss: 0.1157 - acc: 0.9919 - val_loss: 2.0025 - val_acc: 0.5257

Epoch 00004: val_loss did not improve from 0.81082
Epoch 5/6
 - 64s - loss: 0.1022 - acc: 0.9953 - val_loss: 0.5337 - val_acc: 0.8171

Epoch 00005: val_loss improved from 0.81082 to 0.53373, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 6/6
 - 64s - loss: 0.0951 - acc: 0.9966 - val_loss: 0.5012 - val_acc: 0.8291

Epoch 00006: val_loss improved from 0.53373 to 0.50117, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Test accuracy:0.753
current auc_score ------------------> 0.828
Epochs  6  batch_size:  64  lr:  0.0002  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  18  nb_filter:  64  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 64, 48, 48)   3136        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 64, 48, 48)   256         initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 64, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 64, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 64, 24, 24)   256         max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 64, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 72, 24, 24)   4608        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 72, 24, 24)   288         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 72, 24, 24)   0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   11664       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 82, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 82, 24, 24)   328         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 82, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 72, 24, 24)   5904        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 72, 24, 24)   288         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 72, 24, 24)   0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   11664       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 100, 24, 24)  0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 100, 24, 24)  400         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 100, 24, 24)  0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 50, 24, 24)   5000        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 50, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 50, 12, 12)   200         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 50, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 72, 12, 12)   3600        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 72, 12, 12)   288         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 72, 12, 12)   0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   11664       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 72, 12, 12)   4896        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 72, 12, 12)   288         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 72, 12, 12)   0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   11664       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 86, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 86, 12, 12)   344         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 86, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 12384)        0           activation_11[0][0]              
==================================================================================================
Total params: 77,008
Trainable params: 75,404
Non-trainable params: 1,604
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 12384)        77008       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 24768)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          12681728    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 12,761,297
Trainable params: 12,758,669
Non-trainable params: 2,628
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 69s - loss: 0.4632 - acc: 0.8378 - val_loss: 1.6097 - val_acc: 0.5277

Epoch 00001: val_loss improved from inf to 1.60967, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 2/6
 - 64s - loss: 0.2257 - acc: 0.9495 - val_loss: 1.9001 - val_acc: 0.5351

Epoch 00002: val_loss did not improve from 1.60967
Epoch 3/6
 - 64s - loss: 0.1559 - acc: 0.9782 - val_loss: 0.1166 - val_acc: 0.9942

Epoch 00003: val_loss improved from 1.60967 to 0.11662, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 4/6
 - 65s - loss: 0.1223 - acc: 0.9883 - val_loss: 0.0958 - val_acc: 0.9972

Epoch 00004: val_loss improved from 0.11662 to 0.09576, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 5/6
 - 64s - loss: 0.1052 - acc: 0.9926 - val_loss: 0.0882 - val_acc: 0.9969

Epoch 00005: val_loss improved from 0.09576 to 0.08823, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 6/6
 - 64s - loss: 0.0931 - acc: 0.9950 - val_loss: 0.0798 - val_acc: 0.9977

Epoch 00006: val_loss improved from 0.08823 to 0.07976, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Test accuracy:0.743
current auc_score ------------------> 0.910
Epochs  6  batch_size:  64  lr:  0.0002  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  18  nb_filter:  64  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 64, 48, 48)   3136        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 64, 48, 48)   256         initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 64, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 64, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 64, 24, 24)   256         max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 64, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 72, 24, 24)   4608        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 72, 24, 24)   288         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 72, 24, 24)   0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   11664       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 82, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 82, 24, 24)   328         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 82, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 72, 24, 24)   5904        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 72, 24, 24)   288         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 72, 24, 24)   0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   11664       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 100, 24, 24)  0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 100, 24, 24)  400         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 100, 24, 24)  0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 50, 24, 24)   5000        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 50, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 50, 12, 12)   200         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 50, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 72, 12, 12)   3600        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 72, 12, 12)   288         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 72, 12, 12)   0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   11664       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 72, 12, 12)   4896        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 72, 12, 12)   288         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 72, 12, 12)   0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   11664       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 86, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 86, 12, 12)   344         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 86, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 12384)        0           activation_11[0][0]              
==================================================================================================
Total params: 77,008
Trainable params: 75,404
Non-trainable params: 1,604
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 12384)        77008       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 24768)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          12681728    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 12,761,297
Trainable params: 12,758,669
Non-trainable params: 2,628
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 69s - loss: 0.4708 - acc: 0.8368 - val_loss: 1.9117 - val_acc: 0.5225

Epoch 00001: val_loss improved from inf to 1.91168, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 2/6
 - 65s - loss: 0.2302 - acc: 0.9477 - val_loss: 1.6647 - val_acc: 0.5764

Epoch 00002: val_loss improved from 1.91168 to 1.66468, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 3/6
 - 65s - loss: 0.1647 - acc: 0.9742 - val_loss: 2.2389 - val_acc: 0.5166

Epoch 00003: val_loss did not improve from 1.66468
Epoch 4/6
 - 64s - loss: 0.1274 - acc: 0.9866 - val_loss: 0.7173 - val_acc: 0.7216

Epoch 00004: val_loss improved from 1.66468 to 0.71725, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 5/6
 - 64s - loss: 0.1075 - acc: 0.9920 - val_loss: 2.8709 - val_acc: 0.5126

Epoch 00005: val_loss did not improve from 0.71725
Epoch 6/6
 - 65s - loss: 0.0964 - acc: 0.9944 - val_loss: 0.5062 - val_acc: 0.8135

Epoch 00006: val_loss improved from 0.71725 to 0.50620, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Test accuracy:0.666
current auc_score ------------------> 0.818
Epochs  6  batch_size:  64  lr:  0.0002  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  18  nb_filter:  64  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 64, 48, 48)   3136        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 64, 48, 48)   256         initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 64, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 64, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 64, 24, 24)   256         max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 64, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 72, 24, 24)   4608        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 72, 24, 24)   288         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 72, 24, 24)   0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   11664       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 82, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 82, 24, 24)   328         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 82, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 72, 24, 24)   5904        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 72, 24, 24)   288         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 72, 24, 24)   0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   11664       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 100, 24, 24)  0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 100, 24, 24)  400         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 100, 24, 24)  0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 50, 24, 24)   5000        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 50, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 50, 12, 12)   200         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 50, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 72, 12, 12)   3600        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 72, 12, 12)   288         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 72, 12, 12)   0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   11664       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 72, 12, 12)   4896        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 72, 12, 12)   288         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 72, 12, 12)   0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   11664       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 86, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 86, 12, 12)   344         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 86, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 12384)        0           activation_11[0][0]              
==================================================================================================
Total params: 77,008
Trainable params: 75,404
Non-trainable params: 1,604
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 12384)        77008       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 24768)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          12681728    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 12,761,297
Trainable params: 12,758,669
Non-trainable params: 2,628
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 70s - loss: 0.4825 - acc: 0.8254 - val_loss: 1.1294 - val_acc: 0.5932

Epoch 00001: val_loss improved from inf to 1.12942, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 2/6
 - 65s - loss: 0.2437 - acc: 0.9419 - val_loss: 0.7859 - val_acc: 0.6643

Epoch 00002: val_loss improved from 1.12942 to 0.78592, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 3/6
 - 65s - loss: 0.1627 - acc: 0.9747 - val_loss: 1.4457 - val_acc: 0.5435

Epoch 00003: val_loss did not improve from 0.78592
Epoch 4/6
 - 65s - loss: 0.1256 - acc: 0.9868 - val_loss: 1.8245 - val_acc: 0.5404

Epoch 00004: ReduceLROnPlateau reducing learning rate to 6.324555160565053e-05.

Epoch 00004: val_loss did not improve from 0.78592
Epoch 5/6
 - 65s - loss: 0.1023 - acc: 0.9944 - val_loss: 1.0811 - val_acc: 0.6461

Epoch 00005: val_loss did not improve from 0.78592
Epoch 6/6
 - 65s - loss: 0.0938 - acc: 0.9963 - val_loss: 1.0083 - val_acc: 0.6728

Epoch 00006: ReduceLROnPlateau reducing learning rate to 1.999999851818061e-05.

Epoch 00006: val_loss did not improve from 0.78592
Test accuracy:0.709
current auc_score ------------------> 0.755
Epochs  6  batch_size:  64  lr:  0.0002  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  18  nb_filter:  64  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 64, 48, 48)   3136        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 64, 48, 48)   256         initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 64, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 64, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 64, 24, 24)   256         max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 64, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 72, 24, 24)   4608        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 72, 24, 24)   288         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 72, 24, 24)   0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   11664       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 82, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 82, 24, 24)   328         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 82, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 72, 24, 24)   5904        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 72, 24, 24)   288         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 72, 24, 24)   0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   11664       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 100, 24, 24)  0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 100, 24, 24)  400         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 100, 24, 24)  0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 50, 24, 24)   5000        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 50, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 50, 12, 12)   200         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 50, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 72, 12, 12)   3600        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 72, 12, 12)   288         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 72, 12, 12)   0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   11664       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 72, 12, 12)   4896        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 72, 12, 12)   288         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 72, 12, 12)   0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   11664       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 86, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 86, 12, 12)   344         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 86, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 12384)        0           activation_11[0][0]              
==================================================================================================
Total params: 77,008
Trainable params: 75,404
Non-trainable params: 1,604
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 12384)        77008       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 24768)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          12681728    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 12,761,297
Trainable params: 12,758,669
Non-trainable params: 2,628
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 69s - loss: 0.4674 - acc: 0.8322 - val_loss: 0.2582 - val_acc: 0.9429

Epoch 00001: val_loss improved from inf to 0.25820, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 2/6
 - 65s - loss: 0.2300 - acc: 0.9495 - val_loss: 0.1674 - val_acc: 0.9807

Epoch 00002: val_loss improved from 0.25820 to 0.16736, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 3/6
 - 64s - loss: 0.1617 - acc: 0.9756 - val_loss: 0.1250 - val_acc: 0.9901

Epoch 00003: val_loss improved from 0.16736 to 0.12496, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 4/6
 - 65s - loss: 0.1275 - acc: 0.9863 - val_loss: 0.1004 - val_acc: 0.9952

Epoch 00004: val_loss improved from 0.12496 to 0.10044, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 5/6
 - 66s - loss: 0.1073 - acc: 0.9923 - val_loss: 0.0898 - val_acc: 0.9966

Epoch 00005: val_loss improved from 0.10044 to 0.08976, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 6/6
 - 65s - loss: 0.0968 - acc: 0.9940 - val_loss: 0.0884 - val_acc: 0.9961

Epoch 00006: val_loss improved from 0.08976 to 0.08844, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Test accuracy:0.683
current auc_score ------------------> 0.874
Epochs  6  batch_size:  64  lr:  0.0002  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  18  nb_filter:  64  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 64, 48, 48)   3136        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 64, 48, 48)   256         initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 64, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 64, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 64, 24, 24)   256         max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 64, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 72, 24, 24)   4608        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 72, 24, 24)   288         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 72, 24, 24)   0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   11664       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 82, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 82, 24, 24)   328         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 82, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 72, 24, 24)   5904        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 72, 24, 24)   288         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 72, 24, 24)   0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   11664       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 100, 24, 24)  0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 100, 24, 24)  400         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 100, 24, 24)  0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 50, 24, 24)   5000        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 50, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 50, 12, 12)   200         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 50, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 72, 12, 12)   3600        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 72, 12, 12)   288         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 72, 12, 12)   0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   11664       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 72, 12, 12)   4896        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 72, 12, 12)   288         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 72, 12, 12)   0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   11664       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 86, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 86, 12, 12)   344         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 86, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 12384)        0           activation_11[0][0]              
==================================================================================================
Total params: 77,008
Trainable params: 75,404
Non-trainable params: 1,604
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 12384)        77008       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 24768)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          12681728    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 12,761,297
Trainable params: 12,758,669
Non-trainable params: 2,628
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 70s - loss: 0.4968 - acc: 0.8160 - val_loss: 0.2845 - val_acc: 0.9262

Epoch 00001: val_loss improved from inf to 0.28446, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 2/6
 - 64s - loss: 0.2528 - acc: 0.9377 - val_loss: 0.1828 - val_acc: 0.9730

Epoch 00002: val_loss improved from 0.28446 to 0.18281, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 3/6
 - 65s - loss: 0.1754 - acc: 0.9709 - val_loss: 0.1694 - val_acc: 0.9813

Epoch 00003: val_loss improved from 0.18281 to 0.16939, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 4/6
 - 65s - loss: 0.1387 - acc: 0.9826 - val_loss: 0.1093 - val_acc: 0.9928

Epoch 00004: val_loss improved from 0.16939 to 0.10932, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 5/6
 - 64s - loss: 0.1122 - acc: 0.9905 - val_loss: 0.1015 - val_acc: 0.9960

Epoch 00005: val_loss improved from 0.10932 to 0.10153, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 6/6
 - 64s - loss: 0.1008 - acc: 0.9936 - val_loss: 0.0837 - val_acc: 0.9974

Epoch 00006: val_loss improved from 0.10153 to 0.08366, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Test accuracy:0.691
current auc_score ------------------> 0.897
Epochs  6  batch_size:  64  lr:  0.0002  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  18  nb_filter:  64  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 64, 48, 48)   3136        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 64, 48, 48)   256         initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 64, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 64, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 64, 24, 24)   256         max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 64, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 72, 24, 24)   4608        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 72, 24, 24)   288         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 72, 24, 24)   0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   11664       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 82, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 82, 24, 24)   328         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 82, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 72, 24, 24)   5904        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 72, 24, 24)   288         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 72, 24, 24)   0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   11664       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 100, 24, 24)  0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 100, 24, 24)  400         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 100, 24, 24)  0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 50, 24, 24)   5000        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 50, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 50, 12, 12)   200         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 50, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 72, 12, 12)   3600        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 72, 12, 12)   288         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 72, 12, 12)   0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   11664       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 72, 12, 12)   4896        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 72, 12, 12)   288         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 72, 12, 12)   0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   11664       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 86, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 86, 12, 12)   344         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 86, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 12384)        0           activation_11[0][0]              
==================================================================================================
Total params: 77,008
Trainable params: 75,404
Non-trainable params: 1,604
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 12384)        77008       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 24768)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          12681728    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 12,761,297
Trainable params: 12,758,669
Non-trainable params: 2,628
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 70s - loss: 0.4941 - acc: 0.8138 - val_loss: 0.2750 - val_acc: 0.9297

Epoch 00001: val_loss improved from inf to 0.27504, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 2/6
 - 64s - loss: 0.2409 - acc: 0.9431 - val_loss: 0.1720 - val_acc: 0.9797

Epoch 00002: val_loss improved from 0.27504 to 0.17204, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 3/6
 - 64s - loss: 0.1632 - acc: 0.9747 - val_loss: 0.1216 - val_acc: 0.9902

Epoch 00003: val_loss improved from 0.17204 to 0.12156, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 4/6
 - 64s - loss: 0.1296 - acc: 0.9865 - val_loss: 0.0978 - val_acc: 0.9952

Epoch 00004: val_loss improved from 0.12156 to 0.09776, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 5/6
 - 64s - loss: 0.1104 - acc: 0.9918 - val_loss: 0.0962 - val_acc: 0.9964

Epoch 00005: val_loss improved from 0.09776 to 0.09624, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 6/6
 - 64s - loss: 0.0959 - acc: 0.9946 - val_loss: 0.0837 - val_acc: 0.9970

Epoch 00006: val_loss improved from 0.09624 to 0.08370, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Test accuracy:0.727
current auc_score ------------------> 0.886
Epochs  6  batch_size:  64  lr:  0.0002  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  18  nb_filter:  64  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 64, 48, 48)   3136        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 64, 48, 48)   256         initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 64, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 64, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 64, 24, 24)   256         max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 64, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 72, 24, 24)   4608        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 72, 24, 24)   288         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 72, 24, 24)   0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   11664       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 82, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 82, 24, 24)   328         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 82, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 72, 24, 24)   5904        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 72, 24, 24)   288         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 72, 24, 24)   0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   11664       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 100, 24, 24)  0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 100, 24, 24)  400         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 100, 24, 24)  0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 50, 24, 24)   5000        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 50, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 50, 12, 12)   200         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 50, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 72, 12, 12)   3600        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 72, 12, 12)   288         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 72, 12, 12)   0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   11664       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 72, 12, 12)   4896        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 72, 12, 12)   288         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 72, 12, 12)   0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   11664       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 86, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 86, 12, 12)   344         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 86, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 12384)        0           activation_11[0][0]              
==================================================================================================
Total params: 77,008
Trainable params: 75,404
Non-trainable params: 1,604
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 12384)        77008       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 24768)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          12681728    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 12,761,297
Trainable params: 12,758,669
Non-trainable params: 2,628
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 68s - loss: 0.4795 - acc: 0.8263 - val_loss: 0.2633 - val_acc: 0.9334

Epoch 00001: val_loss improved from inf to 0.26328, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 2/6
 - 65s - loss: 0.2333 - acc: 0.9455 - val_loss: 0.1663 - val_acc: 0.9764

Epoch 00002: val_loss improved from 0.26328 to 0.16627, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 3/6
 - 64s - loss: 0.1601 - acc: 0.9757 - val_loss: 0.1266 - val_acc: 0.9906

Epoch 00003: val_loss improved from 0.16627 to 0.12662, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 4/6
 - 64s - loss: 0.1303 - acc: 0.9858 - val_loss: 0.0992 - val_acc: 0.9956

Epoch 00004: val_loss improved from 0.12662 to 0.09920, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 5/6
 - 64s - loss: 0.1078 - acc: 0.9919 - val_loss: 0.0882 - val_acc: 0.9966

Epoch 00005: val_loss improved from 0.09920 to 0.08823, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 6/6
 - 64s - loss: 0.0979 - acc: 0.9937 - val_loss: 0.0908 - val_acc: 0.9974

Epoch 00006: val_loss did not improve from 0.08823
Test accuracy:0.598
current auc_score ------------------> 0.875
Epochs  6  batch_size:  64  lr:  0.0002  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  18  nb_filter:  64  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 64, 48, 48)   3136        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 64, 48, 48)   256         initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 64, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 64, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 64, 24, 24)   256         max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 64, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 72, 24, 24)   4608        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 72, 24, 24)   288         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 72, 24, 24)   0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   11664       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 82, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 82, 24, 24)   328         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 82, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 72, 24, 24)   5904        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 72, 24, 24)   288         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 72, 24, 24)   0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   11664       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 100, 24, 24)  0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 100, 24, 24)  400         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 100, 24, 24)  0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 50, 24, 24)   5000        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 50, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 50, 12, 12)   200         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 50, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 72, 12, 12)   3600        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 72, 12, 12)   288         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 72, 12, 12)   0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   11664       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 72, 12, 12)   4896        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 72, 12, 12)   288         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 72, 12, 12)   0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   11664       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 86, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 86, 12, 12)   344         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 86, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 12384)        0           activation_11[0][0]              
==================================================================================================
Total params: 77,008
Trainable params: 75,404
Non-trainable params: 1,604
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 12384)        77008       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 24768)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          12681728    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 12,761,297
Trainable params: 12,758,669
Non-trainable params: 2,628
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 69s - loss: 0.4629 - acc: 0.8346 - val_loss: 0.2822 - val_acc: 0.9229

Epoch 00001: val_loss improved from inf to 0.28216, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 2/6
 - 64s - loss: 0.2316 - acc: 0.9482 - val_loss: 0.1749 - val_acc: 0.9699

Epoch 00002: val_loss improved from 0.28216 to 0.17492, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 3/6
 - 65s - loss: 0.1593 - acc: 0.9769 - val_loss: 0.1179 - val_acc: 0.9906

Epoch 00003: val_loss improved from 0.17492 to 0.11793, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 4/6
 - 65s - loss: 0.1290 - acc: 0.9859 - val_loss: 0.1034 - val_acc: 0.9962

Epoch 00004: val_loss improved from 0.11793 to 0.10343, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 5/6
 - 65s - loss: 0.1072 - acc: 0.9917 - val_loss: 0.0917 - val_acc: 0.9965

Epoch 00005: val_loss improved from 0.10343 to 0.09171, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 6/6
 - 65s - loss: 0.0994 - acc: 0.9934 - val_loss: 0.0861 - val_acc: 0.9974

Epoch 00006: val_loss improved from 0.09171 to 0.08605, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Test accuracy:0.621
current auc_score ------------------> 0.892
Epochs  6  batch_size:  64  lr:  0.0002  optimizer:  adam
 es_patience:  4  lr_patience:  2
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  18  nb_filter:  64  dropout:  0.2
dense_block  2  reduction_:  0.5  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 64, 48, 48)   3136        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 64, 48, 48)   256         initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 64, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 64, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 64, 24, 24)   256         max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 64, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 72, 24, 24)   4608        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 72, 24, 24)   288         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 72, 24, 24)   0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   11664       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 82, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 82, 24, 24)   328         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 82, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 72, 24, 24)   5904        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 72, 24, 24)   288         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 72, 24, 24)   0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   11664       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 100, 24, 24)  0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 100, 24, 24)  400         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 100, 24, 24)  0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 50, 24, 24)   5000        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 50, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 50, 12, 12)   200         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 50, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 72, 12, 12)   3600        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 72, 12, 12)   288         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 72, 12, 12)   0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   11664       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 68, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 68, 12, 12)   272         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 68, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 72, 12, 12)   4896        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 72, 12, 12)   288         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 72, 12, 12)   0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   11664       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 86, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 86, 12, 12)   344         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 86, 12, 12)   0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 12384)        0           activation_11[0][0]              
==================================================================================================
Total params: 77,008
Trainable params: 75,404
Non-trainable params: 1,604
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 12384)        77008       input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 24768)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          12681728    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 12,761,297
Trainable params: 12,758,669
Non-trainable params: 2,628
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/6
 - 69s - loss: 0.4785 - acc: 0.8252 - val_loss: 0.9539 - val_acc: 0.5981

Epoch 00001: val_loss improved from inf to 0.95388, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 2/6
 - 65s - loss: 0.2294 - acc: 0.9475 - val_loss: 0.1758 - val_acc: 0.9780

Epoch 00002: val_loss improved from 0.95388 to 0.17578, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 3/6
 - 65s - loss: 0.1546 - acc: 0.9781 - val_loss: 0.1242 - val_acc: 0.9921

Epoch 00003: val_loss improved from 0.17578 to 0.12418, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 4/6
 - 65s - loss: 0.1233 - acc: 0.9878 - val_loss: 0.1129 - val_acc: 0.9921

Epoch 00004: val_loss improved from 0.12418 to 0.11295, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 5/6
 - 65s - loss: 0.1039 - acc: 0.9930 - val_loss: 0.0968 - val_acc: 0.9962

Epoch 00005: val_loss improved from 0.11295 to 0.09683, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Epoch 6/6
 - 65s - loss: 0.0952 - acc: 0.9946 - val_loss: 0.0854 - val_acc: 0.9981

Epoch 00006: val_loss improved from 0.09683 to 0.08535, saving model to keras_densenet_siamese_27Oct_600_weights.h5
Test accuracy:0.679
current auc_score ------------------> 0.922
accuracies:  [0.7533602150537635, 0.7431451612903226, 0.666263440860215, 0.7091397849462365, 0.6825268817204301, 0.690994623655914, 0.7268817204301076, 0.5983870967741935, 0.6209677419354839, 0.6788978494623656]
aucs:  [0.8281, 0.9101, 0.8183, 0.7553, 0.8741, 0.8968, 0.8862, 0.8753, 0.892, 0.9221]
mean and std AUC:  0.866+/-0.048  max:   0.9221
(['2-2', '30', '2', '8', '0.2', '0.0002', '6', 'adam'], '0.804+/-0.139', 0.927)
(['2-2', '30', '2', '16', '0.2', '0.0002', '6', 'adam'], '0.87+/-0.055', 0.943)
(['2-2', '30', '2', '32', '0.2', '0.0002', '6', 'adam'], '0.852+/-0.087', 0.896)
(['2-2', '30', '2', '64', '0.2', '0.0002', '6', 'adam'], '0.842+/-0.089', 0.928)
(['2-2', '18', '2', '8', '0.2', '0.0002', '6', 'adam'], '0.886+/-0.023', 0.926)
(['2-2', '18', '2', '16', '0.2', '0.0002', '6', 'adam'], '0.878+/-0.031', 0.907)
(['2-2', '18', '2', '32', '0.2', '0.0002', '6', 'adam'], '0.887+/-0.028', 0.931)
(['2-2', '18', '2', '64', '0.2', '0.0002', '6', 'adam'], '0.866+/-0.048', 0.922)
