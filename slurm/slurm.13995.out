python hello-world.py
python hyperas_simple.py
python hyperas_contrastive_loss.py
python densenet_siamese_best_run.py
python hyperas_densenet.py
python hyperas_densenet_siamese.py
python densenet_simple.py
python keras_densenet_siamese.py
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 18, 96, 96)   324         input_1[0][0]                    
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 18, 96, 96)   72          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 18, 96, 96)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 12, 96, 96)   1944        activation_1[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 30, 96, 96)   0           initial_conv2D[0][0]             
                                                                 dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 30, 96, 96)   120         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 30, 96, 96)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 12, 96, 96)   3240        activation_2[0][0]               
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 42, 96, 96)   0           concatenate_1[0][0]              
                                                                 dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 42, 96, 96)   168         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 42, 96, 96)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 12, 96, 96)   4536        activation_3[0][0]               
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 54, 96, 96)   0           concatenate_2[0][0]              
                                                                 dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 54, 96, 96)   216         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 54, 96, 96)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 54, 96, 96)   2916        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 54, 48, 48)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 54, 48, 48)   216         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 54, 48, 48)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 12, 48, 48)   5832        activation_5[0][0]               
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 66, 48, 48)   0           average_pooling2d_1[0][0]        
                                                                 dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 66, 48, 48)   264         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 66, 48, 48)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 12, 48, 48)   7128        activation_6[0][0]               
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 78, 48, 48)   0           concatenate_4[0][0]              
                                                                 dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 78, 48, 48)   312         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 78, 48, 48)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 12, 48, 48)   8424        activation_7[0][0]               
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 90, 48, 48)   0           concatenate_5[0][0]              
                                                                 dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 90, 48, 48)   360         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 90, 48, 48)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 90, 48, 48)   8100        activation_8[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 90, 24, 24)   0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 90, 24, 24)   360         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 90, 24, 24)   0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 12, 24, 24)   9720        activation_9[0][0]               
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 102, 24, 24)  0           average_pooling2d_2[0][0]        
                                                                 dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 102, 24, 24)  408         concatenate_7[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 102, 24, 24)  0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 12, 24, 24)   11016       activation_10[0][0]              
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 114, 24, 24)  0           concatenate_7[0][0]              
                                                                 dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_2_bn (BatchNormalizatio (None, 114, 24, 24)  456         concatenate_8[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 114, 24, 24)  0           dense_2_2_bn[0][0]               
__________________________________________________________________________________________________
dense_2_2_conv2D (Conv2D)       (None, 12, 24, 24)   12312       activation_11[0][0]              
__________________________________________________________________________________________________
concatenate_9 (Concatenate)     (None, 126, 24, 24)  0           concatenate_8[0][0]              
                                                                 dense_2_2_conv2D[0][0]           
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 126, 24, 24)  504         concatenate_9[0][0]              
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 126, 24, 24)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 126)          0           activation_12[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            127         global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 79,075
Trainable params: 77,347
Non-trainable params: 1,728
__________________________________________________________________________________________________
Train on 39840 samples, validate on 7440 samples
Epoch 1/20
 - 34s - loss: 0.6016 - acc: 0.7192 - val_loss: 0.5822 - val_acc: 0.7555
Epoch 2/20
 - 30s - loss: 0.5184 - acc: 0.7677 - val_loss: 0.4805 - val_acc: 0.8203
Epoch 3/20
 - 30s - loss: 0.4896 - acc: 0.7802 - val_loss: 0.4747 - val_acc: 0.8141
Epoch 4/20
 - 30s - loss: 0.4718 - acc: 0.7882 - val_loss: 0.4598 - val_acc: 0.8114
Epoch 5/20
 - 30s - loss: 0.4571 - acc: 0.7962 - val_loss: 0.4576 - val_acc: 0.8272
Epoch 6/20
 - 30s - loss: 0.4458 - acc: 0.8019 - val_loss: 0.4594 - val_acc: 0.8069
Epoch 7/20
 - 30s - loss: 0.4364 - acc: 0.8059 - val_loss: 0.4866 - val_acc: 0.8269
Epoch 8/20
 - 30s - loss: 0.4289 - acc: 0.8108 - val_loss: 0.4499 - val_acc: 0.8235
Epoch 9/20
 - 30s - loss: 0.4189 - acc: 0.8151 - val_loss: 0.4959 - val_acc: 0.8210
Epoch 10/20
 - 30s - loss: 0.4141 - acc: 0.8186 - val_loss: 0.4428 - val_acc: 0.8414
Epoch 11/20
 - 30s - loss: 0.4066 - acc: 0.8226 - val_loss: 0.4961 - val_acc: 0.7839
Epoch 12/20
 - 29s - loss: 0.4000 - acc: 0.8277 - val_loss: 0.4291 - val_acc: 0.8391
Epoch 13/20
 - 30s - loss: 0.3934 - acc: 0.8314 - val_loss: 0.4250 - val_acc: 0.8542
Epoch 14/20
 - 29s - loss: 0.3865 - acc: 0.8345 - val_loss: 0.4237 - val_acc: 0.8454
Epoch 15/20
 - 29s - loss: 0.3833 - acc: 0.8382 - val_loss: 0.4353 - val_acc: 0.8487
Epoch 16/20
 - 29s - loss: 0.3756 - acc: 0.8451 - val_loss: 0.4234 - val_acc: 0.8390
Epoch 17/20
 - 30s - loss: 0.3694 - acc: 0.8477 - val_loss: 0.4168 - val_acc: 0.8618
Epoch 18/20
 - 30s - loss: 0.3660 - acc: 0.8497 - val_loss: 0.4258 - val_acc: 0.8487
Epoch 19/20
 - 29s - loss: 0.3605 - acc: 0.8522 - val_loss: 0.4116 - val_acc: 0.8321
Epoch 20/20
 - 29s - loss: 0.3561 - acc: 0.8558 - val_loss: 0.4110 - val_acc: 0.8335

  32/7440 [..............................] - ETA: 2s
 224/7440 [..............................] - ETA: 1s
 448/7440 [>.............................] - ETA: 1s
 672/7440 [=>............................] - ETA: 1s
 896/7440 [==>...........................] - ETA: 1s
1120/7440 [===>..........................] - ETA: 1s
1344/7440 [====>.........................] - ETA: 1s
1568/7440 [=====>........................] - ETA: 1s
1792/7440 [======>.......................] - ETA: 1s
2016/7440 [=======>......................] - ETA: 1s
2240/7440 [========>.....................] - ETA: 1s
2432/7440 [========>.....................] - ETA: 1s
2624/7440 [=========>....................] - ETA: 1s
2848/7440 [==========>...................] - ETA: 1s
3072/7440 [===========>..................] - ETA: 1s
3296/7440 [============>.................] - ETA: 1s
3520/7440 [=============>................] - ETA: 1s
3744/7440 [==============>...............] - ETA: 0s
3968/7440 [===============>..............] - ETA: 0s
4192/7440 [===============>..............] - ETA: 0s
4416/7440 [================>.............] - ETA: 0s
4640/7440 [=================>............] - ETA: 0s
4864/7440 [==================>...........] - ETA: 0s
5088/7440 [===================>..........] - ETA: 0s
5312/7440 [====================>.........] - ETA: 0s
5536/7440 [=====================>........] - ETA: 0s
5760/7440 [======================>.......] - ETA: 0s
5952/7440 [=======================>......] - ETA: 0s
6176/7440 [=======================>......] - ETA: 0s
6400/7440 [========================>.....] - ETA: 0s
6624/7440 [=========================>....] - ETA: 0s
6816/7440 [==========================>...] - ETA: 0s
7008/7440 [===========================>..] - ETA: 0s
7232/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 2s 258us/step
Test accuracy: 0.8334677419354839
Test accuracy 0.6: 0.8436827956989247
auc_score ------------------>  0.9127220632443057
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 18, 96, 96)   324         input_2[0][0]                    
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 18, 96, 96)   72          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 18, 96, 96)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 12, 96, 96)   1944        activation_13[0][0]              
__________________________________________________________________________________________________
concatenate_10 (Concatenate)    (None, 30, 96, 96)   0           initial_conv2D[0][0]             
                                                                 dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 30, 96, 96)   120         concatenate_10[0][0]             
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 30, 96, 96)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 12, 96, 96)   3240        activation_14[0][0]              
__________________________________________________________________________________________________
concatenate_11 (Concatenate)    (None, 42, 96, 96)   0           concatenate_10[0][0]             
                                                                 dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 42, 96, 96)   168         concatenate_11[0][0]             
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 42, 96, 96)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 12, 96, 96)   4536        activation_15[0][0]              
__________________________________________________________________________________________________
concatenate_12 (Concatenate)    (None, 54, 96, 96)   0           concatenate_11[0][0]             
                                                                 dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 54, 96, 96)   216         concatenate_12[0][0]             
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 54, 96, 96)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 54, 96, 96)   2916        activation_16[0][0]              
__________________________________________________________________________________________________
average_pooling2d_3 (AveragePoo (None, 54, 48, 48)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 54, 48, 48)   216         average_pooling2d_3[0][0]        
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 54, 48, 48)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 12, 48, 48)   5832        activation_17[0][0]              
__________________________________________________________________________________________________
concatenate_13 (Concatenate)    (None, 66, 48, 48)   0           average_pooling2d_3[0][0]        
                                                                 dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 66, 48, 48)   264         concatenate_13[0][0]             
__________________________________________________________________________________________________
activation_18 (Activation)      (None, 66, 48, 48)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 12, 48, 48)   7128        activation_18[0][0]              
__________________________________________________________________________________________________
concatenate_14 (Concatenate)    (None, 78, 48, 48)   0           concatenate_13[0][0]             
                                                                 dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 78, 48, 48)   312         concatenate_14[0][0]             
__________________________________________________________________________________________________
activation_19 (Activation)      (None, 78, 48, 48)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 12, 48, 48)   8424        activation_19[0][0]              
__________________________________________________________________________________________________
concatenate_15 (Concatenate)    (None, 90, 48, 48)   0           concatenate_14[0][0]             
                                                                 dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 90, 48, 48)   360         concatenate_15[0][0]             
__________________________________________________________________________________________________
activation_20 (Activation)      (None, 90, 48, 48)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 90, 48, 48)   8100        activation_20[0][0]              
__________________________________________________________________________________________________
average_pooling2d_4 (AveragePoo (None, 90, 24, 24)   0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 90, 24, 24)   360         average_pooling2d_4[0][0]        
__________________________________________________________________________________________________
activation_21 (Activation)      (None, 90, 24, 24)   0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 12, 24, 24)   9720        activation_21[0][0]              
__________________________________________________________________________________________________
concatenate_16 (Concatenate)    (None, 102, 24, 24)  0           average_pooling2d_4[0][0]        
                                                                 dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 102, 24, 24)  408         concatenate_16[0][0]             
__________________________________________________________________________________________________
activation_22 (Activation)      (None, 102, 24, 24)  0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 12, 24, 24)   11016       activation_22[0][0]              
__________________________________________________________________________________________________
concatenate_17 (Concatenate)    (None, 114, 24, 24)  0           concatenate_16[0][0]             
                                                                 dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_2_bn (BatchNormalizatio (None, 114, 24, 24)  456         concatenate_17[0][0]             
__________________________________________________________________________________________________
activation_23 (Activation)      (None, 114, 24, 24)  0           dense_2_2_bn[0][0]               
__________________________________________________________________________________________________
dense_2_2_conv2D (Conv2D)       (None, 12, 24, 24)   12312       activation_23[0][0]              
__________________________________________________________________________________________________
concatenate_18 (Concatenate)    (None, 126, 24, 24)  0           concatenate_17[0][0]             
                                                                 dense_2_2_conv2D[0][0]           
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 126, 24, 24)  504         concatenate_18[0][0]             
__________________________________________________________________________________________________
activation_24 (Activation)      (None, 126, 24, 24)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_2 (Glo (None, 126)          0           activation_24[0][0]              
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            127         global_average_pooling2d_2[0][0] 
==================================================================================================
Total params: 79,075
Trainable params: 77,347
Non-trainable params: 1,728
__________________________________________________________________________________________________
Train on 39840 samples, validate on 7440 samples
Epoch 1/20
 - 31s - loss: 0.6055 - acc: 0.7194 - val_loss: 0.5114 - val_acc: 0.8450
Epoch 2/20
 - 29s - loss: 0.5297 - acc: 0.7637 - val_loss: 0.4801 - val_acc: 0.8138
Epoch 3/20
 - 29s - loss: 0.4992 - acc: 0.7747 - val_loss: 0.4889 - val_acc: 0.8056
Epoch 4/20
 - 29s - loss: 0.4817 - acc: 0.7816 - val_loss: 0.4742 - val_acc: 0.8204
Epoch 5/20
 - 29s - loss: 0.4670 - acc: 0.7906 - val_loss: 0.4516 - val_acc: 0.8136
Epoch 6/20
 - 29s - loss: 0.4541 - acc: 0.7964 - val_loss: 0.4664 - val_acc: 0.8206
Epoch 00006: early stopping

  32/7440 [..............................] - ETA: 2s
 224/7440 [..............................] - ETA: 2s
 416/7440 [>.............................] - ETA: 1s
 608/7440 [=>............................] - ETA: 1s
 800/7440 [==>...........................] - ETA: 1s
 992/7440 [===>..........................] - ETA: 1s
1184/7440 [===>..........................] - ETA: 1s
1376/7440 [====>.........................] - ETA: 1s
1568/7440 [=====>........................] - ETA: 1s
1760/7440 [======>.......................] - ETA: 1s
1952/7440 [======>.......................] - ETA: 1s
2144/7440 [=======>......................] - ETA: 1s
2336/7440 [========>.....................] - ETA: 1s
2528/7440 [=========>....................] - ETA: 1s
2720/7440 [=========>....................] - ETA: 1s
2912/7440 [==========>...................] - ETA: 1s
3104/7440 [===========>..................] - ETA: 1s
3296/7440 [============>.................] - ETA: 1s
3488/7440 [=============>................] - ETA: 1s
3680/7440 [=============>................] - ETA: 1s
3872/7440 [==============>...............] - ETA: 0s
4064/7440 [===============>..............] - ETA: 0s
4256/7440 [================>.............] - ETA: 0s
4448/7440 [================>.............] - ETA: 0s
4640/7440 [=================>............] - ETA: 0s
4832/7440 [==================>...........] - ETA: 0s
5024/7440 [===================>..........] - ETA: 0s
5216/7440 [====================>.........] - ETA: 0s
5408/7440 [====================>.........] - ETA: 0s
5600/7440 [=====================>........] - ETA: 0s
5792/7440 [======================>.......] - ETA: 0s
5984/7440 [=======================>......] - ETA: 0s
6176/7440 [=======================>......] - ETA: 0s
6368/7440 [========================>.....] - ETA: 0s
6560/7440 [=========================>....] - ETA: 0s
6752/7440 [==========================>...] - ETA: 0s
6944/7440 [===========================>..] - ETA: 0s
7136/7440 [===========================>..] - ETA: 0s
7328/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 2s 278us/step
Test accuracy: 0.8205645161290323
Test accuracy 0.6: 0.8190860215053763
auc_score ------------------>  0.8790019438663429
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_3 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 18, 96, 96)   324         input_3[0][0]                    
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 18, 96, 96)   72          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_25 (Activation)      (None, 18, 96, 96)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 12, 96, 96)   1944        activation_25[0][0]              
__________________________________________________________________________________________________
concatenate_19 (Concatenate)    (None, 30, 96, 96)   0           initial_conv2D[0][0]             
                                                                 dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 30, 96, 96)   120         concatenate_19[0][0]             
__________________________________________________________________________________________________
activation_26 (Activation)      (None, 30, 96, 96)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 12, 96, 96)   3240        activation_26[0][0]              
__________________________________________________________________________________________________
concatenate_20 (Concatenate)    (None, 42, 96, 96)   0           concatenate_19[0][0]             
                                                                 dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 42, 96, 96)   168         concatenate_20[0][0]             
__________________________________________________________________________________________________
activation_27 (Activation)      (None, 42, 96, 96)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 12, 96, 96)   4536        activation_27[0][0]              
__________________________________________________________________________________________________
concatenate_21 (Concatenate)    (None, 54, 96, 96)   0           concatenate_20[0][0]             
                                                                 dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 54, 96, 96)   216         concatenate_21[0][0]             
__________________________________________________________________________________________________
activation_28 (Activation)      (None, 54, 96, 96)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 54, 96, 96)   2916        activation_28[0][0]              
__________________________________________________________________________________________________
average_pooling2d_5 (AveragePoo (None, 54, 48, 48)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 54, 48, 48)   216         average_pooling2d_5[0][0]        
__________________________________________________________________________________________________
activation_29 (Activation)      (None, 54, 48, 48)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 12, 48, 48)   5832        activation_29[0][0]              
__________________________________________________________________________________________________
concatenate_22 (Concatenate)    (None, 66, 48, 48)   0           average_pooling2d_5[0][0]        
                                                                 dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 66, 48, 48)   264         concatenate_22[0][0]             
__________________________________________________________________________________________________
activation_30 (Activation)      (None, 66, 48, 48)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 12, 48, 48)   7128        activation_30[0][0]              
__________________________________________________________________________________________________
concatenate_23 (Concatenate)    (None, 78, 48, 48)   0           concatenate_22[0][0]             
                                                                 dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 78, 48, 48)   312         concatenate_23[0][0]             
__________________________________________________________________________________________________
activation_31 (Activation)      (None, 78, 48, 48)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 12, 48, 48)   8424        activation_31[0][0]              
__________________________________________________________________________________________________
concatenate_24 (Concatenate)    (None, 90, 48, 48)   0           concatenate_23[0][0]             
                                                                 dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 90, 48, 48)   360         concatenate_24[0][0]             
__________________________________________________________________________________________________
activation_32 (Activation)      (None, 90, 48, 48)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 90, 48, 48)   8100        activation_32[0][0]              
__________________________________________________________________________________________________
average_pooling2d_6 (AveragePoo (None, 90, 24, 24)   0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 90, 24, 24)   360         average_pooling2d_6[0][0]        
__________________________________________________________________________________________________
activation_33 (Activation)      (None, 90, 24, 24)   0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 12, 24, 24)   9720        activation_33[0][0]              
__________________________________________________________________________________________________
concatenate_25 (Concatenate)    (None, 102, 24, 24)  0           average_pooling2d_6[0][0]        
                                                                 dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 102, 24, 24)  408         concatenate_25[0][0]             
__________________________________________________________________________________________________
activation_34 (Activation)      (None, 102, 24, 24)  0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 12, 24, 24)   11016       activation_34[0][0]              
__________________________________________________________________________________________________
concatenate_26 (Concatenate)    (None, 114, 24, 24)  0           concatenate_25[0][0]             
                                                                 dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_2_bn (BatchNormalizatio (None, 114, 24, 24)  456         concatenate_26[0][0]             
__________________________________________________________________________________________________
activation_35 (Activation)      (None, 114, 24, 24)  0           dense_2_2_bn[0][0]               
__________________________________________________________________________________________________
dense_2_2_conv2D (Conv2D)       (None, 12, 24, 24)   12312       activation_35[0][0]              
__________________________________________________________________________________________________
concatenate_27 (Concatenate)    (None, 126, 24, 24)  0           concatenate_26[0][0]             
                                                                 dense_2_2_conv2D[0][0]           
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 126, 24, 24)  504         concatenate_27[0][0]             
__________________________________________________________________________________________________
activation_36 (Activation)      (None, 126, 24, 24)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_3 (Glo (None, 126)          0           activation_36[0][0]              
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 1)            127         global_average_pooling2d_3[0][0] 
==================================================================================================
Total params: 79,075
Trainable params: 77,347
Non-trainable params: 1,728
__________________________________________________________________________________________________
Train on 39840 samples, validate on 7440 samples
Epoch 1/20
 - 32s - loss: 0.6103 - acc: 0.7035 - val_loss: 0.5171 - val_acc: 0.8282
Epoch 2/20
 - 30s - loss: 0.5316 - acc: 0.7602 - val_loss: 0.4989 - val_acc: 0.8124
Epoch 3/20
 - 30s - loss: 0.5032 - acc: 0.7737 - val_loss: 0.4771 - val_acc: 0.8112
Epoch 4/20
 - 30s - loss: 0.4858 - acc: 0.7828 - val_loss: 0.4833 - val_acc: 0.7902
Epoch 5/20
 - 30s - loss: 0.4703 - acc: 0.7905 - val_loss: 0.4427 - val_acc: 0.8254
Epoch 6/20
 - 30s - loss: 0.4580 - acc: 0.7965 - val_loss: 0.4392 - val_acc: 0.8212
Epoch 00006: early stopping

  32/7440 [..............................] - ETA: 2s
 224/7440 [..............................] - ETA: 2s
 416/7440 [>.............................] - ETA: 1s
 608/7440 [=>............................] - ETA: 1s
 800/7440 [==>...........................] - ETA: 1s
 992/7440 [===>..........................] - ETA: 1s
1184/7440 [===>..........................] - ETA: 1s
1376/7440 [====>.........................] - ETA: 1s
1568/7440 [=====>........................] - ETA: 1s
1760/7440 [======>.......................] - ETA: 1s
1952/7440 [======>.......................] - ETA: 1s
2144/7440 [=======>......................] - ETA: 1s
2336/7440 [========>.....................] - ETA: 1s
2528/7440 [=========>....................] - ETA: 1s
2720/7440 [=========>....................] - ETA: 1s
2912/7440 [==========>...................] - ETA: 1s
3104/7440 [===========>..................] - ETA: 1s
3296/7440 [============>.................] - ETA: 1s
3488/7440 [=============>................] - ETA: 1s
3680/7440 [=============>................] - ETA: 1s
3872/7440 [==============>...............] - ETA: 0s
4064/7440 [===============>..............] - ETA: 0s
4256/7440 [================>.............] - ETA: 0s
4448/7440 [================>.............] - ETA: 0s
4640/7440 [=================>............] - ETA: 0s
4832/7440 [==================>...........] - ETA: 0s
5024/7440 [===================>..........] - ETA: 0s
5216/7440 [====================>.........] - ETA: 0s
5408/7440 [====================>.........] - ETA: 0s
5600/7440 [=====================>........] - ETA: 0s
5792/7440 [======================>.......] - ETA: 0s
5984/7440 [=======================>......] - ETA: 0s
6176/7440 [=======================>......] - ETA: 0s
6368/7440 [========================>.....] - ETA: 0s
6560/7440 [=========================>....] - ETA: 0s
6752/7440 [==========================>...] - ETA: 0s
6944/7440 [===========================>..] - ETA: 0s
7136/7440 [===========================>..] - ETA: 0s
7328/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 2s 276us/step
Test accuracy: 0.821236559139785
Test accuracy 0.6: 0.8102150537634408
auc_score ------------------>  0.8973176089721355
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_4 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 18, 96, 96)   324         input_4[0][0]                    
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 18, 96, 96)   72          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_37 (Activation)      (None, 18, 96, 96)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 12, 96, 96)   1944        activation_37[0][0]              
__________________________________________________________________________________________________
concatenate_28 (Concatenate)    (None, 30, 96, 96)   0           initial_conv2D[0][0]             
                                                                 dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 30, 96, 96)   120         concatenate_28[0][0]             
__________________________________________________________________________________________________
activation_38 (Activation)      (None, 30, 96, 96)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 12, 96, 96)   3240        activation_38[0][0]              
__________________________________________________________________________________________________
concatenate_29 (Concatenate)    (None, 42, 96, 96)   0           concatenate_28[0][0]             
                                                                 dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 42, 96, 96)   168         concatenate_29[0][0]             
__________________________________________________________________________________________________
activation_39 (Activation)      (None, 42, 96, 96)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 12, 96, 96)   4536        activation_39[0][0]              
__________________________________________________________________________________________________
concatenate_30 (Concatenate)    (None, 54, 96, 96)   0           concatenate_29[0][0]             
                                                                 dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 54, 96, 96)   216         concatenate_30[0][0]             
__________________________________________________________________________________________________
activation_40 (Activation)      (None, 54, 96, 96)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 54, 96, 96)   2916        activation_40[0][0]              
__________________________________________________________________________________________________
average_pooling2d_7 (AveragePoo (None, 54, 48, 48)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 54, 48, 48)   216         average_pooling2d_7[0][0]        
__________________________________________________________________________________________________
activation_41 (Activation)      (None, 54, 48, 48)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 12, 48, 48)   5832        activation_41[0][0]              
__________________________________________________________________________________________________
concatenate_31 (Concatenate)    (None, 66, 48, 48)   0           average_pooling2d_7[0][0]        
                                                                 dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 66, 48, 48)   264         concatenate_31[0][0]             
__________________________________________________________________________________________________
activation_42 (Activation)      (None, 66, 48, 48)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 12, 48, 48)   7128        activation_42[0][0]              
__________________________________________________________________________________________________
concatenate_32 (Concatenate)    (None, 78, 48, 48)   0           concatenate_31[0][0]             
                                                                 dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 78, 48, 48)   312         concatenate_32[0][0]             
__________________________________________________________________________________________________
activation_43 (Activation)      (None, 78, 48, 48)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 12, 48, 48)   8424        activation_43[0][0]              
__________________________________________________________________________________________________
concatenate_33 (Concatenate)    (None, 90, 48, 48)   0           concatenate_32[0][0]             
                                                                 dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 90, 48, 48)   360         concatenate_33[0][0]             
__________________________________________________________________________________________________
activation_44 (Activation)      (None, 90, 48, 48)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 90, 48, 48)   8100        activation_44[0][0]              
__________________________________________________________________________________________________
average_pooling2d_8 (AveragePoo (None, 90, 24, 24)   0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 90, 24, 24)   360         average_pooling2d_8[0][0]        
__________________________________________________________________________________________________
activation_45 (Activation)      (None, 90, 24, 24)   0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 12, 24, 24)   9720        activation_45[0][0]              
__________________________________________________________________________________________________
concatenate_34 (Concatenate)    (None, 102, 24, 24)  0           average_pooling2d_8[0][0]        
                                                                 dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 102, 24, 24)  408         concatenate_34[0][0]             
__________________________________________________________________________________________________
activation_46 (Activation)      (None, 102, 24, 24)  0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 12, 24, 24)   11016       activation_46[0][0]              
__________________________________________________________________________________________________
concatenate_35 (Concatenate)    (None, 114, 24, 24)  0           concatenate_34[0][0]             
                                                                 dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_2_bn (BatchNormalizatio (None, 114, 24, 24)  456         concatenate_35[0][0]             
__________________________________________________________________________________________________
activation_47 (Activation)      (None, 114, 24, 24)  0           dense_2_2_bn[0][0]               
__________________________________________________________________________________________________
dense_2_2_conv2D (Conv2D)       (None, 12, 24, 24)   12312       activation_47[0][0]              
__________________________________________________________________________________________________
concatenate_36 (Concatenate)    (None, 126, 24, 24)  0           concatenate_35[0][0]             
                                                                 dense_2_2_conv2D[0][0]           
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 126, 24, 24)  504         concatenate_36[0][0]             
__________________________________________________________________________________________________
activation_48 (Activation)      (None, 126, 24, 24)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_4 (Glo (None, 126)          0           activation_48[0][0]              
__________________________________________________________________________________________________
dense_4 (Dense)                 (None, 1)            127         global_average_pooling2d_4[0][0] 
==================================================================================================
Total params: 79,075
Trainable params: 77,347
Non-trainable params: 1,728
__________________________________________________________________________________________________
Train on 39840 samples, validate on 7440 samples
Epoch 1/20
 - 32s - loss: 0.6279 - acc: 0.6823 - val_loss: 0.5474 - val_acc: 0.7809
Epoch 2/20
 - 30s - loss: 0.5419 - acc: 0.7591 - val_loss: 0.4947 - val_acc: 0.8199
Epoch 3/20
 - 30s - loss: 0.5053 - acc: 0.7740 - val_loss: 0.5265 - val_acc: 0.7832
Epoch 4/20
 - 30s - loss: 0.4856 - acc: 0.7823 - val_loss: 0.4466 - val_acc: 0.8196
Epoch 5/20
 - 30s - loss: 0.4704 - acc: 0.7901 - val_loss: 0.4507 - val_acc: 0.8145
Epoch 6/20
 - 30s - loss: 0.4591 - acc: 0.7952 - val_loss: 0.4446 - val_acc: 0.8152
Epoch 7/20
 - 30s - loss: 0.4489 - acc: 0.8013 - val_loss: 0.4420 - val_acc: 0.8110
Epoch 00007: early stopping

  32/7440 [..............................] - ETA: 2s
 224/7440 [..............................] - ETA: 2s
 416/7440 [>.............................] - ETA: 2s
 608/7440 [=>............................] - ETA: 1s
 800/7440 [==>...........................] - ETA: 1s
 992/7440 [===>..........................] - ETA: 1s
1184/7440 [===>..........................] - ETA: 1s
1376/7440 [====>.........................] - ETA: 1s
1568/7440 [=====>........................] - ETA: 1s
1760/7440 [======>.......................] - ETA: 1s
1952/7440 [======>.......................] - ETA: 1s
2144/7440 [=======>......................] - ETA: 1s
2336/7440 [========>.....................] - ETA: 1s
2528/7440 [=========>....................] - ETA: 1s
2720/7440 [=========>....................] - ETA: 1s
2912/7440 [==========>...................] - ETA: 1s
3104/7440 [===========>..................] - ETA: 1s
3296/7440 [============>.................] - ETA: 1s
3488/7440 [=============>................] - ETA: 1s
3680/7440 [=============>................] - ETA: 1s
3872/7440 [==============>...............] - ETA: 1s
4064/7440 [===============>..............] - ETA: 0s
4256/7440 [================>.............] - ETA: 0s
4448/7440 [================>.............] - ETA: 0s
4640/7440 [=================>............] - ETA: 0s
4832/7440 [==================>...........] - ETA: 0s
5024/7440 [===================>..........] - ETA: 0s
5216/7440 [====================>.........] - ETA: 0s
5408/7440 [====================>.........] - ETA: 0s
5600/7440 [=====================>........] - ETA: 0s
5792/7440 [======================>.......] - ETA: 0s
5984/7440 [=======================>......] - ETA: 0s
6176/7440 [=======================>......] - ETA: 0s
6368/7440 [========================>.....] - ETA: 0s
6560/7440 [=========================>....] - ETA: 0s
6752/7440 [==========================>...] - ETA: 0s
6944/7440 [===========================>..] - ETA: 0s
7136/7440 [===========================>..] - ETA: 0s
7328/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 2s 286us/step
Test accuracy: 0.8110215053763441
Test accuracy 0.6: 0.8130376344086021
auc_score ------------------>  0.8935246849346746
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_5 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 18, 96, 96)   324         input_5[0][0]                    
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 18, 96, 96)   72          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_49 (Activation)      (None, 18, 96, 96)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 12, 96, 96)   1944        activation_49[0][0]              
__________________________________________________________________________________________________
concatenate_37 (Concatenate)    (None, 30, 96, 96)   0           initial_conv2D[0][0]             
                                                                 dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 30, 96, 96)   120         concatenate_37[0][0]             
__________________________________________________________________________________________________
activation_50 (Activation)      (None, 30, 96, 96)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 12, 96, 96)   3240        activation_50[0][0]              
__________________________________________________________________________________________________
concatenate_38 (Concatenate)    (None, 42, 96, 96)   0           concatenate_37[0][0]             
                                                                 dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 42, 96, 96)   168         concatenate_38[0][0]             
__________________________________________________________________________________________________
activation_51 (Activation)      (None, 42, 96, 96)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 12, 96, 96)   4536        activation_51[0][0]              
__________________________________________________________________________________________________
concatenate_39 (Concatenate)    (None, 54, 96, 96)   0           concatenate_38[0][0]             
                                                                 dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 54, 96, 96)   216         concatenate_39[0][0]             
__________________________________________________________________________________________________
activation_52 (Activation)      (None, 54, 96, 96)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 54, 96, 96)   2916        activation_52[0][0]              
__________________________________________________________________________________________________
average_pooling2d_9 (AveragePoo (None, 54, 48, 48)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 54, 48, 48)   216         average_pooling2d_9[0][0]        
__________________________________________________________________________________________________
activation_53 (Activation)      (None, 54, 48, 48)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 12, 48, 48)   5832        activation_53[0][0]              
__________________________________________________________________________________________________
concatenate_40 (Concatenate)    (None, 66, 48, 48)   0           average_pooling2d_9[0][0]        
                                                                 dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 66, 48, 48)   264         concatenate_40[0][0]             
__________________________________________________________________________________________________
activation_54 (Activation)      (None, 66, 48, 48)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 12, 48, 48)   7128        activation_54[0][0]              
__________________________________________________________________________________________________
concatenate_41 (Concatenate)    (None, 78, 48, 48)   0           concatenate_40[0][0]             
                                                                 dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 78, 48, 48)   312         concatenate_41[0][0]             
__________________________________________________________________________________________________
activation_55 (Activation)      (None, 78, 48, 48)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 12, 48, 48)   8424        activation_55[0][0]              
__________________________________________________________________________________________________
concatenate_42 (Concatenate)    (None, 90, 48, 48)   0           concatenate_41[0][0]             
                                                                 dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 90, 48, 48)   360         concatenate_42[0][0]             
__________________________________________________________________________________________________
activation_56 (Activation)      (None, 90, 48, 48)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 90, 48, 48)   8100        activation_56[0][0]              
__________________________________________________________________________________________________
average_pooling2d_10 (AveragePo (None, 90, 24, 24)   0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 90, 24, 24)   360         average_pooling2d_10[0][0]       
__________________________________________________________________________________________________
activation_57 (Activation)      (None, 90, 24, 24)   0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 12, 24, 24)   9720        activation_57[0][0]              
__________________________________________________________________________________________________
concatenate_43 (Concatenate)    (None, 102, 24, 24)  0           average_pooling2d_10[0][0]       
                                                                 dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 102, 24, 24)  408         concatenate_43[0][0]             
__________________________________________________________________________________________________
activation_58 (Activation)      (None, 102, 24, 24)  0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 12, 24, 24)   11016       activation_58[0][0]              
__________________________________________________________________________________________________
concatenate_44 (Concatenate)    (None, 114, 24, 24)  0           concatenate_43[0][0]             
                                                                 dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_2_bn (BatchNormalizatio (None, 114, 24, 24)  456         concatenate_44[0][0]             
__________________________________________________________________________________________________
activation_59 (Activation)      (None, 114, 24, 24)  0           dense_2_2_bn[0][0]               
__________________________________________________________________________________________________
dense_2_2_conv2D (Conv2D)       (None, 12, 24, 24)   12312       activation_59[0][0]              
__________________________________________________________________________________________________
concatenate_45 (Concatenate)    (None, 126, 24, 24)  0           concatenate_44[0][0]             
                                                                 dense_2_2_conv2D[0][0]           
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 126, 24, 24)  504         concatenate_45[0][0]             
__________________________________________________________________________________________________
activation_60 (Activation)      (None, 126, 24, 24)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_5 (Glo (None, 126)          0           activation_60[0][0]              
__________________________________________________________________________________________________
dense_5 (Dense)                 (None, 1)            127         global_average_pooling2d_5[0][0] 
==================================================================================================
Total params: 79,075
Trainable params: 77,347
Non-trainable params: 1,728
__________________________________________________________________________________________________
Train on 39840 samples, validate on 7440 samples
Epoch 1/20
 - 33s - loss: 0.6150 - acc: 0.7074 - val_loss: 0.5558 - val_acc: 0.8276
Epoch 2/20
 - 30s - loss: 0.5405 - acc: 0.7625 - val_loss: 0.5042 - val_acc: 0.8130
Epoch 3/20
 - 30s - loss: 0.5077 - acc: 0.7766 - val_loss: 0.4926 - val_acc: 0.8047
Epoch 4/20
 - 30s - loss: 0.4837 - acc: 0.7844 - val_loss: 0.4587 - val_acc: 0.8220
Epoch 5/20
 - 30s - loss: 0.4665 - acc: 0.7919 - val_loss: 0.4757 - val_acc: 0.8093
Epoch 6/20
 - 30s - loss: 0.4507 - acc: 0.8007 - val_loss: 0.4510 - val_acc: 0.8317
Epoch 7/20
 - 30s - loss: 0.4413 - acc: 0.8052 - val_loss: 0.4330 - val_acc: 0.8183
Epoch 8/20
 - 30s - loss: 0.4310 - acc: 0.8088 - val_loss: 0.4202 - val_acc: 0.8435
Epoch 9/20
 - 30s - loss: 0.4216 - acc: 0.8157 - val_loss: 0.4417 - val_acc: 0.8192
Epoch 10/20
 - 30s - loss: 0.4129 - acc: 0.8218 - val_loss: 0.4226 - val_acc: 0.8292
Epoch 11/20
 - 30s - loss: 0.4055 - acc: 0.8262 - val_loss: 0.4238 - val_acc: 0.8457

Epoch 00011: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.
Epoch 12/20
 - 30s - loss: 0.3984 - acc: 0.8299 - val_loss: 0.4225 - val_acc: 0.8395
Epoch 13/20
 - 30s - loss: 0.3964 - acc: 0.8316 - val_loss: 0.4056 - val_acc: 0.8577
Epoch 14/20
 - 30s - loss: 0.3927 - acc: 0.8328 - val_loss: 0.4183 - val_acc: 0.8476
Epoch 15/20
 - 30s - loss: 0.3914 - acc: 0.8343 - val_loss: 0.4267 - val_acc: 0.8437
Epoch 16/20
 - 30s - loss: 0.3902 - acc: 0.8342 - val_loss: 0.4213 - val_acc: 0.8489

Epoch 00016: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.
Epoch 17/20
 - 30s - loss: 0.3872 - acc: 0.8366 - val_loss: 0.4168 - val_acc: 0.8478
Epoch 18/20
 - 30s - loss: 0.3869 - acc: 0.8362 - val_loss: 0.4246 - val_acc: 0.8441
Epoch 00018: early stopping

  32/7440 [..............................] - ETA: 2s
 224/7440 [..............................] - ETA: 2s
 416/7440 [>.............................] - ETA: 1s
 608/7440 [=>............................] - ETA: 1s
 800/7440 [==>...........................] - ETA: 1s
 992/7440 [===>..........................] - ETA: 1s
1184/7440 [===>..........................] - ETA: 1s
1376/7440 [====>.........................] - ETA: 1s
1568/7440 [=====>........................] - ETA: 1s
1760/7440 [======>.......................] - ETA: 1s
1952/7440 [======>.......................] - ETA: 1s
2144/7440 [=======>......................] - ETA: 1s
2336/7440 [========>.....................] - ETA: 1s
2528/7440 [=========>....................] - ETA: 1s
2720/7440 [=========>....................] - ETA: 1s
2912/7440 [==========>...................] - ETA: 1s
3104/7440 [===========>..................] - ETA: 1s
3296/7440 [============>.................] - ETA: 1s
3488/7440 [=============>................] - ETA: 1s
3680/7440 [=============>................] - ETA: 1s
3872/7440 [==============>...............] - ETA: 1s
4064/7440 [===============>..............] - ETA: 0s
4256/7440 [================>.............] - ETA: 0s
4448/7440 [================>.............] - ETA: 0s
4640/7440 [=================>............] - ETA: 0s
4832/7440 [==================>...........] - ETA: 0s
5024/7440 [===================>..........] - ETA: 0s
5216/7440 [====================>.........] - ETA: 0s
5408/7440 [====================>.........] - ETA: 0s
5600/7440 [=====================>........] - ETA: 0s
5792/7440 [======================>.......] - ETA: 0s
5984/7440 [=======================>......] - ETA: 0s
6176/7440 [=======================>......] - ETA: 0s
6368/7440 [========================>.....] - ETA: 0s
6560/7440 [=========================>....] - ETA: 0s
6752/7440 [==========================>...] - ETA: 0s
6944/7440 [===========================>..] - ETA: 0s
7136/7440 [===========================>..] - ETA: 0s
7328/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 2s 281us/step
Test accuracy: 0.8440860215053764
Test accuracy 0.6: 0.8341397849462365
auc_score ------------------>  0.9093605474621343
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_6 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 18, 96, 96)   324         input_6[0][0]                    
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 18, 96, 96)   72          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_61 (Activation)      (None, 18, 96, 96)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 12, 96, 96)   1944        activation_61[0][0]              
__________________________________________________________________________________________________
concatenate_46 (Concatenate)    (None, 30, 96, 96)   0           initial_conv2D[0][0]             
                                                                 dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 30, 96, 96)   120         concatenate_46[0][0]             
__________________________________________________________________________________________________
activation_62 (Activation)      (None, 30, 96, 96)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 12, 96, 96)   3240        activation_62[0][0]              
__________________________________________________________________________________________________
concatenate_47 (Concatenate)    (None, 42, 96, 96)   0           concatenate_46[0][0]             
                                                                 dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 42, 96, 96)   168         concatenate_47[0][0]             
__________________________________________________________________________________________________
activation_63 (Activation)      (None, 42, 96, 96)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 12, 96, 96)   4536        activation_63[0][0]              
__________________________________________________________________________________________________
concatenate_48 (Concatenate)    (None, 54, 96, 96)   0           concatenate_47[0][0]             
                                                                 dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 54, 96, 96)   216         concatenate_48[0][0]             
__________________________________________________________________________________________________
activation_64 (Activation)      (None, 54, 96, 96)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 54, 96, 96)   2916        activation_64[0][0]              
__________________________________________________________________________________________________
average_pooling2d_11 (AveragePo (None, 54, 48, 48)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 54, 48, 48)   216         average_pooling2d_11[0][0]       
__________________________________________________________________________________________________
activation_65 (Activation)      (None, 54, 48, 48)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 12, 48, 48)   5832        activation_65[0][0]              
__________________________________________________________________________________________________
concatenate_49 (Concatenate)    (None, 66, 48, 48)   0           average_pooling2d_11[0][0]       
                                                                 dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 66, 48, 48)   264         concatenate_49[0][0]             
__________________________________________________________________________________________________
activation_66 (Activation)      (None, 66, 48, 48)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 12, 48, 48)   7128        activation_66[0][0]              
__________________________________________________________________________________________________
concatenate_50 (Concatenate)    (None, 78, 48, 48)   0           concatenate_49[0][0]             
                                                                 dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 78, 48, 48)   312         concatenate_50[0][0]             
__________________________________________________________________________________________________
activation_67 (Activation)      (None, 78, 48, 48)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 12, 48, 48)   8424        activation_67[0][0]              
__________________________________________________________________________________________________
concatenate_51 (Concatenate)    (None, 90, 48, 48)   0           concatenate_50[0][0]             
                                                                 dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 90, 48, 48)   360         concatenate_51[0][0]             
__________________________________________________________________________________________________
activation_68 (Activation)      (None, 90, 48, 48)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 90, 48, 48)   8100        activation_68[0][0]              
__________________________________________________________________________________________________
average_pooling2d_12 (AveragePo (None, 90, 24, 24)   0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 90, 24, 24)   360         average_pooling2d_12[0][0]       
__________________________________________________________________________________________________
activation_69 (Activation)      (None, 90, 24, 24)   0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 12, 24, 24)   9720        activation_69[0][0]              
__________________________________________________________________________________________________
concatenate_52 (Concatenate)    (None, 102, 24, 24)  0           average_pooling2d_12[0][0]       
                                                                 dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 102, 24, 24)  408         concatenate_52[0][0]             
__________________________________________________________________________________________________
activation_70 (Activation)      (None, 102, 24, 24)  0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 12, 24, 24)   11016       activation_70[0][0]              
__________________________________________________________________________________________________
concatenate_53 (Concatenate)    (None, 114, 24, 24)  0           concatenate_52[0][0]             
                                                                 dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_2_bn (BatchNormalizatio (None, 114, 24, 24)  456         concatenate_53[0][0]             
__________________________________________________________________________________________________
activation_71 (Activation)      (None, 114, 24, 24)  0           dense_2_2_bn[0][0]               
__________________________________________________________________________________________________
dense_2_2_conv2D (Conv2D)       (None, 12, 24, 24)   12312       activation_71[0][0]              
__________________________________________________________________________________________________
concatenate_54 (Concatenate)    (None, 126, 24, 24)  0           concatenate_53[0][0]             
                                                                 dense_2_2_conv2D[0][0]           
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 126, 24, 24)  504         concatenate_54[0][0]             
__________________________________________________________________________________________________
activation_72 (Activation)      (None, 126, 24, 24)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_6 (Glo (None, 126)          0           activation_72[0][0]              
__________________________________________________________________________________________________
dense_6 (Dense)                 (None, 1)            127         global_average_pooling2d_6[0][0] 
==================================================================================================
Total params: 79,075
Trainable params: 77,347
Non-trainable params: 1,728
__________________________________________________________________________________________________
Train on 39840 samples, validate on 7440 samples
Epoch 1/20
 - 33s - loss: 0.6129 - acc: 0.6952 - val_loss: 0.5194 - val_acc: 0.8442
Epoch 2/20
 - 30s - loss: 0.5205 - acc: 0.7711 - val_loss: 0.5021 - val_acc: 0.8052
Epoch 3/20
 - 30s - loss: 0.4938 - acc: 0.7824 - val_loss: 0.4843 - val_acc: 0.8085
Epoch 4/20
 - 30s - loss: 0.4774 - acc: 0.7885 - val_loss: 0.4850 - val_acc: 0.8117
Epoch 5/20
 - 30s - loss: 0.4646 - acc: 0.7937 - val_loss: 0.4621 - val_acc: 0.8211
Epoch 6/20
 - 30s - loss: 0.4516 - acc: 0.8006 - val_loss: 0.4623 - val_acc: 0.8152
Epoch 00006: early stopping

  32/7440 [..............................] - ETA: 2s
 224/7440 [..............................] - ETA: 2s
 416/7440 [>.............................] - ETA: 1s
 608/7440 [=>............................] - ETA: 1s
 800/7440 [==>...........................] - ETA: 1s
 992/7440 [===>..........................] - ETA: 1s
1184/7440 [===>..........................] - ETA: 1s
1376/7440 [====>.........................] - ETA: 1s
1568/7440 [=====>........................] - ETA: 1s
1760/7440 [======>.......................] - ETA: 1s
1952/7440 [======>.......................] - ETA: 1s
2144/7440 [=======>......................] - ETA: 1s
2336/7440 [========>.....................] - ETA: 1s
2528/7440 [=========>....................] - ETA: 1s
2720/7440 [=========>....................] - ETA: 1s
2912/7440 [==========>...................] - ETA: 1s
3104/7440 [===========>..................] - ETA: 1s
3296/7440 [============>.................] - ETA: 1s
3488/7440 [=============>................] - ETA: 1s
3680/7440 [=============>................] - ETA: 1s
3872/7440 [==============>...............] - ETA: 1s
4064/7440 [===============>..............] - ETA: 0s
4256/7440 [================>.............] - ETA: 0s
4448/7440 [================>.............] - ETA: 0s
4640/7440 [=================>............] - ETA: 0s
4832/7440 [==================>...........] - ETA: 0s
5024/7440 [===================>..........] - ETA: 0s
5216/7440 [====================>.........] - ETA: 0s
5408/7440 [====================>.........] - ETA: 0s
5600/7440 [=====================>........] - ETA: 0s
5792/7440 [======================>.......] - ETA: 0s
5984/7440 [=======================>......] - ETA: 0s
6176/7440 [=======================>......] - ETA: 0s
6368/7440 [========================>.....] - ETA: 0s
6560/7440 [=========================>....] - ETA: 0s
6752/7440 [==========================>...] - ETA: 0s
6944/7440 [===========================>..] - ETA: 0s
7136/7440 [===========================>..] - ETA: 0s
7328/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 2s 282us/step
Test accuracy: 0.8151881720430108
Test accuracy 0.6: 0.8155913978494623
auc_score ------------------>  0.8866824199329403
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_7 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 18, 96, 96)   324         input_7[0][0]                    
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 18, 96, 96)   72          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_73 (Activation)      (None, 18, 96, 96)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 12, 96, 96)   1944        activation_73[0][0]              
__________________________________________________________________________________________________
concatenate_55 (Concatenate)    (None, 30, 96, 96)   0           initial_conv2D[0][0]             
                                                                 dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 30, 96, 96)   120         concatenate_55[0][0]             
__________________________________________________________________________________________________
activation_74 (Activation)      (None, 30, 96, 96)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 12, 96, 96)   3240        activation_74[0][0]              
__________________________________________________________________________________________________
concatenate_56 (Concatenate)    (None, 42, 96, 96)   0           concatenate_55[0][0]             
                                                                 dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 42, 96, 96)   168         concatenate_56[0][0]             
__________________________________________________________________________________________________
activation_75 (Activation)      (None, 42, 96, 96)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 12, 96, 96)   4536        activation_75[0][0]              
__________________________________________________________________________________________________
concatenate_57 (Concatenate)    (None, 54, 96, 96)   0           concatenate_56[0][0]             
                                                                 dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 54, 96, 96)   216         concatenate_57[0][0]             
__________________________________________________________________________________________________
activation_76 (Activation)      (None, 54, 96, 96)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 54, 96, 96)   2916        activation_76[0][0]              
__________________________________________________________________________________________________
average_pooling2d_13 (AveragePo (None, 54, 48, 48)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 54, 48, 48)   216         average_pooling2d_13[0][0]       
__________________________________________________________________________________________________
activation_77 (Activation)      (None, 54, 48, 48)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 12, 48, 48)   5832        activation_77[0][0]              
__________________________________________________________________________________________________
concatenate_58 (Concatenate)    (None, 66, 48, 48)   0           average_pooling2d_13[0][0]       
                                                                 dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 66, 48, 48)   264         concatenate_58[0][0]             
__________________________________________________________________________________________________
activation_78 (Activation)      (None, 66, 48, 48)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 12, 48, 48)   7128        activation_78[0][0]              
__________________________________________________________________________________________________
concatenate_59 (Concatenate)    (None, 78, 48, 48)   0           concatenate_58[0][0]             
                                                                 dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 78, 48, 48)   312         concatenate_59[0][0]             
__________________________________________________________________________________________________
activation_79 (Activation)      (None, 78, 48, 48)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 12, 48, 48)   8424        activation_79[0][0]              
__________________________________________________________________________________________________
concatenate_60 (Concatenate)    (None, 90, 48, 48)   0           concatenate_59[0][0]             
                                                                 dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 90, 48, 48)   360         concatenate_60[0][0]             
__________________________________________________________________________________________________
activation_80 (Activation)      (None, 90, 48, 48)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 90, 48, 48)   8100        activation_80[0][0]              
__________________________________________________________________________________________________
average_pooling2d_14 (AveragePo (None, 90, 24, 24)   0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 90, 24, 24)   360         average_pooling2d_14[0][0]       
__________________________________________________________________________________________________
activation_81 (Activation)      (None, 90, 24, 24)   0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 12, 24, 24)   9720        activation_81[0][0]              
__________________________________________________________________________________________________
concatenate_61 (Concatenate)    (None, 102, 24, 24)  0           average_pooling2d_14[0][0]       
                                                                 dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 102, 24, 24)  408         concatenate_61[0][0]             
__________________________________________________________________________________________________
activation_82 (Activation)      (None, 102, 24, 24)  0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 12, 24, 24)   11016       activation_82[0][0]              
__________________________________________________________________________________________________
concatenate_62 (Concatenate)    (None, 114, 24, 24)  0           concatenate_61[0][0]             
                                                                 dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_2_bn (BatchNormalizatio (None, 114, 24, 24)  456         concatenate_62[0][0]             
__________________________________________________________________________________________________
activation_83 (Activation)      (None, 114, 24, 24)  0           dense_2_2_bn[0][0]               
__________________________________________________________________________________________________
dense_2_2_conv2D (Conv2D)       (None, 12, 24, 24)   12312       activation_83[0][0]              
__________________________________________________________________________________________________
concatenate_63 (Concatenate)    (None, 126, 24, 24)  0           concatenate_62[0][0]             
                                                                 dense_2_2_conv2D[0][0]           
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 126, 24, 24)  504         concatenate_63[0][0]             
__________________________________________________________________________________________________
activation_84 (Activation)      (None, 126, 24, 24)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_7 (Glo (None, 126)          0           activation_84[0][0]              
__________________________________________________________________________________________________
dense_7 (Dense)                 (None, 1)            127         global_average_pooling2d_7[0][0] 
==================================================================================================
Total params: 79,075
Trainable params: 77,347
Non-trainable params: 1,728
__________________________________________________________________________________________________
Train on 39840 samples, validate on 7440 samples
Epoch 1/20
 - 33s - loss: 0.6173 - acc: 0.7128 - val_loss: 0.5472 - val_acc: 0.8435
Epoch 2/20
 - 30s - loss: 0.5444 - acc: 0.7617 - val_loss: 0.5246 - val_acc: 0.8070
Epoch 3/20
 - 30s - loss: 0.5135 - acc: 0.7738 - val_loss: 0.5252 - val_acc: 0.8038
Epoch 4/20
 - 30s - loss: 0.4920 - acc: 0.7831 - val_loss: 0.4718 - val_acc: 0.8183
Epoch 5/20
 - 30s - loss: 0.4724 - acc: 0.7926 - val_loss: 0.4520 - val_acc: 0.8304
Epoch 6/20
 - 30s - loss: 0.4584 - acc: 0.7986 - val_loss: 0.4381 - val_acc: 0.8270
Epoch 00006: early stopping

  32/7440 [..............................] - ETA: 2s
 224/7440 [..............................] - ETA: 2s
 416/7440 [>.............................] - ETA: 2s
 608/7440 [=>............................] - ETA: 1s
 800/7440 [==>...........................] - ETA: 1s
 992/7440 [===>..........................] - ETA: 1s
1184/7440 [===>..........................] - ETA: 1s
1376/7440 [====>.........................] - ETA: 1s
1568/7440 [=====>........................] - ETA: 1s
1760/7440 [======>.......................] - ETA: 1s
1952/7440 [======>.......................] - ETA: 1s
2144/7440 [=======>......................] - ETA: 1s
2336/7440 [========>.....................] - ETA: 1s
2528/7440 [=========>....................] - ETA: 1s
2720/7440 [=========>....................] - ETA: 1s
2912/7440 [==========>...................] - ETA: 1s
3104/7440 [===========>..................] - ETA: 1s
3296/7440 [============>.................] - ETA: 1s
3488/7440 [=============>................] - ETA: 1s
3680/7440 [=============>................] - ETA: 1s
3872/7440 [==============>...............] - ETA: 1s
4064/7440 [===============>..............] - ETA: 0s
4256/7440 [================>.............] - ETA: 0s
4448/7440 [================>.............] - ETA: 0s
4640/7440 [=================>............] - ETA: 0s
4832/7440 [==================>...........] - ETA: 0s
5024/7440 [===================>..........] - ETA: 0s
5216/7440 [====================>.........] - ETA: 0s
5408/7440 [====================>.........] - ETA: 0s
5600/7440 [=====================>........] - ETA: 0s
5792/7440 [======================>.......] - ETA: 0s
5984/7440 [=======================>......] - ETA: 0s
6176/7440 [=======================>......] - ETA: 0s
6368/7440 [========================>.....] - ETA: 0s
6560/7440 [=========================>....] - ETA: 0s
6752/7440 [==========================>...] - ETA: 0s
6944/7440 [===========================>..] - ETA: 0s
7136/7440 [===========================>..] - ETA: 0s
7328/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 2s 287us/step
Test accuracy: 0.8270161290322581
Test accuracy 0.6: 0.8116935483870967
auc_score ------------------>  0.9014812406058503
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_8 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 18, 96, 96)   324         input_8[0][0]                    
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 18, 96, 96)   72          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_85 (Activation)      (None, 18, 96, 96)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 12, 96, 96)   1944        activation_85[0][0]              
__________________________________________________________________________________________________
concatenate_64 (Concatenate)    (None, 30, 96, 96)   0           initial_conv2D[0][0]             
                                                                 dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 30, 96, 96)   120         concatenate_64[0][0]             
__________________________________________________________________________________________________
activation_86 (Activation)      (None, 30, 96, 96)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 12, 96, 96)   3240        activation_86[0][0]              
__________________________________________________________________________________________________
concatenate_65 (Concatenate)    (None, 42, 96, 96)   0           concatenate_64[0][0]             
                                                                 dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 42, 96, 96)   168         concatenate_65[0][0]             
__________________________________________________________________________________________________
activation_87 (Activation)      (None, 42, 96, 96)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 12, 96, 96)   4536        activation_87[0][0]              
__________________________________________________________________________________________________
concatenate_66 (Concatenate)    (None, 54, 96, 96)   0           concatenate_65[0][0]             
                                                                 dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 54, 96, 96)   216         concatenate_66[0][0]             
__________________________________________________________________________________________________
activation_88 (Activation)      (None, 54, 96, 96)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 54, 96, 96)   2916        activation_88[0][0]              
__________________________________________________________________________________________________
average_pooling2d_15 (AveragePo (None, 54, 48, 48)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 54, 48, 48)   216         average_pooling2d_15[0][0]       
__________________________________________________________________________________________________
activation_89 (Activation)      (None, 54, 48, 48)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 12, 48, 48)   5832        activation_89[0][0]              
__________________________________________________________________________________________________
concatenate_67 (Concatenate)    (None, 66, 48, 48)   0           average_pooling2d_15[0][0]       
                                                                 dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 66, 48, 48)   264         concatenate_67[0][0]             
__________________________________________________________________________________________________
activation_90 (Activation)      (None, 66, 48, 48)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 12, 48, 48)   7128        activation_90[0][0]              
__________________________________________________________________________________________________
concatenate_68 (Concatenate)    (None, 78, 48, 48)   0           concatenate_67[0][0]             
                                                                 dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 78, 48, 48)   312         concatenate_68[0][0]             
__________________________________________________________________________________________________
activation_91 (Activation)      (None, 78, 48, 48)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 12, 48, 48)   8424        activation_91[0][0]              
__________________________________________________________________________________________________
concatenate_69 (Concatenate)    (None, 90, 48, 48)   0           concatenate_68[0][0]             
                                                                 dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 90, 48, 48)   360         concatenate_69[0][0]             
__________________________________________________________________________________________________
activation_92 (Activation)      (None, 90, 48, 48)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 90, 48, 48)   8100        activation_92[0][0]              
__________________________________________________________________________________________________
average_pooling2d_16 (AveragePo (None, 90, 24, 24)   0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 90, 24, 24)   360         average_pooling2d_16[0][0]       
__________________________________________________________________________________________________
activation_93 (Activation)      (None, 90, 24, 24)   0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 12, 24, 24)   9720        activation_93[0][0]              
__________________________________________________________________________________________________
concatenate_70 (Concatenate)    (None, 102, 24, 24)  0           average_pooling2d_16[0][0]       
                                                                 dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 102, 24, 24)  408         concatenate_70[0][0]             
__________________________________________________________________________________________________
activation_94 (Activation)      (None, 102, 24, 24)  0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 12, 24, 24)   11016       activation_94[0][0]              
__________________________________________________________________________________________________
concatenate_71 (Concatenate)    (None, 114, 24, 24)  0           concatenate_70[0][0]             
                                                                 dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_2_bn (BatchNormalizatio (None, 114, 24, 24)  456         concatenate_71[0][0]             
__________________________________________________________________________________________________
activation_95 (Activation)      (None, 114, 24, 24)  0           dense_2_2_bn[0][0]               
__________________________________________________________________________________________________
dense_2_2_conv2D (Conv2D)       (None, 12, 24, 24)   12312       activation_95[0][0]              
__________________________________________________________________________________________________
concatenate_72 (Concatenate)    (None, 126, 24, 24)  0           concatenate_71[0][0]             
                                                                 dense_2_2_conv2D[0][0]           
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 126, 24, 24)  504         concatenate_72[0][0]             
__________________________________________________________________________________________________
activation_96 (Activation)      (None, 126, 24, 24)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_8 (Glo (None, 126)          0           activation_96[0][0]              
__________________________________________________________________________________________________
dense_8 (Dense)                 (None, 1)            127         global_average_pooling2d_8[0][0] 
==================================================================================================
Total params: 79,075
Trainable params: 77,347
Non-trainable params: 1,728
__________________________________________________________________________________________________
Train on 39840 samples, validate on 7440 samples
Epoch 1/20
 - 33s - loss: 0.6015 - acc: 0.7117 - val_loss: 0.5303 - val_acc: 0.8270
Epoch 2/20
 - 30s - loss: 0.5243 - acc: 0.7643 - val_loss: 0.4784 - val_acc: 0.8224
Epoch 3/20
 - 30s - loss: 0.4930 - acc: 0.7791 - val_loss: 0.4623 - val_acc: 0.8156
Epoch 4/20
 - 30s - loss: 0.4753 - acc: 0.7862 - val_loss: 0.4824 - val_acc: 0.8196
Epoch 5/20
 - 30s - loss: 0.4620 - acc: 0.7951 - val_loss: 0.4577 - val_acc: 0.8219
Epoch 6/20
 - 30s - loss: 0.4518 - acc: 0.7999 - val_loss: 0.4526 - val_acc: 0.8253
Epoch 00006: early stopping

  32/7440 [..............................] - ETA: 2s
 224/7440 [..............................] - ETA: 2s
 416/7440 [>.............................] - ETA: 2s
 608/7440 [=>............................] - ETA: 1s
 800/7440 [==>...........................] - ETA: 1s
 992/7440 [===>..........................] - ETA: 1s
1184/7440 [===>..........................] - ETA: 1s
1376/7440 [====>.........................] - ETA: 1s
1568/7440 [=====>........................] - ETA: 1s
1760/7440 [======>.......................] - ETA: 1s
1952/7440 [======>.......................] - ETA: 1s
2144/7440 [=======>......................] - ETA: 1s
2336/7440 [========>.....................] - ETA: 1s
2528/7440 [=========>....................] - ETA: 1s
2720/7440 [=========>....................] - ETA: 1s
2912/7440 [==========>...................] - ETA: 1s
3104/7440 [===========>..................] - ETA: 1s
3296/7440 [============>.................] - ETA: 1s
3488/7440 [=============>................] - ETA: 1s
3680/7440 [=============>................] - ETA: 1s
3872/7440 [==============>...............] - ETA: 1s
4064/7440 [===============>..............] - ETA: 0s
4256/7440 [================>.............] - ETA: 0s
4448/7440 [================>.............] - ETA: 0s
4640/7440 [=================>............] - ETA: 0s
4832/7440 [==================>...........] - ETA: 0s
5024/7440 [===================>..........] - ETA: 0s
5216/7440 [====================>.........] - ETA: 0s
5408/7440 [====================>.........] - ETA: 0s
5600/7440 [=====================>........] - ETA: 0s
5792/7440 [======================>.......] - ETA: 0s
5984/7440 [=======================>......] - ETA: 0s
6176/7440 [=======================>......] - ETA: 0s
6368/7440 [========================>.....] - ETA: 0s
6560/7440 [=========================>....] - ETA: 0s
6752/7440 [==========================>...] - ETA: 0s
6944/7440 [===========================>..] - ETA: 0s
7136/7440 [===========================>..] - ETA: 0s
7328/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 2s 286us/step
Test accuracy: 0.8252688172043011
Test accuracy 0.6: 0.8213709677419355
auc_score ------------------>  0.8916939819632327
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_9 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 18, 96, 96)   324         input_9[0][0]                    
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 18, 96, 96)   72          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_97 (Activation)      (None, 18, 96, 96)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 12, 96, 96)   1944        activation_97[0][0]              
__________________________________________________________________________________________________
concatenate_73 (Concatenate)    (None, 30, 96, 96)   0           initial_conv2D[0][0]             
                                                                 dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 30, 96, 96)   120         concatenate_73[0][0]             
__________________________________________________________________________________________________
activation_98 (Activation)      (None, 30, 96, 96)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 12, 96, 96)   3240        activation_98[0][0]              
__________________________________________________________________________________________________
concatenate_74 (Concatenate)    (None, 42, 96, 96)   0           concatenate_73[0][0]             
                                                                 dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 42, 96, 96)   168         concatenate_74[0][0]             
__________________________________________________________________________________________________
activation_99 (Activation)      (None, 42, 96, 96)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 12, 96, 96)   4536        activation_99[0][0]              
__________________________________________________________________________________________________
concatenate_75 (Concatenate)    (None, 54, 96, 96)   0           concatenate_74[0][0]             
                                                                 dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 54, 96, 96)   216         concatenate_75[0][0]             
__________________________________________________________________________________________________
activation_100 (Activation)     (None, 54, 96, 96)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 54, 96, 96)   2916        activation_100[0][0]             
__________________________________________________________________________________________________
average_pooling2d_17 (AveragePo (None, 54, 48, 48)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 54, 48, 48)   216         average_pooling2d_17[0][0]       
__________________________________________________________________________________________________
activation_101 (Activation)     (None, 54, 48, 48)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 12, 48, 48)   5832        activation_101[0][0]             
__________________________________________________________________________________________________
concatenate_76 (Concatenate)    (None, 66, 48, 48)   0           average_pooling2d_17[0][0]       
                                                                 dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 66, 48, 48)   264         concatenate_76[0][0]             
__________________________________________________________________________________________________
activation_102 (Activation)     (None, 66, 48, 48)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 12, 48, 48)   7128        activation_102[0][0]             
__________________________________________________________________________________________________
concatenate_77 (Concatenate)    (None, 78, 48, 48)   0           concatenate_76[0][0]             
                                                                 dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 78, 48, 48)   312         concatenate_77[0][0]             
__________________________________________________________________________________________________
activation_103 (Activation)     (None, 78, 48, 48)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 12, 48, 48)   8424        activation_103[0][0]             
__________________________________________________________________________________________________
concatenate_78 (Concatenate)    (None, 90, 48, 48)   0           concatenate_77[0][0]             
                                                                 dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 90, 48, 48)   360         concatenate_78[0][0]             
__________________________________________________________________________________________________
activation_104 (Activation)     (None, 90, 48, 48)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 90, 48, 48)   8100        activation_104[0][0]             
__________________________________________________________________________________________________
average_pooling2d_18 (AveragePo (None, 90, 24, 24)   0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 90, 24, 24)   360         average_pooling2d_18[0][0]       
__________________________________________________________________________________________________
activation_105 (Activation)     (None, 90, 24, 24)   0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 12, 24, 24)   9720        activation_105[0][0]             
__________________________________________________________________________________________________
concatenate_79 (Concatenate)    (None, 102, 24, 24)  0           average_pooling2d_18[0][0]       
                                                                 dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 102, 24, 24)  408         concatenate_79[0][0]             
__________________________________________________________________________________________________
activation_106 (Activation)     (None, 102, 24, 24)  0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 12, 24, 24)   11016       activation_106[0][0]             
__________________________________________________________________________________________________
concatenate_80 (Concatenate)    (None, 114, 24, 24)  0           concatenate_79[0][0]             
                                                                 dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_2_bn (BatchNormalizatio (None, 114, 24, 24)  456         concatenate_80[0][0]             
__________________________________________________________________________________________________
activation_107 (Activation)     (None, 114, 24, 24)  0           dense_2_2_bn[0][0]               
__________________________________________________________________________________________________
dense_2_2_conv2D (Conv2D)       (None, 12, 24, 24)   12312       activation_107[0][0]             
__________________________________________________________________________________________________
concatenate_81 (Concatenate)    (None, 126, 24, 24)  0           concatenate_80[0][0]             
                                                                 dense_2_2_conv2D[0][0]           
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 126, 24, 24)  504         concatenate_81[0][0]             
__________________________________________________________________________________________________
activation_108 (Activation)     (None, 126, 24, 24)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_9 (Glo (None, 126)          0           activation_108[0][0]             
__________________________________________________________________________________________________
dense_9 (Dense)                 (None, 1)            127         global_average_pooling2d_9[0][0] 
==================================================================================================
Total params: 79,075
Trainable params: 77,347
Non-trainable params: 1,728
__________________________________________________________________________________________________
Train on 39840 samples, validate on 7440 samples
Epoch 1/20
 - 33s - loss: 0.6606 - acc: 0.6547 - val_loss: 0.5414 - val_acc: 0.8444
Epoch 2/20
 - 30s - loss: 0.5575 - acc: 0.7541 - val_loss: 0.5063 - val_acc: 0.8249
Epoch 3/20
 - 30s - loss: 0.5178 - acc: 0.7698 - val_loss: 0.4808 - val_acc: 0.8254
Epoch 4/20
 - 29s - loss: 0.4940 - acc: 0.7814 - val_loss: 0.4919 - val_acc: 0.7976
Epoch 5/20
 - 30s - loss: 0.4767 - acc: 0.7870 - val_loss: 0.4735 - val_acc: 0.8153
Epoch 6/20
 - 29s - loss: 0.4655 - acc: 0.7921 - val_loss: 0.4879 - val_acc: 0.7984
Epoch 00006: early stopping

  32/7440 [..............................] - ETA: 2s
 224/7440 [..............................] - ETA: 2s
 416/7440 [>.............................] - ETA: 2s
 608/7440 [=>............................] - ETA: 1s
 800/7440 [==>...........................] - ETA: 1s
 992/7440 [===>..........................] - ETA: 1s
1184/7440 [===>..........................] - ETA: 1s
1376/7440 [====>.........................] - ETA: 1s
1568/7440 [=====>........................] - ETA: 1s
1760/7440 [======>.......................] - ETA: 1s
1952/7440 [======>.......................] - ETA: 1s
2144/7440 [=======>......................] - ETA: 1s
2336/7440 [========>.....................] - ETA: 1s
2528/7440 [=========>....................] - ETA: 1s
2720/7440 [=========>....................] - ETA: 1s
2912/7440 [==========>...................] - ETA: 1s
3104/7440 [===========>..................] - ETA: 1s
3296/7440 [============>.................] - ETA: 1s
3488/7440 [=============>................] - ETA: 1s
3680/7440 [=============>................] - ETA: 1s
3872/7440 [==============>...............] - ETA: 1s
4064/7440 [===============>..............] - ETA: 0s
4256/7440 [================>.............] - ETA: 0s
4448/7440 [================>.............] - ETA: 0s
4640/7440 [=================>............] - ETA: 0s
4832/7440 [==================>...........] - ETA: 0s
5024/7440 [===================>..........] - ETA: 0s
5216/7440 [====================>.........] - ETA: 0s
5408/7440 [====================>.........] - ETA: 0s
5600/7440 [=====================>........] - ETA: 0s
5792/7440 [======================>.......] - ETA: 0s
5984/7440 [=======================>......] - ETA: 0s
6176/7440 [=======================>......] - ETA: 0s
6368/7440 [========================>.....] - ETA: 0s
6560/7440 [=========================>....] - ETA: 0s
6752/7440 [==========================>...] - ETA: 0s
6944/7440 [===========================>..] - ETA: 0s
7136/7440 [===========================>..] - ETA: 0s
7328/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 2s 289us/step
Test accuracy: 0.7983870967741935
Test accuracy 0.6: 0.7975806451612903
auc_score ------------------>  0.868677484391259
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_10 (InputLayer)           (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 18, 96, 96)   324         input_10[0][0]                   
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 18, 96, 96)   72          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_109 (Activation)     (None, 18, 96, 96)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 12, 96, 96)   1944        activation_109[0][0]             
__________________________________________________________________________________________________
concatenate_82 (Concatenate)    (None, 30, 96, 96)   0           initial_conv2D[0][0]             
                                                                 dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 30, 96, 96)   120         concatenate_82[0][0]             
__________________________________________________________________________________________________
activation_110 (Activation)     (None, 30, 96, 96)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 12, 96, 96)   3240        activation_110[0][0]             
__________________________________________________________________________________________________
concatenate_83 (Concatenate)    (None, 42, 96, 96)   0           concatenate_82[0][0]             
                                                                 dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_0_2_bn (BatchNormalizatio (None, 42, 96, 96)   168         concatenate_83[0][0]             
__________________________________________________________________________________________________
activation_111 (Activation)     (None, 42, 96, 96)   0           dense_0_2_bn[0][0]               
__________________________________________________________________________________________________
dense_0_2_conv2D (Conv2D)       (None, 12, 96, 96)   4536        activation_111[0][0]             
__________________________________________________________________________________________________
concatenate_84 (Concatenate)    (None, 54, 96, 96)   0           concatenate_83[0][0]             
                                                                 dense_0_2_conv2D[0][0]           
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 54, 96, 96)   216         concatenate_84[0][0]             
__________________________________________________________________________________________________
activation_112 (Activation)     (None, 54, 96, 96)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 54, 96, 96)   2916        activation_112[0][0]             
__________________________________________________________________________________________________
average_pooling2d_19 (AveragePo (None, 54, 48, 48)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 54, 48, 48)   216         average_pooling2d_19[0][0]       
__________________________________________________________________________________________________
activation_113 (Activation)     (None, 54, 48, 48)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 12, 48, 48)   5832        activation_113[0][0]             
__________________________________________________________________________________________________
concatenate_85 (Concatenate)    (None, 66, 48, 48)   0           average_pooling2d_19[0][0]       
                                                                 dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 66, 48, 48)   264         concatenate_85[0][0]             
__________________________________________________________________________________________________
activation_114 (Activation)     (None, 66, 48, 48)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 12, 48, 48)   7128        activation_114[0][0]             
__________________________________________________________________________________________________
concatenate_86 (Concatenate)    (None, 78, 48, 48)   0           concatenate_85[0][0]             
                                                                 dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_1_2_bn (BatchNormalizatio (None, 78, 48, 48)   312         concatenate_86[0][0]             
__________________________________________________________________________________________________
activation_115 (Activation)     (None, 78, 48, 48)   0           dense_1_2_bn[0][0]               
__________________________________________________________________________________________________
dense_1_2_conv2D (Conv2D)       (None, 12, 48, 48)   8424        activation_115[0][0]             
__________________________________________________________________________________________________
concatenate_87 (Concatenate)    (None, 90, 48, 48)   0           concatenate_86[0][0]             
                                                                 dense_1_2_conv2D[0][0]           
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 90, 48, 48)   360         concatenate_87[0][0]             
__________________________________________________________________________________________________
activation_116 (Activation)     (None, 90, 48, 48)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 90, 48, 48)   8100        activation_116[0][0]             
__________________________________________________________________________________________________
average_pooling2d_20 (AveragePo (None, 90, 24, 24)   0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 90, 24, 24)   360         average_pooling2d_20[0][0]       
__________________________________________________________________________________________________
activation_117 (Activation)     (None, 90, 24, 24)   0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 12, 24, 24)   9720        activation_117[0][0]             
__________________________________________________________________________________________________
concatenate_88 (Concatenate)    (None, 102, 24, 24)  0           average_pooling2d_20[0][0]       
                                                                 dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 102, 24, 24)  408         concatenate_88[0][0]             
__________________________________________________________________________________________________
activation_118 (Activation)     (None, 102, 24, 24)  0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 12, 24, 24)   11016       activation_118[0][0]             
__________________________________________________________________________________________________
concatenate_89 (Concatenate)    (None, 114, 24, 24)  0           concatenate_88[0][0]             
                                                                 dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
dense_2_2_bn (BatchNormalizatio (None, 114, 24, 24)  456         concatenate_89[0][0]             
__________________________________________________________________________________________________
activation_119 (Activation)     (None, 114, 24, 24)  0           dense_2_2_bn[0][0]               
__________________________________________________________________________________________________
dense_2_2_conv2D (Conv2D)       (None, 12, 24, 24)   12312       activation_119[0][0]             
__________________________________________________________________________________________________
concatenate_90 (Concatenate)    (None, 126, 24, 24)  0           concatenate_89[0][0]             
                                                                 dense_2_2_conv2D[0][0]           
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 126, 24, 24)  504         concatenate_90[0][0]             
__________________________________________________________________________________________________
activation_120 (Activation)     (None, 126, 24, 24)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_10 (Gl (None, 126)          0           activation_120[0][0]             
__________________________________________________________________________________________________
dense_10 (Dense)                (None, 1)            127         global_average_pooling2d_10[0][0]
==================================================================================================
Total params: 79,075
Trainable params: 77,347
Non-trainable params: 1,728
__________________________________________________________________________________________________
Train on 39840 samples, validate on 7440 samples
Epoch 1/20
 - 34s - loss: 0.6150 - acc: 0.7093 - val_loss: 0.5237 - val_acc: 0.8594
Epoch 2/20
 - 30s - loss: 0.5455 - acc: 0.7605 - val_loss: 0.5328 - val_acc: 0.8157
Epoch 3/20
 - 30s - loss: 0.5137 - acc: 0.7737 - val_loss: 0.4774 - val_acc: 0.8207
Epoch 4/20
 - 30s - loss: 0.4911 - acc: 0.7835 - val_loss: 0.4645 - val_acc: 0.8272
Epoch 5/20
 - 30s - loss: 0.4740 - acc: 0.7898 - val_loss: 0.4609 - val_acc: 0.8214
Epoch 6/20
 - 30s - loss: 0.4609 - acc: 0.7957 - val_loss: 0.4288 - val_acc: 0.8405
Epoch 00006: early stopping

  32/7440 [..............................] - ETA: 2s
 224/7440 [..............................] - ETA: 2s
 416/7440 [>.............................] - ETA: 2s
 608/7440 [=>............................] - ETA: 2s
 800/7440 [==>...........................] - ETA: 2s
 992/7440 [===>..........................] - ETA: 1s
1184/7440 [===>..........................] - ETA: 1s
1376/7440 [====>.........................] - ETA: 1s
1568/7440 [=====>........................] - ETA: 1s
1760/7440 [======>.......................] - ETA: 1s
1952/7440 [======>.......................] - ETA: 1s
2144/7440 [=======>......................] - ETA: 1s
2336/7440 [========>.....................] - ETA: 1s
2528/7440 [=========>....................] - ETA: 1s
2720/7440 [=========>....................] - ETA: 1s
2912/7440 [==========>...................] - ETA: 1s
3104/7440 [===========>..................] - ETA: 1s
3296/7440 [============>.................] - ETA: 1s
3488/7440 [=============>................] - ETA: 1s
3680/7440 [=============>................] - ETA: 1s
3872/7440 [==============>...............] - ETA: 1s
4064/7440 [===============>..............] - ETA: 1s
4256/7440 [================>.............] - ETA: 0s
4448/7440 [================>.............] - ETA: 0s
4640/7440 [=================>............] - ETA: 0s
4832/7440 [==================>...........] - ETA: 0s
5024/7440 [===================>..........] - ETA: 0s
5216/7440 [====================>.........] - ETA: 0s
5408/7440 [====================>.........] - ETA: 0s
5600/7440 [=====================>........] - ETA: 0s
5792/7440 [======================>.......] - ETA: 0s
5984/7440 [=======================>......] - ETA: 0s
6176/7440 [=======================>......] - ETA: 0s
6368/7440 [========================>.....] - ETA: 0s
6560/7440 [=========================>....] - ETA: 0s
6752/7440 [==========================>...] - ETA: 0s
6944/7440 [===========================>..] - ETA: 0s
7136/7440 [===========================>..] - ETA: 0s
7328/7440 [============================>.] - ETA: 0s
7440/7440 [==============================] - 2s 301us/step
Test accuracy: 0.8404569892473118
Test accuracy 0.6: 0.8463709677419354
auc_score ------------------>  0.9049414672216441
[0.913, 0.879, 0.897, 0.894, 0.909, 0.887, 0.901, 0.892, 0.869, 0.905]
0.895 ± 0.013
