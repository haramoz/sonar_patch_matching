python keras_dn_simple_multigpu.py
python keras_dn_simple.py
python custom_gridsearch_dn_siamese.py
python custom_gs_dn_siamese_layers_multi.py -g 1
python custom_gridsearch_dn_siamese_layers_avg.py
python custom_gridsearch_dn_siamese_layers.py
Column names are nb_layers_per_block, growth_rate, nb_dense_block, nb_filter, dropout, lr, epochs, opt, reduction, bn, batch_size, fc_dropout, fc_filter, fc_layers
Epochs  14  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
 batch_size:  64  fc_dropout:  0.7  fc_filter:  512  fc_layers:  1
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.4
dense_block  2  reduction_:  0.3  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 53, 24, 24)   4028        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 53, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 53, 12, 12)   212         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 53, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  6360        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 83, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 83, 12, 12)   332         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 83, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  9960        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 113, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 113, 12, 12)  452         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 113, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 16272)        0           activation_11[0][0]              
==================================================================================================
Total params: 161,704
Trainable params: 159,938
Non-trainable params: 1,766
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 16272)        161704      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 32544)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          16663040    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 16,827,305
Trainable params: 16,824,515
Non-trainable params: 2,790
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/14
 - 33s - loss: 0.7525 - acc: 0.7274 - val_loss: 0.5752 - val_acc: 0.7402
Epoch 2/14
 - 27s - loss: 0.4818 - acc: 0.8383 - val_loss: 0.4283 - val_acc: 0.8612
Epoch 3/14
 - 26s - loss: 0.3723 - acc: 0.8921 - val_loss: 0.3860 - val_acc: 0.8863
Epoch 4/14
 - 25s - loss: 0.3008 - acc: 0.9265 - val_loss: 0.2620 - val_acc: 0.9513
Epoch 5/14
 - 26s - loss: 0.2566 - acc: 0.9448 - val_loss: 0.2159 - val_acc: 0.9670
Epoch 6/14
 - 25s - loss: 0.2229 - acc: 0.9600 - val_loss: 0.2108 - val_acc: 0.9660
Epoch 7/14
 - 25s - loss: 0.1988 - acc: 0.9698 - val_loss: 0.1873 - val_acc: 0.9774
Epoch 8/14
 - 26s - loss: 0.1841 - acc: 0.9747 - val_loss: 0.1681 - val_acc: 0.9837
Epoch 9/14
 - 26s - loss: 0.1714 - acc: 0.9790 - val_loss: 0.1528 - val_acc: 0.9888
Epoch 10/14
 - 26s - loss: 0.1589 - acc: 0.9837 - val_loss: 0.1337 - val_acc: 0.9939
Epoch 11/14
 - 26s - loss: 0.1527 - acc: 0.9846 - val_loss: 0.1238 - val_acc: 0.9956
Epoch 12/14
 - 26s - loss: 0.1449 - acc: 0.9878 - val_loss: 0.1280 - val_acc: 0.9949
Epoch 13/14
 - 25s - loss: 0.1403 - acc: 0.9890 - val_loss: 0.1193 - val_acc: 0.9957
Epoch 14/14
 - 25s - loss: 0.1332 - acc: 0.9912 - val_loss: 0.1211 - val_acc: 0.9945
Test accuracy:0.592
current auc_score ------------------> 0.907
Epochs  14  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
 batch_size:  64  fc_dropout:  0.7  fc_filter:  512  fc_layers:  1
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.4
dense_block  2  reduction_:  0.3  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 53, 24, 24)   4028        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 53, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 53, 12, 12)   212         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 53, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  6360        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 83, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 83, 12, 12)   332         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 83, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  9960        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 113, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 113, 12, 12)  452         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 113, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 16272)        0           activation_11[0][0]              
==================================================================================================
Total params: 161,704
Trainable params: 159,938
Non-trainable params: 1,766
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 16272)        161704      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 32544)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          16663040    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 16,827,305
Trainable params: 16,824,515
Non-trainable params: 2,790
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/14
 - 30s - loss: 0.7169 - acc: 0.7409 - val_loss: 0.4859 - val_acc: 0.8111
Epoch 2/14
 - 25s - loss: 0.4683 - acc: 0.8463 - val_loss: 0.4160 - val_acc: 0.8638
Epoch 3/14
 - 24s - loss: 0.3636 - acc: 0.8944 - val_loss: 0.3296 - val_acc: 0.9142
Epoch 4/14
 - 24s - loss: 0.2948 - acc: 0.9267 - val_loss: 0.2573 - val_acc: 0.9533
Epoch 5/14
 - 24s - loss: 0.2501 - acc: 0.9488 - val_loss: 0.2075 - val_acc: 0.9752
Epoch 6/14
 - 24s - loss: 0.2152 - acc: 0.9629 - val_loss: 0.1971 - val_acc: 0.9785
Epoch 7/14
 - 24s - loss: 0.1930 - acc: 0.9720 - val_loss: 0.1679 - val_acc: 0.9864
Epoch 8/14
 - 24s - loss: 0.1791 - acc: 0.9754 - val_loss: 0.1669 - val_acc: 0.9873
Epoch 9/14
 - 24s - loss: 0.1646 - acc: 0.9807 - val_loss: 0.1484 - val_acc: 0.9880
Epoch 10/14
 - 24s - loss: 0.1548 - acc: 0.9843 - val_loss: 0.1382 - val_acc: 0.9921
Epoch 11/14
 - 24s - loss: 0.1483 - acc: 0.9866 - val_loss: 0.1282 - val_acc: 0.9947
Epoch 12/14
 - 24s - loss: 0.1401 - acc: 0.9889 - val_loss: 0.1250 - val_acc: 0.9955
Epoch 13/14
 - 24s - loss: 0.1333 - acc: 0.9906 - val_loss: 0.1148 - val_acc: 0.9966
Epoch 14/14
 - 24s - loss: 0.1313 - acc: 0.9910 - val_loss: 0.1149 - val_acc: 0.9965
Test accuracy:0.660
current auc_score ------------------> 0.875
Epochs  14  batch_size:  64  lr:  0.07  optimizer:  adadelta
 es_patience:  4  lr_patience:  3
 batch_size:  64  fc_dropout:  0.7  fc_filter:  512  fc_layers:  1
------------------------ current config for the test -------------------------
Layers:  [2, 2]  Growth_rate:  30  nb_filter:  16  dropout:  0.4
dense_block  2  reduction_:  0.3  bottleneck:  True
------------------------	  end of configs        -------------------------
pooling:flatten
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 16, 48, 48)   784         input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 16, 48, 48)   64          initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 16, 24, 24)   64          max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_conv2D (Co (None, 120, 24, 24)  1920        activation_2[0][0]               
__________________________________________________________________________________________________
dense_0_0_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 120, 24, 24)  0           dense_0_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_3[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 30, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 46, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 46, 24, 24)   184         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 46, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_conv2D (Co (None, 120, 24, 24)  5520        activation_4[0][0]               
__________________________________________________________________________________________________
dense_0_1_bottleneck_bn (BatchN (None, 120, 24, 24)  480         dense_0_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 120, 24, 24)  0           dense_0_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 30, 24, 24)   32400       activation_5[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 30, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 76, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 76, 24, 24)   304         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 76, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 53, 24, 24)   4028        activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 53, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 53, 12, 12)   212         max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 53, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_conv2D (Co (None, 120, 12, 12)  6360        activation_7[0][0]               
__________________________________________________________________________________________________
dense_1_0_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_0_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 120, 12, 12)  0           dense_1_0_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_8[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 30, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 83, 12, 12)   0           max_pooling2d_2[0][0]            
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 83, 12, 12)   332         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 83, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_conv2D (Co (None, 120, 12, 12)  9960        activation_9[0][0]               
__________________________________________________________________________________________________
dense_1_1_bottleneck_bn (BatchN (None, 120, 12, 12)  480         dense_1_1_bottleneck_conv2D[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 120, 12, 12)  0           dense_1_1_bottleneck_bn[0][0]    
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 30, 12, 12)   32400       activation_10[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 30, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 113, 12, 12)  0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 113, 12, 12)  452         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 113, 12, 12)  0           final_bn[0][0]                   
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 16272)        0           activation_11[0][0]              
==================================================================================================
Total params: 161,704
Trainable params: 159,938
Non-trainable params: 1,766
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 96, 96)    0                                            
__________________________________________________________________________________________________
densenet (Model)                (None, 16272)        161704      input_2[0][0]                    
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
merge_features (Concatenate)    (None, 32544)        0           densenet[1][0]                   
                                                                 densenet[2][0]                   
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 512)          16663040    merge_features[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 512)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 512)          2048        activation_12[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            513         dropout_5[0][0]                  
==================================================================================================
Total params: 16,827,305
Trainable params: 16,824,515
Non-trainable params: 2,790
__________________________________________________________________________________________________
Finished compiling
Train on 31872 samples, validate on 7968 samples
Epoch 1/14
 - 28s - loss: 0.6940 - acc: 0.7502 - val_loss: 1.1844 - val_acc: 0.5621
Epoch 2/14
 - 24s - loss: 0.4542 - acc: 0.8528 - val_loss: 0.3905 - val_acc: 0.8883
Epoch 3/14
 - 24s - loss: 0.3497 - acc: 0.8995 - val_loss: 0.3736 - val_acc: 0.8855
Epoch 4/14
 - 24s - loss: 0.2891 - acc: 0.9292 - val_loss: 0.3038 - val_acc: 0.9266
Epoch 5/14
 - 25s - loss: 0.2465 - acc: 0.9481 - val_loss: 0.2483 - val_acc: 0.9572
Epoch 6/14
 - 25s - loss: 0.2142 - acc: 0.9631 - val_loss: 0.1937 - val_acc: 0.9746
Epoch 7/14
 - 25s - loss: 0.1976 - acc: 0.9696 - val_loss: 0.1617 - val_acc: 0.9885
Epoch 8/14
 - 25s - loss: 0.1793 - acc: 0.9765 - val_loss: 0.1562 - val_acc: 0.9896
Epoch 9/14
 - 25s - loss: 0.1647 - acc: 0.9810 - val_loss: 0.1442 - val_acc: 0.9915
Epoch 10/14
 - 25s - loss: 0.1533 - acc: 0.9849 - val_loss: 0.1240 - val_acc: 0.9947
Epoch 11/14
 - 25s - loss: 0.1461 - acc: 0.9867 - val_loss: 0.1332 - val_acc: 0.9925
Epoch 12/14
 - 25s - loss: 0.1381 - acc: 0.9895 - val_loss: 0.1199 - val_acc: 0.9957
Epoch 13/14
 - 25s - loss: 0.1334 - acc: 0.9895 - val_loss: 0.1112 - val_acc: 0.9967
Epoch 14/14
 - 25s - loss: 0.1268 - acc: 0.9927 - val_loss: 0.1110 - val_acc: 0.9971
Test accuracy:0.571
current auc_score ------------------> 0.913
accuracies:  [0.5924731182795699, 0.6602150537634408, 0.5711021505376344]
aucs:  [0.907, 0.8753, 0.913]
mean and std AUC:  0.898+/-0.017  max:   0.913
(['2-2', '30', '2', '16', '0.4', '0.07', '14', 'adadelta', '0.3', 'TRUE', '64', '0.7', '512', '1'], '0.898+/-0.017', 0.913)
1129.353796679061
Column names are nb_layers_per_block, growth_rate, nb_dense_block, nb_filter, dropout, lr, epochs, opt, reduction, bn, batch_size, pooling
['2-2-2', '18', '3', '32', '0.2', '0.03', '21', 'adadelta', '0.5', 'FALSE', '128', 'avg']
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  18  nb_filter:  32  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  128  lr:  0.03  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 32, 48, 48)   3136        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 32, 48, 48)   128         initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 32, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 32, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 32, 24, 24)   128         max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 32, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   5184        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 50, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 50, 24, 24)   200         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 50, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   8100        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 68, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 68, 24, 24)   272         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 68, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 34, 24, 24)   2312        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 34, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 34, 12, 12)   136         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 34, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   5508        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 52, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 52, 12, 12)   208         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 52, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   8424        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 70, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 70, 12, 12)   280         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 70, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 35, 12, 12)   2450        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 35, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 35, 6, 6)     140         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 35, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 18, 6, 6)     5670        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 18, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 53, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 53, 6, 6)     212         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 53, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 18, 6, 6)     8586        activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 18, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 71, 6, 6)     0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 71, 6, 6)     284         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 71, 6, 6)     0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 71)           0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            72          global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 51,430
Trainable params: 50,436
Non-trainable params: 994
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 16s - loss: 0.6502 - acc: 0.6397 - val_loss: 0.5953 - val_acc: 0.7172
Epoch 2/21
 - 13s - loss: 0.5346 - acc: 0.7608 - val_loss: 0.5356 - val_acc: 0.7412
Epoch 3/21
 - 13s - loss: 0.4808 - acc: 0.7780 - val_loss: 0.5302 - val_acc: 0.7328
Epoch 4/21
 - 13s - loss: 0.4531 - acc: 0.7857 - val_loss: 0.4905 - val_acc: 0.7592
Epoch 5/21
 - 13s - loss: 0.4355 - acc: 0.7940 - val_loss: 0.4558 - val_acc: 0.7770
Epoch 6/21
 - 13s - loss: 0.4215 - acc: 0.8013 - val_loss: 0.4843 - val_acc: 0.7572
Epoch 7/21
 - 13s - loss: 0.4090 - acc: 0.8110 - val_loss: 0.4249 - val_acc: 0.7944
Epoch 8/21
 - 13s - loss: 0.3980 - acc: 0.8161 - val_loss: 0.3930 - val_acc: 0.8199
Epoch 9/21
 - 13s - loss: 0.3869 - acc: 0.8242 - val_loss: 0.3788 - val_acc: 0.8284
Epoch 10/21
 - 13s - loss: 0.3814 - acc: 0.8274 - val_loss: 0.3807 - val_acc: 0.8254
Epoch 11/21
 - 13s - loss: 0.3744 - acc: 0.8328 - val_loss: 0.3890 - val_acc: 0.8227
Epoch 12/21
 - 13s - loss: 0.3662 - acc: 0.8376 - val_loss: 0.3801 - val_acc: 0.8313

Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.009486832768457897.
Epoch 13/21
 - 13s - loss: 0.3611 - acc: 0.8411 - val_loss: 0.3527 - val_acc: 0.8468
Epoch 14/21
 - 13s - loss: 0.3594 - acc: 0.8411 - val_loss: 0.3548 - val_acc: 0.8443
Epoch 15/21
 - 13s - loss: 0.3554 - acc: 0.8445 - val_loss: 0.3571 - val_acc: 0.8421
Epoch 16/21
 - 13s - loss: 0.3543 - acc: 0.8444 - val_loss: 0.3464 - val_acc: 0.8507
Epoch 17/21
 - 13s - loss: 0.3532 - acc: 0.8457 - val_loss: 0.3476 - val_acc: 0.8488
Epoch 18/21
 - 13s - loss: 0.3518 - acc: 0.8466 - val_loss: 0.3464 - val_acc: 0.8479
Epoch 19/21
 - 13s - loss: 0.3514 - acc: 0.8455 - val_loss: 0.3488 - val_acc: 0.8469

Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.0029999998973718025.
Epoch 20/21
 - 13s - loss: 0.3467 - acc: 0.8491 - val_loss: 0.3422 - val_acc: 0.8520
Epoch 21/21
 - 13s - loss: 0.3464 - acc: 0.8492 - val_loss: 0.3411 - val_acc: 0.8518
Test accuracy:0.883
current auc_score ------------------> 0.953
Saved model to disk
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  18  nb_filter:  32  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  128  lr:  0.03  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 32, 48, 48)   3136        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 32, 48, 48)   128         initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 32, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 32, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 32, 24, 24)   128         max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 32, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   5184        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 50, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 50, 24, 24)   200         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 50, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   8100        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 68, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 68, 24, 24)   272         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 68, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 34, 24, 24)   2312        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 34, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 34, 12, 12)   136         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 34, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   5508        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 52, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 52, 12, 12)   208         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 52, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   8424        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 70, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 70, 12, 12)   280         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 70, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 35, 12, 12)   2450        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 35, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 35, 6, 6)     140         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 35, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 18, 6, 6)     5670        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 18, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 53, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 53, 6, 6)     212         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 53, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 18, 6, 6)     8586        activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 18, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 71, 6, 6)     0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 71, 6, 6)     284         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 71, 6, 6)     0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 71)           0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            72          global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 51,430
Trainable params: 50,436
Non-trainable params: 994
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 15s - loss: 0.6203 - acc: 0.6797 - val_loss: 0.6192 - val_acc: 0.6639
Epoch 2/21
 - 13s - loss: 0.5226 - acc: 0.7629 - val_loss: 0.5375 - val_acc: 0.7318
Epoch 3/21
 - 13s - loss: 0.4781 - acc: 0.7800 - val_loss: 0.5543 - val_acc: 0.7129
Epoch 4/21
 - 13s - loss: 0.4533 - acc: 0.7859 - val_loss: 0.4948 - val_acc: 0.7593
Epoch 5/21
 - 13s - loss: 0.4379 - acc: 0.7917 - val_loss: 0.4450 - val_acc: 0.7882
Epoch 6/21
 - 13s - loss: 0.4256 - acc: 0.7974 - val_loss: 0.4395 - val_acc: 0.7879
Epoch 7/21
 - 13s - loss: 0.4144 - acc: 0.8040 - val_loss: 0.4301 - val_acc: 0.7968
Epoch 8/21
 - 13s - loss: 0.4058 - acc: 0.8096 - val_loss: 0.4124 - val_acc: 0.8084
Epoch 9/21
 - 13s - loss: 0.3989 - acc: 0.8147 - val_loss: 0.4174 - val_acc: 0.7989
Epoch 10/21
 - 13s - loss: 0.3915 - acc: 0.8190 - val_loss: 0.4320 - val_acc: 0.7903
Epoch 11/21
 - 13s - loss: 0.3836 - acc: 0.8250 - val_loss: 0.3971 - val_acc: 0.8178
Epoch 12/21
 - 13s - loss: 0.3779 - acc: 0.8285 - val_loss: 0.3865 - val_acc: 0.8284
Epoch 13/21
 - 13s - loss: 0.3723 - acc: 0.8331 - val_loss: 0.4151 - val_acc: 0.8027
Epoch 14/21
 - 13s - loss: 0.3643 - acc: 0.8380 - val_loss: 0.3911 - val_acc: 0.8190
Epoch 15/21
 - 13s - loss: 0.3596 - acc: 0.8400 - val_loss: 0.3911 - val_acc: 0.8189

Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.009486832768457897.
Epoch 16/21
 - 13s - loss: 0.3547 - acc: 0.8441 - val_loss: 0.3760 - val_acc: 0.8321
Epoch 17/21
 - 13s - loss: 0.3528 - acc: 0.8473 - val_loss: 0.3732 - val_acc: 0.8345
Epoch 18/21
 - 13s - loss: 0.3500 - acc: 0.8453 - val_loss: 0.3938 - val_acc: 0.8173
Epoch 19/21
 - 13s - loss: 0.3485 - acc: 0.8485 - val_loss: 0.3694 - val_acc: 0.8362
Epoch 20/21
 - 13s - loss: 0.3474 - acc: 0.8494 - val_loss: 0.3629 - val_acc: 0.8426
Epoch 21/21
 - 13s - loss: 0.3443 - acc: 0.8514 - val_loss: 0.3718 - val_acc: 0.8330
Test accuracy:0.820
current auc_score ------------------> 0.940
------------------------ current config for the test -------------------------
Layers:  [2, 2, 2]  Growth_rate:  18  nb_filter:  32  dropout:  0.2
dense_block:  3  reduction:  0.5  bottleneck:  False
Epochs:  21  batch_size:  128  lr:  0.03  optimizer:  adadelta
 es_patience:  4  lr_patience:  3  pooling:  avg
------------------------	  end of configs        -------------------------
pooling:avg
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 2, 96, 96)    0                                            
__________________________________________________________________________________________________
initial_conv2D (Conv2D)         (None, 32, 48, 48)   3136        input_1[0][0]                    
__________________________________________________________________________________________________
initial_bn (BatchNormalization) (None, 32, 48, 48)   128         initial_conv2D[0][0]             
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 32, 48, 48)   0           initial_bn[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 32, 24, 24)   0           activation_1[0][0]               
__________________________________________________________________________________________________
dense_0_0_bn (BatchNormalizatio (None, 32, 24, 24)   128         max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 32, 24, 24)   0           dense_0_0_bn[0][0]               
__________________________________________________________________________________________________
dense_0_0_conv2D (Conv2D)       (None, 18, 24, 24)   5184        activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 18, 24, 24)   0           dense_0_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 50, 24, 24)   0           max_pooling2d_1[0][0]            
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_0_1_bn (BatchNormalizatio (None, 50, 24, 24)   200         concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 50, 24, 24)   0           dense_0_1_bn[0][0]               
__________________________________________________________________________________________________
dense_0_1_conv2D (Conv2D)       (None, 18, 24, 24)   8100        activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 18, 24, 24)   0           dense_0_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 68, 24, 24)   0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
tr_0_bn (BatchNormalization)    (None, 68, 24, 24)   272         concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 68, 24, 24)   0           tr_0_bn[0][0]                    
__________________________________________________________________________________________________
tr_0_conv2D (Conv2D)            (None, 34, 24, 24)   2312        activation_4[0][0]               
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 34, 12, 12)   0           tr_0_conv2D[0][0]                
__________________________________________________________________________________________________
dense_1_0_bn (BatchNormalizatio (None, 34, 12, 12)   136         average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 34, 12, 12)   0           dense_1_0_bn[0][0]               
__________________________________________________________________________________________________
dense_1_0_conv2D (Conv2D)       (None, 18, 12, 12)   5508        activation_5[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 18, 12, 12)   0           dense_1_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 52, 12, 12)   0           average_pooling2d_1[0][0]        
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_1_1_bn (BatchNormalizatio (None, 52, 12, 12)   208         concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 52, 12, 12)   0           dense_1_1_bn[0][0]               
__________________________________________________________________________________________________
dense_1_1_conv2D (Conv2D)       (None, 18, 12, 12)   8424        activation_6[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 18, 12, 12)   0           dense_1_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 70, 12, 12)   0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
tr_1_bn (BatchNormalization)    (None, 70, 12, 12)   280         concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 70, 12, 12)   0           tr_1_bn[0][0]                    
__________________________________________________________________________________________________
tr_1_conv2D (Conv2D)            (None, 35, 12, 12)   2450        activation_7[0][0]               
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 35, 6, 6)     0           tr_1_conv2D[0][0]                
__________________________________________________________________________________________________
dense_2_0_bn (BatchNormalizatio (None, 35, 6, 6)     140         average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 35, 6, 6)     0           dense_2_0_bn[0][0]               
__________________________________________________________________________________________________
dense_2_0_conv2D (Conv2D)       (None, 18, 6, 6)     5670        activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 18, 6, 6)     0           dense_2_0_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 53, 6, 6)     0           average_pooling2d_2[0][0]        
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_2_1_bn (BatchNormalizatio (None, 53, 6, 6)     212         concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 53, 6, 6)     0           dense_2_1_bn[0][0]               
__________________________________________________________________________________________________
dense_2_1_conv2D (Conv2D)       (None, 18, 6, 6)     8586        activation_9[0][0]               
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 18, 6, 6)     0           dense_2_1_conv2D[0][0]           
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 71, 6, 6)     0           concatenate_5[0][0]              
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
final_bn (BatchNormalization)   (None, 71, 6, 6)     284         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 71, 6, 6)     0           final_bn[0][0]                   
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 71)           0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            72          global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 51,430
Trainable params: 50,436
Non-trainable params: 994
__________________________________________________________________________________________________
Finished compiling
Train on 39840 samples, validate on 7968 samples
Epoch 1/21
 - 15s - loss: 0.7082 - acc: 0.5827 - val_loss: 0.6229 - val_acc: 0.6880
Epoch 2/21
 - 14s - loss: 0.5522 - acc: 0.7388 - val_loss: 0.5217 - val_acc: 0.7597
Epoch 3/21
 - 13s - loss: 0.5009 - acc: 0.7706 - val_loss: 0.4934 - val_acc: 0.7636
Epoch 4/21
 - 12s - loss: 0.4715 - acc: 0.7811 - val_loss: 0.4709 - val_acc: 0.7717
Epoch 5/21
 - 13s - loss: 0.4491 - acc: 0.7926 - val_loss: 0.4634 - val_acc: 0.7757
Epoch 6/21
 - 13s - loss: 0.4337 - acc: 0.7983 - val_loss: 0.4378 - val_acc: 0.7889
Epoch 7/21
 - 13s - loss: 0.4189 - acc: 0.8071 - val_loss: 0.4377 - val_acc: 0.7866
Epoch 8/21
 - 13s - loss: 0.4064 - acc: 0.8137 - val_loss: 0.4042 - val_acc: 0.8067
Epoch 9/21
 - 13s - loss: 0.3963 - acc: 0.8190 - val_loss: 0.3938 - val_acc: 0.8184
Epoch 10/21
 - 13s - loss: 0.3869 - acc: 0.8238 - val_loss: 0.3862 - val_acc: 0.8220
Epoch 11/21
 - 13s - loss: 0.3777 - acc: 0.8312 - val_loss: 0.3745 - val_acc: 0.8311
Epoch 12/21
 - 13s - loss: 0.3699 - acc: 0.8358 - val_loss: 0.3780 - val_acc: 0.8298
Epoch 13/21
 - 13s - loss: 0.3614 - acc: 0.8395 - val_loss: 0.3614 - val_acc: 0.8372
Epoch 14/21
 - 13s - loss: 0.3537 - acc: 0.8454 - val_loss: 0.3511 - val_acc: 0.8445
Epoch 15/21
 - 13s - loss: 0.3478 - acc: 0.8480 - val_loss: 0.3595 - val_acc: 0.8391
Epoch 16/21
 - 13s - loss: 0.3410 - acc: 0.8504 - val_loss: 0.3481 - val_acc: 0.8507
Epoch 17/21
 - 14s - loss: 0.3356 - acc: 0.8552 - val_loss: 0.3336 - val_acc: 0.8583
Epoch 18/21
 - 14s - loss: 0.3280 - acc: 0.8615 - val_loss: 0.3266 - val_acc: 0.8631
Epoch 19/21
 - 13s - loss: 0.3249 - acc: 0.8628 - val_loss: 0.3455 - val_acc: 0.8527
Epoch 20/21
 - 13s - loss: 0.3195 - acc: 0.8651 - val_loss: 0.3213 - val_acc: 0.8631
Epoch 21/21
 - 13s - loss: 0.3137 - acc: 0.8698 - val_loss: 0.3132 - val_acc: 0.8672
Test accuracy:0.877
current auc_score ------------------> 0.949
accuracies:  [0.8831989247311828, 0.8201612903225807, 0.8770161290322581]
aucs:  [0.953, 0.9397, 0.9486]
mean and std AUC:  0.947+/-0.006  max:   0.953
(['2-2-2', '18', '3', '32', '0.2', '0.03', '21', 'adadelta', '0.5', 'FALSE', '128', 'avg'], '0.947+/-0.006', 0.953)
869.4907143940218
